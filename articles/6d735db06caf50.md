---
title: "Agentic AIをどう守るか？網羅的脅威モデルと実践的緩和フレームワーク"
emoji: "🗂"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AgenticAI", "ThreatModel", "GenerativeAI"]
published: true
---

以下の Arxiv ドキュメントの翻訳です。
https://arxiv.org/html/2504.19956

:::message
「エージェントの推論パスを乗っ取る」「永続メモリに虚偽を刷り込む」「人間の信頼を悪用して特権昇格」—LangChain/AutoGPTで構築された**自律AIエージェントが直面する新たな攻撃ベクトルは、OWASP Top 10やNIST RMF、MITRE ATLASなど既存のセキュリティフレームワークでは対処できません**。本論文では、AWS Proactive Securityチームが、これらの脅威を「認知アーキテクチャ」「時間的持続性」「信頼境界」など5つのドメインに体系化したATFAAと、ゼロトラスト・マイクロセグメンテーション・ヒューリスティック監視など実装可能な6つの緩和戦略（SHIELD）を提示します。
:::

**著者：**
- Vineeth Sai Narajala (Amazon Web Services, Proactive Security)
- Om Narayan (Amazon Web Services, Proactive Security)

## 要約

生成AI（GenAI）エージェントが企業環境で一般的になるにつれて、従来のシステムとは大きく異なるセキュリティ上の課題が生じています。これらのエージェントは単なるLLMではなく、推論し、記憶し、行動し、しばしば最小限の人間の監視のもとで動作します。本論文では、GenAIエージェント特有の包括的な脅威モデルを紹介し、自律性、永続的メモリアクセス、複雑な推論、ツール統合がどのように新たなリスクを生み出すかに焦点を当てています。

本研究は9つの主要な脅威を特定し、5つの主要ドメインに整理しています：認知アーキテクチャの脆弱性、時間的持続性の脅威、運用実行の脆弱性、信頼境界の侵害、ガバナンス回避です。これらの脅威は単なる理論上のものではなく、遅延悪用可能性、クロスシステム伝播、クロスシステム横方向移動、既存のフレームワークや標準的アプローチでは検出が困難な微妙な目標の不一致など、実践的な課題をもたらします。

これに対処するため、本研究では2つの補完的なフレームワークを提示します：エージェント固有のリスクを整理するATFAA（自律型AIエージェントのための高度脅威フレームワーク）と、企業のエクスポージャーを削減するように設計された実践的な緩和戦略を提案するSHIELDフレームワークです。

本研究は既存のLLMおよびAIセキュリティの研究に基づいていますが、焦点はエージェントを異なるものにしている点、そしてなぜそれらの違いが重要なのかに完全に当てられています。最終的に、本研究はGenAIエージェントがセキュリティのための新しいレンズを必要としていると主張します。エージェントの独自のアーキテクチャと動作を考慮した脅威モデルと防御策を適応させなければ、強力な新しいツールを深刻な企業責任に変えるリスクがあります。

**キーワード：** 生成AI、脅威モデル、AIエージェント、サイバーセキュリティ、攻撃ベクトル、セキュリティフレームワーク

## I. はじめに

生成AI（GenAI）エージェントは、企業技術の新しいカテゴリーとして台頭しています。従来のシステムとは異なり、これらは大規模言語モデル（LLM）と計画機能、永続的メモリアクセス、サードパーティ/内部ツール統合を組み合わせています[1]。これらのエージェントは応答生成に限定されず、システムと積極的に相互作用し、意思決定を行い、多くの場合最小限の人間の監視のもとで企業環境全体で行動します[2]。

この成長する自律性こそが、これらを差別化し、セキュリティの観点から特に困難にしているものです。GenAIエージェントは組織の境界を越え、変異するAPIコールを行い、企業データを操作できます。時には直接的なユーザー入力なしで[3]。これらは動的で、適応的であり、運用ワークフローに深く組み込まれています。

従来のセキュリティ対策は、これらのエージェントがもたらすリスクを完全には対処できない可能性があります。エージェントアーキテクチャ—推論コンポーネント、メモリシステム、言語インターフェイス、外部ツールの融合—は、ほとんどの既存フレームワークが処理するように設計されたものよりもはるかに広範で複雑な攻撃面を導入します[4]。OWASP Top 10 for LLMs [5]、NIST AI Risk Management Framework [2]、MITRE ATLAS [6]、CSA MAESTRO [7]などの価値あるフレームワークは、LLMを孤立したコンポーネントとして扱うか、高レベルのリスクガイダンスを提供する傾向があります。これらは、自律性、長期メモリアクセス、動的ツール使用が組み合わされたときに生じる創発的なセキュリティ特性を考慮していないことが多いのです。

本論文はそのギャップを埋めることを目的としています。GenAIエージェントが提示する独自の脅威に対処するため、自律型AIエージェントのための高度脅威フレームワーク（ATFAA）と、支援的な防御モデルであるSHIELDを紹介します。本研究の貢献には以下が含まれます：

- 自律性、推論、メモリ、ツール使用から生じるセキュリティへの影響に焦点を当てた、GenAIエージェントアーキテクチャの分析
- これらのエージェント機能を標的とする9つの主要脅威の分類法
- 十分に探求されていない悪用技術を含む、関連する攻撃ベクトルの議論
- STRIDEフレームワークへの脅威のマッピングと、カスタマイズされたSHIELD緩和戦略

この分野は急速に進化しており、この脅威モデルは自律エージェントの運用動作に合わせたセキュリティ戦略を開発するための強固な基盤を提供します。専用の制御がなければ、変革的技術になることが約束されているものが、簡単に重大な企業責任になる可能性があります[6]。

# II. 背景

## A. 文献レビュー

GenAIエージェントの採用が加速しているにもかかわらず、セキュリティ研究の状況は比較的断片化されたままです。最近の文献（2023-2025年）のレビューでは、プロンプトインジェクションなどの基本的なリスクは十分にカバーされている一方で、自律性と持続的な動作に関連する深層的なアーキテクチャ上の懸念は見過ごされることが多いことが明らかになりました。

Wangら[8]は、LLMエージェントのセキュリティ問題について有用な概要を提供していますが、その焦点は主にプロンプト操作であり、システム的脆弱性ではありません。Chenら[9]は「AgentPoison」を通じてメモリ破損を探求し、永続的コンテキストが侵害される可能性があることを実証していますが、より広範な企業への影響には踏み込んでいません。

MITRE ATLAS [6]やNIST AI Risk Management Framework [2]などのフレームワークは有用な出発点ですが、古典的な機械学習システムや一般化されたAIリスクに焦点を当てる傾向があります。例えば、ATLASは敵対的MLパターンに大きく傾倒しており、NISTのフレームワークは高レベルの原則を提供しますが、エージェントに特化した詳細な制御が欠けています。

OWASPのTop 10 for LLM Applications [5]は、LLMを活用したツールでの一般的な問題を強調していますが、推論、メモリ、ツール実行の複合的なリスクを深く探求していません。CSAのMAESTRO [7]とOWASPの新しいAgentic Threat Model [10]は、エージェント固有の懸念に対処することに近づいていますが、まだ初期段階であり、統一された緩和ガイダンスが欠けています。

この研究はここにギャップを浮き彫りにしています：ほとんどの既存フレームワークは、GenAIエージェントをLLMを含む従来のアプリとして扱っており、創発的動作を持つ自律的で相互接続されたシステムとしては扱っていません。本論文は、GenAIエージェントのアーキテクチャと運用上の特徴を考慮して特別に設計されたセキュリティモデルを提案します。

## B. GenAIエージェントアーキテクチャ

GenAIエージェントは、自律システムへの重要なマイルストーンを表しています。テキスト生成に限定された一般的なLLMアプリケーションとは異なり、GenAIエージェントは言語モデルと、最小限または削減された人間の監視のもとで推論、計画、行動を可能にする能力を統合しています[3]。その特徴的な特性は、環境との積極的な相互作用—コマンドに応答するだけでなく、複数の組織システムで意思決定を行い、行動を取ることです[1, 3]。

コアアーキテクチャコンポーネントには通常以下が含まれます：

### 計画と推論エンジン
システムの頭脳であり、通常はLLMによって駆動され、エージェントが目標を達成するために必要な手順を決定できるようにします[3]。本研究では、以下のような高度な推論技術を使用する多数の洗練されたエージェントを観察しました：

- **リフレクション：** 後続の行動を導くために、以前の行動と結果を参照します[8]
- **自己批判：** 出力や思考の誤りを特定し修正します[8]
- **思考の連鎖：** 困難な問題を段階的な論理的推論に分解します[8]
- **サブゴール分解：** 高レベルの目標を実行可能なサブタスクに分割します[8]

### メモリシステム
短期（セッション）メモリと長期（永続的）メモリのモジュールで、エージェントが相互作用間のコンテキストを維持できるようにします—これはセキュリティ上重要な影響を持つ機能です[9]。

### アクションとツール呼び出し
セキュリティの観点から最も懸念されるのは、これらのエージェントが関数呼び出しインターフェイス、APIコール、コード実行を通じて、さまざまなファーストパーティおよびサードパーティのSaaSツールを呼び出す能力です。これらの可能性は、単純なデータ取得からワークフロー実行のような高度な運用タスクまで及びます。

### サポートサービス
Retrieval-Augmented Generation（RAG）用のベクトルデータベース、長期メモリ用の永続ストレージ、企業データソースの統合などが含まれます[3]。

LangChain、LangFlow、AutoGen、CrewAIなどのプラットフォームの登場により、自律エージェントの作成がはるかに民主化されましたが、この統合の容易さと迅速なプロトタイピングには、サードパーティモジュールや軽くスクリーニングされたモジュールの使用からのサプライチェーン脆弱性[4]という形で新たなセキュリティ脅威が伴います。

## C. 現在のセキュリティ課題

既存のセキュリティフレームワークをGenAIエージェントに適用すると、いくつかの根本的な制限が明らかになります。これらのエージェントは、推論、記憶、行動の方法において典型的なソフトウェアシステムとは異なります—これらの能力は、今日の標準的なセキュリティアプローチでは完全には対処されていない全く新しいリスク面を導入します。

### 計画とエージェンシーの脆弱性
より特徴的なリスクの1つは、エージェントがどのように計画し、意思決定するかから生じます。従来のセキュリティモデルは、エージェントの推論プロセス自体をほとんど保護しません。プロンプトインジェクションはLLMにとって既知の懸念事項ですが、エージェントは微妙に操作される可能性のあるより複雑な計画ロジックを導入します[8]。攻撃者は、エージェントが言うことを変えるだけでなく、どのように考えるか、目標をどのように分解するか、複数の行動の中からどのように選択するかを変える可能性があります。この推論プロセスは動的で、ロジックベースであり、しばしば不透明であるため、入力やコンテキストの小さな微調整が大幅に異なる結果につながる可能性があります[11]。

### メモリ持続性のリスク
長期メモリ—多くのGenAIエージェントの主要機能—は、別の未探求の攻撃ベクトルを提示します。永続的メモリアクセスにより、エージェントは相互作用間で知識とコンテキストを保持できますが、段階的なポイズニングのリスクも導入されます。従来のステートレスアプリケーションとは異なり、攻撃者はエージェントのメモリに残り、将来の意思決定に影響を与える誤解を招く情報を導入できます[9]。現在のフレームワークは、これらのメモリシステムを保護する方法や、時間の経過とともに侵害されたことを検出する方法について限定的なガイダンスしか提供していません。

### ツール実行境界
GenAIエージェントは、API、データベースクエリ、さらにはコード実行環境などの外部ツールを呼び出すことができます—多くの場合、推測された目標や自然言語入力に基づいて。この能力は強力ですが、ロールベースアクセス制御（RBAC）が通常対処するものを超える特権管理の課題を生み出します[6]。エージェントは意図せずツールを誤用したり、さらに悪いことに、個々には安全に見えるが一緒になって特権をエスカレートしたり保護をバイパスしたりする行動を連鎖させるように操作されたりする可能性があります。このタイプの悪用は、従来の強制メカニズムを使用して発見することが困難です。

### IDと認証の課題
マルチエージェント環境では、IDが流動的になります。エージェントは、ユーザー、他のエージェント、あるいはシステムを代表して行動する可能性があり、帰属と権限に曖昧さが生じます。これにより、スプーフィング攻撃への扉が開かれ、信頼境界が弱まります。ユーザートークンやサービスアカウントのような従来の認証スキームは、エージェントシステムの運用方法、特にエージェントが互いに相互作用したり、動的に権限を継承したりする場合に完全にはマッピングされない可能性があります[12]。

### マルチエージェント相互作用のセキュリティ
システムが相互作用するエージェントのネットワークをますます展開するにつれて、新しい複雑さの層が生じます。エージェントはタスクを調整し、責任を委任し、他のエージェントとコンテキストを共有する可能性があります—エージェント間の信頼、権限、データ検証について困難な質問を提起します[12]。堅牢な通信プロトコルと信頼検証メカニズムがなければ、悪意のあるまたは誤設定されたエージェントは、システム全体に有害な動作を伝播する可能性があります。

これらの課題は、MITRE ATLAS [6]やNIST AI Risk Management Framework [2]などの既存フレームワークがGenAIエージェントに適用された際に不十分な理由を浮き彫りにしています。これらのフレームワークは一般的なAIシステムに対して価値あるガイダンスを提供する一方で、エージェントAIシステムに存在する独自のアーキテクチャ機能と攻撃ベクトルを適切に対処していません。

![](https://ar5iv.labs.arxiv.org/html/2504.19956/assets/figure1.png)

> Figure 1:General architecture of an Agentic system.

# III. 方法論

本脅威モデリングフレームワークは、体系的な文献レビュー、理論的脅威分析、専門家協議、ケーススタディ分析を組み合わせて、自律型AIエージェントシステムのセキュリティリスクを特定し対処するための包括的なフレームワークを作成しています。この多面的なアプローチにより、文書化された脅威と潜在的な脅威の両方を特定しながら、エージェントAIセキュリティのための構造化された分類法を開発することができました。

## A. 体系的文献分析

第1フェーズでは、エージェントAIシステムに直接焦点を当てたセキュリティ研究の徹底的な調査を行いました。本研究は、学術界および業界のセキュリティチームによる現在の研究（2023-2025年）を優先し、一般的なLLMアプリケーションを超えてエージェントアーキテクチャの独自のセキュリティ特性を具体的に扱った論文に焦点を当てました。

主要な情報源には、主要なセキュリティ会議（IEEE S&P、USENIX Security、CCS、NDSS）からの最近の論文、OWASPやCSAなどの組織からの技術レポート、AIリサーチラボが公開したセキュリティアドバイザリが含まれています。この調査に基づき、本研究は基盤となるLLMインフラストラクチャではなく、エージェントコンポーネントを特に標的とする新興脅威クラスを特定しました。

文献レビュープロセスは構造化された方法論に従いました：

### 情報源の特定
学術データベース（IEEE Xplore、ACM Digital Library）、業界出版物（セキュリティベンダーやAIラボからのレポートなど）、セキュリティ会議議事録を使用して、関連する情報源を特定しました。

### 選択基準
論文は、エージェントAIセキュリティへの明示的な焦点（一般的なLLMセキュリティを超えて）、最新性（2023-2025年の出版物を優先）、脅威またはアーキテクチャを説明する技術的深さに基づいて選択されました。

### 体系的コーディング
各情報源は、確立されたセキュリティ概念（STRIDEなど）と新興のAI固有の懸念に基づく標準化されたルーブリックを使用して、脅威の種類、攻撃ベクトル、影響を受けるエージェントコンポーネント（推論、メモリ、ツールなど）、提案された緩和策についてコーディングされました。

このレビューにより、一般的なLLMセキュリティに関する重要な文献があるにもかかわらず、エージェントシステムの独自の脆弱性を特に標的とする研究が断片化されており、まばらであることが明らかになりました[6]。OWASP Foundationが最近発表したAgentic AI Security Initiative [13]は、「計画と適応メカニズム」、「メモリと環境相互作用」、「自律的ツール使用」などの主要な脆弱性領域を概説する、このギャップを埋める最初の組織的な取り組みの1つです。

## B. 理論的脅威モデリングプロセス

文献の基盤に基づいて、本研究は構造化された理論分析プロセスを通じてエージェントAI脅威の概念的フレームワークを開発しました：

### 概念的フレームワークの開発
本論文は、文献レビューとアーキテクチャ分析からの調査結果を統合して、ATFAAの基礎を形成する5つのコアドメインのエージェント脆弱性を特定しました。これらのドメインは、攻撃の影響を受けやすいエージェント動作の異なる側面を表しています。

### ドメイン分類
特定された各脅威（文献または理論分析から引き出された）は、従来のSTRIDE方法論（既存のセキュリティプラクティスとの統合を容易にするため）と、この新しいATFAAドメイン（エージェント固有のリスクを強調するため）の両方に従って体系的に分類されました。

### 攻撃ベクトル分析
各脅威について、本研究は既知のエージェントアーキテクチャ（RAGパイプライン、ReActパターンなど）と能力（計画、ツール使用、メモリアクセス）に基づいて、潜在的な攻撃ベクトルの理論的分析を実施しました。これには、エージェントコンポーネント間の相互作用を標的とする新しい技術を含む、妥当な悪用メカニズムの詳細な技術的記述の開発が含まれました。

この理論的プロセスにより、文書化された脆弱性を超えて、エージェントシステムの独自の能力とアーキテクチャパターンに基づいて新興の脅威を予測することができました。本研究の分類方法論は、以下の脅威を優先しました：

- エージェントシステムに固有であるか、エージェントシステムによって著しく悪化する（一般的なLLMアプリケーションと比較して）
- 重大な企業セキュリティへの影響を提示する（データ流出、不正な行動、システム破壊など）[14]
- 標準的なセキュリティフレームワークにおいて、堅牢で広く採用された緩和戦略が現在欠けている

## C. 専門家協議と検証

理論的フレームワークを検証し改良するため、本研究は一連の構造化された協議を通じて、セキュリティおよびAIの専門家と関わりました：

### 専門家パネルレビュー
予備的なフレームワークと脅威リストは、業界（AIプラットフォームプロバイダーと企業セキュリティチームを含む）からの7人のセキュリティ研究者とAI実践者のパネルによってレビューされ、脅威の分類、攻撃ベクトルの技術的実現可能性、実際の展開への関連性についてフィードバックを提供しました。

### 敵対的思考演習
本研究は、サイバー脅威モデリングからの技術（攻撃ツリーなど）を活用し、MITRE ATT&CKからの概念をAIエージェントコンテキスト[15]に適応させた構造化された敵対的思考方法論を採用して、文献にまだ文書化されていない潜在的な攻撃ベクトルと悪用シナリオをブレインストーミングし改良しました。

この協議プロセスは、脅威モデルを改良し、多様な視点を反映し、純粋に学術的な概念化を超えた実用的なセキュリティ上の懸念に対処することを保証しました。

## D. ケーススタディ分析

理論的フレームワークを実践的なアプリケーションに根ざすため、本研究は複数のドメインにわたって文書化されたセキュリティインシデントを分析し、仮説的なケーススタディを実施しました。

### 実世界のインシデント調査
AIシステムに関わる実世界のインシデントの調査において、本研究は実用的な脆弱性と失敗モードを理解するためにいくつかの文書化されたセキュリティ失敗を分析しました。特に、Microsoft Tayチャットボットインシデント[16]は、敵対的なユーザー入力に対するAIシステムの感受性を強調し、動作の急速な劣化と不適切な出力をもたらしました。同様に、GitHub Copilot [17]のようなシステムを標的としたプロンプトインジェクション攻撃は、攻撃者がAIアシスタントの推論プロセスを操作し、出力の整合性を損なう方法を実証しました。大規模言語モデル（LLM）データポイズニング[9]に関する新興研究は、メモリと知識の汚染の実現可能性をさらに示し、モデルの信頼性と信頼性に対する長期的なリスクを強調しました。

### アーキテクチャ評価
これを補完して、本研究は広く採用されているAIエージェントフレームワークのアーキテクチャ評価を実施し、重要なセキュリティコンポーネントと潜在的な攻撃面を特定しました。これには以下が含まれました：

- **LangChainのエージェント展開パターン：** ReActエージェントやツール呼び出しメカニズムなどの検討[18]
- **AutoGPTアーキテクチャ：** 自律的なタスク実行ループとメモリ管理に焦点を当てた検討[19]
- **MicrosoftのSemantic Kernel：** プランナー、関数呼び出し、メモリコンポーネントの統合の分析[20]

これらの洞察を合わせて、AIエージェントエコシステムにおける現在の脅威とアーキテクチャ脆弱性の包括的なビューを提供します。

## E. 制限と今後の研究

範囲は包括的ですが、本研究方法論には認識すべき制限があります：

### 理論的焦点
フレームワークは、広範な経験的レッドチームによるライブシステムへの攻撃ではなく、主に理論分析、文献レビュー、専門家協議に基づいています。これは、広範な悪用証拠に基づく決定的なセキュリティ評価ではなく、将来の経験的検証の基盤を表しています。

### アーキテクチャの仮定
脅威モデルは、特定の一般的なアーキテクチャパターン（LLMベースの推論、個別のメモリモジュール、APIベースのツール使用など）を想定しています。高度に新規または非標準のエージェント実装に固有の脅威を完全にはキャプチャしない可能性があります。

### 進化する状況
エージェントAIの分野は急速に進化しています。新しいエージェント能力、アーキテクチャ、フレームワークが間違いなく登場し、この現在のフレームワークで特定されたものを超えた脆弱性を潜在的に導入します。

本研究は、継続的な研究プログラムの最初のステップとして位置づけられており、さらなる探求を必要とするいくつかの重要な領域があります：

### 経験的検証
将来の研究には、異なるフレームワークと展開コンテキストにわたる実世界のエージェント実装に対して特定された脅威の厳密なレッドチーム評価を含めて、それらの技術的実現可能性、影響、提案された緩和策の有効性を検証する必要があります。

### 定量的リスク評価
エージェント脅威によってもたらされるリスクを定量化するためのメトリクスと方法論の開発は、効果的な優先順位付けとリソース配分に不可欠です。これには、ベイジアンリスクモデルの探求、推論パス偏差または目標遵守のメトリクスの開発、または既存のサイバーリスクスコアリングフレームワークの適応が含まれる可能性があります。

### セキュリティバイデザインパターン
これらの脅威に本質的に抵抗するアーキテクチャパターンと開発プラクティスへの研究は、安全なエージェント開発のための貴重なガイダンスを提供します。これには、「最小エージェンシーの原則」のようなパターンの調査、「検証可能な推論ステップ」のための技術の開発、またはより堅牢なメモリ区画化アプローチの設計が含まれる可能性があります。

これらの制限にもかかわらず、本研究は、GenAIエージェント脅威の状況についての体系的な理解が、効果的なセキュリティ制御を開発するための貴重な基盤を提供すると信じています。このような措置がなければ、企業環境で最も変革的な技術の1つになり得るものが、代わりにその最も重大な脆弱性の1つになる可能性があります。

# IV. GenAIエージェントの脅威モデル

GenAIエージェントのセキュリティには、その独自の脅威プロファイルについての微妙な理解が必要です。これらのシステムは、従来のアプリケーションや一般的なLLM展開といくつかの脆弱性を共有していますが、アーキテクチャ要素—特に推論、メモリ、行動間の相互作用—によって区別され、特別な注意を必要とする新しい攻撃ベクトルを導入します[4]。文献、アーキテクチャ分析、理論的モデリングから導出された潜在的な悪用シナリオの包括的な検討に基づいて、本研究はGenAIエージェント展開を特に標的とする複数のドメインにわたる主要なリスクを特定しました。これらの脅威は、従来のSTRIDEモデル（なりすまし、改ざん、否認、情報漏洩、サービス拒否、特権昇格）と、新興のエージェント脅威に特化した分類を提供するこの新しい自律型AIエージェントのための高度脅威フレームワーク（ATFAA）の両方にマッピングされています。

## A. 自律型AIエージェントのための高度脅威フレームワーク（ATFAA）

ATFAAフレームワークは、自律型AIシステム向けに特別に設計された脅威モデリングにおける重要な進化を表しています。主に境界防御またはアプリケーションレベルの脆弱性に焦点を当てた従来のセキュリティモデルとは異なり、ATFAAは推論し、学習し、記憶し、行動し、組織の境界を越えて潜在的に進化するAIエージェントの独自の性質に対処します。

### 1) コア原則

ATFAAは、セキュリティ分析と緩和戦略を導く4つの基本原則に基づいて構築されています：

#### 認知セキュリティ
操作や意図しない影響からエージェントの推論、計画、学習プロセスの完全性と機密性を保護します。

#### 実行の完全性
エージェントの運用機能を保護し、行動とツール呼び出しが意図された目標と認可に合致することを保証し、不正な操作を防ぎます。

#### アイデンティティの一貫性
エージェントアイデンティティ、ユーザーアイデンティティ、システムアイデンティティ間の明確で検証可能で明確な境界を維持し、なりすましを防ぎ、適切な認可コンテキストを保証します。

#### ガバナンスのスケーラビリティ
システムが複雑さ、規模、運用速度において進化するにつれて、継続的な監視、監督、制御メカニズムが効果的で、監査可能で、適応可能であることを保証します。

### 2) 脅威分類法（9つの脅威）

ATFAAは現在、新興の研究やOWASP Agentic AI Threat Model [10]やCSA MAESTRO [7]などのイニシアチブからの概念を引き出して統合し、9つの主要脅威を特定しています。これらの脅威は、自律型AIシステムの包括的な攻撃面を集合的に表す5つのドメインに整理されています。

#### リスク評価基準の説明

各脅威について、本研究は企業GenAIエージェント展開のコンテキストを考慮した、以下の一般的な基準に基づく定性的リスク評価を提供します：

**可能性：** 脅威が発生する確率または容易さの推定。
- **高：** 一般的な弱点を悪用、最小限のアクセス/知識が必要、潜在的に自動化可能
- **中：** 特定のアーキテクチャ知識、持続的なアクセス、連鎖的悪用、または特定の条件が必要
- **低：** まれな条件、高度な専門知識、重要なリソース、または非公開の脆弱性が必要

**影響：** 脅威が実現した場合の潜在的な負の結果。
- **クリティカル：** コア機能、セキュリティ目標、広範なシステム整合性の根本的な侵害、重大な財務/評判損失
- **深刻：** 機能の重大な障害、重大なデータ侵害/損失、不正な高特権アクセス、重大な運用中断
- **中：** パフォーマンスの顕著な劣化、軽微なデータ露出、限定的な不正アクセス、中程度の運用問題

**検出難易度：** 典型的なセキュリティ監視を使用して攻撃が発生しているか、発生したかを検出することがどれほど困難かの推定。
- **極度：** 特殊な深い分析やフォレンジックなしでは通常の動作/学習と区別がつかない
- **高：** 特殊なAI固有のツール/分析が必要、しばしば大幅に遅延した検出
- **中：** 一般的な異常検出をトリガーする可能性があるが、確認するには特定の調査が必要
- **低：** 標準的な監視ツール、ログ、またはセキュリティ制御によって検出される可能性が高い

### 3) ドメイン1：認知アーキテクチャの脆弱性

#### T1: 推論パス乗っ取り（改ざん）

**説明：** 攻撃者は、AIエージェントが意思決定に使用する論理経路を操作し、明らかな論理的一貫性を維持しながら、結論を悪意のある結果に向けてリダイレクトします。

**ベクトル：** 特別に作成された矛盾、微妙なバイアス、または誤解を招く情報をエージェントのコンテキストまたは推論プロセス（間接的なプロンプト操作、汚染されたRAGデータなどを通じて）に注入することにより、攻撃者は表面的な妥当性を維持しながら不正な結果に向かう分岐論理経路を作成できます。これはしばしば現代のLLMにおける思考の連鎖または段階的推論メカニズムを悪用し、「論理分岐点」と呼ばれるもの—明白なエラーフラグなしでエージェントの推論が微妙にリダイレクトされる重要なジャンクション—を作成します。

**リスク：** 可能性：高；影響：クリティカル；検出：深刻

**例：** 攻撃者は、矛盾する財務評価基準をドキュメント処理エージェントの入力データに導入し、コンプライアンス要件に違反するトランザクションを承認させながら、内部的に一貫して見え、表面的なリスク制御を満たす正当化を生成させる可能性があります[8]。

#### T2: 目的関数の破損とドリフト（改ざん）

**説明：** エージェントのコア目標または報酬メカニズムを変更し、その目的を潜在的に秘密裏に変更します。これには、長期間にわたる目標または運用優先順位の段階的なシフト（目的ドリフト）が含まれ、セッション間で段階的に発生するため、検出されないままです。

**ベクトル：** 目標定義、自己改善、または強化学習メカニズムを悪用します。これは、操作されたフィードバック、汚染された報酬モデル、直接的な目標変更、または複数のセッションにわたって一貫して微妙な選好バイアスを導入すること（操作されたユーザーフィードバック、わずかにオフゴールの動作に報酬を与える段階的な相互作用などを介して）によって発生する可能性があります。このような行動は、突然の変更検出アラームをトリガーすることなく、意図された目標または安全制約からエージェントの優先順位を段階的にシフトさせる「目標ドリフトベクトル」を作成できます[5]。

**リスク：** 可能性：中；影響：クリティカル；検出：高

**例：** セキュリティエージェントのフィードバックを操作すると、検証よりも速度を優先するように訓練される可能性があります[8]。時間の経過とともに、セッション間で速度に報酬を与える操作された信号への反復的な露出を通じて、エージェントは疑わしいアクセスパターンをセキュリティ脅威ではなく許容可能な「効率最適化」として分類し始める可能性があります。

### 4) ドメイン2：時間的持続性の脅威

#### T3: 知識、メモリポイズニング、信念ループ（改ざん/情報漏洩）

**説明：** エージェントの知識ベース（RAGデータベースなど）または永続的メモリを、将来の意思決定に影響を与える虚偽または歪曲された情報で侵害します。これは、メモリに保存された操作された信念が後で証拠として取得され、元の虚偽を強化する自己検証サイクル（信念強化ループ）につながる可能性があります。

**ベクトル：** 永続的なデータストア（ベクトルデータベースのポイズニングなど[5]）またはメモリ転送メカニズムを標的にします。埋め込まれた誤情報は持続し、エージェントの理解を歪めます。これは、エージェントが自分自身の過去の結論やメモリを信頼する傾向を悪用します；操作されたデータは、一度生成され保存されると、再参照され、虚偽の情報が定着し、修正に抵抗するループを作成できます[5]。

**リスク：** 可能性：高；影響：深刻（ループが増幅する場合は潜在的にクリティカル）；検出：極度

**例：** 知識ベースに虚偽のセキュリティプロトコル例外を植え付けると、エージェントが不正なアクセスを誤分類する可能性があります[9]。エージェントがこの誤分類をログに記録し、後で自分自身のログを証拠として参照すると、不正確な信念を強化します。

### 5) ドメイン3：運用実行の脆弱性

#### T4: 不正な行動実行（特権昇格）

**説明：** 攻撃者は、意図された権限または運用境界に違反する方法でエージェントを操作して行動を実行したり、ツールを使用したりします。これには、個別には良性の操作のシーケンスを編成して、組み合わせると不正な結果を生成する、または不正確な定義や入力処理を介してエージェントに意図された範囲外の操作を強制することが含まれます。

**ベクトル：** 推論と行動の間のインターフェースを悪用します。これには、個別にセキュリティ境界を尊重するが、集合的に制御をバイパスする複数の操作を連鎖させることによって「認可境界移行」を標的にすることが含まれる場合があります（1つの許可された関数からの出力を別の不正な入力として使用するなど）。あるいは、予期しないツール間の相互作用を活用したり、「関数パラメータインジェクション」（一見良性のデータパラメータ内に悪意のあるコマンドを埋め込む）などの技術を使用したり、過度に広範なツール権限を悪用したりすることによって、「能力境界制御」の曖昧さを悪用することができます[5]。

**リスク：** 可能性：高；影響：クリティカル；検出：高

**例：** 攻撃者は、許可されたデータ取得関数を不十分にサンドボックス化されたコード実行ツールと連鎖させて、機密データを流出させます。あるいは、ドキュメント分類用に設計されたAIエージェントが、ドキュメントメタデータにクエリ言語を埋め込むことによってデータベースクエリを実行するように操作され、ツールインターフェイスでの弱い入力検証を悪用します。

#### T5: 計算リソース操作（サービス拒否）

**説明：** 攻撃者は、リソース割り当てメカニズムを悪用するように設計された入力または相互作用を作成し、計算リソース（CPU、メモリ、GPU、APIクォータ）の過剰な消費を引き起こして、パフォーマンスを劣化させ、サービス拒否状態を作成し、またはセキュリティを損なう運用ショートカットを強制します。

**ベクトル：** これは「リソース割り当て決定ポイント」と呼ばれるもの—エージェントタスク全体に計算リソースを分配する内部メカニズム—を標的にします。不均衡にリソース集約的な処理をトリガーする特別に作成された入力（深くネストされた推論チェーン、大規模なRAG取得を必要とするリクエスト、複雑なツール相互作用など）を生成することにより、攻撃者は他の重要な機能を飢餓状態にしたり、運用コストを増加させたり、エージェントを劣化した、潜在的により安全でない運用モードに強制したりできる「計算ボトルネック」を作成します。

**リスク：** 可能性：高；影響：中；検出：低

### 6) ドメイン4：信頼境界の侵害

#### T6: アイデンティティスプーフィングと信頼悪用（なりすまし）

**説明：** 攻撃者は、エージェント、ユーザー、またはエージェント間アイデンティティに関連する不十分な境界または検証メカニズムを悪用して、偽造された認可コンテキストの下で不正な操作を実行したり、マルチエージェントシステム内で悪意のある指示を伝播したりします。

**ベクトル：** アイデンティティ管理における曖昧さまたは弱点を悪用します。これには、エージェントの行動が人間のアイデンティティに帰属される「アイデンティティ遷移ゾーン」を標的にすること（エージェントの行動が不適切にユーザー権限を継承する「アイデンティティ継承脆弱性」を悪用するなど）が含まれます。また、「エージェント間信頼フレームワーク」を標的にして、「信頼証明チャネル」を侵害すること（APIキーの盗難、認証トークンの操作、プロトコルの弱点の悪用など）によって、信頼されたエージェントアイデンティティを引き受けたり、エージェントエコシステム内の信頼検証プロセスを操作したりすることも含まれます。

**リスク：** 可能性：高；影響：クリティカル；検出：高

#### T7: 人間-エージェント信頼操作（なりすまし）

**説明：** 攻撃者は、AI推奨または出力を信頼する自然な人間の傾向を悪用して、ユーザーを誘導して不正な行動を実行させたり、機密情報を漏洩させたり、欺瞞的なAIガイダンスに基づいてセキュリティ制御をオーバーライドさせたりします。

**ベクトル：** これは「人間-AI信頼インターフェース」と呼ばれるもの—人間がAI出力を評価し、それに基づいて行動する方法に影響を与える心理的およびユーザビリティの側面—を悪用します。AI応答を「信頼増幅信号」（高い確実性を装う、虚偽の権威を参照する、信頼されたコミュニケーションスタイルを模倣する、即座の行動を促す社会工学的プロンプトを生成するなど）を含むように操作することにより、攻撃者はユーザーがエージェントの欺瞞的なガイダンスに基づいて有害な行動を取る可能性を高め、人間の相互作用を通じて技術的制御を効果的にバイパスします。

**リスク：** 可能性：非常に高；影響：深刻；検出：極度

![](https://arxiv.org/html/2504.19956v2/extracted/6407754/TM_figure2.png)

> Figure 2:Agentic System Threats, Trust Boundary, Assets.

### 7) ドメイン5：ガバナンス回避

#### T8: 監視飽和攻撃（サービス拒否）

**説明：** 攻撃者は意図的に、低重要度の監査イベント、アラート、または人間のレビューを必要とする行動の過剰な量を生成し、ガバナンスメカニズム（人間のレビューキュー、自動監視システム）を圧倒し、監視または応答能力を超えます。

**ベクトル：** これは「ガバナンス注意経済学」と呼ばれるもの—監視に利用可能な有限の人的および計算リソース—を悪用します。低重要度のアラート、分析を必要とする複雑なログ、または必須のレビューのためにフラグが立てられた行動（「注意消費イベント」）の大量を生成することにより、攻撃者は、ノイズの中で真に悪意のある行動が見逃されたり、リソースの枯渇またはアラート疲労により監視システムが効果を失ったりする「監視盲点」を作成します。

**リスク：** 可能性：高；影響：深刻；検出：中

#### T9: ガバナンス回避と難読化（否認）

**説明：** 攻撃者は、複雑なエージェント相互作用またはロギングメカニズムの曖昧さを悪用して、責任の追跡を不明瞭にし、フォレンジック分析を妨げ、帰属を防ぎます。さらに、攻撃者は、適応的なセキュリティ制御または確立された検出閾値を回避するために特別に進化したり、ステルスで動作したりする攻撃を設計する可能性があります。

**ベクトル：** 監査可能性と検出を標的にします。これには、攻撃のコンポーネントを複数のエージェントに分散させたり、一時的なアイデンティティを使用したり、（可能であれば）ログを操作したり、複雑で十分にログに記録されていない相互作用を活用して「帰属ギャップ」を作成したりすることにより、「責任帰属接合点」を標的にすることが含まれます。また、閾値以下で一貫して動作（「低速かつ低レベル」攻撃）したり、相関エンジンのトリガーを回避するために攻撃パターンを戦略的に交互に変えたり、観察された防御に対応して動作を適応させて「適応的防御メカニズム」をバイパスしたりすることにより、「検出閾値メカニズム」を悪用することも含まれます。

**リスク：** 可能性：中；影響：深刻；検出：極度

## B. SHIELD緩和フレームワーク

SHIELDは、ATFAA脅威に対する6つの防御戦略を提供します。実装には、保護、パフォーマンス、ユーザビリティ、コストの間のトレードオフが伴います。

### SHIELDの実装：課題と考慮事項

SHIELD戦略は、エージェント脅威を緩和するための道筋を提供しますが、組織はエージェントAIエコシステムを扱う際に実用的な課題を予期すべきです。ヒューリスティック監視は計算集約的で、システムパフォーマンスに潜在的に影響を与え、誤検出を最小化するために洗練されたベースライン化と調整が必要です。真のロギング不変性の実現には、暗号的に保護された追加専用ログや厳格なアクセス制御などの堅牢なソリューションを必要とする複雑さと潜在的なコストが伴います。エージェント行動の頻繁な再認証や多要素検証など、厳格で敏感なエスカレーション制御メカニズムは、エンドユーザーのユーザビリティの摩擦や運用オーバーヘッドを導入する可能性があります。さらに、エージェントが多様なリソースへの柔軟なアクセスを必要とする動的環境では、効果的なセグメンテーション境界を定義し維持することは困難です。これらの課題はフレームワークを無効にするものではありませんが、組織のセキュリティ態勢とリスク許容度のコンテキスト内で特定のリスク評価に基づいて緩和策を優先する、リスクベースのアプローチの必要性を浮き彫りにしています。

### 1) セグメンテーション

**説明：** ワークロードレベルでエージェント能力、データソース、実行環境間に厳格な境界を実装し、ゼロトラスト原則に基づいて侵害されたコンポーネントの潜在的な影響を制限します。

**技術的実装：**
- **ワークロードレベルの分離：** 広範なネットワークセグメントではなく、個々のエージェントコンポーネント、アプリケーション、またはサービスの周りにセキュリティ境界を定義します。
- **ポリシー強制：** エージェントベースのマイクロセグメンテーションツール（Illumio、Guardicore/Akamai、Palo Alto Networksエージェントなど）またはネイティブクラウド制御（AWS Security Groups、Azure NSGs/Firewall、Google Cloud Firewallなど）を使用して、アイデンティティとコンテキストに基づいた詳細なポリシーを強制します。
- **トラフィックマッピングとポリシー定義：** 強制前にエージェント通信フローと依存関係をマッピングします。監視モードでより広範なポリシーから始め、最小権限の原則に基づいてルールを段階的に改良します。
- **コンテナセキュリティ：** コンテナ化されたエージェントコンポーネント間のトラフィックを制御するために、特定のコンテナ分離技術（Dockerネットワークセグメンテーション、Kubernetes Network Policies、Istio/Linkerdなどのサービスメッシュの使用など）を実装します。
- **APIゲートウェイ制御：** エージェントツールと関数へのアクセスを制御するために、ディープパケット検査、スキーマ検証、レート制限を備えたAPIゲートウェイを使用します。
- **監査：** 自動化ツールを使用してポリシー強制を検証し、潜在的な誤設定を特定するために、定期的なマイクロセグメンテーション監査を実施します。

**緩和する脅威：** T4（不正な行動実行）、T5（計算リソース操作）、T6（アイデンティティスプーフィング - エージェント/人間部分）

### 2) ヒューリスティック監視

**説明：** エージェントの推論パターン、意思決定プロセス、動作出力、リソース消費の偏差を特定するために特別に設計された異常検出とアラートシステムを展開し、シグネチャベースの検出を超えます。

**技術的実装：**
- **動作ベースライン化：** 通常のエージェント動作の動的ベースライン（典型的な推論ステップ、ツール使用シーケンス、APIコール頻度、リソース使用率など）を確立します。
- **AI/MLモデル：** これらのベースラインからの偏差を検出するために調整された統計的手法（Z-score、IQRなど）、機械学習アルゴリズム（Isolation Forest、Local Outlier Factor（LOF）、One-Class SVMなど）、またはディープラーニングモデル（オートエンコーダ、シーケンシャル分析用LSTMなど）を実装します。クラウドMLプラットフォーム（SageMaker、Vertex AIなど）または特殊なライブラリ（TensorFlow Probabilityなど）を活用します。
- **コンテキストログ分析：** AI/ML分析機能で強化されたSIEM/SOARプラットフォーム（Splunk、Datadog、Exabeamなど）とエージェントログ（推論トレース、信頼スコア、ツール入力/出力を含む）を統合し、コンテキスト異常検出を行います。
- **データ品質と前処理：** 堅牢な前処理（欠損値の処理、正規化）と関連する特徴エンジニアリングを通じて、監視モデルのための高品質な入力データを保証します。
- **継続的な調整とフィードバック：** 新しいデータでモデルを定期的に再トレーニングし、アナリストがフラグ付けされた異常を検証するフィードバックループを組み込んで、時間の経過とともに精度を向上させ、誤検出を削減します。

**緩和する脅威：** T1（推論パス乗っ取り）、T2（目的関数の破損とドリフト）、T9（ガバナンス回避 - 適応部分）

### 3) 完全性検証

**説明：** 不正な変更や改ざんを検出するために、重要なエージェントコンポーネント（コード、モデル）、データ、メモリ、目標、運用パラメータに対して暗号検証とランタイムチェックを実装します。

**技術的実装：**
- **コードとモデルのハッシング/署名：** 実行前およびランタイム中に定期的に、エージェントコードとMLモデルの暗号ハッシュ（SHA-256など）またはデジタル署名を計算し検証します。
- **ランタイム完全性監視：** Runtime Application Self-Protection（RASP）の概念、または予期しない変更や動作を監視するために設定されたホストベースの侵入検知システム（HIDS）を展開します。
- **メモリ安全性とサンドボックス化：** 実行可能な場合はメモリ安全な言語（Rustなど）を利用するか、WebAssembly（Wasm）サンドボックスなどの安全な実行環境を使用してエージェントコンポーネントを分離し、メモリ破損やランタイム改ざんを防ぎます。
- **データとメモリの完全性チェック：** 永続的なメモリデータストアと重要な設定パラメータに対して、自動検証ワークフローを伴う暗号的完全性証明（HMAC、Merkle Treesなど）を使用します。
- **暗号的証明：** ハードウェアベース（TPMなど）またはソフトウェアベースの証明技術を使用して、エージェントの実行環境と重要なソフトウェアコンポーネントの完全性を検証します。

**緩和する脅威：** T3（知識/メモリポイズニング、信念ループ）、T6（アイデンティティスプーフィング - エージェント間信頼部分）

### 4) エスカレーション制御

**説明：** リアルタイムコンテキストに基づいて、必須の検証、最小権限の割り当て（最小権限の原則）、特権遷移または能力拡張の厳格なチェックを伴う詳細で動的な権限フレームワークを確立します。

**技術的実装：**
- **属性ベースアクセス制御（ABAC）：** ユーザー/エージェント、リソース、行動、環境の豊富な属性に基づいてアクセス決定を行うポリシーエンジン（Open Policy Agent - OPA with Regoなど）を実装します。
- **コードとしてのポリシー：** 認可ポリシーを、CI/CDパイプラインと統合された、管理可能で監査可能でバージョン管理されたコード形式で定義します。
- **コンテキスト認識認証：** 各機密操作またはツール呼び出しについて、行動バイオメトリクスや異常検出に基づく継続的認証方法を潜在的に使用して、アイデンティティと認可コンテキストを検証します。
- **ジャストインタイム（JIT）アクセス：** 昇格された権限が必要な期間のみ付与され、自動的に取り消される自動JIT権限割り当てシステム（HashiCorp Vault、セッションポリシーなどのクラウドIAM機能を使用）を実装します。
- **定期的なレビューと自動化：** 自動化されたコンプライアンスチェックとフィードバックループを活用して、権限とABACルールを定期的に監査し、ポリシーを改良します。

**緩和する脅威：** T4（不正な行動実行）、T6（アイデンティティスプーフィングと信頼悪用）

### 5) ロギング不変性

**説明：** すべての重要なエージェント決定、行動、データアクセス、ツール呼び出し、エージェント間通信について、改ざん耐性があり、包括的で検証可能な監査証跡を作成します。

**技術的実装：**
- **改ざん耐性ストレージ：** 最高レベルの不変性保証を必要とする重要なログについては、write-once, read-many（WORM）ストレージ、暗号的に保護された追加専用データベースを利用します。
- **暗号署名とタイムスタンプ：** ログが生成時に暗号的に署名され（HMACやデジタル署名を使用）、安全で検証可能なタイムスタンプ（信頼されたタイムスタンプ機関やGuardtime KSIなどのブロックチェーンアンカリングを介して）を含むことを保証します。
- **セキュアなログ集約：** ソースまたは転送中の改ざんを防ぐために、セキュアなログ転送プロトコル（TLS暗号化されたsyslog-ngやFluentdなど）を実装して、ログを別の堅牢化されたログリポジトリまたはSIEMシステムに送信します。
- **ログ完全性監視：** 自動化されたツールとワークフローを使用してログチェーンまたは署名の暗号的完全性を定期的に検証します（ハッシュチェーンのチェック、信頼されたキーに対する署名の検証など）。検出された改ざんのアラートをSIEM/SOARと統合します。
- **包括的なコンテンツ：** 機密コンテンツやPIIをログに記録せずに、推論トレース（実行可能な場合）、入力プロンプト/データ、パラメータを伴うツール呼び出し、出力/応答、信頼スコア、アイデンティティ/帰属情報を含む十分なコンテキストをログがキャプチャすることを保証します。
- **ログを、エージェントがアクセスする最高レベルのデータ分類と同じレベルで扱います。** 例えば、HIPAAデータアクセスを持つエージェントから生成されたログは、HIPAAログとして扱う必要があります。

**緩和する脅威：** T9（ガバナンス回避と難読化）

### 6) 分散監視

**説明：** 単一点のガバナンス失敗、バイパス、または共謀を防ぐために、複数の独立したシステム、特殊なエージェント、または人間のレビュアーにわたって監視、検証、承認の責任を分散します。

**技術的実装：**
- **マルチパーティ検証：** マルチシグネチャスキーム、クォーラムベースの承認、または複数の独立したエンティティ（人間または機械）からの検証を必要とするコンセンサスプロトコルを使用して、重要な行動または設定変更のための分散レビューメカニズムを実装します。
- **特殊な監査エージェント：** 事前定義されたポリシーまたは倫理ガイドラインに対して運用エージェントの動作、決定、コンプライアンスを監視するために特別に設計された独立したAIエージェントを展開します。
- **連合監視：** 関連する監視データとダッシュボードへのロールベースのアクセスを持つ多様なステークホルダー（セキュリティチーム、コンプライアンス担当者、ビジネスユニットオーナー、潜在的には外部監査人など）を含む監視構造を確立します。
- **説明可能なAI（XAI）統合：** XAI技術を活用して、エージェントの意思決定プロセスを人間のレビュアーにとってより透明で監査可能にします。
- **適応的ガバナンス：** ヒューリスティック監視（セクション4.2.2）から導出されたリアルタイムリスク評価、または実行されているタスクの感度に基づいて動的に調整される適応的なレビュー閾値または介入トリガーを実装します。
- **独立した監査：** 分散監視メカニズムの有効性を検証するために、定期的な外部監査と敵対的テスト（レッドチーム）を実施します。

**緩和する脅威：** T7（人間-エージェント信頼操作）、T8（監視飽和攻撃）

## C. 脅威モデル概要

以下の表は、分析で特定された9つの脅威の統合ビューを提供し、STRIDEとATFAAフレームワークの両方にマッピングされ、主要なSHIELD緩和戦略と共に示されています。

**表I: 脅威モデル概要：9つの脅威のSTRIDE、ATFAA、SHIELDへのマッピング**

| 脅威ID | 脅威名 | STRIDEカテゴリ | ATFAAドメイン | 主要なSHIELD緩和策 |
|--------|--------|----------------|---------------|-------------------|
| T1 | 推論パス乗っ取り | 改ざん | 認知アーキテクチャ | ヒューリスティック監視 |
| T2 | 目的関数の破損とドリフト | 改ざん | 認知アーキテクチャ | ヒューリスティック監視 |
| T3 | 知識、メモリポイズニング、信念ループ | 改ざん/情報漏洩 | 時間的持続性 | 完全性検証 |
| T4 | 不正な行動実行 | 特権昇格 | 運用実行 | セグメンテーション、エスカレーション制御 |
| T5 | 計算リソース操作 | サービス拒否 | 運用実行 | セグメンテーション |
| T6 | アイデンティティスプーフィングと信頼悪用 | なりすまし | 信頼境界 | エスカレーション制御、セグメンテーション、完全性検証 |
| T7 | 人間-エージェント信頼操作 | なりすまし | 信頼境界 | 分散監視 |
| T8 | 監視飽和攻撃 | サービス拒否 | ガバナンス回避 | 分散監視 |
| T9 | ガバナンス回避と難読化 | 否認 | ガバナンス回避 | ロギング不変性、ヒューリスティック監視 |

## D. 攻撃面の拡大

本研究の最も重要な発見の1つは、GenAIエージェントが従来のソフトウェアや単純なAIモデルと比較して、従来の攻撃面をどれほど劇的に拡大するかということです[4]：

### 認知次元
エージェントシステムの推論、計画、学習能力は、固定ロジックを持つ従来のシステムに直接的な類似物を持たない意思決定プロセスを標的とする全く新しい攻撃ベクトルを作成します[8]。

### 時間的次元
永続的なメモリを持つ長期実行エージェントは、長期間検出されないままである可能性がある段階的な破損、ポイズニング、または目的ドリフトの機会を作成し、ステートレスアプリケーションには存在しない時間ベースの攻撃面を導入します[9]。

### ツール統合とアクション空間
外部ツール、API、潜在的にコードを実行する能力は、侵害の潜在的な影響を大幅に拡大し、エージェントが複数のシステムと相互作用し影響を与えることを可能にし、保護が困難な複雑なアクションチェーンを作成します。

### 信頼境界
従来のシステム境界を越えて動作し、ユーザーと相互作用し（T7）、潜在的に他のエージェントと協力するエージェントは、従来のアプリケーションには存在しない新しいパストラバーサルリスクと複雑な信頼管理課題を作成します[12]。

### アイデンティティの流動性
エージェントアイデンティティとそれが代表して動作するユーザーアイデンティティの間のしばしば曖昧な境界線は、従来の認証と認可モデルに挑戦する新しいなりすましと特権昇格の機会を作成します（T6）[12]。

### ガバナンスの複雑性
エージェント動作の規模、速度、自律性は、効果的な監視、監査、監視のための前例のない課題を作成し、ガバナンスレベルの脆弱性を導入します[6, 12]。

セキュリティチームは、従来の防御境界を根本的に再考し、これらすべての次元にわたるエージェントシステムの独自の特性のために特別に設計された監視と制御メカニズムを開発する必要があります[4]。英国政府からの最近の予測は、「2025年までに、生成AIは完全に新しいリスクを作成するよりも既存のリスクを増幅する可能性が高いが、いくつかの脅威の速度と規模を急激に増加させる」と強調しています[21]。これは、これらのシステムの独自の特性に対処するエージェント固有のセキュリティ制御を開発する緊急性を強化しています。

# V. 脅威モデル分析と影響

## A. GenAIエージェント脅威の独自の特性と広範な影響

ATFAAで概説された脅威は、典型的なサイバーセキュリティリスクとは区別される特性を持っています[4]：

### 遅延効果
多くのエージェント脅威、特にメモリと学習を標的とするもの（T3、T2）は、即座には顕在化せず、潜在的な脆弱性を導入します。初期の侵害（メモリポイズニングなど）は、将来の行動に数日、数週間、または数ヶ月後にのみ影響を与える可能性があり、従来のフォレンジック手法を使用してインシデントをルート原因までトレースすることが極めて困難になります[9]。この時間的複雑さは、標準的なインシデント対応プレイブックに挑戦します。

### 目標不一致の拡大
エージェントの自律性は、小さな誘発された目標の不一致（T2）が時間の経過とともに複合される可能性があることを意味します[8]。

### クロスシステム伝播
複数のシステムと相互作用するエージェントは、侵害伝播のベクトルを作成します[12]。ツールアクセス（T4）または信頼（T6）の悪用により、侵害が急速に拡散する可能性があります。

### 検出の課題
エージェント推論の変動性と不透明性により、悪意のある操作（T1、T3）を通常の動作と区別することが標準的な方法では困難になります[3]。より特殊な監視が必要です。

### 信頼の悪用
人間の信頼（T7）またはエージェント間の信頼（T6）を標的とする脅威は、心理的または関係的要因を操作することによって技術的制御をバイパスします。

### 脅威の相互作用
これらの脅威は相互作用する可能性があります。メモリポイズニング（T3）が目的ドリフト（現在はT2の一部）または不正な行動（T4）を促進する可能性があります。アイデンティティスプーフィング（T6）が不正な行動（T4）を可能にする可能性があります。これは、全体的な緩和策が必要であることを示唆しています。

### セクター固有の影響
結果はコンテキストによって異なります。金融は詐欺リスク（T2、T4）に直面します。医療は患者の転帰またはプライバシーへのリスク（T7、T3）に直面します。重要インフラは潜在的な運動学的影響に直面します。

### 規制とコンプライアンスの課題
エージェントの自律性と不透明性は、既存の規制（GDPRなど）に挑戦します。コンプライアンスの実証、責任の割り当て（T9）、公平性の保証（T3）、説明の提供がより困難になります。

これらの特性と影響は、技術的、運用的、ガバナンス次元にわたってエージェントAIシステムの独自の性質に対処する、SHIELDフレームワークで提案されたものなどの特殊なセキュリティ対策の緊急の必要性を強調しています[6, 12]。

---

# VI. 結論と今後の研究

本論文は、GenAIエージェントのためのATFAA脅威モデルとSHIELD緩和フレームワークを紹介し、エージェント能力（自律性、メモリ、推論、ツール）に固有の5つのドメインにわたる9つの脅威を特定しました[4]。これは、一般的なAI/LLMガイドライン（NIST RMF [2]、MITRE ATLAS [6]、OWASP Top 10 [5]、MAESTRO [7]）を超えた構造を提供します。

GenAIエージェントのセキュリティには、その特定の特性への対処が必要です。エージェント脅威は、時間的複雑性、目標操作の可能性、伝播リスク、検出課題を示し、特殊な対策を必要とします[8, 9, 12]。脅威の相互作用、セクターへの影響、規制上のハードルは、エージェント固有のセキュリティパラダイムの必要性を強調しています。

採用が成長するにつれて[1, 2]、実践者はSHIELDベースの戦略を検討すべきです：

### 多層防御
単一の保護メカニズムに依存するのではなく、複数の重複するセキュリティ制御（セグメンテーション、エスカレーション制御、完全性検証の組み合わせなど）を展開します。

### ゼロトラストアーキテクチャ
見かけのソースまたはネットワークの場所に関係なく、すべてのエージェント行動と相互作用に対して厳格な検証を実装します（エスカレーション制御、堅牢なセグメンテーション）。

### 継続的で特殊な監視
従来のIOCだけでなく、認知的、行動的、時間的異常に焦点を当てて、独自のエージェント攻撃パターンを検出しアラートするように設計された監視システムを展開します（ヒューリスティック監視）。

### 区画化
エージェントサブシステム、データソース、外部リソース間に厳格な境界を実装して（セグメンテーション）、潜在的な侵害を封じ込め、爆風半径を制限します。

### 堅牢なガバナンスと監査
適切な人間の監視メカニズム（分散監視によってサポート）を維持し、説明責任とフォレンジックのために改ざん防止の包括的な記録（ロギング不変性）を保証します。

今後の研究は、多様なエージェントアーキテクチャにわたる厳格なレッドチームとシミュレーションを通じて、特定された脅威と提案されたSHIELD緩和策の有効性の経験的検証を優先すべきです。エージェント脅威に合わせた定量的リスク評価方法論の開発（ベイジアンリスクモデルの探求、推論パス偏差のメトリクス、または目標遵守検証など）と、エージェントシステムのための標準化されたセキュリティバイデザインパターンの確立（「最小エージェンシーの原則」、「検証可能な推論ステップ」、安全なメモリアーキテクチャなどのパターンの調査）も重要な次のステップです。GenAIエージェントのセキュリティ課題に積極的かつ全体的に対処することは、許容できない企業リスクを導入することなく、その変革的な潜在能力を実現するために不可欠です。

# 参考文献

[1] R. Shu, N. Das, M. Yuan, M. Sunkara, and Y. Zhang, "Towards effective genai multi-agent collaboration: Design and evaluation for enterprise applications," 2024, accessed: Apr. 12, 2025. [Online]. Available: https://arxiv.org/abs/2412.05449

[2] National Institute of Standards and Technology, "AI risk management framework (AI RMF 1.0)," NIST, NIST AI 100-1, Jan 2023, accessed: Apr. 12, 2025. [Online]. Available: https://www.nist.gov/itl/ai-risk-management-framework

[3] I. Domkundwar, S. M. N, I. Bhola, and R. Kochhar, "Safeguarding ai agents: Developing and analyzing safety architectures," 2024, accessed: Apr. 12, 2025. [Online]. Available: https://arxiv.org/abs/2409.03793

[4] I. E. Kezron, "Securing the AI supply chain: Mitigating vulnerabilities in AI model development and deployment," World Journal of Advanced Research and Reviews, vol. 22, no. 2, pp. 2336–2346, May 2024. [Online]. Available: https://doi.org/10.30574/wjarr.2024.22.2.1394

[5] OWASP Foundation, "OWASP top 10 for large language model applications," https://owasp.org/www-project-top-10-for-large-language-model-applications/, 2024, accessed: Apr. 12, 2025.

[6] MITRE, "Adversarial threat landscape for artificial-intelligence systems (ATLAS)," https://atlas.mitre.org/, 2023, accessed: Apr. 12, 2025.

[7] Cloud Security Alliance, "Agentic AI threat modeling framework: MAESTRO," CSA Blog. https://cloudsecurityalliance.org/blog/2025/02/06/agentic-ai-threat-modeling-framework-maestro, Feb 2025, accessed: Apr. 12, 2025.

[8] W. Wang, H. Wang, S. Chen, Z. Lin, Z. Wang, L. Li, B. Niu, X. Li, Y. Fei, P. Zhou, L. Yao, X. Jiang, and K.-Y. Lam, "The emerged security and privacy of LLM agent: A survey with case studies," 2024, accessed: Apr. 12, 2025. [Online]. Available: https://arxiv.org/abs/2407.19354

[9] Z. Chen, Z. Xiang, C. Xiao, D. Song, and B. Li, "AGENTPOISON: Red-teaming LLM agents via poisoning memory or knowledge bases," in Advances in Neural Information Processing Systems 37 (NeurIPS 2024), 2024, accessed: Apr. 12, 2025. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2024/file/eb113910e9c3f6242541c1652e30dfd6-Paper-Conference.pdf

[10] OWASP Foundation, "Agentic threats and mitigation," https://genai.owasp.org/resource/agentic-ai-threats-and-mitigations/, 2025, accessed: Apr. 12, 2025.

[11] K. Huang, A. Sheriff, J. Sotiropoulos, R. F. Del, and V. Lu, "Multi-agentic system threat modelling guide OWASP GenAI security project," Apr. 2025. [Online]. Available: https://www.researchgate.net/publication/391204915_Multi-Agentic_system_Threat_Modelling_Guide_OWASP_GenAI_Security_Project

[12] National Institute of Standards and Technology, "AI 100-2 e2023 adversarial machine learning: A taxonomy and terminology of attacks and mitigations," NIST, NIST AI 100-2e2023, Aug 2023, accessed: Apr. 12, 2025. [Online]. Available: https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf

[13] OWASP Foundation, "Announcing the OWASP LLM and Gen AI security project initiative for securing agentic applications," OWASP Blog. https://owasp.org/blog/2024/07/16/Announcing-OWASP-LLM-GenAI-Security-Project-Agentic-Applications, Jul 2024, accessed: Apr. 12, 2025.

[14] E. G. Junior, S. Clinton, C. Hughes, V. S. Narajala, and T. Holmes, "LLM and GenAI data security best practices," Feb. 2025. [Online]. Available: https://www.researchgate.net/publication/391204648_LLM_and_GenAI_Data_Security_Best_Practices

[15] MITRE, "MITRE ATT&CK® framework for machine learning," https://attack.mitre.org/, 2023, accessed: Apr. 12, 2025.

[16] P. Lee, "Learning from Tay's introduction," The Official Microsoft Blog, Mar 2016, accessed: Apr. 12, 2025. [Online]. Available: https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/

[17] Embrace The Red, "GitHub Copilot Chat: From prompt injection to data exfiltration," Blog Post. https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/, Jun 2024, accessed: Apr. 12, 2025.

[18] LangChain Documentation, "Agents," https://python.langchain.com/docs/modules/agents/, 2024, accessed: Apr. 12, 2025.

[19] Significant Gravitas, "AutoGPT," GitHub Repository. https://github.com/Significant-Gravitas/AutoGPT, 2024, accessed: Apr. 12, 2025.

[20] Microsoft, "Semantic kernel," GitHub Repository. https://github.com/microsoft/semantic-kernel, 2024, accessed: Apr. 12, 2025.

[21] UK Government, "Safety and security risks of generative artificial intelligence to 2025," Government Publications. https://www.gov.uk/government/publications/safety-and-security-risks-of-generative-artificial-intelligence-to-2025, Feb 2024, accessed: Apr. 12, 2025.

# littlemex 所感

既存フレームワークの不足と攻撃ベクトルと対策について概要レベルで整理しているのでこれを元にリスクベースで組織としてどこまで自社AIエージェントのセキュリティ対処するか考える際に有効ではあるが、対策がヒューリスティック監視のためにオートエンコーダーを使って異常検知モデルを作りましょう、としれっと書かれていて、これがサラッとできる企業は自社で監査含めて全て設計・実装できるのでこのドキュメントを読まないと思った。AWS からマネージドで包括的なこれらの機能が提供されるのを待つか、これらの領域に高いケイパビリティを持つ企業に外注、OSS/SaaS サービスを利用する、などをしないと多くの日本企業の体力では記事で記載されていた対策にそこまで投資できなそうだと感じた。使えそうな OSS/SaaS などは整理中である。