---
title: "Ray 2.53.0 ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆè§£èª¬"
emoji: "ğŸ”–"
type: "tech"
topics: ["Ray", "æ©Ÿæ¢°å­¦ç¿’", "åˆ†æ•£å‡¦ç†"]
published: true
---

# ã¯ã˜ã‚ã«

https://github.com/ray-project/ray/releases/tag/ray-2.53.0

Ray 2.53.0 ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã€åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€LLM å¯¾å¿œã®å„åˆ†é‡ã«ãŠã„ã¦ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã—ãŸã€‚æœ¬ãƒªãƒªãƒ¼ã‚¹ã«ã¯ 40 ä»¶ã‚’è¶…ãˆã‚‹ Pull Request ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–ã€æ–°æ©Ÿèƒ½ã®è¿½åŠ ã€ãƒã‚°ã®ä¿®æ­£ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€Ray Serveã€Ray Trainã€Ray LLMã€Ray Core ã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ãŠã‘ã‚‹ä¸»è¦ãªå¤‰æ›´ç‚¹ã‚’ç¢ºèªã—ã¾ã™ã€‚ãªãŠã€Ray Data ã«ã¤ã„ã¦ã¯æœ¬è¨˜äº‹ã§ã¯å–ã‚Šæ‰±ã„ã¾ã›ã‚“ã€‚

# Ray ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

Ray ã¯éšå±¤çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚æœ€ä¸‹å±¤ã«ã‚¯ãƒ©ã‚¹ã‚¿ç®¡ç†åŸºç›¤ã§ã‚ã‚‹ Ray Clusters ãŒé…ç½®ã•ã‚Œã€ãã®ä¸Šã«æ±ç”¨åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦ã® Ray Core ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚Ray Core ã¯ Tasksã€Actorsã€Objects ã® 3 ã¤ã®ã‚³ã‚¢æ¦‚å¿µã‚’æä¾›ã—ã€åˆ†æ•£å®Ÿè¡Œã¨ãƒªã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’æ‹…å½“ã—ã¾ã™ã€‚æœ€ä¸Šä½ã® Ray AI Libraries å±¤ã¯ã€Trainã€Tuneã€Serve ã¨ã„ã£ãŸå°‚é–€çš„ãª AI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’çµ±åˆã—ãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚Ray LLM ã¯ç‹¬ç«‹ã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã¯ãªãã€Ray Serve å†…ã«å®Ÿè£…ã•ã‚ŒãŸ LLM ç‰¹åŒ–æ©Ÿèƒ½ç¾¤ã§ã‚ã‚Šã€Response Streamingã€Dynamic Request Batchingã€Multi-node/Multi-GPU Serving ãªã©ã®æœ€é©åŒ–ã‚’æä¾›ã—ã¾ã™ã€‚

å‚ç…§: [Ray Overview](https://docs.ray.io/en/latest/ray-overview/index.html), [Ray AIR Getting Started](https://docs.ray.io/en/latest/ray-air/getting-started.html), [Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html)

```mermaid
graph TB
    subgraph "Ray AI Libraries"
        Train[Ray Train<br/>åˆ†æ•£æ©Ÿæ¢°å­¦ç¿’è¨“ç·´]
        Tune[Ray Tune<br/>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br/>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°]
        Serve[Ray Serve<br/>ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°]
    end

    subgraph "Ray Serve å†…æ©Ÿèƒ½"
        LLM[Ray LLM<br/>LLM æœ€é©åŒ–æ©Ÿèƒ½<br/>- Response Streaming<br/>- Dynamic Batching<br/>- Multi-GPU Serving]
    end

    Core[Ray Core<br/>åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆåŸºç›¤<br/>- Tasks/Actors/Objects<br/>- Scheduling<br/>- Resource Management]

    Clusters[Ray Clusters<br/>ã‚¯ãƒ©ã‚¹ã‚¿ç®¡ç†]

    Core --> Train
    Core --> Tune
    Core --> Serve

    Train -.çµ±åˆ.- Tune

    Serve --> LLM

    Clusters --> Core

    classDef coreLayer fill: #e1f5ff,stroke: #0066cc,stroke-width:3px
    classDef airLayer fill: #fff4e1,stroke: #ff9900,stroke-width:2px
    classDef llmLayer fill: #f0f0f0,stroke: #666,stroke-width:1px

    class Core coreLayer
    class Train,Tune,Serve airLayer
    class LLM llmLayer
```

https://docs.ray.io/en/latest/ray-overview/getting-started.html

# ä¸»è¦ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ

## Ray Serve

Ray Serve ã¯ Ray Core ã®ä¸Šã«æ§‹ç¯‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚2.53.0 ã§ã¯å¯è¦–åŒ–ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ãƒãƒƒãƒå‡¦ç†ã®å„åˆ†é‡ã«ãŠã„ã¦é‡è¦ãªæ”¹å–„ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚

Deployment Topology Visibility ã¯ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’ REST API çµŒç”±ã§å…¬é–‹ã™ã‚‹æ–°æ©Ÿèƒ½ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãŠã‘ã‚‹ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆé–“ã®é–¢ä¿‚æ€§ã‚’å‹•çš„ã«æŠŠæ¡ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã€ãƒ‡ãƒãƒƒã‚°ã‚„å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã¨ã®çµ±åˆãŒå¤§å¹…ã«å®¹æ˜“åŒ–ã•ã‚Œã¾ã™ï¼ˆPR #58355ï¼‰ã€‚

External Autoscaler Integration ã¯ã€Kubernetes HPA ãªã©ã®å¤–éƒ¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºã‚’å¯èƒ½ã«ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã« `external_scaler_enabled` ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ Ray Serve ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ãƒ¬ãƒ—ãƒªã‚«æ•°ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åŸºã¥ãé«˜åº¦ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼å®Ÿè£…ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ï¼ˆPR #57727, #57698ï¼‰ã€‚

ã“ã®æ©Ÿèƒ½ã¯ã€Œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã€ã®ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆRay Serve ã®ãƒ¬ãƒ—ãƒªã‚«æ•°èª¿æ•´ï¼‰ã‚’å¯¾è±¡ã¨ã—ã¦ãŠã‚Šã€Karpenter ãªã©ã®ã€Œã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ¬ãƒ™ãƒ«ã€ã®ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆãƒãƒ¼ãƒ‰æ•°èª¿æ•´ï¼‰ã¨ç•°ãªã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§å‹•ä½œã—ã¾ã™ã€‚Karpenter ã¯ Ray Autoscaler ãŒä½œæˆã—ãŸ Unschedulable Pod ã‚’æ¤œå‡ºã—ã¦è‡ªå‹•çš„ã«ãƒãƒ¼ãƒ‰ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã€æ˜ç¤ºçš„ãªé€£æºè¨­å®šã¯ä¸è¦ã§ã™ã€‚Ray Serve ã®å†…éƒ¨ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã€Ray Autoscalerã€Karpenter ã® 3 ã¤ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ã€ãã‚Œãã‚Œç‹¬ç«‹ã—ã¦å‹•ä½œã—ãªãŒã‚‰å”èª¿çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

Custom Batch Size Function ã¯ã€`@serve.batch` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã§å¯å¤‰é‡ã¿ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒãƒã‚µã‚¤ã‚ºé–¢æ•°ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ©Ÿèƒ½ã§ã‚ã‚Šã€æŸ”è»Ÿãªãƒãƒƒãƒå‡¦ç†å®Ÿè£…ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ï¼ˆPR #59059ï¼‰ã€‚

å‚ç…§: [Ray 2.53.0 Release Notes](https://github.com/ray-project/ray/releases/tag/ray-2.53.0), [Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html), [Ray Serve Configuration](https://docs.ray.io/en/latest/serve/production-guide/config.html), [Ray on Kubernetes Autoscaler](https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/k8s-autoscaler.html), [Karpenter Concepts](https://karpenter.sh/docs/concepts/)

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é¢ã§ã¯ã€Autoscaling Performance Optimization ãŒç‰¹ã«æ³¨ç›®ã§ã™ã€‚ãƒ¡ãƒˆãƒªãƒƒã‚¯é›†ç´„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã€å˜ä¸€ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºã®å ´åˆã«ãŠã„ã¦ O(n log n) ã‹ã‚‰ O(1) ã«æ”¹å–„ã•ã‚Œã¦ãŠã‚Šã€å¤§è¦æ¨¡ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã«ãŠã‘ã‚‹ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å¿œç­”æ€§ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ï¼ˆPR #58962, #58963ï¼‰ã€‚Downscaling Behavior Optimization ã¯ã€æœ€è¿‘ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸãƒ¬ãƒ—ãƒªã‚«ã‚’å„ªå…ˆçš„ã«ãƒ€ã‚¦ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§ã€ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ã®åŠ¹ç‡æ€§ã‚’é«˜ã‚ã¦ã„ã¾ã™ï¼ˆPR #52929ï¼‰ã€‚

## Ray Train

Ray Train ã¯åˆ†æ•£æ©Ÿæ¢°å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚2.53.0 ã§ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼é…ç½®ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚µãƒãƒ¼ãƒˆã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã®å„åˆ†é‡ã«ãŠã„ã¦æ©Ÿèƒ½æ‹¡å¼µãŒè¡Œã‚ã‚Œã¦ã„ã¾ã™ã€‚

Worker Placement with Label Selectors ã¯ã€`ScalingConfig` ã« `label_selector` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã® GPU ã‚¿ã‚¤ãƒ—ã‚„ CPU ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤ãƒãƒ¼ãƒ‰ã¸ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’æ˜ç¤ºçš„ã«é…ç½®ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã€ãƒ˜ãƒ†ãƒ­ã‚¸ãƒ‹ã‚¢ã‚¹ç’°å¢ƒã«ãŠã‘ã‚‹æœ€é©ãªãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨ãŒå®Ÿç¾ã•ã‚Œã¾ã™ï¼ˆPR #58845, #59414ï¼‰ã€‚Multihost JaxTrainer on GPU ã¯ã€åˆ†æ•£ JAX ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã® GPU ã‚µãƒãƒ¼ãƒˆã‚’æ‹¡å¼µã™ã‚‹æ©Ÿèƒ½ã§ã‚ã‚Šã€JAX ã«ãŠã‘ã‚‹å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿç”¨æ€§ãŒå‘ä¸Šã—ã¾ã™ï¼ˆPR #58322ï¼‰ã€‚Checkpoint Consistency Modes ã¯ã€`CheckpointConsistencyMode` ã«ã‚ˆã‚Šä½¿ç”¨ã‚±ãƒ¼ã‚¹ã«å¿œã˜ãŸæŸ”è»Ÿãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾—æˆ¦ç•¥ã‚’æä¾›ã™ã‚‹æ©Ÿèƒ½ã§ã™ï¼ˆPR #58271ï¼‰ã€‚

å‚ç…§: [Ray Train Documentation](https://docs.ray.io/en/latest/train/train.html)

ãƒ‡ãƒ¼ã‚¿å‡¦ç†é¢ã§ã¯ã€Per-Dataset Execution Options ã«ã‚ˆã‚Šã€`DataConfig` ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã® `execution_options` ã‚’è¨­å®šå¯èƒ½ã¨ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ãªã‚‹ç‰¹æ€§ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä¾‹ãˆã°ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰ã«å¯¾ã—ã¦æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®šã‚’å€‹åˆ¥ã«é©ç”¨ã§ãã¾ã™ï¼ˆPR #58717ï¼‰ã€‚Nested Metrics Support ã¯ã€`Result.get_best_checkpoint` ã§ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹æ§‹é€ ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ©Ÿèƒ½ã§ã‚ã‚Šã€è¤‡é›‘ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹éšå±¤ã‚’æŒã¤å®Ÿé¨“ã«ãŠã„ã¦ã‚‚æœ€é©ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®é¸æŠãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ï¼ˆPR #58537ï¼‰ã€‚Non-blocking Checkpoint Retrieval ã¯ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿ã‚’å ±å‘Šã™ã‚‹éš›ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾—ã‚’ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ï¼ˆPR #58870ï¼‰ã€‚

## Ray LLM

Ray LLM ã¯ Ray Serve å†…ã«å®Ÿè£…ã•ã‚ŒãŸ LLM ç‰¹åŒ–æ©Ÿèƒ½ç¾¤ã§ã™ã€‚2.53.0 ã§ã¯ã‚¯ãƒ©ã‚¦ãƒ‰çµ±åˆã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ›´æ–°ã€è¨­å®šã®ç°¡ç´ åŒ–ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚

Ray LLM ã¯ vLLM æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆ©ç”¨ã™ã‚‹çµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼æ©Ÿèƒ½ã§ã™ã€‚vLLM ã¯ PagedAttention ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†ã¨ Continuous Batching ã«ã‚ˆã‚‹ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæœ€é©åŒ–ã‚’æä¾›ã™ã‚‹é«˜æ€§èƒ½ãª LLM æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã‚ã‚Šã€Ray ã¯ãã®åˆ†æ•£å®Ÿè¡ŒåŸºç›¤ã¨ã—ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚vLLM ã¯ `distributed_executor_backend` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆ†æ•£å®Ÿè¡Œãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’é¸æŠå¯èƒ½ã§ã‚ã‚Šã€`ray` ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ Ray Core ã® Actors ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ«ãƒãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ç®¡ç†ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡æ•°ãƒãƒ¼ãƒ‰ãƒ»è¤‡æ•° GPU ã«ã¾ãŸãŒã‚‹å¤§è¦æ¨¡ãªæ¨è«–ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«å®Ÿè¡Œã§ãã¾ã™ã€‚

Ray ã® vLLM çµ±åˆã¯ 2 ã¤ã®å½¢æ…‹ã§æä¾›ã•ã‚Œã¾ã™ã€‚Ray Serve LLM ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€REST API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãªã©ã®æœ¬ç•ªç’°å¢ƒå‘ã‘æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚ä¸€æ–¹ã€Ray Data LLM ã¯ãƒãƒƒãƒæ¨è«–å‡¦ç†ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸¡è€…ã¨ã‚‚ vLLM ã® `AsyncLLMEngine` ã‚’å†…éƒ¨ã§ä½¿ç”¨ã—ã¦ãŠã‚Šã€Ray Core ã®åˆ†æ•£å®Ÿè¡Œæ©Ÿèƒ½ã«ã‚ˆã‚ŠéåŒæœŸã‹ã¤ãƒãƒ«ãƒãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã®å‡¦ç†ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

ä»Šå›ã® 2.53.0 ã«ãŠã‘ã‚‹æ”¹å–„ã¯ã€ã“ã®çµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å¼·åŒ–ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚

Cloud Filesystem Restructuring ã¯ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®å®Ÿè£…ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®å†æ§‹ç¯‰ã§ã™ã€‚Amazon Simple Storage Serviceã€Google Cloud Storageã€Azure Blob Storage ãªã©ã®å„ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹çµ±åˆãŒæ”¹å–„ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿åŠ¹ç‡ãŒå‘ä¸Šã—ã¾ã™ï¼ˆPR #58469ï¼‰ã€‚

Auto-inference of GPU Configuration ã¯ã€é…ç½®ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰ `VLLM_RAY_PER_WORKER_GPUS` ã‚’è‡ªå‹•æ¨è«–ã™ã‚‹æ©Ÿèƒ½ã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«è¨­å®šã™ã‚‹å¿…è¦ãŒãªããªã‚‹ã“ã¨ã§ã€è¨­å®šãƒŸã‚¹ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ãŒé˜²æ­¢ã•ã‚Œã¾ã™ï¼ˆPR #58949ï¼‰ã€‚

Transformers Version Update ã§ã¯ã€transformers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒ 4.57.3 ã«æ›´æ–°ã•ã‚Œã¦ãŠã‚Šã€æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒã‚°ä¿®æ­£ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¾ã™ï¼ˆPR #58980ï¼‰ã€‚

å‚ç…§: [Ray AIR Getting Started](https://docs.ray.io/en/latest/ray-air/getting-started.html), [vLLM Documentation](https://docs.vllm.ai/en/latest/), [Ray Data Batch Inference](https://docs.ray.io/en/latest/data/batch_inference.html), [Issue #58360](https://github.com/ray-project/ray/issues/58360)

## Ray Core

Ray Core ã¯å…¨ã¦ã® Ray ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒä¾å­˜ã™ã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åŸºç›¤ã§ã™ã€‚2.53.0 ã§ã¯ç‰¹ã«ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿¡é ¼æ€§ã®åˆ†é‡ã«ãŠã„ã¦é‡è¦ãªæ”¹å–„ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚

Zero-copy PyTorch Tensor Serialization ã¯ã€æœ¬ãƒªãƒªãƒ¼ã‚¹ã«ãŠã‘ã‚‹æœ€ã‚‚é‡è¦ãªæœ€é©åŒ–ã§ã™ã€‚åˆ†æ•£æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«ãŠã„ã¦ã€ãƒ†ãƒ³ã‚½ãƒ«ã®è»¢é€ã¯é »ç¹ã«ç™ºç”Ÿã™ã‚‹æ“ä½œã§ã™ãŒã€å¾“æ¥ã®å®Ÿè£…ã§ã¯é€ä¿¡å´ã§ãƒ†ãƒ³ã‚½ãƒ«ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹éš›ã«å¿…ãšãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã—ãŸã€‚ã“ã‚Œã¯ç‰¹ã«å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ï¼ˆæ•°å GB ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ LLM ãªã©ï¼‰ã«ãŠã„ã¦æ·±åˆ»ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã£ã¦ãŠã‚Šã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¢—å¤§ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ‚ªåŒ–ã‚’å¼•ãèµ·ã“ã—ã¦ã„ã¾ã—ãŸã€‚

ã“ã®æœ€é©åŒ–ãŒå¯¾è±¡ã¨ã™ã‚‹ã®ã¯ã€**CPU ãƒãƒ¼ãƒ‰é–“ã§ã®ãƒ†ãƒ³ã‚½ãƒ«è»¢é€**ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¤‡æ•°ã®æ¨è«–ãƒãƒ¼ãƒ‰ã«é…å¸ƒã™ã‚‹å ´åˆã‚„ã€è¨“ç·´ãƒãƒ¼ãƒ‰ã§ä¿å­˜ã—ãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¨è«–ãƒãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã‚€å ´åˆã€ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—è¨“ç·´ã§å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã«å…¥åŠ›ãƒãƒƒãƒã‚’é…å¸ƒã™ã‚‹å ´åˆãªã©ã§ã™ã€‚ä¸€æ–¹ã€GPU é–“ã® NVLink é€šä¿¡ã‚„ GPU-CPU é–“ã® cudaMemcpy ã¨ã„ã£ãŸè»¢é€ã¯åˆ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã‚ã‚Šã€ä»Šå›ã®æœ€é©åŒ–ã®å¯¾è±¡å¤–ã§ã™ã€‚ã¤ã¾ã‚Šã€ã“ã®æ©Ÿèƒ½ã¯åˆ†æ•£æ¨è«–ã‚„è¨“ç·´ã®ã€Œæº–å‚™æ®µéšã€ã«ãŠã‘ã‚‹ãƒãƒ¼ãƒ‰é–“ã®ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿å…±æœ‰ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã‚‚ã®ã§ã™ã€‚

> ã©ã“ã‹ã‚‰ã©ã“ã¸ã®ã©ã®ãƒ¬ã‚¤ãƒ¤ã®ãƒ‡ãƒ¼ã‚¿è»¢é€ã®è©±ãªã®ã‹åˆ†æ•£å‡¦ç†ç•Œéšˆã®æƒ…å ±ã¯ã„ã¤ã‚‚ã“ã‚“ãŒã‚‰ãŒã‚‹ã®ã§æ­£ã—ã„ç†è§£ã‚’å¿ƒãŒã‘ãŸã„ã§ã™ã€‚ã€‚

PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã‚’ NumPy é…åˆ—ã®ãƒ¡ãƒ¢ãƒªãƒ“ãƒ¥ãƒ¼ã«å¤‰æ›ã—ï¼ˆ[`zero_copy_tensors_reducer`](https://github.com/ray-project/ray/blob/master/python/ray/_private/tensor_serialization_utils.py)ï¼‰ã€uint8 ãƒ“ãƒ¥ãƒ¼ã§ãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦ç›´æ¥å‚ç…§ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã‚’å®Œå…¨ã«æ’é™¤ã—ã¦ã„ã¾ã™ã€‚

:::message
PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã‚’ NumPy é…åˆ—ã®ãƒ¡ãƒ¢ãƒªãƒ“ãƒ¥ãƒ¼ã«å¤‰æ›ã™ã‚‹ã¨ã¯ã€ãƒ†ãƒ³ã‚½ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã›ãšã«ã€CPU ä¸Šã«ã‚ã‚‹ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ¡ãƒ¢ãƒªé ˜åŸŸã‚’ã€NumPy é…åˆ—ã¨ã—ã¦ç›´æ¥å…±æœ‰ãƒ»æ“ä½œã™ã‚‹å¤‰æ›ã®ã“ã¨ã§ã™ã€‚`tensor.numpy()` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãŸã ã—ãƒ†ãƒ³ã‚½ãƒ«ãŒ CPU ä¸Šã«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
:::

ã“ã®æœ€é©åŒ–ã«ã‚ˆã‚Šã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¤‡æ•°ãƒãƒ¼ãƒ‰é–“ã§å…±æœ‰ã™ã‚‹éš›ã€ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã‚’å®Œå…¨ã«æ’é™¤ã—ã€ãƒã‚¤ãƒ³ã‚¿ã®ã¿ã‚’æ¸¡ã™ãŸã‚ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤§å¹…ã«å‰Šæ¸›ã•ã‚Œã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ã¯ç’°å¢ƒå¤‰æ•° `RAY_ENABLE_ZERO_COPY_TORCH_TENSORS=1` ã‚’ Ray ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã«è¨­å®šã™ã‚‹ã“ã¨ã§æœ‰åŠ¹åŒ–ã•ã‚Œã¾ã™ï¼ˆPR #57639ï¼‰ã€‚

å‚ç…§: [Ray Core Walkthrough](https://docs.ray.io/en/latest/ray-core/walkthrough.html)

Cloud Resource Availability Awareness ã¯ã€ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒªã‚½ãƒ¼ã‚¹å¯ç”¨æ€§ã‚’èªè­˜ã—ã€åˆ©ç”¨ä¸å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã¸ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å›é¿ã—ã¾ã™ï¼ˆPR #58623ï¼‰ã€‚

# ã¾ã¨ã‚

å€‹äººçš„ã«ã¯ Ray ã«ã¤ã„ã¦ã‚ã¾ã‚Šã‚ã‹ã£ã¦ã„ãªã‹ã£ãŸã®ã§ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’é€šã˜ã¦ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ§‹æˆã€Kubernetesã€ã‚¯ãƒ©ã‚¦ãƒ‰å´ã®æ©Ÿèƒ½ã¨ã®é€£æºã€ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã€ãªã©ã®çŸ¥è¦‹ã‚’å¾—ã‚‰ã‚ŒãŸã®ã§ã‚ˆã‹ã£ãŸã§ã™ã€‚å¤ã„ã®ã§å‹•ãã‹ä¸æ˜ã§ã™ãŒä¸åº¦åˆ¥ä»¶ã§ Whisper ã‚’è§¦ã£ã¦ã„ã‚‹ã®ã§ Ray Serve on EKS ã§æ¨è«–ã•ã›ã¦çŸ¥è¦‹ã‚’å¾—ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚Ray Train ã¨ SageMaker HyperPod ã®é€£æºã‚‚å…¨ãã©ã†ã™ã¹ãã‹ã‚ã‹ã£ã¦ãªã„ã®ã§èª¿ã¹ãŸã„ã§ã™ã€‚

https://github.com/aws-samples/ray-serve-whisper-streaming-on-eks?tab=readme-ov-file

## å‚è€ƒæ–‡çŒ®

[Ray 2.53.0 Release Notes](https://github.com/ray-project/ray/releases/tag/ray-2.53.0)
[Ray Overview](https://docs.ray.io/en/latest/ray-overview/index.html)
[Ray Core Walkthrough](https://docs.ray.io/en/latest/ray-core/walkthrough.html)
[Ray Train Documentation](https://docs.ray.io/en/latest/train/train.html)
[Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html)
[Ray Serve Configuration](https://docs.ray.io/en/latest/serve/production-guide/config.html)
[Ray on Kubernetes Autoscaler](https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/k8s-autoscaler.html)
[Karpenter Concepts](https://karpenter.sh/docs/concepts/)
[vLLM Documentation](https://docs.vllm.ai/en/latest/)
[Ray Data Batch Inference](https://docs.ray.io/en/latest/data/batch_inference.html)
