---
title: "Amazon SageMaker HyperPod -- Managed Tiered Checkpointing"
emoji: "ğŸ’¾"
type: "idea"
topics: ["AWS", "SageMaker", "HyperPod", "åˆ†æ•£å­¦ç¿’", "Checkpoint"]
published: true
---

## ã¯ã˜ã‚ã«

æœ¬è¨˜äº‹ã¯ SageMaker HyperPod æ©Ÿèƒ½è§£èª¬ã‚·ãƒªãƒ¼ã‚ºã®ä¸€éƒ¨ã§ã™ã€‚ä»¥ä¸‹ã®è¨˜äº‹ã‚‚å…¬é–‹æ¸ˆã¿ã§ã™ã®ã§ã€ã‚ã‚ã›ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚

https://zenn.dev/yunokiisshin/articles/45a746434b2090

https://zenn.dev/yunokiisshin/articles/be0db364a7f8e2

å¤§è¦æ¨¡ãªåˆ†æ•£å­¦ç¿’ã§ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãŒå­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ä½ä¸‹è¦å› ã«ãªã‚Šã¾ã™ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆ70B ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸Šï¼‰ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯æ•°ç™¾ GB ã«åŠã¶ã“ã¨ãŒã‚ã‚Šã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ›¸ãè¾¼ã¿ä¸­ã¯ GPU ãŒå¾…æ©ŸçŠ¶æ…‹ã¨ãªã‚Šã¾ã™ã€‚

Amazon SageMaker HyperPod ã® **Managed Tiered Checkpointing** ã¯ã€ä¿å­˜å…ˆã‚’ CPU ãƒ¡ãƒ¢ãƒªã¨ Amazon S3 ã® 2 éšå±¤ã«åˆ†ã‘ã‚‹ã“ã¨ã§ã€ä¿å­˜ã®é«˜é€ŸåŒ–ã¨ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’ä¸¡ç«‹ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ä»•çµ„ã¿ã€å®Ÿè£…æ–¹æ³•ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã€ãŠã‚ˆã³ FSx for Lustre + DRAï¼ˆData Repository Associationï¼‰ã¨ã®ä½¿ã„åˆ†ã‘ã‚’è§£èª¬ã—ã¾ã™ã€‚

:::message alert
æœ¬è¨˜äº‹ã¯ 2026 å¹´ 2 æœˆæ™‚ç‚¹ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãªã©ã«åŸºã¥ãèª¿æŸ»è¨˜äº‹ã§ã™ã€‚å†…å®¹ã«èª¤ã‚ŠãŒã‚ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹ãŸã‚ã€å¿…ãšæœ€æ–°ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ­£ã¨ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚èª¤ã‚Šã‚’ç™ºè¦‹ã•ã‚ŒãŸå ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
:::

## æ¦‚è¦ã¨ FSx + DRA ã¨ã®æ¯”è¼ƒ

:::message
æœ¬æ©Ÿèƒ½ã¯ [EKS ç’°å¢ƒã§ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ãŒå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)ã•ã‚Œã¦ã„ã¾ã™ã€‚Slurm ç’°å¢ƒã§ã®åˆ©ç”¨å¯å¦ã«ã¤ã„ã¦ã¯ã€å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ˜ç¤ºçš„ãªè¨˜è¼‰ãŒãªã„ãŸã‚ã€æœ€æ–°ã®æƒ…å ±ã‚’ AWS ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**FSx for Lustre ã¨ã®ä½µç”¨ã«ã¤ã„ã¦**: Managed Tiered Checkpointing ã¨ FSx for Lustre + DRA ã¯æŠ€è¡“çš„ã«ä½µç”¨å¯èƒ½ã§ã™ãŒã€ã©ã¡ã‚‰ã‚‚ Amazon S3 ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ°¸ç¶šåŒ–ã™ã‚‹ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®å½¹å‰²ãŒé‡è¤‡ã—ã¾ã™ã€‚FSx ãŒæ§‹ç¯‰æ¸ˆã¿ã®å ´åˆã¯ã€FSx ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜ã«ã€Managed Tiered Checkpointing ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã«ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
:::

### FSx for Lustre + Data Repository Associationï¼ˆDRAï¼‰

HyperPod ã§ã¯ **[Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/) + [DRA](https://docs.aws.amazon.com/fsx/latest/LustreGuide/create-dra-linked-data-repo.html)** ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã‚‚åºƒãåˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

```mermaid
graph LR
    TN["å­¦ç¿’ãƒãƒ¼ãƒ‰"] -->|"torch.save<br/>å­¦ç¿’ã®ä¸­æ–­"| FSx["FSx for Lustre<br/>å…±æœ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"]
    FSx -->|"DRA<br/>å¤‰æ›´æ¤œçŸ¥"| DRA["Data Repository<br/>Association"]
    DRA -->|"ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰<br/>ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ<br/>æ•°åˆ†"| S3["Amazon S3<br/>æ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"]

    style TN fill: #1a237e,color: #ffffff
    style FSx fill: #0d47a1,color: #ffffff
    style DRA fill: #1565c0,color: #ffffff
    style S3 fill: #1976d2,color: #ffffff
```

FSx + DRA ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¯ã€å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒ `torch.save()` ã§ FSx ã«æ›¸ãè¾¼ã¿ï¼ˆæ›¸ãè¾¼ã¿å®Œäº†ã¾ã§å­¦ç¿’ã‚’ä¸­æ–­ï¼‰ã€DRA ãŒå¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¦ S3 ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ S3 ã«æ°¸ç¶šåŒ–ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚ã“ã®æ–¹å¼ã¯ã€POSIX äº’æ›ã®å…±æœ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦ãªå ´åˆã‚„ã€è¤‡æ•°ãƒãƒ¼ãƒ‰é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ãŒå¿…é ˆãªç’°å¢ƒã«é©ã—ã¦ã„ã¾ã™ã€‚

ä¸€æ–¹ã€Managed Tiered Checkpointing ã¯ã€CPU ãƒ¡ãƒ¢ãƒªã‚’æ´»ç”¨ã—ãŸé«˜é€ŸåŒ–ã¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚’é‡è¦–ã—ãŸè¨­è¨ˆã§ã™ã€‚ä»¥ä¸‹ã«ä¸¡æ–¹å¼ã®ç‰¹æ€§ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚

| æ¯”è¼ƒé …ç›® | FSx + DRA | Managed Tiered Checkpointing |
|---------|------------------|----------------------------|
| å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ | FSx æ›¸ãè¾¼ã¿å®Œäº†ã¾ã§ä¸­æ–­[^2] | Level 3ï¼ˆPyTorch 2.9+ï¼‰ä½¿ç”¨æ™‚ã¯å­¦ç¿’ã¨ä¸¦åˆ—å®Ÿè¡Œã€Level 1/2 ã§ã¯ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼å®Œäº†ã¾ã§ä¸­æ–­[^4] |
| ãƒãƒ¼ãƒ‰éšœå®³æ™‚ã®å¾©æ—§ | FSx ã¾ãŸã¯ S3 ã‹ã‚‰å¾©å…ƒ | ãƒ¡ãƒ¢ãƒªãƒ¬ãƒ—ãƒªã‚«ã‹ã‚‰é«˜é€Ÿå¾©æ—§ |
| POSIX äº’æ›æ€§ | ã‚ã‚Šï¼ˆæ¨™æº–ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼‰ | ãªã—ï¼ˆå°‚ç”¨ API ä½¿ç”¨ï¼‰ |
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ | å¾—æ„ï¼ˆå…±æœ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼‰ | S3 ç›´æ¥èª­è¾¼ã§å¯¾å¿œ |
| S3 ä¿å­˜å½¢å¼ | å˜ä¸€ã® `.pt` ãƒ•ã‚¡ã‚¤ãƒ« | PyTorch DCP ã® sharded checkpointï¼ˆ`.distcp`ï¼‰ |
| æœˆé¡ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆ | FSx for Lustre è²»ç”¨ãŒç™ºç”Ÿ[^1] | CPU ãƒ¡ãƒ¢ãƒªåˆ©ç”¨ã§ S3 ã®ã¿èª²é‡‘ |
| æ¨å¥¨ã‚±ãƒ¼ã‚¹ | POSIX äº’æ›æ€§ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ãŒå¿…é ˆ | ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé«˜é€ŸåŒ–ã¨ã‚³ã‚¹ãƒˆæœ€é©åŒ– |

ä»¥é™ã§ã¯ã€Managed Tiered Checkpointing ã®ä»•çµ„ã¿ã¨å®Ÿè£…æ–¹æ³•ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

## éšå±¤åŒ–æˆ¦ç•¥

Managed Tiered Checkpointing ã¯ **2 ã¤ã®éšå±¤**ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†ã—ã¾ã™ã€‚é«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ä¸»è¦å±¤ã¨ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã® **CPU ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰** ã‚’ä½¿ç”¨ã—ã€æ°¸ç¶šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ã®å‰¯æ¬¡å±¤ã¨ã—ã¦ **Amazon S3** ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```mermaid
graph TB
    subgraph "Tier 1: CPU ãƒ¡ãƒ¢ãƒª"
        M1["ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã®<br/>CPU ãƒ¡ãƒ¢ãƒª<br/>é€Ÿåº¦: GB/s"]
        M2["éš£æ¥ãƒãƒ¼ãƒ‰ã¸ã®<br/>è‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"]
    end

    subgraph "Tier 2: Amazon S3"
        S1["S3 ãƒã‚±ãƒƒãƒˆ<br/>æ°¸ç¶šä¿å­˜å…ˆ<br/>è€ä¹…æ€§: 99.999999999%"]
    end

    M1 -->|"è‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆ"| M2
    M1 -->|"å®šæœŸçš„ã«<br/>éåŒæœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"| S1

    style M1 fill: #1b5e20,color: #ffffff
    style M2 fill: #2e7d32,color: #ffffff
    style S1 fill: #0d47a1,color: #ffffff
```

| éšå±¤ | ä¿å­˜å…ˆ | é€Ÿåº¦ | è€ä¹…æ€§ | ç”¨é€” |
|------|--------|------|--------|------|
| Tier 1 | CPU ãƒ¡ãƒ¢ãƒª | é«˜é€Ÿï¼ˆGB/sï¼‰ | ãƒãƒ¼ãƒ‰é–“ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä¿è­· | é«˜é »åº¦ä¿å­˜ãƒ»é«˜é€Ÿå¾©æ—§ |
| Tier 2 | Amazon S3 | ä½é€Ÿï¼ˆæ•°ç™¾ MB/sï¼‰ | é«˜è€ä¹…ï¼ˆ99.999999999%ï¼‰ | ä½é »åº¦ä¿å­˜ï¼ˆæ°¸ç¶šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰ |

### ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥

Tier 1ï¼ˆCPU ãƒ¡ãƒ¢ãƒªï¼‰ã«ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã€**éš£æ¥ã™ã‚‹è¨ˆç®—ãƒãƒ¼ãƒ‰é–“ã§è‡ªå‹•çš„ã«ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆ**ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å˜ä¸€ã¾ãŸã¯è¤‡æ•°ã®ãƒãƒ¼ãƒ‰éšœå®³æ™‚ã«ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ã—ã€é«˜é€Ÿã«å¾©æ—§ã§ãã¾ã™ã€‚

ãƒ¡ãƒ¢ãƒªç®¡ç†ã¯ã€EKS ç’°å¢ƒã§ã¯ Kubernetes DaemonSet ã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ‡ãƒ¼ãƒ¢ãƒ³ãŒæ‹…å½“ã—ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã®åˆ†æ•£ãƒ¡ãƒ¢ãƒªï¼ˆdisaggregated memoryï¼‰ã‚’ç®¡ç†ã—ã¾ã™ã€‚

:::message
`InstanceMemoryAllocationPercentage` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã«å‰²ã‚Šå½“ã¦ã‚‹ CPU ãƒ¡ãƒ¢ãƒªã®å‰²åˆã‚’è¨­å®šã§ãã¾ã™ï¼ˆ20-100% ã®ç¯„å›²ã§æŒ‡å®šï¼‰ã€‚å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãŒä½¿ç”¨ã™ã‚‹ãƒ¡ãƒ¢ãƒªã¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã¯è¨­å®šä¾‹ã§ã™ï¼ˆ`--tiered-storage-config` å†…ã«å«ã‚ã¾ã™ï¼‰ã€‚

```json
{
  "Mode": "Enable",
  "InstanceMemoryAllocationPercentage": 50
}
```
:::

## éåŒæœŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

æœ€å¤§ã®ç‰¹å¾´ã¯ã€**å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ã‚’çŸ­ç¸®ã—ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜**ã§ãã‚‹ç‚¹ã§ã™ã€‚[PyTorch DCPï¼ˆDistributed Checkpointï¼‰](https://pytorch.org/docs/stable/distributed.checkpoint.html)ã® `async_save()` ã«ã‚ˆã‚ŠéåŒæœŸä¿å­˜ã‚’å®Ÿç¾ã—ã€PyTorch 2.9+ ã® Level 3 æœ€é©åŒ–ï¼ˆå¾Œè¿°ï¼‰ã‚’ä½¿ç”¨ã™ã‚Œã°å­¦ç¿’è¨ˆç®—ã¨å®Œå…¨ã«ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

```mermaid
graph LR
    B1["å­¦ç¿’<br/>å½±éŸ¿æœ€å°åŒ–"] --> B2["Tier 1: RAM<br/>é«˜é€Ÿã‚³ãƒ”ãƒ¼"]
    B2 -.->|"ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰<br/>éåŒæœŸå‡¦ç†"| B3["Tier 2: S3<br/>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]

    style B1 fill: #1b5e20,color: #ffffff
    style B2 fill: #f57f17,color: #000000
    style B3 fill: #0d47a1,color: #ffffff
```

Tiered Checkpointing ã§ã¯ã€Tier 1ï¼ˆRAMï¼‰ã¸ã®é«˜é€Ÿãªã‚³ãƒ”ãƒ¼ã¨ S3 ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éåŒæœŸã«å®Ÿè¡Œã—ã€å­¦ç¿’ã¸ã®å½±éŸ¿ã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚PyTorch 2.9+ ã® Level 3 æœ€é©åŒ–ï¼ˆDefaultStagerï¼‰ã‚’ä½¿ç”¨ã™ã‚Œã°ã€å­¦ç¿’è¨ˆç®—ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ãŒå®Œå…¨ã«ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

## å®Ÿè£…ã¨ API

### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ§‹æˆ

Managed Tiered Checkpointing ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆæ™‚ã« `--tiered-storage-config` ã§æœ‰åŠ¹åŒ–ã—ã¾ã™ï¼ˆ[ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)å‚ç…§ï¼‰ã€‚

**EKS ç’°å¢ƒã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹æˆä¾‹**

```bash
aws sagemaker create-cluster \
    --cluster-name my-training-cluster \
    --orchestrator "Eks={ClusterArn=arn: aws: eks: us-west-2:123456789012: cluster/my-eks}" \
    --instance-groups '[{
        "InstanceGroupName": "training-group",
        "InstanceType": "ml.p5.48xlarge",
        "InstanceCount": 4,
        "LifeCycleConfig": {
            "SourceS3Uri": "s3://my-bucket/lifecycle-scripts",
            "OnCreate": "on_create.sh"
        },
        "ExecutionRole": "arn: aws: iam::123456789012: role/MyRole",
        "InstanceStorageConfigs": [
            { "EbsVolumeConfig": {"VolumeSizeInGB": 500} }
        ]
    }]' \
    --vpc-config '{
        "SecurityGroupIds": ["sg-xxxxxxxxxxxxxxxxx"],
        "Subnets": ["subnet-xxxxxxxxxxxxxxxxx"]
    }' \
    --tiered-storage-config '{"Mode": "Enable"}'
```

**[ç„¡åŠ¹åŒ–ã™ã‚‹å ´åˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-remove.html)**

```bash
aws sagemaker update-cluster \
    --cluster-name my-training-cluster \
    --tiered-storage-config '{"Mode": "Disable"}'
```

### Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

å°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª [`amzn-sagemaker-checkpointing`](https://pypi.org/project/amzn-sagemaker-checkpointing/) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚`sagemaker` SDK ã¨ã¯åˆ¥ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã™ã€‚

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š

```python
import os
import time
import torch.distributed as dist
from amzn_sagemaker_checkpointing.config.sagemaker_checkpoint_config import (
    SageMakerCheckpointConfig,
)
from amzn_sagemaker_checkpointing.checkpointing.filesystem.filesystem import (
    SageMakerTieredStorageWriter,
    SageMakerTieredStorageReader,
)

# åˆ†æ•£å­¦ç¿’ã®åˆæœŸåŒ–
dist.init_process_group(backend="nccl")

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š
checkpoint_config = SageMakerCheckpointConfig(
    namespace=os.environ.get("TRAINING_JOB_NAME", f"job-{int(time.time())}"),
    # namespace ã«ä½¿ç”¨å¯èƒ½ãªæ–‡å­—: è‹±æ•°å­—ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿
    world_size=dist.get_world_size(),
    s3_tier_base_path="s3://my-bucket/checkpoints",
)
```

`SageMakerCheckpointConfig` ã®ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | èª¬æ˜ |
|---|---|---|
| `namespace` | str | å­¦ç¿’ã‚¸ãƒ§ãƒ–ã®ä¸€æ„ãªè­˜åˆ¥å­ï¼ˆè‹±æ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³ãƒ»ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿ï¼‰ |
| `world_size` | int | åˆ†æ•£ãƒ—ãƒ­ã‚»ã‚¹æ•°ï¼ˆ`dist.get_world_size()` ã‹ã‚‰å–å¾—ï¼‰ |
| `s3_tier_base_path` | str | S3 ä¿å­˜å…ˆãƒ‘ã‚¹ |
| `save_to_s3` | bool | S3 ã¸ã®ä¿å­˜ã‚’æœ‰åŠ¹åŒ–ï¼ˆä¿å­˜ã”ã¨ã«å‹•çš„ã«åˆ‡æ›¿å¯èƒ½ï¼‰ |

### å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¸ã®çµ±åˆ

DCP ã® `async_save()` / `load()` ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã¯ [AWS å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)ã«åŸºã¥ãã‚³ãƒ¼ãƒ‰ä¾‹ã§ã™ã€‚

```python
from torch.distributed.checkpoint import async_save, load

future = None
in_memory_ckpt_freq = 10   # 10 ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ¡ãƒ¢ãƒªä¿å­˜
s3_ckpt_freq = 50           # 50 ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã« S3 æ°¸ç¶šåŒ–

for step, batch in enumerate(dataloader):
    # é€šå¸¸ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—
    loss = model(batch)
    loss.backward()
    optimizer.step()

    # Tiered Checkpointing: éåŒæœŸã§ä¿å­˜
    if step % in_memory_ckpt_freq == 0 or step % s3_ckpt_freq == 0:
        state_dict = {
            "model": model.state_dict(),
            "optimizer": optimizer.state_dict(),
            "step": step,
        }

        # S3 ã¸ã®ä¿å­˜ã¯ã‚ˆã‚Šä½ã„é »åº¦ã§å®Ÿè¡Œ
        checkpoint_config.save_to_s3 = (step % s3_ckpt_freq == 0)

        storage_writer = SageMakerTieredStorageWriter(
            checkpoint_config=checkpoint_config,
            step=step,
        )

        # å‰å›ã®éåŒæœŸä¿å­˜ã®å®Œäº†ã‚’ç¢ºèª
        if future is not None:
            exc = future.exception()
            if exc is not None:
                print(f"Checkpoint save failed: {str(exc)}")

        future = async_save(state_dict=state_dict, storage_writer=storage_writer)
```

:::message
**FSDP ã¨ã®çµ±åˆ**: [FSDPï¼ˆFully Sharded Data Parallelï¼‰](https://pytorch.org/docs/stable/fsdp.html)ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`model.state_dict()` ã¯ `SHARDED_STATE_DICT` å½¢å¼ã§è¿”ã•ã‚Œã¾ã™ã€‚PyTorch DCP ã¯ã“ã®å½¢å¼ã‚’ç›´æ¥æ‰±ãˆã‚‹ãŸã‚ã€è¿½åŠ ã®å¤‰æ›ã¯ä¸è¦ã§ã™ã€‚FSDP ã® `StateDictType.SHARDED_STATE_DICT` ã‚’è¨­å®šã—ãŸä¸Šã§ä¸Šè¨˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãã®ã¾ã¾é©ç”¨ã§ãã¾ã™ã€‚
:::

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿

`SageMakerTieredStorageReader` ã¯ã€ãƒ¡ãƒ¢ãƒªå±¤ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã™ã‚‹ã¨è‡ªå‹•çš„ã« S3 å±¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚

```python
state_dict = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "step": 0,  # åˆæœŸå€¤ã€‚load() ã«ã‚ˆã‚Šå®Ÿéš›ã®ä¿å­˜å€¤ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
}

# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿ï¼ˆstep çœç•¥æ™‚ï¼‰
storage_reader = SageMakerTieredStorageReader(
    checkpoint_config=checkpoint_config,
)

try:
    load(state_dict, storage_reader=storage_reader)
    # load() ã¯ state_dict ã‚’ in-place ã§æ›´æ–°ã™ã‚‹
    # èª­ã¿è¾¼ã¿å¾Œã€ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã«åæ˜ 
    model.load_state_dict(state_dict["model"])
    optimizer.load_state_dict(state_dict["optimizer"])
    start_step = state_dict["step"]
except BaseException as e:
    print(f"Checkpoint load failed: {str(e)}")

# ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã¿
storage_reader = SageMakerTieredStorageReader(
    checkpoint_config=checkpoint_config,
    step=500,
)

try:
    load(state_dict, storage_reader=storage_reader)
    model.load_state_dict(state_dict["model"])
    optimizer.load_state_dict(state_dict["optimizer"])
except BaseException as e:
    print(f"Checkpoint load failed at step 500: {str(e)}")
```

::::details è£œè¶³: state_dict ã¨ .pt ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºç¤

PyTorch ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹éš›ã€**state_dict**ï¼ˆçŠ¶æ…‹è¾æ›¸ï¼‰ã¨ã„ã† Python è¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

**state_dict ã¨ã¯**
- ãƒ¢ãƒ‡ãƒ«ã®å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ï¼‰**ã‚’æ ¼ç´ã—ãŸè¾æ›¸
- ä¾‹: `{"layer1.weight": Tensor(...), "layer1.bias": Tensor(...), ...}`
- å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŠ ãˆã€registered buffersï¼ˆBatchNorm ã® running_mean ç­‰ï¼‰ã‚‚å«ã¾ã‚Œã‚‹

**åŸºæœ¬çš„ãªä¿å­˜ãƒ»ãƒ­ãƒ¼ãƒ‰**
```python
# ä¿å­˜
torch.save(model.state_dict(), "checkpoint.pt")

# ãƒ­ãƒ¼ãƒ‰
model = MyModel()
model.load_state_dict(torch.load("checkpoint.pt", weights_only=True))
```

**.pt ãƒ•ã‚¡ã‚¤ãƒ«**
- Python ã® pickle å½¢å¼ã§ã‚·ãƒªã‚¢ãƒ«åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
- æ…£ä¾‹çš„ã« `.pt` ã¾ãŸã¯ `.pth` æ‹¡å¼µå­ã‚’ä½¿ç”¨
- å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜

è©³ç´°ã¯ [PyTorch ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰](https://pytorch.org/tutorials/beginner/saving_loading_models.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

::::

::::details è£œè¶³: FSDPï¼ˆFully Sharded Data Parallelï¼‰ã®å¿…è¦æ€§

å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆ70B ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸Šï¼‰ã¯ã€å˜ä¸€ GPU ã®ãƒ¡ãƒ¢ãƒªã«åã¾ã‚Šã¾ã›ã‚“ã€‚**FSDP** ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¤‡æ•° GPU ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚

**DDPï¼ˆDistributedDataParallelï¼‰ã¨ã®é•ã„**

| æ–¹å¼ | ãƒ¡ãƒ¢ãƒªä½¿ç”¨ | å¯¾è±¡ãƒ¢ãƒ‡ãƒ« |
|------|-----------|-----------|
| **DDP** | å„ GPU ã«**ãƒ¢ãƒ‡ãƒ«å…¨ä½“**ã‚’ã‚³ãƒ”ãƒ¼ | 1 ã¤ã® GPU ã«åã¾ã‚‹ãƒ¢ãƒ‡ãƒ« |
| **FSDP** | å„ GPU ã«**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€éƒ¨**ã ã‘ã‚’ä¿å­˜ | GPU ãƒ¡ãƒ¢ãƒªã‚’è¶…ãˆã‚‹å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ« |

**FSDP ã®ä»•çµ„ã¿**
```
é€šå¸¸ï¼ˆ280GB ãƒ¢ãƒ‡ãƒ«ã€FP32 ã®å ´åˆï¼‰:
GPU 0: [å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 280GB] â†’ ãƒ¡ãƒ¢ãƒªä¸è¶³

FSDPï¼ˆ8 GPU ã«åˆ†æ•£ï¼‰:
GPU 0: [ã‚·ãƒ£ãƒ¼ãƒ‰ 1/8]  35GB
GPU 1: [ã‚·ãƒ£ãƒ¼ãƒ‰ 2/8]  35GB
...
GPU 7: [ã‚·ãƒ£ãƒ¼ãƒ‰ 8/8]  35GB
```

å„ GPU ã¯è‡ªåˆ†ã®æ‹…å½“éƒ¨åˆ†ã ã‘ã‚’ä¿æŒã™ã‚‹ãŸã‚ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚è©³ç´°ã¯ [PyTorch FSDP API ç´¹ä»‹](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

::::

::::details è£œè¶³: SHARDED_STATE_DICT ã¨ PyTorch DCP ã®çµ±åˆ

FSDP ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜æ™‚ã« state_dict ã®å½¢å¼ã‚’é¸æŠã§ãã¾ã™ã€‚

**2 ã¤ã®å½¢å¼**

| å½¢å¼ | èª¬æ˜ | å•é¡Œç‚¹ |
|------|------|--------|
| **FULL_STATE_DICT** | å…¨ GPU ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ 1 ç®‡æ‰€ï¼ˆGPU 0ï¼‰ã«é›†ç´„ | GPU 0 ã®ãƒ¡ãƒ¢ãƒªä¸è¶³ã€é›†ç´„æ™‚é–“ãŒé•·ã„ |
| **SHARDED_STATE_DICT** | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ãŸã¾ã¾ä¿å­˜ | é€šå¸¸ã® torch.save() ã¯éå¯¾å¿œ |

**å¾“æ¥æ–¹å¼ã®å•é¡Œ**
```python
# [NG] å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ GPU 0 ã«é›†ç´„ï¼ˆé…ã„ã€ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼‰
with FSDP.state_dict_type(model, StateDictType.FULL_STATE_DICT):
    state_dict = model.state_dict()  # 280GB ã‚’ GPU 0 ã«é›†ç´„
    torch.save(state_dict, "checkpoint.pt")
```

**PyTorch DCP ã®è§£æ±ºç­–**
```python
# [OK] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ãŸã¾ã¾ä¿å­˜ï¼ˆé€Ÿã„ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
with FSDP.state_dict_type(model, StateDictType.SHARDED_STATE_DICT):
    state_dict = model.state_dict()  # åˆ†å‰²ã•ã‚ŒãŸã¾ã¾
    async_save(state_dict, storage_writer=writer)  # å„ GPU ãŒä¸¦åˆ—ã«ä¿å­˜
```

PyTorch DCP ã¯ `DTensor`ï¼ˆåˆ†æ•£ãƒ†ãƒ³ã‚½ãƒ«ï¼‰ã‚„ `ShardedTensor`ï¼ˆåˆ†å‰²ã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«ï¼‰ã‚’**ãƒã‚¤ãƒ†ã‚£ãƒ–ã«ç†è§£**ã™ã‚‹ãŸã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é›†ç´„ãŒä¸è¦ã§ã™ã€‚å„ GPU ãŒè‡ªåˆ†ã®æ‹…å½“éƒ¨åˆ†ã‚’ä¸¦åˆ—ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€é«˜é€ŸåŒ–ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’ä¸¡ç«‹ã—ã¾ã™ã€‚

è©³ç´°ã¯ [PyTorch Distributed Checkpoint ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

::::

## PyTorch DCP async_save ã®å†…éƒ¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

Managed Tiered Checkpointing ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã™ã‚‹ä¸­æ ¸æŠ€è¡“ã¯ã€DCP ã® **`async_save`** ã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€OSS ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è§£èª¬ã—ã¾ã™ã€‚

### 3 æ®µéšã®æœ€é©åŒ–æˆ¦ç•¥

PyTorch DCP ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®ä¸¦åˆ—åŒ–ã‚’æ®µéšçš„ã«å®Ÿç¾ã—ã¾ã™ï¼ˆ[PyTorch éåŒæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://pytorch.org/tutorials/recipes/distributed_async_checkpoint_recipe.html)ã€[async_save å®Ÿè£…](https://github.com/pytorch/pytorch/blob/main/torch/distributed/checkpoint/state_dict_saver.py)å‚ç…§ï¼‰ã€‚

:::message
æœ¬è¨˜äº‹ã§ã¯ã€ç†è§£ã—ã‚„ã™ã•ã®ãŸã‚æœ€é©åŒ–ã®æ®µéšã‚’ **Level 1 / Level 2 / Level 3** ã¨å‘¼ã‚“ã§ã„ã¾ã™ã€‚ã“ã‚Œã¯ç­†è€…ç‹¬è‡ªã®åˆ†é¡ã§ã‚ã‚Šã€PyTorch å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ŒBasic async_saveã€ã€ŒPinned Memory optimizationã€ã€ŒDefaultStagerã€ã¨ã—ã¦èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚
:::

#### Level 1: åŸºæœ¬çš„ãª async_save

```mermaid
graph LR
    L1A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"] --> L1B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã€ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°"]
    L1B --> L1C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰"]

    style L1A fill: #fff3e0,stroke: #e65100
    style L1B fill: #fff3e0,stroke: #e65100
    style L1C fill: #fff9c4,stroke: #f57f17
```

GPUâ†’CPU ã‚³ãƒ”ãƒ¼ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰ãŒãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€å­¦ç¿’ãŒä¸€æ™‚åœæ­¢ã—ã¾ã™ã€‚ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿ã®ã¿ãŒéåŒæœŸåŒ–ã•ã‚Œã¾ã™ã€‚

**Level 1 ã®èª²é¡Œ**: GPUâ†’CPU ã‚³ãƒ”ãƒ¼ãŒãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆæ•°ç™¾ GBï¼‰ã§ã¯å­¦ç¿’ãŒæ•°ç§’ã‹ã‚‰æ•°åç§’åœæ­¢ã—ã¾ã™ã€‚

#### Level 2: Pinned Memory æœ€é©åŒ–

```mermaid
graph LR
    L2A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"] --> L2B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>Pinned Memoryã€é«˜é€ŸåŒ–"]
    L2B --> L2C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰"]
    L2C -.->|"ãƒãƒƒãƒ•ã‚¡å†åˆ©ç”¨"| L2B

    style L2A fill: #e8f5e9,stroke: #2e7d32
    style L2B fill: #e8f5e9,stroke: #2e7d32
    style L2C fill: #fff9c4,stroke: #f57f17
```

Pinned Memoryï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°ä¸å¯èƒ½ãª CPU ãƒ¡ãƒ¢ãƒªï¼‰ã‚’ä½¿ç”¨ã—ã¦ GPUâ†’CPU è»¢é€ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚ãƒãƒƒãƒ•ã‚¡ã‚’å­¦ç¿’å…¨ä½“ã§å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚‚å‰Šæ¸›ã•ã‚Œã¾ã™ã€‚

**Level 2 ã®èª²é¡Œ**: GPUâ†’CPU ã‚³ãƒ”ãƒ¼ã¯é«˜é€ŸåŒ–ã•ã‚Œã¾ã—ãŸãŒã€ä¾ç„¶ã¨ã—ã¦ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚å­¦ç¿’ã®ä¸€æ™‚åœæ­¢ãŒç™ºç”Ÿã—ã¾ã™ã€‚

#### Level 3: DefaultStager (PyTorch 2.9+)

**Level 3 ã®æ”¹å–„**: Level 2 ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€GPUâ†’CPU ã‚³ãƒ”ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã«å®Œå…¨ã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã—ã€å­¦ç¿’è¨ˆç®—ã¨ä¸¦åˆ—å®Ÿè¡Œã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```mermaid
graph LR
    L3A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"]
    L3B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰"]
    L3C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰"]

    L3A -.->|"ä¸¦åˆ—å®Ÿè¡Œ"| L3B
    L3B --> L3C

    style L3A fill: #e3f2fd,stroke: #1565c0
    style L3B fill: #c8e6c9,stroke: #388e3c
    style L3C fill: #fff9c4,stroke: #f57f17
```

state dict ã®æ§‹ç¯‰ã¨ GPUâ†’CPU ã‚³ãƒ”ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã«å®Œå…¨ã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å­¦ç¿’è¨ˆç®—ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ãŒçœŸã®ä¸¦åˆ—å®Ÿè¡Œã¨ãªã‚Šã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãŒå­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚

### Managed Tiered Checkpointing ã¨ã®çµ±åˆ

Managed Tiered Checkpointing ã¯ã€PyTorch DCP ã® `async_save()` ã‚’ä½¿ç”¨ã—ã¦éåŒæœŸä¿å­˜ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ï¼ˆ[ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)å‚ç…§ï¼‰ã€‚ä½¿ç”¨ã™ã‚‹ PyTorch ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚„è¨­å®šã«ã‚ˆã£ã¦ã€ä¸Šè¨˜ã® Level 1/2/3 ã„ãšã‚Œã‹ã®æœ€é©åŒ–ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚

```mermaid
graph LR
    subgraph Training["å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹<br/>ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰"]
        GPU["GPU è¨ˆç®—<br/>Forward/Backward"]
    end

    subgraph Staging["ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°<br/>ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰"]
        DICT["State Dict æ§‹ç¯‰"]
        COPY["GPU â†’ CPU<br/>ãƒ¡ãƒ¢ãƒªè»¢é€"]
    end

    subgraph Upload["ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br/>éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰"]
        TIER1["Tier 1<br/>CPU ãƒ¡ãƒ¢ãƒªä¿å­˜"]
        TIER2["Tier 2<br/>S3 ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]
    end

    GPU -.->|"ä¸¦åˆ—å®Ÿè¡Œ"| DICT
    DICT --> COPY
    COPY --> TIER1
    TIER1 --> TIER2

    style Training fill: #e3f2fd,stroke: #1565c0
    style Staging fill: #e8f5e9,stroke: #2e7d32
    style Upload fill: #fff3e0,stroke: #e65100
    style GPU fill: #bbdefb,stroke: #1976d2
```

ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€**GPU è¨ˆç®—ï¼ˆå­¦ç¿’ï¼‰ã€ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆGPUâ†’CPU è»¢é€ï¼‰ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆS3 ä¿å­˜ï¼‰ãŒ 3 æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ä¸¦åˆ—å®Ÿè¡Œ**ã•ã‚Œã¾ã™ã€‚å­¦ç¿’ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€å‰ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†ã‚’å¾…ãŸãšã«é–‹å§‹ã§ãã‚‹ãŸã‚ã€å­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ä½ä¸‹ãŒæŠ‘åˆ¶ã•ã‚Œã¾ã™ã€‚

:::message
**ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: Level 3 ã® DefaultStager ã¯ã€GPU ãƒ¡ãƒ¢ãƒªã¨ CPU ãƒ¡ãƒ¢ãƒªã®ä¸¡æ–¹ã«ãƒ¢ãƒ‡ãƒ«ã® state dict ã‚’ä¸€æ™‚çš„ã«ä¿æŒã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ ã—ã¾ã™ã€‚å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€CPU ãƒ¡ãƒ¢ãƒªå®¹é‡ã®è¨ˆç”»ãŒé‡è¦ã§ã™ã€‚Managed Tiered Checkpointing ã§ã¯ã€`InstanceMemoryAllocationPercentage`ï¼ˆ20-100%ï¼‰ã§ã“ã®ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚
:::

## ã¾ã¨ã‚

Managed Tiered Checkpointing ã¯ã€å¤§è¦æ¨¡åˆ†æ•£å­¦ç¿’ã«ãŠã‘ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã«å¯¾ã™ã‚‹å®Ÿç”¨çš„ãªæ©Ÿèƒ½ã§ã™ã€‚å€‹äººçš„ã«ã¯å…¨ã¦ FSx for Lustre ã§æ§‹ç¯‰ã—ã¦ã„ã‚‹äººãŸã¡ãŒã“ã®æ©Ÿèƒ½ã‚’æ–°ãŸã«ä½¿ã†ã‹ã¨ã„ã†ã¨ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®å®Ÿå‹™ãƒã‚¦ãƒã‚¦ãŒãªã„ã®ã§æ­£ç›´ã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ã€‚2 éšå±¤ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†ã™ã‚‹éšå±¤åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šé€Ÿåº¦ã¨è€ä¹…æ€§ã‚’ä¸¡ç«‹ã™ã‚‹æ‰‹æ³•è‡ªä½“ã¯å„ªã‚Œã¦ã„ã‚‹ã¨æ„Ÿã˜ã¾ã™ã—ã€ãƒãƒãƒ¼ã‚¸ãƒ‰ã§ã‚„ã‚‰ãªã„ã¨ã—ã¦ã‚‚ãƒã‚¤ãƒ†ã‚£ãƒ–ã« PyTorch DCP ã® `async_save()` ã«ã‚ˆã‚‹éåŒæœŸä¿å­˜ã§å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹å¯¾å¿œã‚’å®Ÿè£…ã™ã‚‹ã®ã¯æœ‰ç”¨ãã†ã§ã™ã€‚

:::message
**Checkpointless Training ã¨ã®é•ã„**: AWS SageMaker HyperPod ã§ã¯ã€åˆ¥ã®éšœå®³å¾©æ—§æ©Ÿèƒ½ã¨ã—ã¦ [Checkpointless Training](https://zenn.dev/yunokiisshin/articles/45a746434b2090) ã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚Checkpointless Training ã¯ GPU ãƒ¡ãƒ¢ãƒªå†…ã®å†—é•·ãƒ¬ãƒ—ãƒªã‚«ã«ã‚ˆã‚‹é«˜é€Ÿ in-memory å¾©æ—§ã«ç‰¹åŒ–ã—ï¼ˆNeMo Framework å¿…é ˆï¼‰ã€Managed Tiered Checkpointing ã¯ PyTorch DCP ã‚’ä½¿ç”¨ã—ãŸéšå±¤åŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ã‚ˆã‚‹æŸ”è»Ÿãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚’æä¾›ã—ã¾ã™ã€‚ãã‚Œãã‚Œç•°ãªã‚‹æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ä½µç”¨å¯èƒ½æ€§ã«ã¤ã„ã¦ã¯ä»Šå¾Œèª¿æŸ»ã‚’é€²ã‚ã¾ã™ã€‚
:::

## å‚è€ƒè³‡æ–™

- [Managed Tiered Checkpointing ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing.html)
- [Managed Tiered Checkpointing ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)
- [amzn-sagemaker-checkpointing (PyPI)](https://pypi.org/project/amzn-sagemaker-checkpointing/) -- v1.1.2
- [aws-samples/awsome-distributed-training (GitHub)](https://github.com/aws-samples/awsome-distributed-training)
- [AI on SageMaker HyperPod](https://awslabs.github.io/ai-on-sagemaker-hyperpod/) -- HyperPod ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- [PyTorch Distributed Checkpoint](https://pytorch.org/docs/stable/distributed.checkpoint.html)
- [PyTorch Distributed Checkpoint Tutorial](https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html)
- [PyTorch Asynchronous Checkpoint Tutorial](https://pytorch.org/tutorials/recipes/distributed_async_checkpoint_recipe.html) -- async_save ã®è©³ç´°å®Ÿè£…è§£èª¬
- [PyTorch DCP state_dict_saver.py](https://github.com/pytorch/pytorch/blob/main/torch/distributed/checkpoint/state_dict_saver.py) -- async_save ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
- [PyTorch FSDP](https://pytorch.org/docs/stable/fsdp.html)
- [Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/)
- [FSx for Lustre Data Repository Association](https://docs.aws.amazon.com/fsx/latest/LustreGuide/create-dra-linked-data-repo.html)
- [s3torchconnector](https://github.com/amazon-science/s3torchconnector) -- S3 ã‹ã‚‰ã®ç›´æ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

[^1]: ã‚³ã‚¹ãƒˆæ•°å€¤ã¯ FSx for Lustre SSD ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰æ–™é‡‘ï¼ˆç´„ $140/TB-monthï¼‰ã«ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®¹é‡ã‚„ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° IOPS ã®è¿½åŠ æ–™é‡‘ã‚’å«ã‚ãŸæ¦‚ç®—ã§ã™ã€‚S3 Standard ã®æ–™é‡‘ã¯ä¸€èˆ¬çš„ãªæ–™é‡‘ã«åŸºã¥ãã¾ã™ã€‚å®Ÿéš›ã®æ–™é‡‘ã¯ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹ã€ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ç­‰ã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ã€‚æœ€æ–°ã®æ–™é‡‘ã¯ [AWS å…¬å¼æ–™é‡‘ãƒšãƒ¼ã‚¸](https://aws.amazon.com/pricing/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
[^2]: FSx for Lustre ã¸ã®æ›¸ãè¾¼ã¿æ™‚é–“ã¯ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹æˆã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé »åº¦ã€FSx ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨­å®šã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ã€‚FSx for Lustre ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ€§èƒ½ã¯ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦è¨­å®šå¯èƒ½ã§ã™ã€‚è©³ç´°ã¯ [Amazon FSx for Lustre ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹](https://docs.aws.amazon.com/fsx/latest/LustreGuide/performance.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
[^3]: Managed Tiered Checkpointing ã®[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing.html)ã§ã¯ "Improved training throughput" ã¨å®šæ€§çš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ãŒã€å…·ä½“çš„ãªå‰Šæ¸›ç‡ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
[^4]: Tier 1 ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã®æ‰€è¦æ™‚é–“ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒãƒ¼ãƒ‰é–“ã®å¸¯åŸŸå¹…ã«ä¾å­˜ã—ã¾ã™ã€‚å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯å…·ä½“çš„ãªæ‰€è¦æ™‚é–“ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ãŒã€ãƒ‡ã‚£ã‚¹ã‚¯ I/O ã‚ˆã‚Šã‚‚é«˜é€Ÿãªãƒ¡ãƒ¢ãƒªæ“ä½œã§ã‚ã‚‹ã“ã¨ã‹ã‚‰ã€å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ã‚’æœ€å°åŒ–ã§ãã¾ã™ã€‚
