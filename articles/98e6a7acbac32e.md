---
title: "Amazon SageMaker HyperPod -- Managed Tiered Checkpointing"
emoji: "ğŸ’¾"
type: "tech"
topics: ["AWS", "SageMaker", "HyperPod", "åˆ†æ•£å­¦ç¿’", "Checkpoint"]
published: false
---

## ã¯ã˜ã‚ã«

æœ¬è¨˜äº‹ã¯ SageMaker HyperPod æ©Ÿèƒ½è§£èª¬ã‚·ãƒªãƒ¼ã‚ºã®ä¸€éƒ¨ã§ã™ã€‚ä»¥ä¸‹ã‚‚ã™ã§ã«è¨˜äº‹ã¨ã—ã¦æ›¸ã„ã¦ã‚ã‚‹ã®ã§å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚

https://zenn.dev/yunokiisshin/articles/45a746434b2090

å¤§è¦æ¨¡ãªåˆ†æ•£å­¦ç¿’ã§ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãŒå­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ä½ä¸‹è¦å› ã«ãªã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒæ•°åã‹ã‚‰æ•°ç™¾ GB ã«åŠã¶å ´åˆã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ›¸ãè¾¼ã¿ã«æ•°åˆ†ã‹ã‚‰æ•°ååˆ†ã‚’è¦ã—ã€ãã®é–“ GPU ã¯å¾…æ©ŸçŠ¶æ…‹ã¨ãªã‚Šã¾ã™ã€‚

Amazon SageMaker HyperPod ã® **Managed Tiered Checkpointing** ã¯ã€ä¿å­˜å…ˆã‚’ CPU ãƒ¡ãƒ¢ãƒªã¨ Amazon S3 ã® 2 éšå±¤ã«åˆ†ã‘ã‚‹ã“ã¨ã§ã€ä¿å­˜ã®é«˜é€ŸåŒ–ã¨ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’ä¸¡ç«‹ã™ã‚‹æ©Ÿèƒ½ã§ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ä»•çµ„ã¿ã€å®Ÿè£…æ–¹æ³•ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã€ãŠã‚ˆã³ FSx for Lustre + DRA ã¨ã®ä½¿ã„åˆ†ã‘ã‚’è§£èª¬ã—ã¾ã™ã€‚

:::message
**å®Ÿéš›ã«è©¦ã™éš›ã®æ¨å¥¨ãƒªãƒã‚¸ãƒˆãƒª**: Managed Tiered Checkpointing ã‚’è©¦ã™éš›ã¯ã€AWS ã® GenAI Frameworks team ãŒç®¡ç†ã™ã‚‹ [`awsome-distributed-training`](https://github.com/aws-samples/awsome-distributed-training) ãƒªãƒã‚¸ãƒˆãƒªã®åˆ©ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚å®Ÿç¸¾ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã¨ã‚µãƒ³ãƒ—ãƒ«ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ç’°å¢ƒæ§‹ç¯‰ã‚’åŠ¹ç‡åŒ–ã§ãã¾ã™ã€‚ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¨ã—ã¦ã¯ [AI on SageMaker HyperPod](https://awslabs.github.io/ai-on-sagemaker-hyperpod/) ã‚‚ãŠã™ã™ã‚ã§ã™ã€‚
:::

:::message alert
æœ¬è¨˜äº‹ã¯ 2026 å¹´ 2 æœˆæ™‚ç‚¹ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€ãªã©ã«åŸºã¥ãèª¿æŸ»è¨˜äº‹ã§ã™ã€‚é–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚‹ãŸã‚å¿…ãšæœ€æ–°ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ­£ã¨ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚é–“é•ã„ãŒã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆãã ã•ã„ã€‚
:::

## æ¦‚è¦

:::message
æœ¬æ©Ÿèƒ½ã¯ [EKS ç’°å¢ƒã§ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ãŒå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)ã•ã‚Œã¦ã„ã¾ã™ã€‚Slurm ç’°å¢ƒã§ã®åˆ©ç”¨å¯å¦ã«ã¤ã„ã¦ã¯ã€å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ˜ç¤ºçš„ãªè¨˜è¼‰ãŒãªã„ãŸã‚ã€æœ€æ–°ã®æƒ…å ±ã‚’ AWS ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**FSx for Lustre ã¨ã®ä½µç”¨ã«ã¤ã„ã¦**: Managed Tiered Checkpointing ã¨ FSx for Lustre + DRA ã¯æŠ€è¡“çš„ã«ä½µç”¨å¯èƒ½ã§ã™ãŒã€ã©ã¡ã‚‰ã‚‚ Amazon S3 ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ°¸ç¶šåŒ–ã™ã‚‹ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®å½¹å‰²ãŒé‡è¤‡ã—ã¾ã™ã€‚FSx ãŒæ§‹ç¯‰æ¸ˆã¿ã®å ´åˆã¯ã€FSx ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜ã«ã€Managed Tiered Checkpointing ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã«ä½¿ã„åˆ†ã‘ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼ˆè©³ç´°ã¯ã€Œä½¿ã„åˆ†ã‘ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‚ç…§ï¼‰ã€‚
:::

### å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: FSx for Lustre + DRA

Managed Tiered Checkpointing ã®å°å…¥ä»¥å‰ã€HyperPod ã§ã¯ **[FSx for Lustre](https://aws.amazon.com/fsx/lustre/) + [DRAï¼ˆData Repository Associationï¼‰](https://docs.aws.amazon.com/fsx/latest/LustreGuide/create-dra-linked-data-repo.html)** ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãŒæ¨™æº–çš„ã§ã—ãŸã€‚

```mermaid
graph LR
    TN["å­¦ç¿’ãƒãƒ¼ãƒ‰"] -->|"torch.save<br/>5-30 ç§’<br/>å­¦ç¿’ã®ä¸­æ–­"| FSx["FSx for Lustre<br/>å…±æœ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"]
    FSx -->|"DRA<br/>å¤‰æ›´æ¤œçŸ¥"| DRA["Data Repository<br/>Association"]
    DRA -->|"ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰<br/>ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ<br/>æ•°åˆ†"| S3["Amazon S3<br/>æ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"]

    style TN fill: #1a237e,color: #ffffff
    style FSx fill: #0d47a1,color: #ffffff
    style DRA fill: #1565c0,color: #ffffff
    style S3 fill: #1976d2,color: #ffffff
```

å¾“æ¥æ–¹å¼ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¯ã€å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒ `torch.save()` ã§ FSx ã«æ›¸ãè¾¼ã¿ï¼ˆ5-30 ç§’ã€å­¦ç¿’ã‚’ä¸­æ–­ï¼‰ã€DRA ãŒå¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¦ S3 ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ S3 ã«æ°¸ç¶šåŒ–ï¼ˆæ•°åˆ†ï¼‰ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚ã“ã®æ–¹å¼ã«ã¯ã€å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ï¼ˆ5-30 ç§’ï¼‰ã€FSx ã®é«˜ã‚³ã‚¹ãƒˆï¼ˆæœˆé¡ $140-$500/TBï¼‰ã€S3 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé…å»¶ã€å®¹é‡ç®¡ç†ã¨ã„ã£ãŸèª²é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚

Managed Tiered Checkpointing ã¯ã“ã‚Œã‚‰ã®èª²é¡Œã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«è§£æ±ºã—ã¾ã™ã€‚

| æ¯”è¼ƒé …ç›® | FSx + DRAï¼ˆå¾“æ¥ï¼‰ | Managed Tiered Checkpointing |
|---------|------------------|----------------------------|
| å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ | 5-30 ç§’ï¼ˆFSx æ›¸ãè¾¼ã¿ï¼‰ | 1-2 ç§’ï¼ˆãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ï¼‰ |
| æœˆé¡ã‚³ã‚¹ãƒˆï¼ˆ1.2 TB æƒ³å®šï¼‰ | $180ï¼ˆFSxï¼‰+ $32ï¼ˆS3ï¼‰[^1] | $32ï¼ˆS3 ã®ã¿ï¼‰[^1] |
| ãƒãƒ¼ãƒ‰éšœå®³æ™‚ã®å¾©æ—§ | æ•°åˆ†ï¼ˆFSx ã¾ãŸã¯ S3 ã‹ã‚‰å¾©å…ƒï¼‰ | æ•°ç§’ï¼ˆãƒ¡ãƒ¢ãƒªãƒ¬ãƒ—ãƒªã‚«ã‹ã‚‰å¾©æ—§ï¼‰ |
| ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ | æ•°ç™¾ãƒãƒ¼ãƒ‰ï¼ˆFSx ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°åˆ¶é™ã‚ã‚Šï¼‰ | æ•°åƒãƒãƒ¼ãƒ‰ï¼ˆå„ãƒãƒ¼ãƒ‰ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ï¼‰ |
| S3 ä¿å­˜å½¢å¼ | å˜ä¸€ã® `.pt` ãƒ•ã‚¡ã‚¤ãƒ« | PyTorch DCP ã® sharded checkpointï¼ˆ`.distcp`ï¼‰ |
| æ¨å¥¨ã‚±ãƒ¼ã‚¹ | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ãŒå¿…é ˆãªæ—¢å­˜æ§‹æˆ | æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ã‚³ã‚¹ãƒˆæœ€é©åŒ– |

ä»¥é™ã§ã¯ã€Managed Tiered Checkpointing ã®ä»•çµ„ã¿ã¨å®Ÿè£…æ–¹æ³•ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

## éšå±¤åŒ–æˆ¦ç•¥

Managed Tiered Checkpointing ã¯ **2 ã¤ã®éšå±¤**ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†ã—ã¾ã™ã€‚é«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ä¸»è¦å±¤ã¨ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã® **CPU ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰** ã‚’ä½¿ç”¨ã—ã€æ°¸ç¶šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ã®å‰¯æ¬¡å±¤ã¨ã—ã¦ **Amazon S3** ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```mermaid
graph TB
    subgraph "Tier 1: CPU ãƒ¡ãƒ¢ãƒª -- é«˜é€Ÿãƒ»ä¸»è¦å±¤"
        M1["ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰ã®<br/>CPU ãƒ¡ãƒ¢ãƒª (RAM)<br/>é€Ÿåº¦: GB/s"]
        M2["éš£æ¥ãƒãƒ¼ãƒ‰ã¸ã®<br/>è‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"]
    end

    subgraph "Tier 2: Amazon S3 -- è€ä¹…æ€§ãƒ»å‰¯æ¬¡å±¤"
        S1["S3 ãƒã‚±ãƒƒãƒˆ<br/>æ°¸ç¶šä¿å­˜å…ˆ<br/>è€ä¹…æ€§: 99.999999999%"]
    end

    M1 -->|"è‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆ"| M2
    M1 -->|"å®šæœŸçš„ã«<br/>éåŒæœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"| S1

    style M1 fill: #1b5e20,color: #ffffff
    style M2 fill: #2e7d32,color: #ffffff
    style S1 fill: #0d47a1,color: #ffffff
```

| éšå±¤ | ä¿å­˜å…ˆ | é€Ÿåº¦ | è€ä¹…æ€§ | ç”¨é€” |
|------|--------|------|--------|------|
| Tier 1 | CPU ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰ | é«˜é€Ÿï¼ˆGB/sï¼‰ | ãƒãƒ¼ãƒ‰é–“ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä¿è­· | é«˜é »åº¦ä¿å­˜ãƒ»é«˜é€Ÿå¾©æ—§ |
| Tier 2 | Amazon S3 | ä½é€Ÿï¼ˆæ•°ç™¾ MB/sï¼‰ | é«˜è€ä¹…ï¼ˆ99.999999999%ï¼‰ | ä½é »åº¦ä¿å­˜ï¼ˆæ°¸ç¶šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰ |

### ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥

Tier 1ï¼ˆCPU ãƒ¡ãƒ¢ãƒªï¼‰ã«ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã€**éš£æ¥ã™ã‚‹è¨ˆç®—ãƒãƒ¼ãƒ‰é–“ã§è‡ªå‹•çš„ã«ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ãƒˆ**ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å˜ä¸€ã¾ãŸã¯è¤‡æ•°ã®ãƒãƒ¼ãƒ‰éšœå®³æ™‚ã«ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ã—ã€é«˜é€Ÿã«å¾©æ—§ã§ãã¾ã™ã€‚

ãƒ¡ãƒ¢ãƒªç®¡ç†ã¯ã€EKS ç’°å¢ƒã§ã¯ Kubernetes DaemonSet ã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ‡ãƒ¼ãƒ¢ãƒ³ãŒæ‹…å½“ã—ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã®åˆ†æ•£ãƒ¡ãƒ¢ãƒªï¼ˆdisaggregated memoryï¼‰ã‚’ç®¡ç†ã—ã¾ã™ã€‚

:::message
`InstanceMemoryAllocationPercentage` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç”¨ã«å‰²ã‚Šå½“ã¦ã‚‹ CPU ãƒ¡ãƒ¢ãƒªã®å‰²åˆã‚’è¨­å®šã§ãã¾ã™ï¼ˆ0-100%ï¼‰ã€‚å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãŒä½¿ç”¨ã™ã‚‹ãƒ¡ãƒ¢ãƒªã¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚

è¨­å®šä¾‹ï¼ˆ`--tiered-storage-config` å†…ã«å«ã‚ã‚‹ï¼‰:
```json
{
  "Mode": "Enable",
  "InstanceMemoryAllocationPercentage": 50
}
```
:::

## éåŒæœŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

æœ€å¤§ã®ç‰¹å¾´ã¯ã€**å­¦ç¿’ã‚’ä¸­æ–­ã›ãšã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜**ã§ãã‚‹ç‚¹ã§ã™ã€‚[PyTorch DCPï¼ˆDistributed Checkpointï¼‰](https://pytorch.org/docs/stable/distributed.checkpoint.html)ã® `async_save()` ã«ã‚ˆã‚ŠéåŒæœŸä¿å­˜ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

```mermaid
graph TB
    subgraph "å¾“æ¥æ–¹å¼ -- åŒæœŸä¿å­˜"
        direction LR
        A1["å­¦ç¿’"] --> A2["ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ<br/>ä¿å­˜ 5-30 ç§’<br/>å­¦ç¿’ä¸­æ–­"] --> A3["å­¦ç¿’"] --> A4["ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ<br/>ä¿å­˜ 5-30 ç§’<br/>å­¦ç¿’ä¸­æ–­"] --> A5["å­¦ç¿’"]
    end

    subgraph "Tiered Checkpointing -- éåŒæœŸä¿å­˜"
        direction LR
        B1["å­¦ç¿’ -- ä¸­æ–­ãªã—"]
        B2["Tier1: RAM ã‚³ãƒ”ãƒ¼<br/>1-2 ç§’"] -.->|"ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰"| B3["Tier2: S3<br/>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]
    end

    style A2 fill: #b71c1c,color: #ffffff
    style A4 fill: #b71c1c,color: #ffffff
    style B1 fill: #1b5e20,color: #ffffff
    style B2 fill: #f57f17,color: #000000
    style B3 fill: #0d47a1,color: #ffffff
```

å¾“æ¥æ–¹å¼ã§ã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ä¸­ã«å­¦ç¿’ãŒä¸­æ–­ã•ã‚Œã¾ã™ï¼ˆå›³ã®èµ¤è‰²ãƒãƒ¼ãƒ‰ï¼‰ã€‚Tiered Checkpointing ã§ã¯ Tier 1ï¼ˆRAMï¼‰ã¸ã®ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆ1-2 ç§’ï¼‰å¾Œã™ãã«å­¦ç¿’ã‚’å†é–‹ã§ãã€S3 ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éåŒæœŸã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

## å®Ÿè£…ã¨ API

### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ§‹æˆ

Managed Tiered Checkpointing ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½œæˆæ™‚ã« `--tiered-storage-config` ã§æœ‰åŠ¹åŒ–ã—ã¾ã™ï¼ˆ[ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)å‚ç…§ï¼‰ã€‚

**EKS ç’°å¢ƒã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹æˆä¾‹**:

```bash
aws sagemaker create-cluster \
    --cluster-name my-training-cluster \
    --orchestrator "Eks={ClusterArn=arn: aws: eks: us-west-2:123456789012: cluster/my-eks}" \
    --instance-groups '[{
        "InstanceGroupName": "training-group",
        "InstanceType": "ml.p5.48xlarge",
        "InstanceCount": 4,
        "LifeCycleConfig": {
            "SourceS3Uri": "s3://my-bucket/lifecycle-scripts",
            "OnCreate": "on_create.sh"
        },
        "ExecutionRole": "arn: aws: iam::123456789012: role/MyRole",
        "InstanceStorageConfigs": [
            { "EbsVolumeConfig": {"VolumeSizeInGB": 500} }
        ]
    }]' \
    --vpc-config '{
        "SecurityGroupIds": ["sg-xxxxxxxxxxxxxxxxx"],
        "Subnets": ["subnet-xxxxxxxxxxxxxxxxx"]
    }' \
    --tiered-storage-config '{"Mode": "Enable"}'
```

**ç„¡åŠ¹åŒ–ã™ã‚‹å ´åˆ**:

```bash
aws sagemaker update-cluster \
    --cluster-name my-training-cluster \
    --tiered-storage-config '{"Mode": "Disable"}'
```

### Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

å°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª [`amzn-sagemaker-checkpointing`](https://pypi.org/project/amzn-sagemaker-checkpointing/)ï¼ˆv1.1.2ã€Apache License 2.0ã€Python 3.10 ä»¥ä¸Šï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚`sagemaker` SDK ã¨ã¯åˆ¥ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã™ã€‚

```bash
pip install amzn-sagemaker-checkpointing s3torchconnector tenacity torch boto3
```

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š

```python
import os
import time
import torch.distributed as dist
from amzn_sagemaker_checkpointing.config.sagemaker_checkpoint_config import (
    SageMakerCheckpointConfig,
)
from amzn_sagemaker_checkpointing.checkpointing.filesystem.filesystem import (
    SageMakerTieredStorageWriter,
    SageMakerTieredStorageReader,
)

# åˆ†æ•£å­¦ç¿’ã®åˆæœŸåŒ–
dist.init_process_group(backend="nccl")

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š
checkpoint_config = SageMakerCheckpointConfig(
    namespace=os.environ.get("TRAINING_JOB_NAME", f"job-{int(time.time())}"),
    # namespace ã«ä½¿ç”¨å¯èƒ½ãªæ–‡å­—: è‹±æ•°å­—ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿
    world_size=dist.get_world_size(),
    s3_tier_base_path="s3://my-bucket/checkpoints",
)
```

`SageMakerCheckpointConfig` ã®ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | èª¬æ˜ |
|---|---|---|
| `namespace` | str | å­¦ç¿’ã‚¸ãƒ§ãƒ–ã®ä¸€æ„ãªè­˜åˆ¥å­ï¼ˆè‹±æ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³ãƒ»ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿ï¼‰ |
| `world_size` | int | åˆ†æ•£ãƒ—ãƒ­ã‚»ã‚¹æ•°ï¼ˆ`dist.get_world_size()` ã‹ã‚‰å–å¾—ï¼‰ |
| `s3_tier_base_path` | str | S3 ä¿å­˜å…ˆãƒ‘ã‚¹ |
| `save_to_s3` | bool | S3 ã¸ã®ä¿å­˜ã‚’æœ‰åŠ¹åŒ–ï¼ˆä¿å­˜ã”ã¨ã«å‹•çš„ã«åˆ‡æ›¿å¯èƒ½ï¼‰ |

### å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¸ã®çµ±åˆ

[PyTorch DCPï¼ˆDistributed Checkpointï¼‰](https://pytorch.org/docs/stable/distributed.checkpoint.html)ã® `async_save()` / `load()` ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã¯ [AWS å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)ã«åŸºã¥ãã‚³ãƒ¼ãƒ‰ä¾‹ã§ã™ã€‚

```python
from torch.distributed.checkpoint import async_save, load

future = None
in_memory_ckpt_freq = 10   # 10 ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ¡ãƒ¢ãƒªä¿å­˜
s3_ckpt_freq = 50           # 50 ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã« S3 æ°¸ç¶šåŒ–

for step, batch in enumerate(dataloader):
    # é€šå¸¸ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—
    loss = model(batch)
    loss.backward()
    optimizer.step()

    # Tiered Checkpointing: éåŒæœŸã§ä¿å­˜
    if step % in_memory_ckpt_freq == 0 or step % s3_ckpt_freq == 0:
        state_dict = {
            "model": model.state_dict(),
            "optimizer": optimizer.state_dict(),
            "step": step,
        }

        # S3 ã¸ã®ä¿å­˜ã¯ã‚ˆã‚Šä½ã„é »åº¦ã§å®Ÿè¡Œ
        checkpoint_config.save_to_s3 = (step % s3_ckpt_freq == 0)

        storage_writer = SageMakerTieredStorageWriter(
            checkpoint_config=checkpoint_config,
            step=step,
        )

        # å‰å›ã®éåŒæœŸä¿å­˜ã®å®Œäº†ã‚’ç¢ºèª
        if future is not None:
            exc = future.exception()
            if exc is not None:
                print(f"Checkpoint save failed: {str(exc)}")

        future = async_save(state_dict=state_dict, storage_writer=storage_writer)
```

:::message
**FSDP ã¨ã®çµ±åˆ**: [FSDPï¼ˆFully Sharded Data Parallelï¼‰](https://pytorch.org/docs/stable/fsdp.html)ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€`model.state_dict()` ã¯ `SHARDED_STATE_DICT` å½¢å¼ã§è¿”ã•ã‚Œã¾ã™ã€‚PyTorch DCP ã¯ã“ã®å½¢å¼ã‚’ç›´æ¥æ‰±ãˆã‚‹ãŸã‚ã€è¿½åŠ ã®å¤‰æ›ã¯ä¸è¦ã§ã™ã€‚FSDP ã® `StateDictType.SHARDED_STATE_DICT` ã‚’è¨­å®šã—ãŸä¸Šã§ä¸Šè¨˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãã®ã¾ã¾é©ç”¨ã§ãã¾ã™ã€‚
:::

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿

`SageMakerTieredStorageReader` ã¯ã€ãƒ¡ãƒ¢ãƒªå±¤ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã™ã‚‹ã¨è‡ªå‹•çš„ã« S3 å±¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚

```python
state_dict = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "step": 0,  # åˆæœŸå€¤ã€‚load() ã«ã‚ˆã‚Šå®Ÿéš›ã®ä¿å­˜å€¤ã§ä¸Šæ›¸ãã•ã‚Œã‚‹
}

# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿ï¼ˆstep çœç•¥æ™‚ï¼‰
storage_reader = SageMakerTieredStorageReader(
    checkpoint_config=checkpoint_config,
)

try:
    load(state_dict, storage_reader=storage_reader)
    # load() ã¯ state_dict ã‚’ in-place ã§æ›´æ–°ã™ã‚‹
    # èª­ã¿è¾¼ã¿å¾Œã€ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã«åæ˜ 
    model.load_state_dict(state_dict["model"])
    optimizer.load_state_dict(state_dict["optimizer"])
    start_step = state_dict["step"]
except BaseException as e:
    print(f"Checkpoint load failed: {str(e)}")

# ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã¿
storage_reader = SageMakerTieredStorageReader(
    checkpoint_config=checkpoint_config,
    step=500,
)

try:
    load(state_dict, storage_reader=storage_reader)
    model.load_state_dict(state_dict["model"])
    optimizer.load_state_dict(state_dict["optimizer"])
except BaseException as e:
    print(f"Checkpoint load failed at step 500: {str(e)}")
```

## PyTorch DCP async_save ã®å†…éƒ¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

Managed Tiered Checkpointing ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã™ã‚‹ä¸­æ ¸æŠ€è¡“ã¯ã€PyTorch Distributed Checkpointï¼ˆDCPï¼‰ã® **`async_save`** ã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€OSS ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è§£èª¬ã—ã¾ã™ã€‚

### 3 æ®µéšã®æœ€é©åŒ–æˆ¦ç•¥

PyTorch DCP ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®ä¸¦åˆ—åŒ–ã‚’æ®µéšçš„ã«å®Ÿç¾ã—ã¾ã™ï¼ˆ[PyTorch éåŒæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://docs.pytorch.org/tutorials/recipes/distributed_async_checkpoint_recipe.html)ã€[async_save å®Ÿè£…](https://github.com/pytorch/pytorch/blob/main/torch/distributed/checkpoint/state_dict_saver.py)å‚ç…§ï¼‰ã€‚

```mermaid
graph TB
    subgraph Level1["Level 1: åŸºæœ¬çš„ãª async_save"]
        L1A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"] --> L1B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>(ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã€ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°)"]
        L1B --> L1C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>(éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰)"]
    end

    subgraph Level2["Level 2: Pinned Memory æœ€é©åŒ–"]
        L2A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"] --> L2B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>(Pinned Memoryã€é«˜é€ŸåŒ–)"]
        L2B --> L2C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>(éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰)"]
        L2C -.->|"ãƒãƒƒãƒ•ã‚¡å†åˆ©ç”¨"| L2B
    end

    subgraph Level3["Level 3: DefaultStager (PyTorch 2.9+)"]
        L3A["GPU è¨ˆç®—<br/>å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"]
        L3B["GPU â†’ CPU ã‚³ãƒ”ãƒ¼<br/>(ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰)"]
        L3C["ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿<br/>(éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰)"]

        L3A -.->|"ä¸¦åˆ—å®Ÿè¡Œ"| L3B
        L3B --> L3C
    end

    style Level1 fill: #fff3e0,stroke: #e65100
    style Level2 fill: #e8f5e9,stroke: #2e7d32
    style Level3 fill: #e3f2fd,stroke: #1565c0
    style L3A fill: #bbdefb,stroke: #1976d2
    style L3B fill: #c8e6c9,stroke: #388e3c
    style L3C fill: #fff9c4,stroke: #f57f17
```

**Level 1** ã§ã¯ã€GPUâ†’CPU ã‚³ãƒ”ãƒ¼ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰ãŒãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€å­¦ç¿’ãŒä¸€æ™‚åœæ­¢ã—ã¾ã™ã€‚ãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿ã®ã¿ãŒéåŒæœŸåŒ–ã•ã‚Œã¾ã™ã€‚

**Level 2** ã§ã¯ã€Pinned Memoryï¼ˆãƒšãƒ¼ã‚¸ãƒ³ã‚°ä¸å¯èƒ½ãª CPU ãƒ¡ãƒ¢ãƒªï¼‰ã‚’ä½¿ç”¨ã—ã¦ GPUâ†’CPU è»¢é€ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚ãƒãƒƒãƒ•ã‚¡ã‚’å­¦ç¿’å…¨ä½“ã§å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚‚å‰Šæ¸›ã•ã‚Œã¾ã™ã€‚

**Level 3**ï¼ˆPyTorch 2.9+ ã® **DefaultStager**ï¼‰ã§ã¯ã€state dict ã®æ§‹ç¯‰ã¨ GPUâ†’CPU ã‚³ãƒ”ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã«å®Œå…¨ã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å­¦ç¿’è¨ˆç®—ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ãŒçœŸã®ä¸¦åˆ—å®Ÿè¡Œã¨ãªã‚Šã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãŒå­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚

### Managed Tiered Checkpointing ã¨ã®çµ±åˆ

Managed Tiered Checkpointing ã¯ã€ã“ã® Level 3 ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚

```mermaid
graph LR
    subgraph Training["å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"]
        GPU["GPU è¨ˆç®—<br/>Forward/Backward"]
    end

    subgraph Staging["ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"]
        DICT["State Dict æ§‹ç¯‰"]
        COPY["GPU â†’ CPU<br/>ãƒ¡ãƒ¢ãƒªè»¢é€"]
    end

    subgraph Upload["ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆéåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"]
        TIER1["Tier 1<br/>CPU ãƒ¡ãƒ¢ãƒªä¿å­˜"]
        TIER2["Tier 2<br/>S3 ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]
    end

    GPU -.->|"ä¸¦åˆ—å®Ÿè¡Œ"| DICT
    DICT --> COPY
    COPY --> TIER1
    TIER1 --> TIER2

    style Training fill: #e3f2fd,stroke: #1565c0
    style Staging fill: #e8f5e9,stroke: #2e7d32
    style Upload fill: #fff3e0,stroke: #e65100
    style GPU fill: #bbdefb,stroke: #1976d2
```

ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€**GPU è¨ˆç®—ï¼ˆå­¦ç¿’ï¼‰ã€ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆGPUâ†’CPU è»¢é€ï¼‰ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆS3 ä¿å­˜ï¼‰ãŒ 3 æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ä¸¦åˆ—å®Ÿè¡Œ**ã•ã‚Œã¾ã™ã€‚å­¦ç¿’ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€å‰ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†ã‚’å¾…ãŸãšã«é–‹å§‹ã§ãã‚‹ãŸã‚ã€å­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ä½ä¸‹ãŒå¤§å¹…ã«æŠ‘åˆ¶ã•ã‚Œã¾ã™ã€‚

:::message
**ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: Level 3 ã® DefaultStager ã¯ã€GPU ãƒ¡ãƒ¢ãƒªã¨ CPU ãƒ¡ãƒ¢ãƒªã®ä¸¡æ–¹ã«ãƒ¢ãƒ‡ãƒ«ã® state dict ã‚’ä¸€æ™‚çš„ã«ä¿æŒã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ ã—ã¾ã™ã€‚å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€CPU ãƒ¡ãƒ¢ãƒªå®¹é‡ã®è¨ˆç”»ãŒé‡è¦ã§ã™ã€‚Managed Tiered Checkpointing ã§ã¯ã€`InstanceMemoryAllocationPercentage`ï¼ˆ20-100%ï¼‰ã§ã“ã®ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚
:::

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | åŒæœŸ S3 ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ | Managed Tiered Checkpointing |
|-----------|----------------------|----------------------------|
| ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜æ™‚é–“ | æ•°åˆ†ã‹ã‚‰æ•°ååˆ†ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºä¾å­˜ï¼‰[^2] | æ•°ç§’ï¼ˆTier 1 ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ï¼‰[^4] |
| å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ | ä¿å­˜æ™‚é–“ã¨åŒç­‰ | ã»ã¼ã‚¼ãƒ­ï¼ˆéåŒæœŸï¼‰ |
| å¾©æ—§å…ƒã®é¸æŠ | S3 ã®ã¿ | ãƒ¡ãƒ¢ãƒª -> S3 ã®é †ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ |
| ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆ | S3 ã®ã¿ | ãƒ¡ãƒ¢ãƒª + S3ï¼ˆæ®µéšçš„ï¼‰ |
| å­¦ç¿’ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆä½ä¸‹ | æ•°% ã‹ã‚‰åæ•°%[^2] | å¤§å¹…ã«å‰Šæ¸›[^3] |

:::message
**Checkpointless Training ã¨ã®é–¢ä¿‚**: Managed Tiered Checkpointing ã¨ [Checkpointless Training](https://zenn.dev/yunokiisshin/articles/45a746434b2090) ã¯è£œå®Œçš„ãªé–¢ä¿‚ã§ã™ã€‚Checkpointless Training ã¯ GPU ãƒ¡ãƒ¢ãƒªå†…ã®å†—é•·ãƒ¬ãƒ—ãƒªã‚«ã«ã‚ˆã‚‹é«˜é€Ÿ in-memory å¾©æ—§ã‚’æ‹…ã„ã€Tiered Checkpointing ã¯ã‚«ã‚¿ã‚¹ãƒˆãƒ­ãƒ•ã‚£ãƒƒã‚¯ãªéšœå®³ï¼ˆè¤‡æ•°ãƒãƒ¼ãƒ‰åŒæ™‚éšœå®³ã‚„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†æ§‹ç¯‰ï¼‰ã«å¯¾ã™ã‚‹æ°¸ç¶šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ‹…ã„ã¾ã™ã€‚ä½µç”¨ã™ã‚‹ã“ã¨ã§ã€è»½å¾®ãªãƒãƒ¼ãƒ‰éšœå®³ã‹ã‚‰å¤§è¦æ¨¡ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼éšœå®³ã¾ã§å¹…åºƒã„éšœå®³ã‚·ãƒŠãƒªã‚ªã«å¯¾å¿œã§ãã¾ã™ã€‚
:::

## ä½¿ã„åˆ†ã‘ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

### åˆ¤æ–­åŸºæº–

ä»¥ä¸‹ã®è¡¨ã‚’å‚è€ƒã«ã€ç’°å¢ƒã«é©ã—ãŸæ–¹å¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

| åˆ¤æ–­åŸºæº– | Managed Tiered Checkpointing | FSx + DRA |
|---------|-----|-----|
| FSx æœªæ§‹ç¯‰ã®æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | é©åˆ | ä¸è¦ |
| ã‚³ã‚¹ãƒˆæœ€é©åŒ–é‡è¦– | é©åˆï¼ˆFSx æœˆé¡ä¸è¦ï¼‰ | FSx ã‚³ã‚¹ãƒˆç™ºç”Ÿ |
| å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ã®æœ€å°åŒ– | 1-2 ç§’ã®ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ã®ã¿ | 5-30 ç§’ |
| æ•°åƒãƒãƒ¼ãƒ‰è¦æ¨¡ | é©åˆ | FSx ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°åˆ¶é™ã‚ã‚Š |
| PyTorch DCP æ¨™æº–åŒ– | é©åˆ | åˆ¥æ–¹å¼ |
| æ—¢å­˜ FSx ã‚¤ãƒ³ãƒ•ãƒ©ã®æ´»ç”¨ | - | é©åˆ |
| å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ï¼ˆæ•°å TBï¼‰ | S3 ç›´æ¥èª­è¾¼ã§å¯¾å¿œå¯ | é©åˆ |
| POSIX äº’æ›æ€§å¿…é ˆ | éå¯¾å¿œ | é©åˆ |
| ãƒªãƒ¼ã‚¸ãƒ§ãƒ³/ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ¶ç´„ | åˆ¶ç´„ã‚ã‚Šï¼ˆ[è©³ç´°](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)å‚ç…§ï¼‰ | åºƒãåˆ©ç”¨å¯èƒ½ |

### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹æˆï¼ˆFSx + Managed Tieredï¼‰

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜ç”¨ã« FSx ã‚’ç¶™ç¶šä½¿ç”¨ã—ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®ã¿ Managed Tiered Checkpointing ã«ç§»è¡Œã™ã‚‹æ§‹æˆã‚‚æœ‰åŠ¹ã§ã™ã€‚ãŸã ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ S3 ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã‚€ï¼ˆ[`s3torchconnector`](https://github.com/amazon-science/s3torchconnector) ãªã©ï¼‰ã“ã¨ã§ã•ã‚‰ã«ã‚³ã‚¹ãƒˆå‰Šæ¸›ã§ãã‚‹å ´åˆãŒå¤šã„ãŸã‚ã€[FSx for Lustre](https://aws.amazon.com/fsx/lustre/) ã®ç¶™ç¶šåˆ©ç”¨ãŒæœ¬å½“ã«å¿…è¦ã‹ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

## ã¾ã¨ã‚

Managed Tiered Checkpointing ã¯ã€å¤§è¦æ¨¡åˆ†æ•£å­¦ç¿’ã«ãŠã‘ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®èª²é¡Œã«å¯¾ã™ã‚‹å®Ÿç”¨çš„ãªè§£æ±ºç­–ã§ã™ã€‚

CPU ãƒ¡ãƒ¢ãƒªï¼ˆTier 1ï¼‰ã¨ Amazon S3ï¼ˆTier 2ï¼‰ã® 2 éšå±¤ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†ã™ã‚‹éšå±¤åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€é€Ÿåº¦ã¨è€ä¹…æ€§ã‚’ä¸¡ç«‹ã—ã¾ã™ã€‚PyTorch DCP ã® `async_save()` ã«ã‚ˆã‚‹éåŒæœŸä¿å­˜ã§å­¦ç¿’ã®ä¸­æ–­æ™‚é–“ã‚’æ•°åç§’ã‹ã‚‰ 1-2 ç§’ã«çŸ­ç¸®ã—ã€FSx for Lustre ãŒä¸è¦ã¨ãªã‚‹ã“ã¨ã§æœˆé¡ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã‚‚å‰Šæ¸›å¯èƒ½ã§ã™ã€‚ãƒãƒ¼ãƒ‰é–“ã®ãƒ¡ãƒ¢ãƒªãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ‰éšœå®³æ™‚ã«ã¯æ•°ç§’ã§å¾©æ—§ã§ãã€å„ãƒãƒ¼ãƒ‰ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚æ•°åƒãƒãƒ¼ãƒ‰è¦æ¨¡ã«ã‚‚å¯¾å¿œã§ãã¾ã™ã€‚

æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ Managed Tiered Checkpointing ã®æ¡ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚æ—¢å­˜ã® FSx ç’°å¢ƒãŒã‚ã‚‹å ´åˆã¯ã€FSx ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…±æœ‰ã«æ®‹ã—ã¤ã¤ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã®ã¿ Tiered Checkpointing ã«ç§»è¡Œã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹æˆã‚‚æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

## å‚è€ƒè³‡æ–™

- [Managed Tiered Checkpointing ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing.html)
- [Managed Tiered Checkpointing ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing-setup.html)
- [amzn-sagemaker-checkpointing (PyPI)](https://pypi.org/project/amzn-sagemaker-checkpointing/) -- v1.1.2
- [aws-samples/awsome-distributed-training (GitHub)](https://github.com/aws-samples/awsome-distributed-training)
- [AI on SageMaker HyperPod](https://awslabs.github.io/ai-on-sagemaker-hyperpod/) -- HyperPod ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- [PyTorch Distributed Checkpoint](https://pytorch.org/docs/stable/distributed.checkpoint.html)
- [PyTorch Distributed Checkpoint Tutorial](https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html)
- [PyTorch Asynchronous Checkpoint Tutorial](https://pytorch.org/tutorials/recipes/distributed_async_checkpoint_recipe.html) -- async_save ã®è©³ç´°å®Ÿè£…è§£èª¬
- [PyTorch DCP state_dict_saver.py](https://github.com/pytorch/pytorch/blob/main/torch/distributed/checkpoint/state_dict_saver.py) -- async_save ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
- [PyTorch FSDP](https://pytorch.org/docs/stable/fsdp.html)
- [Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/)
- [FSx for Lustre Data Repository Association](https://docs.aws.amazon.com/fsx/latest/LustreGuide/create-dra-linked-data-repo.html)
- [s3torchconnector](https://github.com/amazon-science/s3torchconnector) -- S3 ã‹ã‚‰ã®ç›´æ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

[^1]: ã‚³ã‚¹ãƒˆæ•°å€¤ã¯ FSx for Lustre ã®ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰æ–™é‡‘ã¨ S3 Standard ã®ä¸€èˆ¬çš„ãªæ–™é‡‘ã«åŸºã¥ãæ¦‚ç®—ã§ã™ã€‚å®Ÿéš›ã®æ–™é‡‘ã¯ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹ã€ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ç­‰ã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ã€‚æœ€æ–°ã®æ–™é‡‘ã¯ [AWS å…¬å¼æ–™é‡‘ãƒšãƒ¼ã‚¸](https://aws.amazon.com/pricing/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
[^2]: å¾“æ¥æ–¹å¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ•°å€¤ï¼ˆå¾©æ—§æ™‚é–“ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ I/O ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ç­‰ï¼‰ã¯ã€å¤§è¦æ¨¡åˆ†æ•£å­¦ç¿’ã«ãŠã‘ã‚‹ä¸€èˆ¬çš„ãªçŸ¥è¦‹ã«åŸºã¥ãæ¨å®šå€¤ã§ã™ã€‚AWS ã®å…¬å¼ç™ºè¡¨ã«ã‚ˆã‚‹æ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿéš›ã®å€¤ã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ§‹æˆã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé »åº¦ç­‰ã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ã€‚
[^3]: Managed Tiered Checkpointing ã®[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.aws.amazon.com/sagemaker/latest/dg/managed-tier-checkpointing.html)ã§ã¯ "Improved training throughput" ã¨å®šæ€§çš„ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ãŒã€å…·ä½“çš„ãªå‰Šæ¸›ç‡ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
[^4]: Tier 1 ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼ã®æ‰€è¦æ™‚é–“ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒãƒ¼ãƒ‰é–“ã®å¸¯åŸŸå¹…ã«ä¾å­˜ã—ã¾ã™ã€‚å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã¯ 1-2 ç§’ç¨‹åº¦ã§ã™ãŒã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆæ•°ç™¾ GB è¦æ¨¡ï¼‰ã§ã¯ã‚ˆã‚Šé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

---

## é–¢é€£è¨˜äº‹ï¼ˆHyperPod ã®ä»–ã®è€éšœå®³æ€§æ©Ÿèƒ½ï¼‰

æœ¬è¨˜äº‹ã§è§£èª¬ã—ãŸ Managed Tiered Checkpointing ã¯ã€HyperPod ã®è€éšœå®³æ€§æ©Ÿèƒ½ã® 1 ã¤ã§ã™ã€‚é–¢é€£ã™ã‚‹ä»–ã®æ©Ÿèƒ½ã‚‚åˆ¥è¨˜äº‹ã§è§£èª¬ã—ã¦ã„ã¾ã™ã€‚

- **[Checkpointless Training å¾¹åº•è§£èª¬](https://zenn.dev/yunokiisshin/articles/45a746434b2090)** - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸è¦ã®é«˜é€Ÿéšœå®³å¾©æ—§
- **[Elastic Training å¾¹åº•è§£èª¬](https://zenn.dev/yunokiisshin/articles/be0db364a7f8e2)** - ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å®¹é‡ã«å¿œã˜ãŸå‹•çš„ãªãƒãƒ¼ãƒ‰æ•°ã®å¢—æ¸›
- **[Health Monitoring Agent å¾¹åº•è§£èª¬](https://zenn.dev/yunokiisshin/articles/0742d879958d3a)** - ãƒªã‚½ãƒ¼ã‚¹ã®å¸¸æ™‚ç›£è¦–ã¨è‡ªå‹•éšœå®³å¾©æ—§
