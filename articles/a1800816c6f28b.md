---
title: "202411.News"
emoji: "😎"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["TechNews", "AWS"]
published: true
---

自分用のまとめ、re:invent 2024 特集

# まとめ系記事とか

- [Top announcements of AWS re:Invent 2024](https://aws.amazon.com/jp/blogs/aws/top-announcements-of-aws-reinvent-2024/)
- [AWS re:Invent 2024 の記事一覧(Classmethod)](https://dev.classmethod.jp/referencecat/aws-reinvent-2024/?utm_source=dev.classmethod.jp&utm_medium=banner&utm_campaign=contentsbanner&utm_content=aws-reinvent-2024)

# 20241205(JST) 編集

## [Accelerate foundation model training and fine-tuning with new Amazon SageMaker HyperPod recipes](https://aws.amazon.com/blogs/machine-learning/accelerate-foundation-model-training-and-fine-tuning-with-new-amazon-sagemaker-hyperpod-recipes/)

- 機能概要: Amazon SageMaker HyperPodレシピは、データサイエンティストと開発者が短時間で最先端の性能で基盤モデル（FM）のトレーニングとファインチューニングを行うための最適化されたレシピを提供します。これにより、人気のある公開されているFM（例：Llama 3.1 405B、Llama 3.2 90B、Mixtral 8x22B）のトレーニングを迅速に開始できます。
- アップデート日付: 2024/12/04
- 特徴:
  - SageMaker HyperPodレシピは、トレーニングに必要な計算リソースを自動的に調整し、最適なトレーニングプランを作成できます。
  - トレーニング性能を最大化し、コストを削減するために、GPUまたはTrainiumベースのインスタンスをシームレスに切り替えることができます。
  - サポートされているサービス: SageMaker HyperPod、Slurm、Amazon EKS（Elastic Kubernetes Service）、SageMakerトレーニングジョブ。
  - オプション機能: モデル固有のトレーニングパラメータの調整や、チェックポイント管理、TensorBoardロギングの自動化など。
- 利用ケース:
  - 大規模な基盤モデルを迅速にトレーニング・ファインチューニングしたい場合に最適です。
  - トレーニングの自動化や、トレーニングの途中で障害が発生した場合の高速復旧を行いたい場面。
- 注意事項:
  - インスタンスの設定やデータの配置に関して、事前にレシピの編集が必要です。
  - 訓練を開始する前に、GitHubリポジトリからの設定ファイルの調整が求められます。
- 対応リージョン: 東京リージョン対応あり
- 簡単な利用手順の概要
  - 手順1: SageMaker HyperPodレシピのGitHubリポジトリからレシピをクローンし、必要な設定を行います。
  - 手順2: 例えば、インスタンスの種類やデータセットの場所などのパラメータを設定します。
  - 手順3: 設定ファイルを保存し、トレーニングを実行します。
- 専門用語:

| カテゴリー         | 専門用語                          | 説明                                                   |
|------------------|----------------------------------|------------------------------------------------------|
| サービス         | Amazon SageMaker HyperPod        | 高速トレーニングとファインチューニングを支援するAWSのサービス               |
| クラスタ管理     | Slurm                           | 分散トレーニングのためのジョブスケジューラ、特にクラスター管理に使用される |
| モデルタイプ     | Llama, Mixtral                  | 公開されている基盤モデル、SageMakerでサポートされているトレーニング対象    |
| 訓練方法         | ディストリビュートトレーニング    | 複数の計算リソースで並列にトレーニングを行う方法                          |
| インスタンス     | Trainium, GPU                   | トレーニングに特化したAWSのコンピューティングリソース                        |

## [Announcing GenAI Index in Amazon Kendra](https://aws.amazon.com/blogs/ai/announcing-genai-index-in-amazon-kendra/)

- 機能概要: Amazon Kendraは、AIを活用した検索サービスで、組織がインテリジェントな検索体験や生成AIアプリケーションのための情報検索強化生成(RAG)システムを構築できるようにします。新たに、Kendra GenAI Indexが導入され、AWSの顧客はこれを利用して高度な検索精度を実現することができます。GenAI Indexは、最新の情報検索技術とセマンティックモデルを活用し、様々なデータソースからコンテンツを容易に取り込むことができます。

- アップデート日付: 2024/12/04

- 特徴:
  - Kendra GenAI Indexは、生成AIアプリケーションのために特化した検索インデックスで、AWSの他のサービスとの連携が可能です。
  - 最新の情報検索技術とセマンティックモデルにより、高い検索精度が提供されます。
  - Amazon Bedrock Knowledge BaseやAmazon Q Businessなど、AWSの生成AIサービスとの相互運用が可能です。
  - 43の異なるデータソースへのコネクタをサポートし、さまざまなコンテンツのインジェストを容易にします。

- 利用ケース:
  - 生成AIアプリケーションのための情報検索機能を強化したい企業。
  - 大量のコンテンツを処理する知識ベースを構築し、AIを活用した高度な検索・応答システムを作成する企業。

- 注意事項:
  - 現在、US East (N. Virginia) および US West (Oregon) リージョンのみで利用可能です。
  - 東京リージョンには対応していません。

- 対応リージョン: US East (N. Virginia)、US West (Oregon)（東京リージョン非対応）

- 簡単な利用手順の概要:
  - 手順1: AWSのコンソールからKendra GenAI Indexを有効化し、適切なデータソースを選択します。
  - 手順2: Amazon Bedrock Knowledge Baseでインデックスを利用し、生成AIアプリケーションと連携します。

- 専門用語:

| カテゴリー         | 専門用語                          | 簡潔な説明                                                   |
|--------------------|-----------------------------------|------------------------------------------------------------|
| モデル             | セマンティックモデル              | 言語や意味を理解するために使用されるAIモデル。                 |
| データソース       | コネクタ                          | 異なるデータソースとの接続を提供するインターフェース。         |

## [Amazon Bedrock Data Automation now available in preview](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-data-automation-now-available-in-preview/)

- 機能概要: Amazon Bedrock Data Automation（BDA）は、開発者がドキュメント、画像、動画、音声などの非構造化のマルチモーダルコンテンツから価値あるインサイトを自動生成し、Generative AI（GenAI）ベースのアプリケーションを構築できる新機能です。これにより、動画の重要な瞬間の要約、不適切な画像コンテンツの検出、複雑なドキュメントの自動分析などが可能になります。BDAは、出力のカスタマイズも可能で、システムやアプリケーションに必要な一貫性のあるフォーマットで特定のインサイトを生成できます。
- アップデート日付: 2024/12/04
- 特徴:
  - 開発者が非構造化のマルチモーダルコンテンツを処理し、貴重なインサイトを自動的に抽出することができる。
  - 既存の代替ソリューションと比較して、低コストで高精度な結果を提供し、視覚的根拠やハルシネーションの軽減機能を備えている。
  - Bedrock Knowledge Basesとの統合により、RAG（Retrieval Augmented Generation）向けの有用な情報を生成できる。
  - サンプルデータを使ってBDAの出力を設定し、アプリケーションに統合することで、スケールでの非構造化コンテンツ処理が可能。
- 利用ケース:
  - 文書処理の自動化、メディア分析、非構造化データを中心とした自動化ソリューションの構築。
  - 大量の非構造化データから有用な情報を引き出して、生成型AIを活用したアプリケーションに組み込む場合。
- 注意事項:
  - 現在はUS West (Oregon)リージョンでプレビュー提供中で、東京リージョンには対応していない。
- 対応リージョン: US West (Oregon)リージョンのみ対応、東京リージョン未対応
- 簡単な利用手順の概要
  - 手順1: BedrockコンソールでBDAを設定し、サンプルデータを使って出力をカスタマイズする。
  - 手順2: 統一されたマルチモーダル推論APIをアプリケーションに統合し、非構造化コンテンツをスケールで処理する。

| カテゴリー         | 専門用語                             | 説明                                                         |
|------------------|-------------------------------------|------------------------------------------------------------|
| コンテンツ        | マルチモーダルコンテンツ               | 文章、画像、音声、動画などの複数の形式で提供されるデータ。                              |

## [Amazon Bedrock Knowledge Bases now supports structured data retrieval](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-bedrock-knowledge-bases-structured-data-retrieval/)

- 機能概要: Amazon Bedrock Knowledge Basesが、自然言語で構造化データをクエリする機能をサポートするようになりました。この機能により、ユーザーは複数の構造化データソースから直接データを取得することができ、データを移動させたり前処理を行う必要がありません。自然言語処理を活用して、クエリをSQLに変換し、データソースから直接情報を引き出せます。
- アップデート日付: 2024/12/04
- 特徴:
  - 自然言語をSQLに変換するモジュールが組み込まれ、構造化データを効率的に検索できるようになりました。
  - SQL変換精度を高めるために、データベーススキーマや過去のクエリ履歴などのコンテキスト情報を活用しています。
  - 現在、Amazon RedshiftやAmazon Sagemaker Lakehouseからデータを取得できる。
  - 生成されたSQLクエリを実行し、結果を要約して提示する機能が提供されています。
- 利用ケース:
  - 小売業のアナリストが「先月のトップ5販売商品は？」といった質問をし、SQLクエリを自動的に生成し、データベースから情報を取得するケース。
  - 様々な構造化データに基づいたカスタム生成AIアプリケーションの開発に利用される。
- 注意事項:
  - 現時点では、Amazon RedshiftおよびAmazon Sagemaker Lakehouseのみがサポートされています。
  - 一部の商業リージョンにて利用可能です。
- 対応リージョン: 東京リージョンは対応しています。
- 簡単な利用手順の概要:
  - 手順1: Amazon Bedrock Knowledge Basesを有効にし、対象のデータソース（Amazon RedshiftやSagemaker Lakehouse）を接続します。
  - 手順2: 自然言語でデータクエリを入力し、結果を受け取ります。
- 専門用語:

| カテゴリー            | 専門用語                 | 説明                                                      |
|-------------------|---------------------|---------------------------------------------------------|
| 自然言語処理          | 自然言語からSQLへの変換 (NL2SQL)  | ユーザーが入力した自然言語の質問をSQLクエリに変換する技術。            |
| データベース         | Amazon Sagemaker Lakehouse | 機械学習向けの統合型データレイクおよびウェアハウス。                  |
| アプリケーション開発 | カスタム生成AIアプリケーション | 特定のニーズに合わせて開発された生成AIを活用したアプリケーション。   |

## [Solve complex problems with new scenario analysis capability in Amazon Q in QuickSight](https://aws.amazon.com/jp/blogs/aws/solve-complex-problems-with-new-scenario-analysis-capability-in-amazon-q-in-quicksight/)

- **機能概要**:  
  Amazon QuickSightの新機能であるAmazon Qは、ビジネスユーザーが自然言語プロンプトを使用して複雑な問題に対するシナリオ分析を行えるようにする。従来、スプレッドシートや他のツールで時間をかけて行っていた分析を、AIアシスタントが自動的にデータを解析し、提案されたアクションを提示することで、短時間で解決に導く。

- **アップデート日付**: 2024/12/04

### 特徴:
- **メインの機能特徴**:  
  ビジネスユーザーが「新しいシカゴ店をニューヨークの旗艦店と同じくらい成功させるにはどうすればよいか？」といった質問を自然言語で入力することで、Amazon Qが解析手法を提案し、自動的にデータを分析して結果と行動提案を可視化して提示する。
- **性能向上**:  
  従来のスプレッドシートと比較して、最大10倍のスピードでシナリオ分析を完了できる。
- **対応するサービス**:  
  Amazon Athena、Amazon Aurora、Amazon Redshift、Amazon S3、Amazon OpenSearch Serviceと連携可能。また、QuickSightダッシュボードからのデータ読み取りが可能。
- **オプション機能**:  
  CSVファイルや単一テーブルの.xlsxファイルをアップロードして、独自のデータを分析に取り込むことも可能。

### 利用ケース:
- イベントの登録者情報を分析して、マーケティング効果を高める企業を特定し、参加者数を増やすための最適な戦略を策定するケース。例えば、登録者数が少ない企業を見つけて、どの企業に対してマーケティングを強化すべきか優先順位をつけることができる。

### 注意事項:
- 現在、プレビュー版として提供されており、QuickSight Proユーザーのみが対象。
- CSVおよび単一テーブルの.xlsxファイルに制限される。

### 対応リージョン:
- 東京リージョンでは**未対応**。現在、US East (N. Virginia) と US West (Oregon) のみで利用可能。

### 簡単な利用手順の概要:
1. Amazon QuickSightにログインし、Amazon Q機能を有効化する。
2. 分析に使用するデータソース（Amazon Athena、Redshiftなど）を接続するか、CSVまたは.xlsxファイルをアップロードする。
3. 自然言語で質問を入力し、提案されたシナリオ分析手法を選択する。
4. 分析結果と提案されたアクションを確認し、必要に応じて変更や再分析を行う。

### 専門用語:

| **カテゴリー**         | **専門用語**         | **説明**                                           |
|----------------------|---------------------|---------------------------------------------------|
| 分析手法              | シナリオ分析          | 特定のシナリオに基づいてビジネス戦略を策定するためのデータ分析。 |

## [Use Amazon Q Developer to build ML models in Amazon SageMaker Canvas]()

- **機能概要**:  
  Amazon Q DeveloperがAmazon SageMaker Canvasで利用可能になりました。この機能は、機械学習（ML）の専門知識を持たないビジネスアナリストやデータエンジニアなどのドメインエキスパートが、自然言語でMLモデルを構築できるように支援します。データ分析からモデル構築、デプロイまで、ガイド付きのMLワークフローで迅速にビジネス課題を解決できるようになります。

- **アップデート日付**: 2024/12/04

- **特徴**:  
  - **ガイド付きワークフロー**: 自然言語で指示を入力することで、MLモデル構築が可能。データの前処理からモデルの選択、評価、デプロイまで一貫したサポートを提供します。  
  - **データ準備とAutoML**: データの異常値除去や変換を自動で実施し、最適なモデルを提案します。  
  - **透明性と説明可能性**: データ変換ステップやモデルの精度指標を表示し、技術者がレビュー、検証、更新できるようにします。  
  - **性能指標**: 回帰モデルではRMSE（Root Mean Square Error）を表示し、分類モデルでは混同行列や適合率-再現率スコアを確認可能です。

- **利用ケース**:  
  - ビジネスアナリストが販売データを使用して、将来の販売価格を予測。  
  - マーケティングチームがキャンペーンの効果を予測するためのモデル構築。  
  - データエンジニアが新しいデータセットを評価し、異常値を修正してモデル精度を向上。

- **注意事項**:  
  - この機能は現在プレビュー版として提供されており、正式リリースではありません。  
  - SageMaker Canvasのワークスペースやモデル構築に必要なリソースには標準の料金が適用されます。  

- **対応リージョン**:  
  - 現時点ではプレビュー版として提供されているため、東京リージョンでの対応についてはAWSの公式ページを確認する必要があります。

- **簡単な利用手順の概要**  
  1. **SageMaker Canvasを起動**し、「Amazon Q Developer」を選択。  
  2. **新しい会話を開始**し、予測したいビジネス課題を自然言語で入力。  
  3. **データセットをアップロード**し、ターゲットカラムを選択。  
  4. **データ品質の確認と修正**を実施し、モデルトレーニングを開始。  
  5. **モデルの評価指標を確認**し、必要に応じて修正後、デプロイを行う。

- **専門用語**:

| カテゴリー              | 専門用語                  | 簡潔な説明                                             |
|------------------------|---------------------------|--------------------------------------------------------|
| 機械学習                | 回帰モデル (Regression Model) | 連続値を予測するMLモデル。                            |
| データ分析              | 異常値 (Outlier)            | データの中で他と大きく異なる値。                       |
| データ変換              | データ変換 (Data Transformation) | データをMLに適した形式に変換するプロセス。             |
| 性能評価                | RMSE (Root Mean Square Error) | 予測値と実測値の誤差の平均を二乗平均平方根で表したもの。|

## [Amazon Bedrock Guardrails now supports multimodal toxicity detection with image support (preview)](https://aws.amazon.com/jp/blogs/aws/amazon-bedrock-guardrails-now-supports-multimodal-toxicity-detection-with-image-support/)

- **機能概要:**  
  Amazon Bedrock Guardrailsが、テキストに加えて画像データにも対応したマルチモーダルの有害コンテンツ検出機能を提供するプレビューを開始しました。この新機能により、生成AIアプリケーション内で有害な画像コンテンツを検出し、ブロックすることが可能になります。

- **アップデート日付:** 2024/12/04

- **特徴:**  
  - テキストと画像コンテンツの両方に対する有害コンテンツ検出・フィルタリング機能を提供。  
  - 「憎悪」「侮辱」「性的」「暴力」といったカテゴリに基づいてコンテンツを検出し、設定した閾値に応じてブロック可能。  
  - すべてのAmazon Bedrockの基盤モデル（FMs）およびカスタムファインチューニング済みモデルで利用可能。  
  - **API連携:** Amazon Bedrock Guardrails独自の`ApplyGuardrail` APIを使用することで、モデルに依存せずにコンテンツ検証が可能。  
  - オプション機能として、PII（個人識別情報）のマスキングやコンテキストに応じた検証をサポート。

- **利用ケース:**  
  KONE社では、設計図やマニュアルを統合した生成AIアプリケーションでの活用を検討しており、特に文脈や関連性を検証する機能が有効だと評価しています。

- **注意事項:**  
  - テキスト用の「不正行為」や「プロンプト攻撃」のカテゴリは画像データには適用されません。  
  - プレビュー段階の機能であるため、正式版リリース時に変更が生じる可能性があります。

- **対応リージョン:**  
  - 東京リージョン（Asia Pacific: Tokyo）を含む複数のリージョンで利用可能（米国東部、米国西部、ヨーロッパ、AWS GovCloudなど）。

- **簡単な利用手順の概要:**  
  1. **手順1:** AWS Management Consoleにログインし、Amazon BedrockのGuardrailsを選択。  
  2. **手順2:** 新しいガードレールを作成し、テキストと画像のコンテンツフィルタを設定。  
  3. **手順3:** 設定を保存し、モデルを選択してガードレールをテスト。  
  4. **手順4:** `ApplyGuardrail` APIを使用して、アプリケーション内でコンテンツをリアルタイムで評価。

---

### 専門用語リスト

| カテゴリー               | 説明                                                              |
|--------------------------|------------------------------------------------------------------|
| Amazon Bedrock Guardrails | Amazon Bedrock内で有害コンテンツの検出やフィルタリングを行う機能。   |
| マルチモーダル             | テキストや画像など複数のデータ形式を同時に扱う技術。                    |
| PII (Personally Identifiable Information) | 個人を識別できる情報で、プライバシー保護のためにマスキングされる。 |

## [New Amazon Bedrock capabilities enhance data processing and retrieval](https://aws.amazon.com/jp/blogs/aws/new-amazon-bedrock-capabilities-enhance-data-processing-and-retrieval/)

- **機能概要**:  
Amazon Bedrockが新たに提供する4つの機能拡張により、生成AIを活用したデータ処理と検索がより効率的に行えるようになりました。これにより、企業は構造化および非構造化データから迅速かつ費用効果の高い形でインサイトを得ることが可能になります。

- **アップデート日付**: 2024/12/04

- **特徴**:
  - **Amazon Bedrock Data Automation (プレビュー版)**: 文書、画像、音声、動画などのマルチモーダルな非構造化データからインサイトを抽出するフルマネージド機能です。IDP（Intelligent Document Processing）やRAG（Retrieval-Augmented Generation）のワークフローを迅速かつ低コストで構築できます。  
    - 結果は標準出力とカスタム出力として生成可能で、APIで一元管理が可能です。
  - **マルチモーダルデータ処理**: Bedrock Knowledge Basesが、Amazon Bedrock Data Automationを用いてテキストと視覚情報を同時に処理することをサポートします。これにより、テキストと画像が含まれるドキュメントの回答精度と関連性が向上します。
  - **GraphRAGのサポート**: Amazon Bedrock Knowledge Basesが、グラフ技術を活用したRAG機能を提供します。複雑なデータ間の関係を管理し、より包括的かつ正確な回答を生成します。
  - **構造化データの検索**: データウェアハウスやデータレイクに対する自然言語クエリをサポートし、RedshiftやNeptune Analyticsなどのデータソースからインサイトを抽出します。SQLの自動生成とクエリ実行を一元管理します。

- **利用ケース**:
  - 保険会社が自動車保険の請求処理を自動化することで、業務の効率化と生産性向上を図ることができます。
  - メディア企業がテレビ番組を分析し、シーンごとの要約や企業ロゴ検出を通じて広告配置を最適化します。
  - 金融サービス企業が複雑な財務書類を解析し、GraphRAGを活用して異なる財務エンティティ間の関係を把握します。

- **注意事項**:
  - カスタム出力は現在、文書と画像のみに対応しています（プレビュー段階）。
  - GraphRAG機能を利用する際は、Amazon Neptune Analyticsに追加料金が発生します。
  - 構造化データの検索機能には、データクエリのための追加料金が適用されます。

- **対応リージョン**:
  - Amazon Bedrock Data Automation: 米国西部（オレゴン）リージョンでプレビュー提供中。  
  - 東京リージョンでは、現時点でサポートされていません。

- **簡単な利用手順の概要**:  
  1. Amazon Bedrockコンソールで「Data Automation」を選択し、対象となるドキュメントやファイルをアップロードします。  
  2. 標準出力またはカスタム出力を設定し、必要なインサイトを生成します。  
  3. Amazon S3バケットに保存された結果をレビューし、カスタマイズしたブループリントをプロジェクトに統合します。  
  4. 必要に応じて、構造化データの検索やGraphRAG機能をKnowledge Basesに設定し、統合された情報からクエリ結果を取得します。

### Notes
- 後で検証

## [Reduce costs and latency with Amazon Bedrock Intelligent Prompt Routing and prompt caching (preview)](https://aws.amazon.com/jp/blogs/aws/reduce-costs-and-latency-with-amazon-bedrock-intelligent-prompt-routing-and-prompt-caching-preview/)

- **機能概要**:  
Amazon Bedrockがプレビューとして「Intelligent Prompt Routing」と「Prompt Caching」の2つの機能を導入しました。これにより、生成AIアプリケーションにおけるコスト削減と遅延の低減を可能にします。

- **アップデート日付**: 2024/12/04

- **特徴**:  
  - **Intelligent Prompt Routing**  
    プロンプトごとに最適なファウンデーションモデル（FMs）を選択し、クエリの複雑さに応じてモデルを切り替えることで、品質とコストのバランスを最適化します。AnthropicのClaudeファミリー（Claude 3.5 Sonnet と Claude 3 Haiku）やMetaのLLaMAファミリー（Llama 3.1 70B と 8B）などが対応しています。  
    - 最大30%のコスト削減が可能です。  
  - **Prompt Caching**  
    同じコンテキストを複数回利用する際、コンテキストを一時的にキャッシュすることで、コストを最大90%、遅延を最大85%削減します。  
    - キャッシュは最終アクセスから5分間保持されます。

- **利用ケース**:  
  - **Intelligent Prompt Routing**: カスタマーサポートアシスタントなど、単純なクエリを軽量で安価なモデルに、複雑なクエリを高性能なモデルに割り当てることで、効率的なリソース利用が可能です。  
  - **Prompt Caching**: ドキュメントQ&Aシステムやコーディングアシスタントなど、同じコンテキストを頻繁に参照するアプリケーションに適しています。

- **注意事項**:  
  - プロンプトキャッシュは最終アクセスから5分で期限切れになります。  
  - プロンプトルーティングはプレビュー版であり、サポート対象のモデルに制限があります。

- **対応リージョン**:  
  - **東京リージョン**の対応状況はまだ明記されていません。

- **簡単な利用手順の概要**:  
  1. AWSマネジメントコンソールで「Foundation Models」の「Prompt routers」を選択します。  
  2. ルータを選択し、モデル間のルーティング設定を確認します。  
  3. AWS CLIまたはAWS SDKを使用して、指定したARNを`model-id`としてAPI呼び出しを行います。

- **専門用語**:

| カテゴリー         | 専門用語                  | 簡潔な説明 |
|-------------------|--------------------------|-----------|
| モデルファミリー   | LLaMA                     | Meta社の生成AIモデルファミリー。|
| API                | Converse API              | Amazon Bedrockが提供する対話型API。|
| 機能               | Intelligent Prompt Routing | プロンプトに最適なモデルを自動選択する機能。|
| 機能               | Prompt Caching            | プロンプト内のコンテキストをキャッシュする機能。|
| リソース           | Inference Profile         | 特定のモデルに関連付けられた推論プロファイル。|

## [Amazon Bedrock Marketplace: Access over 100 foundation models in one place](https://aws.amazon.com/jp/blogs/aws/amazon-bedrock-marketplace-access-over-100-foundation-models-in-one-place/)

- **機能概要:**  
  Amazon Bedrock Marketplaceは、Amazon Bedrockを通じて、IBMやNvidiaといった大手企業のモデルから、韓国語処理に特化したUpstagesのSolar Pro、タンパク質研究用のEvolutionary ScaleのESM3など、100を超える汎用および専門特化型のファウンデーションモデル（FMs）を1か所で発見、テスト、デプロイできる新しい機能です。モデルの管理が簡略化され、企業向けのユースケースに迅速に適応できます。

- **アップデート日付:** 2024/12/04

### 特徴  
- **モデルアクセス:**  
  Amazon Bedrockの標準APIを介して、汎用モデルや専門特化型モデルにアクセス可能。Converse APIに対応したモデルは、Amazon Bedrock AgentsやKnowledge Basesと連携可能。  
- **多様なモデルプロバイダー:**  
  IBM、Nvidia、Anthropic、Metaなどの大手企業に加え、Arcee AIやWidn.AIのようなマルチリンガルモデルを提供する新興企業も利用可能。  
- **インフラ統合:**  
  Amazon SageMakerを利用したインフラ展開に対応し、推論エンドポイントを簡単に管理。既存のIAMロールやVPCに統合することで、セキュリティ面も強化。  
- **オプション機能:**  
  VPCデプロイメントやカスタムIAMロール設定など、高度なオプション設定が可能。

### 利用ケース  
- 特定のドメインや言語に最適化されたモデルを迅速に選択してデプロイし、エンタープライズ向けのアプリケーションで利用する。  
- AI生成テキスト、画像生成、タンパク質構造予測など、さまざまなユースケースでAIモデルを即座にテストおよび導入する。  
- モデル管理やAPIの統一により、マルチテナント環境での効率的な運用が可能。

### 注意事項  
- 各モデルは、モデルプロバイダーの設定に基づいたソフトウェア料金とAmazon SageMakerによるホスティング料金が別途発生します。  
- インフラ展開後のエンドポイント管理と設定変更は、Marketplace内の「Deployments」ページから行います。  

### 対応リージョン  
- 東京リージョン (Asia Pacific (Tokyo)) を含む、以下のリージョンで利用可能:  
  - US East (N. Virginia)、US West (Oregon)、Asia Pacific (Mumbai)、Europe (Frankfurt)など。

### 簡単な利用手順の概要  
- **手順1:** Amazon Bedrockコンソールで「Model catalog」を選択し、使用したいモデルを検索。  
- **手順2:** モデル詳細ページで、料金や使用条件を確認し、サブスクリプションを選択。  
- **手順3:** デプロイ設定を行い、エンドポイントを起動後、Playgroundでテストを実施。  

### 専門用語

| **用語**                    | **説明**                                                                                          |
|-----------------------------|---------------------------------------------------------------------------------------------------|
| **Converse API**             | チャット向けモデルの切り替えを簡単に行うAPI。                                                      |

## [AWS announces Amazon SageMaker Partner AI Apps](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-sagemaker-partner-ai-apps/)

- **機能概要**:  
  AWSが新たに提供する「Amazon SageMaker Partner AI Apps」は、顧客がSageMaker内でパートナー企業によるAIおよび機械学習（ML）開発向けのアプリケーションを簡単に発見し、導入し、活用できるようにする機能です。これにより、データやモデルを外部に移動させることなく、安全かつプライベートにパートナーソリューションを統合し、高性能なAIモデルを迅速に開発できます。

- **アップデート日付**: 2024/12/04

- **特徴**:  
  - **メインの機能特徴**:  
    SageMaker環境内で、外部パートナーが提供するAIアプリケーションを安全に利用し、統合できる機能を提供します。
  - **性能についての言及**:  
    アプリの管理やスケーリングがSageMaker内で完全に管理され、データやモデルの流出リスクが軽減されます。  
    従来は複数の分断されたインターフェイスを行き来する必要がありましたが、統一された開発環境を提供することで開発者体験が向上します。
  - **対応するサービスやモデル**:  
    Comet（実験管理）、Deepchecks（品質・コンプライアンス評価）、Fiddler（モデル監視・解析）、Lakera（セキュリティ保護）などのパートナーアプリケーションをサポートしています。
  - **オプション機能**:  
    アプリケーションごとに、実験管理、モデル品質評価、セキュリティ管理など、特化した機能を利用可能です。

- **利用ケース**:  
  - AIモデル開発時の実験管理、品質評価、運用時の監視と改善、セキュリティ強化が必要な企業が想定されます。特に、データを外部に出すことなく、統一された環境でAIモデルの開発と運用を効率化したい場合に適しています。

- **注意事項**:  
  - Gov Cloudリージョンでは利用できません。  
  - パートナーアプリケーションごとに追加のサブスクリプションが必要となる場合があります。

- **対応リージョン**:  
  東京リージョンは対応していますが、Gov Cloudは対象外です。

- **簡単な利用手順の概要**:  
  1. SageMakerコンソールから「Partner AI Apps」にアクセスします。  
  2. 利用したいアプリケーションを検索し、サブスクライブします。  
  3. 必要な権限を設定し、SageMaker環境内でアプリケーションを起動します。  
  4. アプリケーションを用いてモデルの開発、管理、評価を行います。

---

### 専門用語リスト

| **カテゴリー**       | **専門用語**           | **説明**                                                                 |
|----------------------|------------------------|--------------------------------------------------------------------------|
| パートナーアプリ      | Comet                  | AIモデル開発における実験管理、可視化を行うアプリケーション。               |
| パートナーアプリ      | Deepchecks             | AIモデルの品質とコンプライアンス評価を行うアプリケーション。              |
| パートナーアプリ      | Fiddler                | AIモデルの監視、解析、運用改善を行うアプリケーション。                    |
| パートナーアプリ      | Lakera                 | AIアプリケーションをセキュリティ攻撃やデータ漏洩から保護するアプリケーション。|
| セキュリティ          | データエクスフィルトレーション | データが意図せず外部に流出すること。                                      |

### Notes
- 後で検証
- パートナー企業がどう機能を組み込めるのかの軸で調べる

## [Maximize accelerator utilization for model development with new Amazon SageMaker HyperPod task governance](https://aws.amazon.com/jp/blogs/aws/maximize-accelerator-utilization-for-model-development-with-new-amazon-sagemaker-hyperpod-task-governance/)

- **機能概要**:  
  Amazon SageMaker HyperPod タスクガバナンスは、生成AIモデルの開発において、GPUやTrainiumなどのアクセラレータを効率的に活用するための新機能です。タスクごとにリソース割り当てを動的かつ中央管理することで、計算リソースの無駄を減らし、AIプロジェクトの市場投入までの時間短縮とコスト管理を可能にします。

- **アップデート日付**: 2024/12/04

- **特徴**:  
  - **リソース管理**: GPUやvCPU、メモリの利用状況をリアルタイムでモニタリングし、プロジェクトごとの割り当てを最適化。  
  - **動的リソース割り当て**: 低優先度のタスクを一時停止してチェックポイントを保存し、高優先度のタスクにリソースを即時割り当て。  
  - **チーム間でのリソース共有**: チーム内で未使用のリソースを他チームが借用可能。公平なリソース配分を設定できる。  
  - **監視と監査**: Amazon CloudWatch Container Insights や Amazon Managed Grafana と統合し、リソース使用状況を可視化。  

- **利用ケース**:  
  - 生成AIモデルのトレーニング、ファインチューニング、推論の最適化。  
  - 限られた計算リソースを効率的に割り当て、複数チーム間でのリソース競争を軽減。  
  - タスクの優先順位に基づく動的なリソース管理とスケジューリング。  

- **注意事項**:  
  - クラスターは Amazon EKS に対応しており、SageMaker HyperPod クラスターの設定が必要。  
  - 東京リージョンでは現在未対応。

- **対応リージョン**:  
  - 米国東部（バージニア北部）  
  - 米国東部（オハイオ）  
  - 米国西部（オレゴン）  
  - 東京リージョンでの対応は未発表。

- **簡単な利用手順の概要**:  
  - **手順1**: Amazon SageMaker コンソールで HyperPod クラスターを選択し、ダッシュボードからリソース利用状況を確認。  
  - **手順2**: クラスターポリシーを設定し、タスクの優先順位やリソース配分を調整。  
  - **手順3**: HyperPod CLI を使用してトレーニングジョブを開始し、リソース割り当てを確認。  

### カテゴリーと専門用語

| カテゴリー         | 専門用語            | 簡潔な説明                                          |
|--------------------|---------------------|-----------------------------------------------------|
| 計算リソース管理   | GPU                  | グラフィック処理装置で、AIトレーニングに使用される。 |
|                    | Trainium             | Amazonが開発したAI向け専用プロセッサ。              |
|                    | vCPU                 | 仮想中央処理装置。仮想化環境で使用されるCPUの単位。 |
| タスク管理         | チェックポイント     | タスクの中断時点を記録し、再開時にその時点から開始できる機能。 |
|                    | 優先順位クラス       | タスクに割り当てられた優先度を示す分類。            |
| モニタリング       | CloudWatch Container Insights | クラウド上でのリソース使用状況を可視化するサービス。 |
|                    | Amazon Managed Grafana| ダッシュボード作成とモニタリングのための管理サービス。 |

## [Meet your training timelines and budgets with new Amazon SageMaker HyperPod flexible training plans](https://aws.amazon.com/jp/blogs/aws/meet-your-training-timelines-and-budgets-with-new-amazon-sagemaker-hyperpod-flexible-training-plans/)

- **機能概要**:  
Amazon SageMaker HyperPodは、基盤モデル（FMs）のトレーニングを効率的かつ予算内で完了するための柔軟なトレーニングプランを提供します。分散トレーニングライブラリと高い回復性を備え、リソースの可用性に基づいて最適なトレーニング計画を立てることが可能です。

- **アップデート日付**: 2024/12/04  

- **特徴**:  
  - **メインの機能特徴**:  
    データサイエンティストがFMsのトレーニングを指定された期間内で完了できる最適なプランを作成し、トレーニングジョブを完全に管理します。
  - **性能について**:  
    従来のトレーニングと比較して、トレーニング時間を最大40%短縮可能です。  
  - **対応サービスやモデル**:  
    対応するインスタンスタイプは、`ml.p4d.48xlarge`、`ml.p5.48xlarge`、`ml.p5e.48xlarge`、`ml.p5en.48xlarge`、および `ml.trn2.48xlarge`です。  
    `Trn2`と`P5en`インスタンスはUS East (Ohio)リージョンのみで利用可能です。
  - **オプション機能**:  
    トレーニングプランを複数のセグメントに分割し、リソースの可用性に応じた段階的な実行をサポートします。  

- **利用ケース**:  
  - 大規模な基盤モデルをトレーニングする際に、可用性の低い計算リソースを効率的に利用し、期間内にトレーニングを完了したい場合。  

- **注意事項**:  
  - トレーニングプランは作成後12時間以内に前払いする必要があります。
  - 東京リージョン（ap-northeast-1）は現在未対応です。  

- **対応リージョン**:  
  US East (N. Virginia)、US East (Ohio)、US West (Oregon)。東京リージョンは未対応。  

- **簡単な利用手順の概要**:  
  - 手順1: SageMaker AIコンソールで「Training plans」を選択し、新しいトレーニングプランを作成します。  
  - 手順2: トレーニング期間、インスタンスタイプと数を選択し、最適なトレーニングプランを検索します。  
  - 手順3: 提案されたプランを確認し、トレーニング詳細を入力してプランを作成します。  
  - 手順4: 作成後、トレーニングが自動的にスケジュールされ、開始されます。  

### カテゴリーと専門用語一覧  

| カテゴリー       | 専門用語               | 説明                                    |
|------------------|------------------------|-----------------------------------------|
| トレーニング     | Foundation Models (FMs) | 大規模な基盤となるAIモデル              |
| リソース管理     | SageMaker HyperPod      | 分散トレーニングのためのリソース管理機能|
| サービス         | Managed Spot Training   | インスタンス中断に自動対応する機能     |


## [Getting started with Amazon Bedrock Agents custom orchestrator](https://aws.amazon.com/jp/blogs/machine-learning/getting-started-with-amazon-bedrock-agents-custom-orchestrator/)

- 機能概要: Amazon Bedrock Agents のカスタムオーケストレーター機能は、ユーザーがワークフローの各ステップでツールとの相互作用を詳細に制御できるようにします。これにより、特定の業務ニーズに最適なエージェントの動作を調整することができ、精度、適応性、効率を向上させます。カスタムオーケストレーターを利用することで、タスクの計画、完了、検証を管理することができます。
- アップデート日付: 2024/11/27
- 特徴:
  - ユーザーが具体的なオーケストレーション戦略を定義し、エージェントの動作を最適化できます。
  - ReAct（デフォルト）とReWoo（カスタムオーケストレーション）を比較し、速度とパフォーマンスのトレードオフに注目しています。ReWooはより迅速な応答時間を実現しますが、ReActは柔軟性と透明性が高いです。
  - Amazon Bedrock Agentsは、ツールや知識ベースとの統合を通じてエージェントの効率的な動作を支援します。
  - カスタムオーケストレーターを使用して、特定の業務ニーズに合わせたオーケストレーション戦略を構築できます。
- 利用ケース:
  - 高速で複雑なタスク処理が求められる状況で、ReWoo戦略を使用して応答時間を短縮する場合。
  - 柔軟性が求められる場面では、エージェントが逐次的にステップを評価しながら最適な行動を取るReAct戦略を使用する場合。
  - 反復的なワークフローを自動化し、ツールや知識ベースと連携して効率的にタスクを完了する場合。
- 注意事項:
  - ReWooは、ステップごとの評価を省略するため、高速な応答を実現する一方で、実装の難易度が高くなることがあります。
  - カスタムオーケストレーターの作成には、Lambda関数を使用する必要があります。
- 対応リージョン: 東京リージョン対応あり
- 簡単な利用手順の概要
  - 手順1: AWS Lambda関数を使用してカスタムオーケストレーターを作成。
  - 手順2: Amazon Bedrock Agentsにおいて、カスタムオーケストレーターをエージェントに適用。
  - 手順3: 作成したカスタムオーケストレーション戦略を他のエージェントに再利用。
- 専門用語:

| カテゴリー          | 専門用語            | 説明                                               |
|-------------------|--------------------|----------------------------------------------------|
| オーケストレーション | カスタムオーケストレーター | エージェントのワークフローの管理をカスタマイズする機能。ユーザーはオーケストレーションの戦略を定義する。 |
| 戦略                | ReAct              | エージェントが逐次的に判断し、動作を調整するオーケストレーション戦略。柔軟性が高い。            |
| 戦略                | ReWoo              | エージェントが一度の計画で全てのタスクを実行する戦略。速度を優先するが、実装が複雑。         |
| API                | Amazon Bedrock Converse API | Amazon Bedrock Agents と連携して、自然言語処理を管理するAPI。                        |

### Notes
- 後で検証

## [Easily deploy and manage hundreds of LoRA adapters with SageMaker efficient multi-adapter inference](https://aws.amazon.com/jp/blogs/machine-learning/easily-deploy-and-manage-hundreds-of-lora-adapters-with-sagemaker-efficient-multi-adapter-inference/)

- 機能概要: Amazon SageMaker の新しい効率的なマルチアダプター推論機能により、ユーザーは、SageMaker API を使用して数百のファインチューニングされた LoRA アダプターを簡単にデプロイおよび管理できるようになります。この機能では、アダプターを GPU メモリ、CPU メモリ、またはローカルディスクから動的に読み込むことができ、性能を損なうことなく、エンドポイントの再デプロイなしで個別のアダプターの追加、削除、更新を実行できます。
- アップデート日付: 2024/11/29
- 特徴:
  - LoRA アダプターを効率的にデプロイおよび管理でき、複数のアダプターを共通のベースモデルで使用できます。
  - 従来の手法に比べて、より低コストで迅速にファインチューニングができ、カスタマイズされた AI を効率的に提供可能です。
  - 対応するサービス: Amazon SageMaker。
  - オプション機能: 個別のアダプターの動的な管理、パフォーマンスの評価、アダプターの迅速な更新。
- 利用ケース:
  - SaaS やマーケティング企業が顧客ごとの画像や文書に基づくパーソナライズを行う。
  - 医療や金融業界の企業が一般的なベースモデルを再利用し、特定のタスクに適応したアダプターを効率的に管理する。
  - AI モデルのカスタマイズを大規模で運用する企業。
- 注意事項:
  - 利用には、SageMaker のインスタンス（例: ml.g5.12xlarge）の使用が必要で、事前にサービスクォータの増加が必要な場合がある。
- 対応リージョン: 東京リージョン対応あり
- 簡単な利用手順の概要
  - 手順1: SageMaker Studio にてドメインを作成し、推論コンポーネントを設定します。
  - 手順2: 基本モデルと複数の LoRA アダプターを同じエンドポイントにデプロイします。
  - 手順3: 推論時にアダプターを動的に切り替え、特定のタスクに適した結果を得ます。
  
| カテゴリー     | 専門用語                         | 説明                                                          |
|----------------|----------------------------------|-------------------------------------------------------------|
| モデル技術    | LoRA (Low-Rank Adaptation)       | モデルの一部のパラメータのみをファインチューニングして効率的にカスタマイズする手法。 |
| サービス      | Amazon SageMaker                 | AWS のマネージドサービスで、機械学習モデルのデプロイと管理を簡単に行える。      |
| コンピューティング | ml.g5.12xlarge                   | Amazon SageMaker における推論用インスタンスの一つ。高性能な GPU を搭載。          |
| 手法          | パラメータ効率的ファインチューニング (PEFT) | 大規模モデルのパラメータを全て更新するのではなく、少部分のみを更新することで効率的にカスタマイズ。 |

### Notes
- 後で検証
- これまでも LMI で提供されていたが何がアップデートされた？

## [Cohere Rerank 3.5 is now available in Amazon Bedrock through Rerank API](https://aws.amazon.com/jp/blogs/machine-learning/cohere-rerank-3-5-is-now-available-in-amazon-bedrock-through-rerank-api/)

- 機能概要: Cohereの高度な再ランクモデル「Rerank 3.5」がAmazon Bedrockを通じて利用可能になりました。このモデルは、AWSユーザーが検索の関連性とコンテンツのランキング機能を大幅に向上させることを可能にし、情報検索システムを強化します。Rerank 3.5は、従来のベクトル検索を超えて、動的なクエリ時分析に基づく精度の高い文書関連性評価を提供します。
- アップデート日付: 2024/12/01
- 特徴:
  - CohereのRerank 3.5は、クエリと関連する文書のリストを入力として受け取り、意味的な類似度に基づいて文書を並べ替えます。
  - 性能について、従来のキーワード一致やベクトル検索と比較して、検索結果の順序を最適化し、ユーザーの意図やビジネスルールを反映させる高度な再ランク技術を提供します。
  - Amazon BedrockおよびAmazon Bedrock Knowledge Basesを通じて利用でき、簡単に既存システムに統合できます。
  - オプション機能として、さまざまな業界向けに多言語対応があり、特にグローバルな企業で利用が見込まれます。
- 利用ケース:
  - 企業の検索システムの精度向上や、電子商取引サイトでの製品発見の最適化など、さまざまな情報検索のシナリオで活用できます。
- 注意事項:
  - Amazon BedrockのRerank APIは、Amazon Bedrock Knowledge Basesを利用せずとも機能する柔軟性があります。
- 対応リージョン: 東京リージョン（ap-northeast-1）に対応
- 簡単な利用手順の概要
  - 手順1: Amazon Bedrockコンソールにアクセスし、Rerank APIを有効化
  - 手順2: 必要なライブラリをインポートし、Boto3クライアントを初期化
  - 手順3: rerank_text関数を使って、クエリに関連する文書の順位付けを実施
- 専門用語:

| カテゴリー        | 専門用語                | 説明                                                        |
|-------------------|-------------------------|-------------------------------------------------------------|
| モデル            | Rerank 3.5              | Cohereが提供する再ランク機能を持つモデル。検索結果の関連性を高める。  |
| 機能              | Rerank API              | 文書を意味的に並べ替えるためのAPI。クエリとドキュメントの関連性を分析。 |

### Notes
- 後で検証

## [Now available: Storage optimized Amazon EC2 I7ie instances](https://aws.amazon.com/jp/blogs/aws/now-available-storage-optimized-amazon-ec2-i7ie-instances/)

- 機能概要: 新しいストレージ最適化されたAmazon EC2 I7ieインスタンスは、最大120TBの低遅延NVMeストレージと、3.2GHzのオールコアターボ周波数を持つ第5世代Intel Xeon Scalableプロセッサを搭載しています。これらのインスタンスは、リアルタイムストレージパフォーマンスやI/Oレイテンシ、計算パフォーマンスなどの向上を実現しています。
- アップデート日付: 2024/12/01
- 特徴:
  - 最大120TBのNVMeストレージ、最大192vCPUs、最大1.5TiBのメモリをサポート。
  - 前世代のストレージ最適化インスタンスと比較して、最大65%のストレージパフォーマンス向上、50%低いI/Oレイテンシ、最大40%の計算パフォーマンス向上。
  - NoSQLデータベース、分散ファイルシステム、データウェアハウス、分析などのI/O集中的なワークロードに最適。
  - インスタンスサイズは9種類で、最大100Gbpsのネットワーク帯域幅と高いEBS帯域幅をサポート。
- 利用ケース:
  - NoSQLデータベースや分散ファイルシステム、検索エンジン、データウェアハウス、分析など、ランダムIOPSを多く要求するI/O集中的なワークロードに適しています。
- 注意事項:
  - 対応リージョン: 東京リージョンは未対応、US East (N. Virginia) とUS East (Ohio) に対応、US West (Oregon) も近日中に対応予定。
  - インスタンスはOn-Demand、Spot、Savings Plan、Dedicated Instance、Dedicated Host形式で提供されます。
- 対応リージョン: 東京リージョンは未対応。
- 簡単な利用手順の概要:
  - 手順1: EC2コンソールまたはCLIを使用して、I7ieインスタンスを選択。
  - 手順2: インスタンスサイズ、ストレージタイプ、オプションを選択し、起動。

### 専門用語

| カテゴリー | 専門用語 | 説明 |
| --- | --- | --- |
| プロセッサ | Intel Xeon Scalable | 第5世代のインテル製プロセッサで、3.2GHzのオールコアターボ周波数を提供。 |
| ストレージ | NVMe | 高速なデータ転送を可能にするストレージインターフェース。 |
| 帯域幅 | EBS帯域幅 | Elastic Block Store（EBS）を使用したデータ転送の速度。 |
| ネットワーク | Elastic Network Adapter (ENA) | 高速なネットワーク通信をサポートするAWSのインターフェース。 |

## [Introducing storage optimized Amazon EC2 I8g instances powered by AWS Graviton4 processors and 3rd gen AWS Nitro SSDs](https://aws.amazon.com/jp/blogs/aws/introducing-storage-optimized-amazon-ec2-i8g-instances-powered-by-aws-graviton4-processors-and-3rd-gen-aws-nitro-ssds/)

- 機能概要: EC2 I8g インスタンスは、AWS Graviton4 プロセッサと第3世代 AWS Nitro SSD を搭載したストレージ最適化インスタンスで、リアルタイムストレージパフォーマンスが最も優れた EC2 インスタンスです。これにより、より高いストレージ性能、低遅延、低レイテンシーの変動が提供され、特に I/O 集約型のワークロードに適しています。
- アップデート日付: 2024/12/01
- 特徴:
  - AWS Graviton4 プロセッサにより、最大60%のコンピューティング性能向上と2倍のキャッシュを提供。
  - 第3世代 AWS Nitro SSD により、ストレージ性能が向上し、I4g インスタンスと比較して、22.5 TB のストレージあたり65%のリアルタイム性能向上、60% の遅延変動の低減が実現。
  - 最大 96 vCPUs、768 GiB のメモリ、22.5 TB のストレージを提供することで、I4g インスタンスと比較して、より多くの計算およびストレージの選択肢が得られる。
  - EC2 I8g インスタンスは、ストレージ集約型ワークロード向けに特化しており、MySQL、PostgreSQL、MongoDB などのリアルタイムデータベースや、Apache Spark などのリアルタイム分析に適している。
- 利用ケース:
  - 低遅延でデータにアクセスする必要があるトランザクションデータベース（MySQL、PostgreSQL）、NoSQL データベース（Aerospike、Apache Druid、MongoDB）、およびリアルタイム分析（Apache Spark）に利用。
- 注意事項:
  - サポートされているオペレーティングシステムは、Amazon Linux 2、CentOS Stream 8 以降、Ubuntu 18.04 以降、Red Hat Enterprise 8.2 以降などが含まれている。
  - ネットワークバーストをサポートし、ストレージデータのネットワーク越しのデータ水和、バックアップ、スナップショットなどが可能。
- 対応リージョン: 現在、US East (N. Virginia) および US West (Oregon) リージョンで利用可能。東京リージョンには未対応。
- 簡単な利用手順の概要:
  - 手順1: Amazon EC2 コンソールにアクセスし、EC2 I8g インスタンスを選択。
  - 手順2: 必要なインスタンスタイプとストレージオプションを選択。
  - 手順3: インスタンスを起動し、対象のワークロードを実行。

| カテゴリー     | 専門用語       | 簡潔な説明                                                   |
|----------------|----------------|------------------------------------------------------------|
| プロセッサ     | AWS Graviton4   | ARM アーキテクチャに基づいた、AWS の最もパワフルでエネルギー効率の良いプロセッサ。 |
| ストレージ     | AWS Nitro SSD   | AWS によってカスタム構築された SSD。高パフォーマンスと低遅延を提供。             |
| インスタンスタイプ | EC2 I8g        | ストレージ最適化された EC2 インスタンスタイプ。リアルタイムストレージ性能が向上。   |
| ネットワーキング | バーストネットワーク | ストレージ集約型ワークロードでのネットワーク帯域幅を一時的に増加させる機能。      |

## [Amazon MemoryDB Multi-Region is now generally available](https://aws.amazon.com/jp/blogs/aws/amazon-memorydb-multi-region-is-now-generally-available/)

- 機能概要: Amazon MemoryDB Multi-Regionは、複数のAWSリージョンにまたがるアクティブ-アクティブ型のデータベースを提供する完全に管理されたサービスです。この機能により、99.999%の可用性、マイクロ秒単位の読み取りおよびミリ秒単位の書き込み遅延を実現し、複数のAWSリージョン間でデータを効率的に同期できます。これにより、災害復旧や高可用性を確保しながら、リージョン間のデータ複製を簡素化します。
- アップデート日付: 2024/12/01
- 特徴:
  - 高可用性と災害復旧を提供し、99.999%の可用性を達成。
  - マイクロ秒単位の読み取りとミリ秒単位の書き込み遅延を実現。
  - AWSリージョン間でデータを非同期でレプリケーション、データ伝播は1秒未満で完了。
  - データの地理的要件を満たすために、データの保持リージョンを選択可能。
- 利用ケース:
  - 高可用性を必要とするアプリケーション、特にグローバルに展開される分散型アプリケーション。
  - 地理的要件に基づいてデータをリージョンごとに保持する必要がある場合。
  - リージョン間でシームレスなデータレプリケーションと迅速な災害復旧を実現したいシステム。
- 注意事項:
  - 利用可能なリージョンに制限があり、一部の地域ではサポートされていない。
  - 定期的なデータ同期のため、データの複製にかかる遅延を考慮する必要がある。
- 対応リージョン: 東京リージョン（東京リージョンを含む複数のアジア太平洋地域で対応あり）
- 簡単な利用手順の概要:
  - 手順1: AWS Management ConsoleからMemoryDBを選択し、「Create cluster」を選択。
  - 手順2: 「Multi-Region cluster」を選び、必要な設定を入力してクラスターを作成。
  - 手順3: 必要に応じて他のリージョンで追加のクラスターを作成。
  - 手順4: AWS CLIまたはコンソールで設定したクラスターのステータスを確認。

- 専門用語:

| カテゴリー       | 専門用語               | 説明                                               |
|------------------|------------------------|----------------------------------------------------|
| サービス         | Amazon MemoryDB         | AWSが提供する、インメモリ型のデータベースサービス。高可用性と低レイテンシを提供。  |
| レプリケーション | アクティブ-アクティブ型  | 全てのリージョンが読み書き可能で、データがリアルタイムで同期される仕組み。           |

## [Amazon SageMaker Lakehouse integrated access controls now available in Amazon Athena federated queries](https://aws.amazon.com/jp/blogs/aws/amazon-sagemaker-lakehouse-integrated-access-controls-now-available-in-amazon-athena-federated-queries/)

- 機能概要: Amazon SageMaker Lakehouseは、データレイクとデータウェアハウスを統合し、データソースに対するカタログ機能とアクセス管理機能を提供します。これにより、複数のデータソースを一元的に管理し、データの転送や重複を避けながら、効率的な分析とセキュリティ管理が可能になります。
- アップデート日付: 2024/12/03
- 特徴:
  - SageMaker LakehouseとAmazon Athenaが連携し、データソースに対する一貫したアクセス制御とカタログ機能を提供。
  - Athenaでのクエリ実行時に、データの場所を変更せずにアクセス管理を適用。
  - サポート対象サービスには、Amazon S3、Amazon Redshift、Amazon Aurora、Amazon DynamoDB、Google BigQueryなどが含まれます。
  - Fine-Grained Access Control (FGAC)により、データレイクやOLTPデータソースへのアクセス制御を細かく設定可能。
- 利用ケース:
  - データ分析者やデータサイエンティストが複数のデータソースを統一的に利用し、アクセス権に基づいて必要なデータのみを分析するケース。
  - セキュリティ要求が高い環境で、細かなアクセス権限設定を適用しつつ、効率的なデータ分析を行いたい場合。
- 注意事項:
  - 本機能は、Athenaを使用したクエリ実行時に限定されます。
  - DynamoDBなど一部のデータソースは、現在プレビュー版として提供されています。
- 対応リージョン: 東京リージョン（Asia Pacific (Tokyo)）を含む複数のAWSリージョンで利用可能。
- 簡単な利用手順の概要:
  - 手順1: Amazon SageMaker Unified Studioにアクセスし、プロジェクトを作成または選択します。
  - 手順2: データソース（例: DynamoDB）を選択し、SageMaker Lakehouseでカタログを作成します。
  - 手順3: Athenaでクエリを実行し、設定したアクセス制御が適用されることを確認します。
- 専門用語:

| カテゴリー                | 専門用語                         | 説明                                                          |
|-------------------------|----------------------------------|-------------------------------------------------------------|
| サービス                 | Amazon SageMaker Lakehouse       | データレイクとデータウェアハウスを統合し、AI/MLアプリケーションを構築するためのプラットフォーム。 |
| サービス                 | AWS Glue Data Catalog            | データソースのメタデータを一元管理するためのAWSサービス。                                        |
| セキュリティ             | Fine-Grained Access Control (FGAC) | データに対する細かいアクセス権限を定義し、適用するための機能。                                      |
| データベース             | OLTP (Online Transaction Processing) | トランザクション処理を行うためのデータベースシステム。                                              |

## [Simplify analytics and AI/ML with new Amazon SageMaker Lakehouse](https://aws.amazon.com/blogs/machine-learning/simplify-analytics-and-ai-ml-with-new-amazon-sagemaker-lakehouse/)

- 機能概要: Amazon SageMaker Lakehouseは、Amazon S3データレイクとAmazon Redshiftデータウェアハウスのデータを統一し、単一のデータコピーで分析やAI/MLアプリケーションを構築するための機能です。この機能は、AWSの機械学習と分析能力を統合し、分析とAIのためのシームレスな体験を提供します。
- アップデート日付: 2024/12/03
- 特徴:
  - SageMaker Lakehouseは、Amazon S3とRedshift間でデータを統一し、Apache Iceberg互換のエンジンでデータをインプレースでクエリする柔軟性を提供します。
  - 他の分析ツールやAI/MLエンジンにも対応しており、異なるソースからのデータを一元的に管理できます。
  - AWS Glue、Amazon Athena、Amazon SageMaker AIなどのツールを使用して、データのクエリやモデル開発をサポートします。
  - SQLによる分析やJupyter Labノートブックを利用したデータ操作が可能です。
- 利用ケース:
  - 複数のデータソースからのデータを統合し、分析やAI/MLモデルを開発する場合。
  - Amazon RedshiftやAmazon S3を使用する既存のデータ環境を活用し、データシェアリングを簡素化する場合。
  - データレイクとデータウェアハウス間でのデータ統合をスムーズに行いたい場合。
- 注意事項:
  - SageMaker Lakehouseは、データを統一するためにいくつかの設定が必要であり、ユーザーの環境に合わせたカスタマイズが求められます。
  - Jupyter Labノートブックの使用には「データ分析およびAI/MLモデル開発」プロファイルを選択する必要があります。
- 対応リージョン: 東京リージョン (Asia Pacific Tokyo) に対応しています。
- 簡単な利用手順の概要:
  - 手順1: Amazon SageMaker Unified Studioにアクセスし、新しいプロジェクトを作成します。
  - 手順2: プロジェクトのプロファイルを選択し、必要なリソースを設定します。
  - 手順3: データソースを追加し、クエリエディタでデータにアクセスします。
  - 手順4: 必要に応じてAthenaやRedshiftを使ってクエリを実行し、データを分析します。

| カテゴリー   | 専門用語                    | 説明                                                                 |
|------------|----------------------------|----------------------------------------------------------------------|
| 機能         | Apache Iceberg              | 分散データ処理のためのオープンソースのファイル形式で、データウェアハウスやデータレイクに対応。 |

### Notes
- [Amazon SageMaker Lakehouse and Amazon Redshift supports zero-ETL integrations from applications](https://aws.amazon.com/jp/blogs/aws/introducing-amazon-sagemaker-lakehouse-support-for-zero-etl-integrations-from-applications/) 類似のものが多すぎるので割愛

## [New Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse](https://aws.amazon.com/blogs/analytics/new-amazon-dynamodb-zero-etl-integration-with-amazon-sagemaker-lakehouse/)

- 機能概要: Amazon DynamoDBとAmazon SageMaker LakehouseのゼロETL統合により、DynamoDBのデータを分析や機械学習ワークロードで活用するためのパイプライン構築の手間を省き、数クリックでデータの抽出・活用が可能になります。この統合により、DynamoDBテーブルのキャパシティを消費せずに、データの動きを最小限に抑えながら簡単に分析やMLを実行できます。
- アップデート日付: 2024/12/03
- 特徴:
  - DynamoDBのデータを、Amazon SageMaker Lakehouseを使用してAmazon S3やRedshiftで一元化し、分析・MLワークロードを簡単に実行できるようにします。
  - ゼロETL統合により、従来のETLパイプライン構築の煩雑さを排除し、データの移動にかかる運用負担を軽減します。
  - 対応するサービス: Amazon DynamoDB, Amazon SageMaker Lakehouse, AWS Glue, Amazon S3, Apache Iceberg。
  - オプション機能: AWS KMSやカスタム暗号化キーを利用したデータの暗号化。
- 利用ケース:
  - DynamoDBに保存されているデータを、追加のインフラ設定なしでAmazon SageMaker Lakehouseに統合し、データ分析や機械学習のワークロードを簡単に実行したい場合。
  - ETLパイプラインの管理を減らし、より効率的にデータを抽出・活用したい企業。
- 注意事項:
  - ゼロETL統合の実行に必要なIAMロールやリソースポリシー設定に関する事前準備が必要です。
  - 統合後のデータ処理には、DynamoDBテーブルのサイズに依存した時間がかかる場合があります。
- 対応リージョン: 東京リージョン対応あり (Asia Pacific (Tokyo))。
- 簡単な利用手順の概要:
  - 手順1: AWS Glueコンソールで「Zero-ETL integrations」を選択し、DynamoDBをデータソースとして設定。
  - 手順2: S3バケットをターゲットとして指定し、必要なIAMロールと暗号化設定を行う。
  - 手順3: 設定内容を確認し、統合を作成。
- 専門用語:

| カテゴリ     | 専門用語             | 説明                                                                                         |
|--------------|----------------------|----------------------------------------------------------------------------------------------|
| データ統合   | Zero-ETL              | ETL (Extract, Transform, Load) の手順を省略するデータ統合手法。これにより、データの移動や変換を最小化。 |
| データ解析   | SageMaker Lakehouse   | データレイクとデータウェアハウスを統合した分析・MLプラットフォーム。                            |
| データストレージ | Apache Iceberg         | 分散データ処理に対応したオープンソースのデータフォーマット。                                      |

## [Discover, govern, and collaborate on data and AI securely with Amazon SageMaker Data and AI Governance](https://aws.amazon.com/jp/blogs/aws/discover-govern-and-collaborate-on-data-and-ai-securely-with-amazon-sagemaker-data-and-ai-governance/)

- **機能概要**: Amazon SageMaker Data and AI Governanceは、データおよびAI資産の管理を簡素化するための機能を提供し、データチームがデータやAIモデルを企業全体で効果的に発見、アクセス、協力できるように支援します。このプラットフォームは、データのカタログ化、発見、ガバナンスを統一された体験で提供し、安全にデータを利用できるようにします。
- **アップデート日付**: 2024/12/03
- **特徴**:
  - Amazon SageMaker Unified Studioを通じて、データとAI資産の管理が可能。
  - 機械学習を活用して、データ資産や列名を自動的にビジネス名に変換する機能。
  - SageMaker Catalogは、Amazon DataZoneに基づいており、AWSの既存のワークフローとツールとの統合がシームレス。
  - データとAI資産のアクセス制御には、ビジネス目的に基づいたプロジェクトを使用して、AIモデルやデータの安全な共有が可能。
  - AIガードレール機能を使って、アプリケーションにおけるAIの安全性を強化。
  - APIサポートを提供し、既存プロセスとの統合が容易に。
- **利用ケース**:
  - データサイエンティストやエンジニアが、データの発見、アクセス、ガバナンスを簡素化し、AIモデルのガードレールを使用して、安全に利用するケース。
  - ビジネスユースケースに基づいてプロジェクトを作成し、チームでの共同作業をサポートするケース。
- **注意事項**:
  - サービスはプレビュー段階で提供されており、一部機能は進行中である可能性がある。
- **対応リージョン**: 東京リージョン対応
- **簡単な利用手順の概要**:
  - 手順1: Amazon SageMaker Unified Studioにログインし、プロジェクトを作成する。
  - 手順2: データカタログを探索し、利用したいデータ資産を見つける。
  - 手順3: 必要に応じてデータへのアクセスリクエストを送信し、承認を得る。
  
### 専門用語

| カテゴリー          | 専門用語                   | 説明                                                         |
|---------------------|----------------------------|--------------------------------------------------------------|
| データ管理          | Amazon DataZone            | データガバナンスとカタログ機能を提供するAWSのプラットフォーム。             |
| データカタログ      | SageMaker Catalog          | データとAI資産のカタログ管理機能を提供するSageMaker内のリポジトリ。         |

## [Introducing the next generation of Amazon SageMaker: The center for all your data, analytics, and AI](https://aws.amazon.com/blogs/aws/introducing-the-next-generation-of-amazon-sagemaker-the-center-for-all-your-data-analytics-and-ai/)

- 機能概要: Amazon SageMakerの次世代バージョンが発表され、データ探索、準備、統合、大規模データ処理、SQL分析、機械学習（ML）モデル開発とトレーニング、生成的AIアプリケーション開発のための統合プラットフォームを提供します。これには、既存のAmazon SageMaker AIも統合されています。
- アップデート日付: 2024/12/03
- 特徴:
  - 新しいAmazon SageMakerは、データとAI開発のための統合環境「SageMaker Unified Studio」を提供します。
  - 複数のAWSツール（Amazon Athena、Amazon EMR、AWS Glue、Amazon Redshiftなど）と連携し、シームレスなデータ処理が可能です。
  - Amazon Bedrock IDEを使用して、生成的AIアプリケーションの開発が可能です。
  - 「Amazon Q」を活用し、開発フローをAIで支援します。
- 利用ケース:
  - データ分析、モデル開発、生成的AIアプリケーションの構築など、広範なAI/MLワークフローに対応。
  - チームでの共同作業やデータ共有を安全に行い、モデルのトレーニング、データ準備、予測などを統一された環境で管理。
- 注意事項:
  - Amazon SageMaker Unified Studioは現在プレビュー版として利用可能で、正式リリース前のバージョンです。
  - 既存のAmazon Bedrock Studioは2025年2月28日まで利用可能ですが、新しいワークスペースの作成はできません。
- 対応リージョン: 東京リージョン（アジアパシフィック（東京））に対応
- 簡単な利用手順の概要
  - 手順1: SageMaker Unified StudioのドメインURLでサインイン
  - 手順2: プロジェクトを作成し、データソースを追加
  - 手順3: SQLクエリエディタやビジュアルETLツールを使用してデータを処理
  - 手順4: 生成的AIアプリケーションを作成し、テスト・最適化

### 専門用語:

| カテゴリー  | 専門用語             | 簡潔な説明                                                                                                                                                        |
|-------------|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| データレイク  | Amazon SageMaker Lakehouse | Amazon S3データレイクとRedshiftデータウェアハウス、サードパーティのデータソースを統合して利用できる。                                                              |

## [Announcing the general availability of data lineage in the next generation of Amazon SageMaker and Amazon DataZone](https://aws.amazon.com/jp/blogs/aws/announcing-the-general-availability-of-data-lineage-in-the-next-generation-of-amazon-sagemaker-and-amazon-datazone/)

- **機能概要**:  
  Amazon DataZoneと次世代Amazon SageMakerにおいて、データの出所を可視化するデータリネージュ機能が正式に一般提供開始されました。この機能は、AWS GlueやAmazon Redshiftからデータ変換の履歴を自動的に収集し、データのトレーサビリティを強化します。これにより、ビジネスアナリストやデータエンジニア、データガバナンス担当者がデータの影響範囲を即座に把握し、信頼性の高いデータ駆動型の意思決定を行うことが可能になります。

- **アップデート日付**: 2024/12/03

- **特徴**:
  - データの自動リネージュ収集をAWS GlueおよびAmazon Redshiftでサポートし、手動作業を削減。
  - データ変換履歴、スナップショット、カラムマッピングを可視化し、影響分析やトラブルシューティングを容易に。
  - OpenLineage互換のイベントを使用して、カスタムパイプラインからリネージュ情報をプログラム的に登録可能。
  - Amazon SageMaker Unified Studioのカタログ機能としてリネージュが統合され、データユーザーは同一プラットフォーム内でリネージュ情報を管理可能。

- **利用ケース**:
  - ビジネスアナリストがデータの出所を確認し、データの信頼性を担保するために利用。
  - ダッシュボードの異常な数値変動の原因を調査する際、データエンジニアが影響分析を行うために活用。
  - 監査人からのデータの移動履歴や変換履歴に関する質問に対して、データスチュワードが迅速に回答するために使用。

- **注意事項**:
  - AWS GlueやAmazon Redshiftからのリネージュイベント収集はオプトイン設定が必要。
  - リネージュ情報の収集には、ストレージとAPIリクエストに基づくコストが発生。詳細はAmazon DataZoneの料金ページを参照。
  - 自動収集されるイベントは、テーブル作成、スキーマ変更、変換クエリなどのデータ変換操作を含む。

- **対応リージョン**:  
  東京リージョンを含む、Amazon DataZoneが利用可能な全てのリージョンで対応。

- **簡単な利用手順の概要**:
  1. AWS Glue Data CatalogやAmazon Redshiftのデータソース実行ジョブをAmazon DataZoneに設定し、定期的にメタデータを収集。
  2. カスタムリネージュ情報をAPI経由でプログラム的に登録。
  3. Amazon DataZoneポータル内でリネージュタブを利用して、データの出所や変換履歴を確認。

- **専門用語**:

| カテゴリー            | 専門用語           | 説明                                        |
|-----------------------|-------------------|---------------------------------------------|
| APIイベント           | OpenLineage       | データリネージュ情報を標準化された形式で提供するイベントプロトコル。 |

### Notes
- Next Genration Next Genration SageMaker が来ることはあるのか・・
- もはや次世代過ぎてついていけてないんだけど個人的には Notebook の AL2023 対応ほしい、Studio Notebook だと DinD だから開発環境としては使いづらいし、正直 Notebook が一番使いやすい・・

## [New capabilities from Amazon Q Business enable ISVs to enhance generative AI experiences]()

- **機能概要**:  
  Amazon Q Businessが新たに提供する機能により、ISV (Independent Software Vendors) は、複数のSaaSアプリケーションからデータを一元的に取得し、企業の知識とユーザーのコンテキストを活用したAI機能を統合できます。これにより、より個別化されたユーザー体験が可能になり、業務効率の向上とユーザーエンゲージメントの強化が期待されます。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **Amazon Qインデックスによるデータ統合**: 複数の外部データソースを一つのAPIを通じて取得し、ISVの既存AI機能を強化可能。  
  - **データ所有権とアクセス制御**: ユーザーはインデックスに対するデータ所有権を保持し、アクセス権を管理可能。  
  - **エンベッド型AIアシスタント**: Amazon Q Embeddedにより、ISVはユーザーインターフェースにAIアシスタントを埋め込むことができ、カスタマイズされた外観を設定可能。  
  - **API経由でのデータ検索機能**: `SearchRelevantContent` APIを活用し、関連データを効率的に検索。  
  - **カスタマイズ可能なUI**: ブランドに合わせたUIの外観、アシスタント名、ウェルカムメッセージなどを設定可能。

- **利用ケース**:  
  - SaaSアプリケーションにおけるユーザーの業務支援や自動化。  
  - 複数の企業アプリケーション間で一貫性のある情報提供。  
  - 企業のナレッジデータを活用したカスタマーサポートや業務効率化。

- **注意事項**:  
  - データアクセスにはユーザーの明示的な許可が必要。  
  - 対応リージョンに制限があり、東京リージョンでのサポートは現在未対応。

- **対応リージョン**:  
  - **対応済み**: 米国東部（N.バージニア）、米国西部（オレゴン）。  
  - **東京リージョン**: 未対応。今後の対応予定。

- **簡単な利用手順の概要**:  
  - **手順1**: ISVがAmazon Qインデックスにアプリケーションを登録し、ユーザーにデータソース接続の認証情報を提供。  
  - **手順2**: AWSマネジメントコンソールでユーザーがインデックスを作成し、ISVにアクセス権を付与。  
  - **手順3**: ISVは`SearchRelevantContent` APIを使用してデータを取得し、機能を強化。  
  - **手順4**: Amazon Q EmbeddedでUIをカスタマイズし、ブランドに最適化したアシスタントを提供。

- **専門用語**:  

| カテゴリー       | 専門用語               | 説明                                                                                 |
| ---------------- | ---------------------- | ------------------------------------------------------------------------------------ |
| データ管理       | Amazon Q インデックス   | 複数のSaaSアプリケーションからデータを一元的に管理・取得するための仕組み。               |
| API              | SearchRelevantContent  | インデックス内の関連コンテンツを検索するためのAPI。                                   |
| UIカスタマイズ   | Amazon Q Embedded      | アプリケーションにAIアシスタントを埋め込む機能。外観や機能をカスタマイズ可能。         |
| データアクセス   | Data Accessors         | ISVがデータへのアクセス権を取得する際に必要な認証情報の設定。                         |

### Notes
- Q 関連大杉、、力入れとる

## [Investigate and remediate operational issues with Amazon Q Developer (in preview)]()

- **機能概要**:  
Amazon Q Developerの新しい機能がプレビューとして公開され、運用上の問題を自動的に調査し、診断から根本原因分析、そして修正までをサポートします。AWSリソース間の関係を自動的に検出し、アプリケーショントポロジーを作成することで、迅速な障害復旧が可能になります。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **運用調査と修復のガイド機能**: CloudWatchやAWS Systems Managerと統合し、運用問題を調査し、修復手順を自動的に提示。  
  - **仮説生成と提案機能**: DynamoDB、Lambda、ECSなど、AWSのさまざまなサービスから収集したメトリクスを基に、問題に関する仮説を生成。ユーザーは仮説を受け入れて調査を進めることが可能。  
  - **自動修復の推奨**: AWS Systems Managerのオートメーションランブックを提案し、対応する問題に対する修正手順を実行可能。  
  - **ドキュメント参照**: AWS re:Post記事や公式ドキュメントへのリンクを提供し、問題解決を支援。  

- **利用ケース**:  
  - 監視対象のアプリケーションでCloudWatchアラームが発生した場合に、根本原因を特定して迅速に問題を修正するための運用支援ツールとして活用。  
  - 複雑なマイクロサービス環境における問題調査やリソース間の依存関係の把握。  
  - 業務時間外や緊急時における運用対応を自動化して、オペレーションの効率を向上。  

- **注意事項**:  
  - 現在はプレビュー版であり、正式リリース前に仕様変更される可能性がある。  
  - サポート対象リージョンは限定されており、現時点では **US East (N. Virginia)** のみ対応。  

- **対応リージョン**:  
  - 東京リージョンは現時点で未対応。

- **簡単な利用手順の概要**:  
  - 手順1: CloudWatchアラームを設定し、対象アプリケーションのメトリクスを監視する。  
  - 手順2: アラーム通知を受信したら、CloudWatchから **Investigate** を選択し、新規調査を開始する。  
  - 手順3: Amazon Q Developerが提示する仮説と関連メトリクスを確認し、適切な仮説を選択。  
  - 手順4: 提案されたランブックを確認し、必要なパラメータを入力して実行する。  
  - 手順5: 実行結果を確認し、調査の進行状況を **Feed** で管理する。

### カテゴリーと専門用語

| カテゴリー                | 専門用語                      | 簡潔な説明                                                                 |
|--------------------------|------------------------------|---------------------------------------------------------------------------|
| トポロジーマップ           | Topology Map                 | アプリケーション内のリソース間の関係を可視化したマップ。                   |

### Notes
- めっちゃよさそう、対応リージョンでの調査しかできないのか？

## [Introducing Amazon Nova foundation models: Frontier intelligence and industry leading price performance](https://aws.amazon.com/jp/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/)

- **機能概要**:  
  Amazon Novaは、Amazon Bedrock上で提供される次世代のファウンデーションモデルで、生成AIタスクにおけるコストとレイテンシーを削減しつつ、最先端の知能を活用することができます。企業の多様なワークロードに対応し、複雑なドキュメントや動画の解析、AIエージェントの構築、魅力的なコンテンツの生成が可能です。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **メインの機能特徴**:  
    Amazon Novaは、テキスト、画像、動画を入力として処理し、テキストやマルチモーダル出力を生成できる複数のモデルを提供します。  
  - **性能**:  
    従来のモデルと比較して、低レイテンシー、高精度、そして高コストパフォーマンスを実現しています。特に、300Kトークンまでの長文処理や、最大30分の動画解析が可能です。  
  - **サポートモデル**:  
    - **Amazon Nova Micro**: テキストのみを対象とした高速・低コストモデル。  
    - **Amazon Nova Lite**: テキスト、画像、動画の入力を処理する低コスト・マルチモーダルモデル。  
    - **Amazon Nova Pro**: 高精度かつマルチモーダル処理に優れたモデル。  
    - **Amazon Nova Premier**: 2025年初頭にリリース予定の高度なマルチモーダルモデル。  
  - **オプション機能**:  
    各モデルはカスタマイズが可能で、業界特化型の用語やドキュメント構造に適応するように調整できます。また、生成された画像や動画にはウォーターマークが自動的に付加されます。

- **利用ケース**:  
  - 長文ドキュメントの要約、翻訳、分類。  
  - 画像・動画からの情報抽出や可視化。  
  - マーケティングや広告向けの動画コンテンツ生成。  
  - APIやツールを用いたエージェントによる複雑なワークフローの自動化。

- **注意事項**:  
  - 現時点では動画内のオーディオ解析には対応していません。  
  - すべての生成コンテンツには安全管理と責任あるAI利用を促進するための制御機能が組み込まれています。

- **対応リージョン**:  
  - 東京リージョンでの対応は現在未確認ですが、US East (N. Virginia)、US West (Oregon)、US East (Ohio)で利用可能です。

- **簡単な利用手順の概要**:  
  1. Amazon BedrockコンソールでAmazon Novaモデルへのアクセスをリクエストします。  
  2. Playgroundでモデルを選択し、テキストやファイルを入力して応答を確認します。  
  3. SDKやAWS CLIを使用して、API経由でモデルに入力を送信し、出力を取得します。  

- **専門用語**:  
  - **ファウンデーションモデル** (Foundation Model): 複数のタスクに対応可能な大規模AIモデル。  
  - **マルチモーダル** (Multimodal): テキスト、画像、動画など複数のデータ形式を統合して処理する技術。  
  - **モデルディスティレーション** (Model Distillation): 大規模モデルから小規模モデルに知識を転移して効率を最適化する技術。


# 20241204(JST) 編集

## Related to Amazon Bedrock

- [Introducing latency-optimized inference for foundation models in Amazon Bedrock](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/latency-optimized-inference-foundation-models-amazon-bedrock/)

## Related to Amazon Q

- [Announcing Amazon Q Developer transformation capabilities for .NET, mainframe, and VMware workloads in a web experience (preview)](https://aws.amazon.com/jp/blogs/aws/announcing-amazon-q-developer-transformation-capabilities-for-net-mainframe-and-vmware-workloads-preview/)
- [Amazon Q Business is adding new workflow automation capability and 50+ action integrations](https://aws.amazon.com/jp/blogs/aws/amazon-q-business-is-adding-new-workflow-automation-capability-and-50-action-integrations/)
- [Amazon Q Business adds support to extract insights from visual elements within documents](https://aws.amazon.com/about-aws/whats-new/2024/12/amazon-q-business-extract-insights-visual-elements-documents)
  - This new feature enables users to query information embedded in various types of visual, including diagrams, infographics, charts, and image-based content
- [Announcing Amazon Q Developer transformation capabilities for .NET in IDE (preview)](https://aws.amazon.com/blogs/aws/announcing-amazon-q-developer-transformation-capabilities-for-net-preview/)
- [New Amazon Q Developer agent capabilities include generating documentation, code reviews, and unit tests](https://aws.amazon.com/jp/blogs/aws/new-amazon-q-developer-agent-capabilities-include-generating-documentation-code-reviews-and-unit-tests/)

### Notes

## [Introducing multi-agent collaboration capability for Amazon Bedrock (preview)](https://aws.amazon.com/jp/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/)

- **機能概要**:  
Amazon Bedrockの新機能である「マルチエージェントコラボレーション」により、複数のAIエージェントが協力して、専門的なスキルを活かしながら複雑なマルチステップのタスクを効率的に処理することが可能になります。従来、開発者はオープンソースソリューションでエージェントのオーケストレーションやメモリ管理などを手動で実装する必要がありましたが、この機能により、これらの作業が大幅に簡略化されます。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **簡単なセットアップ**: 複雑なコーディングを必要とせずに、数分でエージェントを作成、デプロイ、管理可能。  
  - **コンポーザビリティ**: 既存のエージェントをサブエージェントとして統合し、シームレスに協力できる。  
  - **効率的なエージェント間通信**: スーパーバイザーエージェントが一貫したインターフェースを介してサブエージェントと通信し、タスク完了を効率化。  
  - **最適化されたコラボレーションモード**:  
    - スーパーバイザーモード: 複雑な問題を分析し、サブエージェントを順次または並列に呼び出す。  
    - スーパーバイザーとルーティングモード: 単純なリクエストは直接サブエージェントにルーティングし、複雑なものはスーパーバイザーモードに切り替える。  
  - **統合トレース＆デバッグコンソール**: マルチエージェントの相互作用を可視化・分析できる。  

- **利用ケース**:  
  - 投資アドバイザリーシステム: 財務データ分析、調査、予測、投資推奨などの専門エージェントが協力してタスクを遂行する。  
  - 小売業の運用システム: 需要予測、在庫配分、サプライチェーンの調整、価格最適化などを複数エージェントで管理する。  
  - ソーシャルメディアキャンペーン管理: コンテンツ戦略エージェントとエンゲージメント予測エージェントを組み合わせて最適な投稿内容とタイミングを提案する。  

- **注意事項**:  
  - プレビュー期間中はリアルタイムチャットアシスタントなどの同期型ユースケースに対応。  
  - サブエージェントのコラボレーションは最大3階層までのエージェントチーム構成が可能。  
  - エージェント間の会話履歴共有機能は、簡単なタスクを処理する際に無効化することが推奨される。  

- **対応リージョン**:  
  東京リージョンを含むAmazon Bedrock AgentsがサポートされているすべてのAWSリージョンで利用可能（AWS GovCloud（US-West）は除く）。  

- **簡単な利用手順の概要**:  
  - **手順1**: Amazon Bedrockコンソールで「エージェント作成」から専門エージェント（例: コンテンツ戦略エージェント、エンゲージメント予測エージェント）を個別に作成。  
  - **手順2**: スーパーバイザーエージェントを作成し、マルチエージェントコラボレーションを有効化。  
  - **手順3**: 作成したサブエージェントをスーパーバイザーエージェントに関連付けて、チームとしてタスクを実行。  
  - **手順4**: エージェントの動作をテストし、統合トレースコンソールでワークフローを確認。  

- **専門用語**:  

| **カテゴリー**                | **専門用語**                 | **説明**                                                                                 |
|---------------------------|--------------------------|------------------------------------------------------------------------------------------|
| マルチエージェントシステム        | スーパーバイザーエージェント         | サブエージェントを統括し、タスクを分割・調整する中心的な役割を担うエージェント。                                                |
| マルチエージェントシステム        | サブエージェント                   | 特定のタスクやスキルに特化したエージェント。スーパーバイザーにより調整されて動作する。                                          |
| コラボレーションモード           | スーパーバイザーモード             | スーパーバイザーが入力を分析し、サブエージェントを順次または並列に呼び出してタスクを処理するモード。                          |
| コラボレーションモード           | ルーティングモード                 | 単純なリクエストはサブエージェントに直接ルーティングし、複雑なリクエストはスーパーバイザーモードに切り替えるモード。               |

### Notes
- 後で検証

## [Investigate and remediate operational issues with Amazon Q Developer (in preview)](https://aws.amazon.com/jp/blogs/aws/investigate-and-remediate-operational-issues-with-amazon-q-developer/)

- **機能概要**:  
Amazon Q Developerは、AWSのワークロードにおける運用上の問題を診断し、根本原因を特定して解決するためのジェネレーティブAIを活用した機能を提供します。CloudWatchやAWS Systems Managerと統合されており、リソース間の関係を自動的に発見し、問題を迅速に解決できるようサポートします。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **問題の調査と解決の自動化**: Amazon Q Developerは、アプリケーションのトポロジーマップを作成し、アラームの原因となったコンポーネントを特定します。  
  - **仮説生成と提案**: DynamoDB、Lambda、ECSなどのサービスから関連するメトリクスを基に仮説を提示し、その理由も確認可能です。  
  - **リメディエーションの自動化**: AWS Systems Managerのオートメーションランブックを提案し、過去の実行履歴も確認できます。  
  - **統合された操作環境**: CloudWatchやLambdaメトリクスから直接インシデントを調査し、フィードに追加できます。  

- **利用ケース**:  
  - DynamoDBのスロットリングやLambdaのパフォーマンス低下など、クラウドアプリケーションで発生するパフォーマンス問題の診断と解決。  
  - システム管理者が複数のAWSサービスにまたがる複雑な問題を迅速に調査し、影響を最小限に抑える。

- **注意事項**:  
  - 現在プレビュー版であり、US East (N. Virginia) リージョンのみで提供されています。  
  - トラブルシューティングは、AWSサービスの構成やメトリクスの正確な設定に依存します。  

- **対応リージョン**:  
  - **東京リージョン**: 現時点では未対応

- **簡単な利用手順の概要**:  
  - **手順1**: CloudWatchアラームを設定し、メトリクスを監視します。  
  - **手順2**: アラームが発生した際にAmazon Q Developerを使用して新しい調査を開始します。  
  - **手順3**: 提案された仮説と修復アクションを確認し、適用するランブックを選択します。  
  - **手順4**: パラメータを入力し、実行結果を確認してフィードに追加します。

## [Introducing GitLab Duo with Amazon Q](https://aws.amazon.com/jp/blogs/aws/introducing-gitlab-duo-with-amazon-q/)

- **機能概要**:  
GitLab Duo with Amazon Q は、AWS の Amazon Q Developer エージェントを GitLab に統合し、AI を活用した開発支援機能を提供することで、DevSecOps の効率化と開発ワークフローの変革を実現します。これにより、開発者はコードレビューや機能開発、レガシーコードの移行を GitLab 内でシームレスに行えるようになります。

- **アップデート日付**: 2024/12/03  

- **特徴**:  
  - **統合型開発支援**: Amazon Q Developer を GitLab のクイックアクション `/q` コマンドを通じて操作可能。  
  - **コード生成とマージリクエストの自動化**: 既存コードベースの解析に基づき、コードを生成し、自動的にマージリクエストを作成。  
  - **コードレビューの自動化**: セキュリティ脆弱性や品質問題をスキャンし、修正提案を自動生成。  
  - **レガシーコードの移行支援**: Java 8 や 11 から Java 17 へのコード移行を自動化し、移行プランや依存関係の変更を報告。  

- **利用ケース**:  
  - **新機能の開発**: Web アプリケーションの新規サインアップ機能をコード生成機能で素早く実装。  
  - **コードレビューの効率化**: セキュリティやベストプラクティスに従ったコードレビューを AI が補助。  
  - **レガシーコードのアップグレード**: Java 17 への移行タスクを自動化し、移行作業の効率を向上。  

- **注意事項**:  
  - 現在プレビュー版として提供されており、GitLab Ultimate サブスクリプションを持つセルフマネージド環境でのみ利用可能。  
  - 生成されたコードには第三者のオープンソースコードが含まれる場合があり、利用者が責任を持ってレビューする必要がある。  

- **対応リージョン**: 東京リージョンを含むすべての AWS リージョンで対応。  

- **簡単な利用手順の概要**:  
  1. GitLab の Issue、コメント、またはマージリクエスト内で `/q dev` コマンドを使用して Amazon Q Developer を起動。  
  2. 自動生成されたコードをレビューし、コメントを追加。必要に応じて `/q dev` や `/q fix` でコードを修正。  
  3. レガシーコードの移行では、Issue の説明欄に `/q transform` コマンドを記載して移行タスクを自動化。  

### Notes
- GitLab 買収を座して待つ・・

## [Prevent factual errors from LLM hallucinations with mathematically sound Automated Reasoning checks (preview)](https://aws.amazon.com/jp/blogs/aws/prevent-factual-errors-from-llm-hallucinations-with-mathematically-sound-automated-reasoning-checks-preview/)  

- **機能概要**:  
  Amazon Bedrock Guardrailsに「Automated Reasoning Checks」が追加され、生成された回答が幻覚（hallucination）による事実誤認を防ぐための数学的な検証が可能になりました。これにより、回答が既知の事実と整合していることを論理的に証明し、信頼性の高い出力を提供できます。  

- **アップデート日付**: 2024/12/03  

- **特徴**:  
  - **事実誤認防止**: LLMが生成する回答を形式論理に基づいて検証し、誤った情報が含まれていないか確認します。  
  - **唯一の機能**: 他の主要クラウドプロバイダーにはない、生成AIの安全性、プライバシー、正確性を統合的に提供するソリューションです。  
  - **Amazon Bedrock Guardrails対応**: コンテキストベースの検証やPII（個人識別情報）のフィルタリングなど、他のガードレール機能と組み合わせて利用可能です。  
  - **ポリシー管理**: ユーザーのドメイン知識を形式論理で定義し、ポリシーとしてシステムに登録できます。  

- **利用ケース**:  
  - **人事ポリシーの確認**: 従業員からの問い合わせに対する回答が正しいかを検証。  
  - **製品情報の検証**: 製品仕様や販売条件について生成された回答の正確性を保証。  
  - **業務フローの正確性**: オペレーションマニュアルに基づいた回答が適切であるか確認。  

- **注意事項**:  
  - **プレビュー版**: 現在、米国西部（オレゴン）リージョンでのみプレビュー版が提供されています。正式版提供前に、AWSアカウントチームに問い合わせる必要があります。  

- **対応リージョン**:  
  - 東京リージョンは未対応（2024年12月時点）。  

- **簡単な利用手順の概要**:  
  - 手順1: Amazon Bedrockコンソールにアクセスし、ガードレール設定から新しいポリシーを作成。  
  - 手順2: 組織のルールや手順を記載したドキュメントをアップロード。  
  - 手順3: 自動生成されたポリシーをレビューし、精度を確認後、ガードレールに適用。  
  - 手順4: テスト環境でポリシーを使用し、LLMの回答が正しいかを検証。  

### Notes
- 数学的に検証、の部分が気になる、調べる
- 後で検証

## [Build faster, more cost-efficient, highly accurate models with Amazon Bedrock Model Distillation (preview)](https://aws.amazon.com/jp/blogs/aws/build-faster-more-cost-efficient-highly-accurate-models-with-amazon-bedrock-model-distillation-preview/)

- 機能概要: Amazon Bedrock Model Distillationは、特定のユースケースに合わせて高精度で高速かつコスト効率の良いモデルを構築するための機能で、教師モデルから生成された応答を使用して、より小さい学生モデルをファインチューニングすることにより、知識移転を行います。これにより、大規模な基盤モデルを使うよりも最大5倍速く、最大75%コスト削減が可能になりますが、精度の低下はわずか2%未満です。
- アップデート日付: 2024/12/03
- 特徴:
  - 教師モデル（大規模な基盤モデル）から生成された応答を使って、学生モデルをファインチューニングするプロセスを自動化。
  - より小さなモデルでも、教師モデルに近い精度を維持しつつ、最大で5倍の高速化と75%のコスト削減を実現。
  - 対応するサービスはAnthropic、Meta、Amazonのモデル。
  - 合成データ生成技術を活用し、トレーニングデータを強化。
- 利用ケース:
  - 膨大なユーザーインタラクションを扱う生成AIアプリケーションで、モデルの遅延を減らし、コスト効率を高める。
  - Retrieval Augmented Generation（RAG）やその他のタスクで、精度をほとんど損なうことなくモデルのサイズを削減したい場合。
- 注意事項:
  - 教師モデルと学生モデルは同じモデルファミリーから選択する必要がある（例：Meta Llama 3.1 405B Instructを教師モデルとして選択した場合、学生モデルはLlama 3.1 70Bまたは8B Instructに制限される）。
  - 東京リージョンでは利用不可、米国東部（バージニア北部）および米国西部（オレゴン）でプレビュー対応中。
- 対応リージョン: 米国東部（バージニア北部）、米国西部（オレゴン）【東京リージョン未対応】
- 簡単な利用手順の概要
  - 手順1: Amazon Bedrockコンソールにアクセスし、「カスタムモデル」を選択。
  - 手順2: 「ディスティレーションジョブの作成」を選び、教師モデルと学生モデルを選択。
  - 手順3: Amazon S3からデータセットをアップロードし、ディスティレーションジョブを作成。
  - 手順4: 進行状況を「ジョブ」タブで追跡し、モデルを「モデル」タブで確認。

### 専門用語:

| カテゴリー        | 専門用語             | 説明                                                             |
|-------------------|----------------------|------------------------------------------------------------------|
| モデル関連       | 教師モデル（Teacher Model） | より大規模で精度が高い基盤モデル。学生モデルに知識を移転する役割を担う。  |
| モデル関連       | 学生モデル（Student Model） | より小さなモデルで、教師モデルに近い精度を持つようにファインチューニングされる。 |
| データ処理        | 知識移転（Knowledge Transfer） | 教師モデルから学生モデルへ精度を維持しつつ学習内容を移すプロセス。          |
| データ処理        | 合成データ（Synthetic Data） | データセットを強化するために生成されるデータ。教師モデルの応答を基にする。   |

### Notes
- 後で検証
- フィルタしたログを使って微調整可能

## [Introducing Amazon Aurora DSQL](https://aws.amazon.com/jp/blogs/database/introducing-amazon-aurora-dsql/)

- 機能概要: Amazon Aurora DSQLは、常に可用性が求められるアプリケーション向けに設計された最速のサーバーレス分散SQLデータベースです。サーバーレスの設計により、インフラ管理が不要で、データベースのシャーディングやインスタンスのアップグレードなしで、ワークロードに合わせて無制限にスケールします。また、アクティブ-アクティブ分散アーキテクチャを採用しており、単一リージョン構成で99.99%、複数リージョン構成で99.999%の可用性を提供します。PostgreSQL互換で、開発者は既存のツールやフレームワークを活用できます。
- アップデート日付: 2024/12/03
- 特徴:
  - サーバーレス設計でインフラ管理が不要、スケーラビリティと高可用性を提供。
  - 単一リージョン構成で99.99%、複数リージョン構成で99.999%の可用性を実現。
  - PostgreSQL互換で、PostgreSQLドライバー、ツール、フレームワークをサポート。
  - オプティミスティック・コンカレンシー・コントロール（OCC）を使用して、スケーリング時のパフォーマンスを最適化。
- 利用ケース:
  - 高可用性と強いデータ一貫性が求められるアプリケーションの構築。
  - 複数リージョンに跨るデータセンター間の同期と冗長性の確保。
  - クラウド環境でのサーバーレスアーキテクチャを活用したデータベースのスケーリング。
- 注意事項:
  - 現在はプレビュー版として提供されているため、使用には注意が必要。
  - サポートされるリージョンについては公式ガイドを参照する必要がある。
- 対応リージョン: 東京リージョンは現在対応していない可能性があり、公式ガイドで確認が必要。
- 簡単な利用手順の概要:
  - 手順1: Aurora DSQLコンソールまたはAWS CLIを使って、クラスタの作成を開始。
  - 手順2: クラスタを設定し、PostgreSQL互換のデータベースとして利用を開始。
  - 手順3: 必要に応じてマルチリージョン設定やセキュリティ設定を行う。

### 専門用語:

| カテゴリー           | 専門用語                  | 説明                                               |
|--------------------|------------------------|----------------------------------------------------|
| データベース管理   | サーバーレス             | サーバーの管理をユーザーが行わないデータベース運用方式。自動でスケールし、インフラ管理が不要。|
| データベースアーキテクチャ | アクティブ-アクティブ分散アーキテクチャ | データベースノードが複数のアクティブな状態で動作し、障害発生時もダウンタイムなく処理を続ける仕組み。 |
| 同期処理           | オプティミスティック・コンカレンシー・コントロール (OCC) | 競合を検出する前提でトランザクションを処理し、長時間のトランザクションでも他のトランザクションに影響を与えない手法。 |

### Notes
- 今回のトップクラスの What's new
- [Amazon Aurora DSQLのUser Guideに沿ってNode.jsで基本的な操作を試してみた](https://dev.classmethod.jp/articles/trying-aurora-dsql-crud-with-nodejs/)

## [New Amazon S3 Tables: Storage optimized for analytics workloads](https://aws.amazon.com/jp/blogs/aws/new-amazon-s3-tables-storage-optimized-for-analytics-workloads/)

- 機能概要: Amazon S3 Tablesは、日次購入トランザクションやセンサーのストリーミングデータ、広告インプレッションなどのタブラデータを効率よく保存するために最適化されたストレージサービスです。これにより、Amazon AthenaやAmazon EMR、Apache Sparkなどのクエリエンジンで簡単にクエリを実行できます。自己管理型のテーブルストレージと比較して、最大3倍のクエリ性能向上と10倍の取引速度向上が期待でき、完全に管理されたサービスとして運用効率も向上します。
- アップデート日付: 2024/12/03
- 特徴:
  - Apache Icebergフォーマットでのデータ保存とクエリの最適化。
  - クエリパフォーマンスは自己管理型ストレージに対して最大3倍、取引速度は最大10倍向上。
  - Amazon AthenaやAmazon Redshift、EMRなどとの統合が可能。
  - 自動的なデータコンパクション、スナップショット管理、未参照ファイルの削除機能。
- 利用ケース:
  - 日次トランザクションやセンサーデータのクエリに適したストレージ。
  - ビッグデータ解析やストリーミングデータの分析を高速化。
  - データ保管と運用の効率化が求められる大規模なデータセットの管理。
- 注意事項:
  - 現在、AWS Glue Data Catalogとの統合はプレビュー版であり、全てのAWS Analyticsサービスで利用可能というわけではない。
  - 対応するAWS CLIは最新版に更新する必要がある場合がある。
- 対応リージョン: 東京リージョン未対応（US East (Ohio, N. Virginia)およびUS West (Oregon)のみ対応）
- 簡単な利用手順の概要
  - 手順1: AWS CLIを使用してテーブルバケットを作成する。
  - 手順2: Apache Sparkを利用してIcebergテーブルを作成し、データを挿入する。
- 専門用語:

| カテゴリー       | 専門用語          | 説明                                                                                                                                                        |
|----------------|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ストレージ      | Iceberg          | Parquetファイルを管理するためのオープンソースフォーマット。大規模データセットのクエリを効率化するために広く使われている。                                          |
| コンパクション  | Compaction       | 小さなテーブルオブジェクトを結合して、クエリ性能を向上させるためのプロセス。対象となるファイルサイズを設定可能で、新しいスナップショットとして書き直される。     |

### Notes
- よさげ

## [Amazon DynamoDB global tables previews multi-Region strong consistency](https://aws.amazon.com/about-aws/whats-new/2024/12/amazon-dynamodb-global-tables-previews-multi-region-strong-consistency)

- 機能概要: Amazon DynamoDB global tablesは、完全に管理されたサーバーレスなマルチリージョン・マルチアクティブデータベースで、今後の強力な一貫性をサポートします。この新機能により、ゼロの回復時点目標(RPO)で、高可用性を備えたマルチリージョンアプリケーションを構築でき、最も高いレベルのレジリエンスを実現します。
- アップデート日付: 2024/12/03
- 特徴:
  - DynamoDB global tablesにおけるマルチリージョン強い一貫性が利用可能になる。
  - アプリケーションは、どのリージョンからでも最新のデータを読み取ることができ、複数のリージョンにわたる一貫性の管理を不要にする。
  - 高い一貫性を必要とするグローバルアプリケーションの構築に最適で、ユーザープロファイル管理、在庫管理、金融取引処理などに利用可能。
  - DynamoDB global tablesの価格設定に基づいて課金される。
- 利用ケース:
  - グローバルアプリケーションの構築で、強い一貫性が必要な場合に使用。
  - ユーザープロファイル管理、在庫追跡、金融取引処理などに最適。
- 注意事項:
  - この機能はプレビュー段階であり、利用可能なリージョンに制限がある。
- 対応リージョン: 東京リージョンには未対応。利用可能なリージョンは、米国東部（バージニア北部）、米国東部（オハイオ）、および米国西部（オレゴン）。
- 簡単な利用手順の概要:
  - 手順1: DynamoDBコンソールにログイン。
  - 手順2: global tables設定を選択。
  - 手順3: マルチリージョン強い一貫性を有効にして、必要なリージョンを選択。

| カテゴリー        | 専門用語             | 説明                                                       |
|-----------------|---------------------|----------------------------------------------------------|
| 一貫性の概念      | 強い一貫性           | システム全体でデータの整合性を保証し、どのリージョンからも最新データを読み取れる状態。  |
| 設定             | RPO（回復時点目標）   | システムの障害発生後に許容されるデータ損失量の指標。                |
| アーキテクチャ     | マルチアクティブ      | 複数のリージョンで同時にアクティブなデータを保持するアーキテクチャ。           |

### Notes
- [[アップデート] Amazon DynamoDB Global Tableがマルチリージョンの強い整合性をサポートしました (プレビュー) #AWSreinvent](https://dev.classmethod.jp/articles/amazon-dynamodb-global-tables-previews-multi-region-strong-consistency/)

## [Introducing queryable object metadata for Amazon S3 buckets (preview)](https://aws.amazon.com/jp/blogs/aws/introducing-queryable-object-metadata-for-amazon-s3-buckets-preview/)

- 機能概要: Amazon S3では、大規模なデータを扱う顧客が多いため、特定の条件に一致するオブジェクトを迅速に検索できる新機能が追加されました。この新しい機能は、S3オブジェクトのメタデータを自動的に生成し、Apache Icebergを使用して完全に管理されたテーブルに格納します。これにより、AthenaやRedshift、QuickSight、Apache Sparkなどのツールを使用して、スケーラブルにメタデータを照会し、オブジェクトを特定することができます。
- アップデート日付: 2024/12/03
- 特徴:
  - S3オブジェクトに関連するメタデータ（オブジェクトのキー、サイズ、作成/変更時間、ストレージクラスなど）を自動生成し、Icebergテーブルとして格納。
  - Apache Iceberg互換のツール（Athena、Redshift、Spark）でメタデータを効率的に照会可能。
  - メタデータは自動的にキャプチャされ、オブジェクトの作成・削除・メタデータの変更が追跡され、数分以内にテーブルに反映される。
  - S3に保存された動画の推論レスポンスには、生成されたコンテンツをAI生成物として識別するためのメタデータが付与される。
- 利用ケース:
  - 大量のS3オブジェクトから特定の条件に一致するデータを迅速に検索する必要がある分析やデータ処理、AIトレーニングのワークロードに活用される。
  - S3のデータ更新履歴を追跡し、オブジェクトごとの履歴データを簡単に管理するユースケースに適用可能。
- 注意事項:
  - メタデータの生成とストレージには追加料金がかかる。
  - 現在は米国東部（オハイオ、ノースバージニア）および米国西部（オレゴン）リージョンでのみ利用可能。
  - AWS Glue Data Catalogとの統合はプレビュー段階。
- 対応リージョン: 東京リージョン（ap-northeast-1）は対応していないが、米国東部（オハイオ、ノースバージニア）および米国西部（オレゴン）で対応。
- 簡単な利用手順の概要:
  - 手順1: S3メタデータテーブルを保存するためのバケットを作成。
  - 手順2: メタデータテーブル設定を作成し、データバケットに関連付け。
  - 手順3: Apache Sparkを使用して、S3テーブルからメタデータをクエリ。
- 専門用語:

| カテゴリー         | 専門用語         | 説明                                                       |
|------------------|----------------|----------------------------------------------------------|
| メタデータ       | S3オブジェクトメタデータ | S3オブジェクトに関連する情報（キー、サイズ、作成日など）を指し、検索や管理に活用される。 |
| クエリツール     | Apache Spark    | 大規模データ処理に使用される分散コンピューティングフレームワーク。                    |
| データ管理      | AWS Glue Data Catalog | データカタログサービス、データセットのメタデータを一元管理する。                    |

### Notes
- 後で検証

## [New Amazon S3 Tables: Storage optimized for analytics workloads](https://aws.amazon.com/jp/blogs/aws/new-amazon-s3-tables-storage-optimized-for-analytics-workloads/)

- 機能概要: Amazon S3 Tablesは、Apache Iceberg形式でのタブラー（表形式）データストレージを提供する新しい機能で、データ分析ワークロード向けに最適化されています。これにより、人気のあるクエリエンジン（Amazon Athena、Amazon EMR、Apache Sparkなど）を使用して効率的にクエリを実行でき、自己管理型のテーブルストレージと比較して高速なパフォーマンスと高い取引処理能力を実現します。
- アップデート日付: 2024/12/03
- 特徴:
  - Amazon S3 Tablesは、タブラー形式のデータを効率的にストレージし、簡単にクエリを実行できるように設計されています。
  - 性能については、自己管理型ストレージと比べて最大3倍のクエリ速度向上と最大10倍の取引処理能力を提供します。
  - 対応するサービスには、Amazon Athena、Amazon EMR、Apache Sparkなどがあり、Iceberg形式でのデータ管理に特化しています。
  - オプション機能として、テーブルのメンテナンス（コンパクション、スナップショット管理、未参照ファイルの削除）が自動的に行われます。
- 利用ケース:
  - 日次の購入トランザクションデータ、ストリーミングセンサーデータ、広告インプレッションデータなどのクエリが必要な分析ワークロードでの利用。
- 注意事項:
  - 本機能は現在、US East（オハイオ、N.バージニア）およびUS West（オレゴン）リージョンで利用可能であり、東京リージョンには対応していません。
  - データ管理や最適化に関連するコストが発生します（ストレージ、リクエスト、コンパクション料金など）。
- 対応リージョン: 現在、US East（オハイオ、N.バージニア）およびUS West（オレゴン）リージョンに対応。東京リージョンは未対応。
- 簡単な利用手順の概要
  - 手順1: AWS CLIを使用してテーブルバケットを作成します。
  - 手順2: 作成したバケット内でテーブルを作成し、Iceberg形式でデータを挿入します。
  - 手順3: AthenaやEMRなどのサービスからテーブルをクエリします。
  
- 専門用語:

| カテゴリー      | 専門用語             | 説明                                                                 |
|-----------------|----------------------|----------------------------------------------------------------------|
| データストレージ | Iceberg              | Apache Icebergは、データレイクでのデータ管理を効率化するオープンソース形式。|
| メンテナンス     | コンパクション       | 複数の小さなファイルを1つの大きなファイルにまとめ、クエリパフォーマンスを向上させる操作。|
| メンテナンス     | スナップショット管理 | テーブルのスナップショット（データの状態）を管理し、不要なものを削除する操作。|
| データストレージ | テーブルバケット     | S3における、Iceberg形式でのデータを管理するための専用バケット。|

### Notes
- 後で検証

## [Amazon EC2 Trn2 Instances and Trn2 UltraServers for AI/ML training and inference are now available](https://aws.amazon.com/jp/blogs/aws/amazon-ec2-trn2-instances-and-trn2-ultraservers-for-aiml-training-and-inference-is-now-available/)

- 機能概要: Amazon EC2 Trn2 インスタンスと Trn2 UltraServers は、機械学習 (ML) のトレーニングと推論に最適化された新しい EC2 コンピューティングオプションです。これらは、AWS Trainium チップの第2世代である Trainium2 を搭載しており、パフォーマンスとコスト効率を大幅に向上させます。
- アップデート日付: 2024/12/03
- 特徴:
  - Trn2 インスタンスは、従来の Trn1 インスタンスに比べて4倍の速度、4倍のメモリ帯域幅、3倍のメモリ容量を提供します。
  - GPUベースの EC2 P5e と P5en インスタンスに対して、30〜40% 優れた価格性能を発揮します。
  - Trn2 UltraServers は、64 個の Trainium2 チップを搭載し、モデル並列処理や推論において優れた性能を提供します。
  - Trn2 インスタンスと UltraServers は、分散トレーニングと推論をサポートするため、EC2 UltraClusters 内でスケールアウト可能です。
  - ソフトウェア側では、AWS Neuron SDK とともに、PyTorch、JAX、Hugging Face、PyTorch Lightning などのフレームワークをサポートします。
- 利用ケース:
  - トレーニング: 大規模な機械学習モデルのトレーニングにおいて、Trn2 インスタンスは高い計算能力と効率を提供します。
  - 推論: UltraServers は、低遅延でリアルタイムの推論をサポートします。
- 注意事項:
  - 現在、US East (Ohio) リージョンで利用可能で、東京リージョンは未対応です。
  - インスタンスの予約は最大64インスタンスまで、最大6ヶ月の期間で行えます。
- 対応リージョン: 現在はUS East (Ohio) リージョンでの提供のみ。東京リージョンには対応していません。
- 簡単な利用手順の概要
  - 手順1: AWS EC2 Capacity Blocks for MLを使用して、最大64インスタンスの予約を行います。
  - 手順2: AWS Deep Learning AMIを使って、PyTorchやJAXなどのフレームワークをセットアップします。
  - 手順3: AWS Neuron SDKを使って、既存のアプリケーションをTrn2 インスタンス向けにコンパイルします。
- 専門用語:

| カテゴリー        | 専門用語        | 説明                                                     |
|-------------------|-----------------|----------------------------------------------------------|
| インスタンス      | Trn2 インスタンス | AWS Trainium2 チップを搭載した新しい EC2 インスタンス。     |
| チップ            | Trainium2 チップ | AWSが開発した、第2世代の機械学習用専用チップ。             |
| メモリ            | HBM (High Bandwidth Memory) | 高速なメモリ技術で、Trn2 チップに搭載された96GiB の高速メモリ。 |
| ネットワーク       | NeuronLink       | 高帯域幅・低遅延のインターコネクト技術。                  |
| ソフトウェア       | Neuron SDK       | AWSの専用開発キットで、PyTorchやJAX向けに最適化されたツール。 |
| トレーニング       | FP8 (Floating Point 8-bit) | 精度が低く、機械学習のトレーニングで効率的な浮動小数点演算。  |

### Notes
- 後で検証

## [Blog: Amazon VPC Lattice: modernize and simplify your enterprise network architectures](https://aws.amazon.com/jp/blogs/networking-and-content-delivery/amazon-vpc-vattice-modernize-and-simplify-your-enterprise-network-architectures/)

## [Amazon VPC Lattice: Modernizing Networking with Application Networking](https://aws.amazon.com/jp/blogs/aws/amazon-vpc-lattice-modernizing-networking-with-application-networking/)

- 機能概要: Amazon VPC Latticeは、サービス間通信を簡素化するためのフルマネージドアプリケーションネットワーキングサービスです。これにより、AWS上のサービスがセキュアで効率的に相互通信できるようになります。また、サービス間認証やアクセス制御が強化され、VPC間やAWS外のリソースとの接続もサポートされます。
- アップデート日付: 2024/12/02
- 特徴:
  - VPC Latticeは、サービス間通信の簡素化とセキュリティ強化を目的としたサービスで、AWSの各種計算サービス（Amazon ECS、AWS Fargate、Amazon EC2、Amazon EKS、AWS Lambda）と統合されている。
  - セキュリティ面では、ゼロトラストアーキテクチャの実現をサポートし、サービス間の認証と認可を強化します。
  - ハイブリッド接続に対応し、オンプレミスとAWS間のシームレスな接続を提供します。
  - 複数のリージョンやVPC、サービスに対する高可用性とレジリエンシーを提供します。
- 利用ケース:
  - 複数のVPCやAWSアカウント間のサービス間通信を簡単に構築したい場合。
  - AWS内外のリソース間でセキュアな接続を行い、ゼロトラストセキュリティモデルを適用したい場合。
  - ハイブリッド環境（AWSとオンプレミス）でのアプリケーション接続を簡素化したい場合。
  - クロスリージョンでのサービス間通信やフェイルオーバーを効率的に管理したい場合。
- 注意事項:
  - 利用するためにはVPC Lattice対応の設定が必要です。
  - 一部の機能は特定のリージョンでのみ利用可能です。
- 対応リージョン: 東京リージョンに対応しています。
- 簡単な利用手順の概要:
  - 手順1: AWSマネジメントコンソールでVPC Latticeサービスを選択。
  - 手順2: 新しいネットワーキング設定を作成し、対象サービスを接続。
  - 手順3: セキュリティポリシーとアクセス制御の設定を行う。
  - 手順4: クロスリージョンやオンプレミスとの接続を設定。

### 専門用語

| カテゴリー         | 専門用語         | 説明                                                  |
|--------------------|------------------|-------------------------------------------------------|
| アーキテクチャ     | ゼロトラスト      | ユーザーやデバイスが内部・外部に関わらず常に検証されるセキュリティモデル。 |

### Notes
- 後で検証
- なにやら VPC Lattice でいい感じでアプリケーション全般をつなげようとしている感じ。EKS Hybrid Node のアップデート含めてアカウントやらネットワークまたいでいろいろなリソースに閉じてアクセスしたり、管理したりがやりやすくなってそう。
- WebSocket で通信する推論専用サーバ (DJL Serving on SageMaker とか)と前段のアプリケーションサーバを VPC Lattice(PrivateLink) 使って WebSocket 通信させるサンプルとかいいかもしれん。

## [AWS Clean Rooms now supports multiple clouds and data sources](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/aws-clean-rooms-multiple-clouds-data-sources/)

- 機能概要: AWS Clean Roomsは、複数のクラウドやデータソースとのデータコラボレーションをサポートするようになりました。これにより、企業とそのパートナーは、SnowflakeやAmazon Athenaに保存されたデータを、データを移動したり共有したりすることなく簡単にコラボレーションできます。これにより、従来のETL処理を排除し、データ移行に伴うコストや複雑さを解消します。
- アップデート日付: 2024/12/01
- 特徴:
  - AWS Clean Roomsは、AWSやSnowflake上のデータセットを活用する企業間で、安全にコラボレーションできるようにします。
  - 従来のデータ移行を避け、データ共有を行わずに、データの整合性を保ちながら共同作業が可能です。
  - 対応するサービス: Snowflake, Amazon Athena, Amazon S3
  - オプション機能: データを移動したりコピーしたりせずに、最新のデータを基にしたコラボレーションが可能。
- 利用ケース:
  - メディアパブリッシャーがAmazon S3に保存されたデータと、広告主がSnowflakeに保存されたデータを共同で分析し、広告支出を評価する。
- 注意事項:
  - 現時点では、利用できるAWSリージョンが限られている可能性があるため、対応リージョンの確認が必要です。
- 対応リージョン: 東京リージョン対応
- 簡単な利用手順の概要
  - 手順1: AWS Clean Roomsにサインインし、必要なデータソースを設定。
  - 手順2: コラボレーションしたい企業を招待し、共同でデータ分析を開始。
- 専門用語:

| カテゴリー      | 専門用語             | 説明                                             |
|-----------------|----------------------|--------------------------------------------------|
| データ管理      | Snowflake             | クラウドデータウェアハウスサービス、分析用のデータを管理するためのツール。 |
| クラウドサービス | Amazon Athena         | サーバーレスのインタラクティブクエリサービス、Amazon S3のデータを分析。 |
| データ移行      | ETL (Extract, Transform, Load) | データの抽出、変換、ロード処理を意味し、データを移動・統合するための手順。 |
| データセキュリティ | データクリーンルーム   | 複数の企業がセキュアな環境でデータを共有し、分析する場所。

### Notes
- [[アップデート] AWS Clean RoomsがデータソースとしてSnowflakeとAmazon Athenaをサポートしました](https://dev.classmethod.jp/articles/aws-clean-rooms-support-multi-clouds-data-sources/)
- Clean Rooms よいじゃん、、

## [Streamline Kubernetes cluster management with new Amazon EKS Auto Mode](https://aws.amazon.com/jp/blogs/aws/streamline-kubernetes-cluster-management-with-new-amazon-eks-auto-mode/)

- 機能概要: Amazon EKS Auto Modeは、Kubernetesクラスタの管理を簡素化する新しい機能で、プロビジョニングから維持管理までを単一のクリックで行えます。これにより、計算、ストレージ、ネットワーキングの管理が自動化され、アプリケーション開発に集中できるようになります。
- アップデート日付: 2024/12/01
- 特徴:
  - クラスタインフラの管理が自動化され、Kubernetesの専門知識がなくても利用可能になります。
  - AWSがインフラ管理を担当し、コスト最適化、スケーラビリティ、セキュリティが強化されます。
  - GPU対応やストレージボリュームサポートなど、Kubernetesの主要機能を自動でサポートします。
  - オプションで、クイック設定またはカスタム設定でクラスタ作成が可能です。
- 利用ケース:
  - Kubernetesインフラ管理の負担を減らし、アプリケーション開発や運用に集中したい場合に利用されます。特に、大規模なクラウド環境でのKubernetesアプリケーション運用を簡素化したいユーザーに最適です。
- 注意事項:
  - 現在、EKS Auto Modeは、Kubernetes 1.29以上を使用するEKSクラスタに対応しており、地域によっては利用できない場合があります。
- 対応リージョン: 東京リージョンを含むすべての商業AWSリージョンに対応（中国リージョンを除く）。
- 簡単な利用手順の概要:
  - 手順1: Amazon EKSコンソールにアクセスし、クラスタ作成を開始。
  - 手順2: クイック設定またはカスタム設定を選択し、必要な情報を入力してクラスタを作成。
- 専門用語:

| カテゴリー     | 専門用語       | 説明                                                           |
|--------------|--------------|----------------------------------------------------------------|
| 自動化         | Auto Mode      | EKSクラスタの計算リソース、ストレージ、ネットワークの管理を自動化する新機能。     |
| インフラ管理   | eksctl        | EKSクラスタの管理ツール。コマンドラインでEKSクラスタの作成や設定が可能。   |

### Notes
- [[アップデート] EKS で Auto Mode が追加されたので試してみた#AWSreInvent](https://dev.classmethod.jp/articles/eks-auto-mode/)
- karpenter との使い分けはどう考えるべきだろうか

## [Use your on-premises infrastructure in Amazon EKS clusters with Amazon EKS Hybrid Nodes](https://aws.amazon.com/jp/blogs/aws/use-your-on-premises-infrastructure-in-amazon-eks-clusters-with-amazon-eks-hybrid-nodes/)

- 機能概要: Amazon EKS Hybrid Nodesは、オンプレミスおよびエッジインフラストラクチャをAWSクラウド内のEKSクラスターに接続し、ハイブリッド環境でのKubernetes管理を統一する新機能です。これにより、EKSがKubernetesの制御プレーンを管理し、オンプレミスのリソースを効率的に利用できます。
- アップデート日付: 2024/12/01
- 特徴:
  - オンプレミスとクラウド両方のインフラストラクチャをEKSクラスターに接続し、Kubernetesの一貫した運用が可能になる。
  - Amazon EKS on AWS OutpostsやEKS Anywhereとの比較で、オンプレミスハードウェア管理が可能。
  - Amazon EKS機能やAWSサービス（CloudWatch, IAM Roles Anywhereなど）と統合。
  - CiliumやCalico CNIドライバがサポートされ、ネットワーク設定の柔軟性が向上。
- 利用ケース:
  - 企業がオンプレミスのインフラをクラウドのEKSクラスターに統合し、ハイブリッド環境で一貫したKubernetes管理を行うケース。
  - 既存のオンプレミスインフラを活用し、クラウドにおけるスケールと可用性を享受する場合。
- 注意事項:
  - 対応するOSは、Amazon Linux 2023、Ubuntu 20.04/22.04/24.04、RHEL 8/9のいずれかが必要。
  - EKS Hybrid Nodesは、AWS GovCloud（US）リージョンおよび中国リージョンには未対応。
- 対応リージョン: 東京リージョン対応
- 簡単な利用手順の概要:
  - 手順1: EKSクラスターを作成し、オンプレミスのノードおよびポッド用のCIDRブロックを指定。
  - 手順2: ハイブリッドノードをEKSクラスターに接続するためのCLIツール「nodeadm」を使用してインストール。
  - 手順3: 必要なCNIドライバ（CiliumやCalico）をインストールして、ノードを準備。
- 専門用語:

| カテゴリー           | 専門用語          | 簡潔な説明                                                       |
|--------------------|-----------------|---------------------------------------------------------------|
| オーケストレーション | CNI (Container Network Interface) | コンテナ間のネットワーク接続を管理するための標準インターフェース。               |

### Notes
- [EKSハイブリッドノードの一般提供開始。EKSのコントロールプレーンのみをAWSに移譲できるようになりました！](https://dev.classmethod.jp/articles/eks-hybrid-node/)
- 待ってたやつ
- 後で試す(VPC Endpoint も併用したい)

## [New APIs in Amazon Bedrock to enhance RAG applications, now available](https://aws.amazon.com/jp/blogs/aws/new-apis-in-amazon-bedrock-to-enhance-rag-applications-now-available/)

## [New APIs in Amazon Bedrock to enhance RAG applications, now available](https://aws.amazon.com/blogs/aws/new-apis-in-amazon-bedrock-to-enhance-rag-applications-now-available/)

- 機能概要: Amazon Bedrock Knowledge Basesでは、カスタムコネクタやストリーミングデータの取り込みをサポートし、Retrieval Augmented Generation（RAG）を活用することで、より精度の高い生成AIアプリケーションの開発を支援します。これにより、データの更新や削除が効率的に行え、リアルタイムでのデータアクセスが可能になります。また、Rerank APIを使用することで、RAGアプリケーションのレスポンス精度を向上させます。
- アップデート日付: 2024/12/01
- 特徴:
  - カスタムコネクタとストリーミングデータの取り込みにより、データの同期が効率化され、データの更新や削除が迅速に行えるようになりました。
  - レスポンスの精度を向上させるために、Rerank APIを使用して、最も関連性の高いコンテンツを優先的に提供することが可能です。
  - Amazon Rerank 1.0とCohere Rerank 3.5モデルに対応。
  - 独立して使用可能なRerank APIも提供されており、Amazon Bedrock Knowledge Basesを利用していなくても活用できます。
- 利用ケース:
  - チャットボットやエンタープライズ検索などのRAGベースの生成AIアプリケーションで、データのリアルタイム更新や精度の高い回答が求められる場合に役立ちます。
  - 複雑なクエリに対応するため、Rerank APIを活用して関連性の高い文書を優先的に提供するシナリオにも最適です。
- 注意事項:
  - Rerank APIの利用には、特定のリージョン（US West, Canada, Europe, Asia Pacific）での対応が必要です。東京リージョンでも利用可能です。
  - データ同期には時間がかかる場合があり、初期設定時には数分から数時間を要することがあります。
- 対応リージョン: 東京リージョン対応有

- 簡単な利用手順の概要
  - 手順1: Amazon BedrockコンソールまたはAWS SDKを使用してカスタムコネクタとストリーミングデータの取り込みを設定。
  - 手順2: 必要なモデルへのアクセスをリクエストし、データソースを同期。
  - 手順3: Rerank APIを使用して、取得したデータをクエリに基づいて優先順位付け。

- 専門用語:

| カテゴリー        | 専門用語               | 説明                                                                 |
|------------------|-----------------------|----------------------------------------------------------------------|
| サービス        | Rerank API             | 取得したデータの優先順位を再調整するAPIで、クエリに基づいて最も関連性の高いコンテンツを優先的に提供。   |
| データ操作      | カスタムコネクタ       | 特定のデータソースから直接データを取り込むための設定。                                                      |

### Notes
- [[アップデート] Amazon BedrockにRerankモデルが追加されました #AWSreInvent](https://dev.classmethod.jp/articles/update-amazon-bedrock-rerank-model-added-aws-reinvent/)
- 後で検証
- 調査: リランキングはどう実装しているのだろうか、ラベルデータはどう集めている、トレーニング

## [Securely share AWS resources across VPC and account boundaries with PrivateLink, VPC Lattice, EventBridge, and Step Functions](https://aws.amazon.com/jp/blogs/aws/securely-share-aws-resources-across-vpc-and-account-boundaries-with-privatelink-vpc-lattice-eventbridge-and-step-functions/)

- 機能概要: AWSリソース（EC2インスタンスやECS、EKSコンテナサービス、HTTPSサービスなど）をVPCやAWSアカウントを超えて安全に共有し、EventBridgeやStep Functionsを利用してイベント駆動型アプリケーションを構築したり、ワークフローをオーケストレーションする機能が提供されます。これにより、既存のレガシーシステムをモダンなクラウドネイティブアプリケーションと統合することが可能になります。
- アップデート日付: 2024/12/01
- 特徴:
  - VPC LatticeやAWS PrivateLinkを基盤に、複数のAWSアカウント間でリソースの共有を実現。
  - EventBridgeやStep Functionsと連携することで、プライベートHTTPSサービスのイベント駆動型アーキテクチャの構築が容易に。
  - 新たに、プライベートリソースにアクセスするための簡素化された手段が提供され、既存のLambdaやSQSの統合を除去可能。
  - オプション機能として、複数のサービスを一括で管理できるリソース共有の作成が可能。
- 利用ケース:
  - 複数のAWSアカウント間でEC2インスタンスやECS、EKSなどのリソースを共有して、イベント駆動型アプリケーションを構築。
  - プライベートリソースへのアクセスをEventBridgeやStep Functionsで行い、ワークフローの自動化や統合を実現。
- 注意事項:
  - リソースの共有にはAWS Resource Access Manager (RAM) を使用。
  - データ転送に対するGB単位の課金が適用される。
  - この機能は一部のAWSリージョンで利用可能。
- 対応リージョン: 東京リージョンは対応しており、21のAWSリージョンで利用可能。
- 簡単な利用手順の概要
  - 手順1: VPCコンソールからリソースゲートウェイを作成。
  - 手順2: リソース設定を行い、リソースの共有を設定。
  - 手順3: 他のアカウントでリソースをアクセスし、EventBridgeやStep Functionsを利用してサービスを接続。

### 専門用語:

| カテゴリー          | 専門用語           | 説明                                                       |
|---------------------|--------------------|------------------------------------------------------------|
| VPCリソース管理    | Resource Owner VPC  | リソースを共有するVPC。リソースゲートウェイを作成し、共有を管理。         |
| VPCリソース管理    | Resource Gateway    | リソースにアクセスするためのエントリーポイント。複数のリソースを提供。     |
| リソース共有      | Resource Configuration | リソースゲートウェイを通じてアクセス可能なリソースを定義。                   |
| リソース管理      | Resource Consumer    | リソースを消費する側のユーザー。例えば、サービスにアクセスして利用。      |
| ネットワーク      | Service Network      | リソースの共有を行うために使用するネットワーク。                           |
| イベント駆動型アーキテクチャ | EventBridge           | イベントの配信および管理サービス。プライベートリソースへのアクセスも可能。   |
| ワークフロー管理  | Step Functions       | 複数のAWSサービスを連携させ、ワークフローをオーケストレーションするサービス。 |

### Notes
- [【アップデート】AWS PrivateLinkでNLBを介さずにVPC内リソースにアクセスできるようになりました！ #AWSreInvent](https://dev.classmethod.jp/articles/privatelink-vpc-endpoint-direct-access-update/)

## [New RAG evaluation and LLM-as-a-judge capabilities in Amazon Bedrock](https://aws.amazon.com/jp/blogs/aws/new-rag-evaluation-and-llm-as-a-judge-capabilities-in-amazon-bedrock/)

- 機能概要: Amazon Bedrockでは、RAG評価とLLM-as-a-judgeという2つの新機能が追加され、生成AIアプリケーションのテストと改善が効率化されます。これにより、生成AIアプリケーションの評価が自動化され、フィードバックループが短縮され、開発のスピードが向上します。
- アップデート日付: 2024/12/01
- 特徴:
  - RAG評価（Retrieval Augmented Generation）を使用して、知識ベースに基づくアプリケーションの評価を自動で行い、設定の最適化を支援します。
  - LLM-as-a-judgeは、ヒューマンエバリュエーションを模倣する評価を、コストと時間を削減しながら提供します。
  - これらの機能は、正確さ、役立ち度、責任あるAIの基準（拒否応答や有害性など）を含む複数の評価基準を提供します。
  - 評価結果は自然言語での説明と0から1のスコア形式で提供され、誰でも理解できるようになっています。
- 利用ケース:
  - AI-poweredアプリケーションのテストと評価を効率化し、生成AIシステムの性能改善を支援。
  - モデルの選定や設定調整を短期間で行い、品質改善を進める。
- 注意事項:
  - 現在、英語コンテンツが最適化されており、他の言語もサポートされているが、対応言語には制限がある。
  - 対応リージョンでのみ利用可能（東京リージョンも対応）。
- 対応リージョン: 東京リージョン（Asia Pacific (Tokyo)）
- 簡単な利用手順の概要
  - 手順1: Amazon Bedrockコンソールで「Evaluations」セクションにアクセスし、評価を作成。
  - 手順2: 評価の設定を選択（RAG評価またはLLM-as-a-judgeを選択）し、使用する評価モデルを選定。
  - 手順3: 評価データセット（JSONLファイル）をS3にアップロードし、結果の保存先を設定。
  - 手順4: 評価結果を確認し、生成されたスコアとフィードバックを分析。

| カテゴリー       | 専門用語                        | 説明                                                                                           |
|----------------|--------------------------------|------------------------------------------------------------------------------------------------|
| モデル評価     | LLM-as-a-judge                 | 人間の評価者のように動作し、AIモデルの応答を評価する機能。                                           |
| 評価基準       | 正確さ（Correctness）            | モデルの応答が正しいかどうかを評価する基準。                                                           |
| 評価基準       | 役立ち度（Helpfulness）          | 応答がどれだけ有用であるかを評価する基準。                                                           |
| 評価基準       | 有害性（Harmfulness）            | 応答が有害でないかを評価する基準。                                                                 |

### Notes
- 後で検証
- [[新機能] Amazon Bedrock Knowledge BasesにRAG評価機能が追加されました(プレビュー版) #AWSreInvent](https://dev.classmethod.jp/articles/amazon-bedrock-knowledge-bases-rag-evaluation-preview/)

## [Amazon Bedrock Knowledge Bases now provides auto-generated query filters for improved retrieval](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-bedrock-knowledge-bases-auto-generated-query-filters-improved-retrieval/)

- 機能概要: Amazon Bedrock Knowledge Basesは、Retrieval-Augmented Generation (RAG) ワークフローを活用して、ユーザーが独自のGenAIアプリケーションにコンテキスト情報を取り込む際に、精度が高く低遅延で安全な検索結果を提供します。今回のアップデートにより、自動生成されたクエリフィルターにより、検索結果の精度が向上し、手動で複雑なフィルター式を作成することなく関連するドキュメントを取得できます。
- アップデート日付: 2024/12/01
- 特徴:
  - 自動生成されたクエリフィルターにより、検索結果の精度が向上し、ドキュメントのメタデータを基にしたフィルタリングが可能になります。
  - 以前の手動メタデータフィルタリング機能を拡張した形で、特定の属性やコンテンツを持つドキュメントの取得を簡素化します。
  - RAGアプリケーションが複数のドキュメントからユーザーの問い合わせに対して検索を行い、特定の属性に基づいたフィルターを自動で適用します。
  - 特に「ワシントン州でクレームを提出する方法」などの具体的なクエリに対して、州名を自動的にフィルターとして適用します。
- 利用ケース:
  - 特定の地域や条件に関連する情報を素早くフィルタリングして取得したい場合に有用です。例えば、ユーザーが「ワシントン州に関するクレーム」の情報を求めているときに、地域を自動的に適用して、関連するドキュメントのみを表示することができます。
- 注意事項:
  - 現時点では、US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Seoul), Europe (Frankfurt), Europe (Zurich), AWS GovCloud (US-West) の各リージョンでサポートされています。
- 対応リージョン: 東京リージョン (Asia Pacific (Tokyo)) に対応
- 簡単な利用手順の概要:
  - 手順1: Amazon Bedrock Knowledge Basesの設定画面に移動し、クエリフィルター自動生成機能を有効化します。
  - 手順2: 必要に応じて、対象のドキュメントやデータソースを指定し、検索を実行します。
  - 手順3: クエリに対して自動で適用されるフィルター結果を確認し、最適なドキュメントを取得します。

| カテゴリー   | 専門用語                       | 説明                                                                                                                                     |
|-------------|--------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|
| 機能        | クエリフィルター自動生成        | ユーザーのクエリに関連するドキュメントを自動的にフィルタリングし、より精度高く情報を提供する機能。                                                   |
| サービス    | Amazon Bedrock Knowledge Bases  | Amazonのクラウドサービスで、GenAIアプリケーションに必要なデータからコンテキスト情報を抽出し、高精度で生成・取得できるプラットフォーム。                  |

### Notes
- 後で検証
- [Knowledge Bases for Amazon Bedrock がメタデータフィルタリングをサポートし検索精度向上](https://aws.amazon.com/jp/blogs/news/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/)
- The implicitFilterConfiguration is specified in the vectorSearchConfiguration of the Retrieve request body. Include the following fields: これか？

## [Amazon Bedrock Knowledge Bases now supports streaming responses](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-bedrock-knowledge-bases-streaming-retrieveandgeneratestream-api/)

- 機能概要: Amazon Bedrock Knowledge Basesは、企業のデータソースからのコンテキスト情報を組み込んだ高精度で低遅延なカスタムGenAIアプリケーションを作成するための完全管理型エンドツーエンドのRetrieval-Augmented Generation（RAG）ワークフローを提供します。この度、RetrieveAndGenerateStream APIが新たにサポートされ、Bedrock Knowledge Baseの顧客は、Large Language Model（LLM）によって生成される応答を、完全な応答を待つことなく、生成中にストリーミングで受け取ることができるようになりました。
- アップデート日付: 2024/12/01
- 特徴:
  - RetrieveAndGenerateStream APIにより、LLMからの応答をストリーミングで受け取れるようになり、応答開始までの遅延が減少します。
  - 従来、RAGワークフローの最終段階では、応答生成に数秒の遅延が発生していましたが、この新機能により、最初の応答が迅速に提供され、ユーザー体験が向上します。
  - 現在、すべてのAmazon Bedrock Knowledge Baseリージョンでサポートされています。
  - ドキュメントで詳細を確認可能。
- 利用ケース:
  - ラテンシーが重要なアプリケーションにおいて、生成中に応答を受け取りながらインタラクティブに処理を進める場合に役立ちます。
- 注意事項:
  - まだすべてのユースケースに最適化されていない可能性があり、特に非常に大規模なデータセットを扱う場合に遅延や精度の問題が発生することがあります。
- 対応リージョン: 東京リージョンにも対応しています。
- 簡単な利用手順の概要:
  - 手順1: RetrieveAndGenerateStream APIを使用するために、Amazon Bedrock Knowledge Baseでの設定を行います。
  - 手順2: APIを呼び出し、生成される応答をストリーミングで受け取ります。
  - 手順3: 必要に応じて、リアルタイムで応答を処理し、アプリケーションに反映させます。

| カテゴリー      | 専門用語       | 簡潔な説明                                             |
|----------------|----------------|--------------------------------------------------------|
| API            | RetrieveAndGenerateStream | ストリーミングで応答を受け取るための新しいAPI。                         |

- support of RetrieveAndGenerateStream API in Bedrock Knowledge Bases

### Notes
- [[アップデート] Amazon Bedrock Knowledge bases がストリーミングレスポンスをサポートしました #AWSreInvent](https://dev.classmethod.jp/articles/amazon-bedrock-knowledge-bases-streaming-retrieveandgeneratestream-api/)
- The feature currently only works with Anthropic Claude 3.5 Sonnet.


## [AWS Marketplace now offers EC2 Image Builder components from independent software vendors](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/aws-marketplace-ec2-image-builder-components-software-vendors/)

- 機能概要: AWS Marketplaceで独立系ソフトウェアベンダー（ISV）のEC2 Image Builderコンポーネントが提供され、Amazon Machine Image（AMI）のビルドプロセスを簡素化できるようになりました。これにより、ISVのコンポーネントを簡単に検索、購読、そしてゴールデンイメージに組み込むことができ、最新のバージョンのコンポーネントがAWS Marketplaceでリリースされると自動的に更新されます。
- アップデート日付: 2024/12/01
- 特徴:
  - AWS MarketplaceでISVのEC2 Image Builderコンポーネントを見つけて購読し、ゴールデンイメージに組み込むことが可能に。
  - カスタムコードを記述することなく、システムを最新の状態に保つ自動更新機能。
  - Datadog、Dynatrace、Fortinet、OpenVPN、Ciscoなど、人気のあるプロバイダーのソフトウェアがサポートされている。
  - ゴールデンイメージを組織内で共有するために、購読したコンポーネントの権限をAWSアカウント間で配布することが可能。
- 利用ケース:
  - 企業がAMIsのビルドプロセスを効率化したい場合、特にセキュリティ、ガバナンス、コンプライアンスの要件を満たすためのソフトウェアを組み込みたい場合。
  - 自動更新機能を活用して、システムを常に最新の状態に保ち、手動での更新作業を削減する場合。
- 注意事項:
  - ゴールデンイメージをAWSアカウント間で共有する際は、購読したコンポーネントのライセンスが必要。
- 対応リージョン: 東京リージョン対応あり
- 簡単な利用手順の概要
  - 手順1: AWS MarketplaceでEC2 Image Builderコンポーネントを検索して購読
  - 手順2: Image Builderコンソールでコンポーネントをゴールデンイメージに組み込む
  - 手順3: 自動更新設定を行い、システムを最新状態に保つ
- 専門用語:

| カテゴリ | 専門用語 | 説明 |
| --- | --- | --- |
| サービス | EC2 Image Builder | Amazon EC2インスタンスのイメージ（AMI）を自動で作成するサービス |
| サービス | AWS Marketplace | ソフトウェア、サービス、AMIを販売・購入できるAWSのオンラインマーケットプレイス |
| コンポーネント | ISV (Independent Software Vendor) | 独立系ソフトウェアベンダー、AWS Marketplaceで提供されるサードパーティのソフトウェアの提供者 |
| ガバナンス | ゴールデンイメージ | 設定、セキュリティ、ポリシーが規定された標準的なイメージ、全組織で一貫して使用されることを目的に作成 |

### Notes
- [AWS Marketplace で EC2 Image Builder で利用できるコンポーネントが提供されるようになりました #AWSreInvent](https://dev.classmethod.jp/articles/marketplace-ec2-image-builder-component/)

## [New Amazon EC2 P5en instances with NVIDIA H200 Tensor Core GPUs and EFAv3 networking](https://aws.amazon.com/jp/blogs/aws/new-amazon-ec2-p5en-instances-with-nvidia-h200-tensor-core-gpus-and-efav3-networking/)

- 機能概要: Amazon EC2 P5enインスタンスは、NVIDIA H200 Tensor Core GPUsと4世代Intel Xeon Scalableプロセッサを搭載し、機械学習（ML）トレーニングや推論のパフォーマンスを向上させます。これにより、MLや深層学習、生成AI、リアルタイムデータ処理、HPCアプリケーションにおける効率が大幅に向上します。
- アップデート日付: 2024/12/02
- 特徴:
  - NVIDIA H200 Tensor Core GPUsと4世代Intel Xeon Scalableプロセッサによる強力な性能。
  - PCIe Gen5を使用し、CPUとGPU間の帯域幅が最大4倍に向上。P5インスタンスに比べて最大35％のレイテンシ改善を実現。
  - 最大3200 GbpsのElastic Fabric Adapter（EFAv3）によるネットワーク性能向上。
  - 高いスループットを提供し、深層学習、生成AI、HPCなどの大規模なワークロードに最適化された性能を提供。
  - AWS Management ConsoleやAWS CLIを使用して、EC2 Capacity Blocksを予約してインスタンスを実行可能。
- 利用ケース:
  - 大規模なMLトレーニングや推論、特に生成AIや深層学習モデルにおける効率的なデータ処理と低レイテンシの実現。
  - HPCワークロード（天気予測や金融モデリング、製薬研究など）でのシミュレーションや解析。
- 注意事項:
  - EC2 Capacity Blocksは最大8週間前に予約可能で、事前購入したブロックでのみインスタンスを実行できます。
  - 現在利用可能なリージョンはUS East (Ohio), US West (Oregon), Asia Pacific (Tokyo)など。
- 対応リージョン: 東京リージョンを含むUS East (Ohio), US West (Oregon), Asia Pacific (Tokyo), US East (Atlanta) Local Zone (us-east-1-atl-2a)。
- 簡単な利用手順の概要
  - 手順1: EC2 Capacity Blocksを選択して、必要な容量と期間を指定。
  - 手順2: EC2 Capacity Blockの購入後、AWS Management Console、CLI、またはSDKを使用してインスタンスを起動。
  - 手順3: AWS CLIでのサンプルコマンドを使用して、EFAv3の利点を最大化したインスタンスの起動。
  
- 専門用語:

| カテゴリー | 専門用語            | 簡潔な説明                                            |
|------------|---------------------|-----------------------------------------------------|
| ハードウェア | NVIDIA H200 Tensor Core GPUs | 高速な計算処理を提供するNVIDIAの次世代GPU。深層学習に最適。   |
| ハードウェア | Intel Xeon Scalableプロセッサ | 高性能なサーバー用プロセッサ。大規模計算処理向け。             |
| ネットワーク | PCIe Gen5            | CPUとGPU間の通信帯域幅を大幅に向上させるインターフェース。        |
| ネットワーク | Elastic Fabric Adapter (EFA) | AWSでの低レイテンシ、スケーラブルなネットワーク通信を提供。         |
| ストレージ   | Amazon FSx for Lustre | 高速ストレージシステムで、大規模なデータ解析に使用。             |

### Notes
- [NVIDIA H200 Tensor Core GPU を搭載した EC2 インスタンスが東京リージョンに初登場 P5en インスタンス一般提供開始されました](https://dev.classmethod.jp/articles/nvidia-h200-tensor-core-gpu-ec2-p5en/)
- [AWS Nitro System](https://docs.aws.amazon.com/ja_jp/ec2/latest/instancetypes/ec2-nitro-instances.html)
- EFAv3 using Nitro v5
- ローカルストレージのパフォーマンスが上がってるので推論処理も効果あるよ

# 20241125(JST) 編集

## [Amazon SageMaker Inference now supports G6e instances](https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-now-supports-g6e-instances/)

- 機能概要: Amazon SageMakerが、NVIDIAのL40S Tensor Core GPUを搭載したG6eインスタンスのサポートを開始しました。これにより、開発者はコスト効率の良い高性能なGPUインスタンスを利用して、さまざまな生成AIモデルを推論することが可能になりました。
- アップデート日付: 2024/11/22
- 特徴:
  - G6eインスタンスは、最大384GBのGPUメモリを搭載し、大規模言語モデルを単一GPUノードで処理する能力を提供します。
  - G5インスタンスと比較して、G6eインスタンスは高いパフォーマンスを提供し、コスト効率が向上しています。
  - サポートするモデルには、Llama 3.2 11B VisionやLlama 2 13B、Qwen 2.5 14Bなどが含まれます。
  - 最大8GPUを持つインスタンスで、モデルサイズが最大90Bパラメータまで対応可能です。
- 利用ケース:
  - チャットボットや会話型AI
  - テキスト生成や要約
  - 画像生成や視覚モデル
- 注意事項:
  - G6eインスタンスは、コスト効率とパフォーマンスを重視する高スループットな推論ワークロード向けに最適化されていますが、大規模なモデルを扱う場合はインスタンスの選定に注意が必要です。
- 対応リージョン: 東京リージョンに対応
- 簡単な利用手順の概要:
  - 手順1: AWSアカウントとIAMロールを準備し、Amazon SageMaker StudioでG6eインスタンスを使ってモデルをデプロイします。

| カテゴリー           | 専門用語                | 説明                                                             |
|--------------------|------------------------|------------------------------------------------------------------|
| GPUインスタンス      | G6eインスタンス         | NVIDIA L40S Tensor Core GPUを搭載した、生成AI向けの高性能インスタンス。 |
| モデル               | Llama 3.2 11B Vision   | 高性能な生成AIモデルの一つで、画像生成や視覚認識に使用される。          |
| パラメータ数         | 90Bパラメータモデル     | G6eインスタンスは最大90Bのパラメータを持つ大規模なモデルをサポート。       |

### Notes
- G6e instances powered by NVIDIA’s L40S Tensor Core GPUs
- each GPU providing 48 GB of high bandwidth memory
- Up to 400 Gbps of networking throughput
- G6e instances are ideal for fine-tuning and deploying open large language models