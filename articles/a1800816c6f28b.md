---
title: "202411.News"
emoji: "😎"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["TechNews", "AWS"]
published: true
---

自分用のまとめ、re:invent 2024 特集

# 20241205(JST) 編集

## [Amazon SageMaker Lakehouse integrated access controls now available in Amazon Athena federated queries](https://aws.amazon.com/jp/blogs/aws/amazon-sagemaker-lakehouse-integrated-access-controls-now-available-in-amazon-athena-federated-queries/)

- 機能概要: Amazon SageMaker Lakehouseは、データレイクとデータウェアハウスを統合し、データソースに対するカタログ機能とアクセス管理機能を提供します。これにより、複数のデータソースを一元的に管理し、データの転送や重複を避けながら、効率的な分析とセキュリティ管理が可能になります。
- アップデート日付: 2024/12/03
- 特徴:
  - SageMaker LakehouseとAmazon Athenaが連携し、データソースに対する一貫したアクセス制御とカタログ機能を提供。
  - Athenaでのクエリ実行時に、データの場所を変更せずにアクセス管理を適用。
  - サポート対象サービスには、Amazon S3、Amazon Redshift、Amazon Aurora、Amazon DynamoDB、Google BigQueryなどが含まれます。
  - Fine-Grained Access Control (FGAC)により、データレイクやOLTPデータソースへのアクセス制御を細かく設定可能。
- 利用ケース:
  - データ分析者やデータサイエンティストが複数のデータソースを統一的に利用し、アクセス権に基づいて必要なデータのみを分析するケース。
  - セキュリティ要求が高い環境で、細かなアクセス権限設定を適用しつつ、効率的なデータ分析を行いたい場合。
- 注意事項:
  - 本機能は、Athenaを使用したクエリ実行時に限定されます。
  - DynamoDBなど一部のデータソースは、現在プレビュー版として提供されています。
- 対応リージョン: 東京リージョン（Asia Pacific (Tokyo)）を含む複数のAWSリージョンで利用可能。
- 簡単な利用手順の概要:
  - 手順1: Amazon SageMaker Unified Studioにアクセスし、プロジェクトを作成または選択します。
  - 手順2: データソース（例: DynamoDB）を選択し、SageMaker Lakehouseでカタログを作成します。
  - 手順3: Athenaでクエリを実行し、設定したアクセス制御が適用されることを確認します。
- 専門用語:

| カテゴリー                | 専門用語                         | 説明                                                          |
|-------------------------|----------------------------------|-------------------------------------------------------------|
| サービス                 | Amazon SageMaker Lakehouse       | データレイクとデータウェアハウスを統合し、AI/MLアプリケーションを構築するためのプラットフォーム。 |
| サービス                 | AWS Glue Data Catalog            | データソースのメタデータを一元管理するためのAWSサービス。                                        |
| セキュリティ             | Fine-Grained Access Control (FGAC) | データに対する細かいアクセス権限を定義し、適用するための機能。                                      |
| データベース             | OLTP (Online Transaction Processing) | トランザクション処理を行うためのデータベースシステム。                                              |

## [Simplify analytics and AI/ML with new Amazon SageMaker Lakehouse](https://aws.amazon.com/blogs/machine-learning/simplify-analytics-and-ai-ml-with-new-amazon-sagemaker-lakehouse/)

- 機能概要: Amazon SageMaker Lakehouseは、Amazon S3データレイクとAmazon Redshiftデータウェアハウスのデータを統一し、単一のデータコピーで分析やAI/MLアプリケーションを構築するための機能です。この機能は、AWSの機械学習と分析能力を統合し、分析とAIのためのシームレスな体験を提供します。
- アップデート日付: 2024/12/03
- 特徴:
  - SageMaker Lakehouseは、Amazon S3とRedshift間でデータを統一し、Apache Iceberg互換のエンジンでデータをインプレースでクエリする柔軟性を提供します。
  - 他の分析ツールやAI/MLエンジンにも対応しており、異なるソースからのデータを一元的に管理できます。
  - AWS Glue、Amazon Athena、Amazon SageMaker AIなどのツールを使用して、データのクエリやモデル開発をサポートします。
  - SQLによる分析やJupyter Labノートブックを利用したデータ操作が可能です。
- 利用ケース:
  - 複数のデータソースからのデータを統合し、分析やAI/MLモデルを開発する場合。
  - Amazon RedshiftやAmazon S3を使用する既存のデータ環境を活用し、データシェアリングを簡素化する場合。
  - データレイクとデータウェアハウス間でのデータ統合をスムーズに行いたい場合。
- 注意事項:
  - SageMaker Lakehouseは、データを統一するためにいくつかの設定が必要であり、ユーザーの環境に合わせたカスタマイズが求められます。
  - Jupyter Labノートブックの使用には「データ分析およびAI/MLモデル開発」プロファイルを選択する必要があります。
- 対応リージョン: 東京リージョン (Asia Pacific Tokyo) に対応しています。
- 簡単な利用手順の概要:
  - 手順1: Amazon SageMaker Unified Studioにアクセスし、新しいプロジェクトを作成します。
  - 手順2: プロジェクトのプロファイルを選択し、必要なリソースを設定します。
  - 手順3: データソースを追加し、クエリエディタでデータにアクセスします。
  - 手順4: 必要に応じてAthenaやRedshiftを使ってクエリを実行し、データを分析します。

| カテゴリー   | 専門用語                    | 説明                                                                 |
|------------|----------------------------|----------------------------------------------------------------------|
| 機能         | Apache Iceberg              | 分散データ処理のためのオープンソースのファイル形式で、データウェアハウスやデータレイクに対応。 |

### Notes
- [Amazon SageMaker Lakehouse and Amazon Redshift supports zero-ETL integrations from applications](https://aws.amazon.com/jp/blogs/aws/introducing-amazon-sagemaker-lakehouse-support-for-zero-etl-integrations-from-applications/) 類似のものが多すぎるので割愛

## [New Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse](https://aws.amazon.com/blogs/analytics/new-amazon-dynamodb-zero-etl-integration-with-amazon-sagemaker-lakehouse/)

- 機能概要: Amazon DynamoDBとAmazon SageMaker LakehouseのゼロETL統合により、DynamoDBのデータを分析や機械学習ワークロードで活用するためのパイプライン構築の手間を省き、数クリックでデータの抽出・活用が可能になります。この統合により、DynamoDBテーブルのキャパシティを消費せずに、データの動きを最小限に抑えながら簡単に分析やMLを実行できます。
- アップデート日付: 2024/12/03
- 特徴:
  - DynamoDBのデータを、Amazon SageMaker Lakehouseを使用してAmazon S3やRedshiftで一元化し、分析・MLワークロードを簡単に実行できるようにします。
  - ゼロETL統合により、従来のETLパイプライン構築の煩雑さを排除し、データの移動にかかる運用負担を軽減します。
  - 対応するサービス: Amazon DynamoDB, Amazon SageMaker Lakehouse, AWS Glue, Amazon S3, Apache Iceberg。
  - オプション機能: AWS KMSやカスタム暗号化キーを利用したデータの暗号化。
- 利用ケース:
  - DynamoDBに保存されているデータを、追加のインフラ設定なしでAmazon SageMaker Lakehouseに統合し、データ分析や機械学習のワークロードを簡単に実行したい場合。
  - ETLパイプラインの管理を減らし、より効率的にデータを抽出・活用したい企業。
- 注意事項:
  - ゼロETL統合の実行に必要なIAMロールやリソースポリシー設定に関する事前準備が必要です。
  - 統合後のデータ処理には、DynamoDBテーブルのサイズに依存した時間がかかる場合があります。
- 対応リージョン: 東京リージョン対応あり (Asia Pacific (Tokyo))。
- 簡単な利用手順の概要:
  - 手順1: AWS Glueコンソールで「Zero-ETL integrations」を選択し、DynamoDBをデータソースとして設定。
  - 手順2: S3バケットをターゲットとして指定し、必要なIAMロールと暗号化設定を行う。
  - 手順3: 設定内容を確認し、統合を作成。
- 専門用語:

| カテゴリ     | 専門用語             | 説明                                                                                         |
|--------------|----------------------|----------------------------------------------------------------------------------------------|
| データ統合   | Zero-ETL              | ETL (Extract, Transform, Load) の手順を省略するデータ統合手法。これにより、データの移動や変換を最小化。 |
| データ解析   | SageMaker Lakehouse   | データレイクとデータウェアハウスを統合した分析・MLプラットフォーム。                            |
| データストレージ | Apache Iceberg         | 分散データ処理に対応したオープンソースのデータフォーマット。                                      |

## [Discover, govern, and collaborate on data and AI securely with Amazon SageMaker Data and AI Governance](https://aws.amazon.com/jp/blogs/aws/discover-govern-and-collaborate-on-data-and-ai-securely-with-amazon-sagemaker-data-and-ai-governance/)

- **機能概要**: Amazon SageMaker Data and AI Governanceは、データおよびAI資産の管理を簡素化するための機能を提供し、データチームがデータやAIモデルを企業全体で効果的に発見、アクセス、協力できるように支援します。このプラットフォームは、データのカタログ化、発見、ガバナンスを統一された体験で提供し、安全にデータを利用できるようにします。
- **アップデート日付**: 2024/12/03
- **特徴**:
  - Amazon SageMaker Unified Studioを通じて、データとAI資産の管理が可能。
  - 機械学習を活用して、データ資産や列名を自動的にビジネス名に変換する機能。
  - SageMaker Catalogは、Amazon DataZoneに基づいており、AWSの既存のワークフローとツールとの統合がシームレス。
  - データとAI資産のアクセス制御には、ビジネス目的に基づいたプロジェクトを使用して、AIモデルやデータの安全な共有が可能。
  - AIガードレール機能を使って、アプリケーションにおけるAIの安全性を強化。
  - APIサポートを提供し、既存プロセスとの統合が容易に。
- **利用ケース**:
  - データサイエンティストやエンジニアが、データの発見、アクセス、ガバナンスを簡素化し、AIモデルのガードレールを使用して、安全に利用するケース。
  - ビジネスユースケースに基づいてプロジェクトを作成し、チームでの共同作業をサポートするケース。
- **注意事項**:
  - サービスはプレビュー段階で提供されており、一部機能は進行中である可能性がある。
- **対応リージョン**: 東京リージョン対応
- **簡単な利用手順の概要**:
  - 手順1: Amazon SageMaker Unified Studioにログインし、プロジェクトを作成する。
  - 手順2: データカタログを探索し、利用したいデータ資産を見つける。
  - 手順3: 必要に応じてデータへのアクセスリクエストを送信し、承認を得る。
  
### 専門用語

| カテゴリー          | 専門用語                   | 説明                                                         |
|---------------------|----------------------------|--------------------------------------------------------------|
| データ管理          | Amazon DataZone            | データガバナンスとカタログ機能を提供するAWSのプラットフォーム。             |
| データカタログ      | SageMaker Catalog          | データとAI資産のカタログ管理機能を提供するSageMaker内のリポジトリ。         |

## [Introducing the next generation of Amazon SageMaker: The center for all your data, analytics, and AI](https://aws.amazon.com/blogs/aws/introducing-the-next-generation-of-amazon-sagemaker-the-center-for-all-your-data-analytics-and-ai/)

- 機能概要: Amazon SageMakerの次世代バージョンが発表され、データ探索、準備、統合、大規模データ処理、SQL分析、機械学習（ML）モデル開発とトレーニング、生成的AIアプリケーション開発のための統合プラットフォームを提供します。これには、既存のAmazon SageMaker AIも統合されています。
- アップデート日付: 2024/12/03
- 特徴:
  - 新しいAmazon SageMakerは、データとAI開発のための統合環境「SageMaker Unified Studio」を提供します。
  - 複数のAWSツール（Amazon Athena、Amazon EMR、AWS Glue、Amazon Redshiftなど）と連携し、シームレスなデータ処理が可能です。
  - Amazon Bedrock IDEを使用して、生成的AIアプリケーションの開発が可能です。
  - 「Amazon Q」を活用し、開発フローをAIで支援します。
- 利用ケース:
  - データ分析、モデル開発、生成的AIアプリケーションの構築など、広範なAI/MLワークフローに対応。
  - チームでの共同作業やデータ共有を安全に行い、モデルのトレーニング、データ準備、予測などを統一された環境で管理。
- 注意事項:
  - Amazon SageMaker Unified Studioは現在プレビュー版として利用可能で、正式リリース前のバージョンです。
  - 既存のAmazon Bedrock Studioは2025年2月28日まで利用可能ですが、新しいワークスペースの作成はできません。
- 対応リージョン: 東京リージョン（アジアパシフィック（東京））に対応
- 簡単な利用手順の概要
  - 手順1: SageMaker Unified StudioのドメインURLでサインイン
  - 手順2: プロジェクトを作成し、データソースを追加
  - 手順3: SQLクエリエディタやビジュアルETLツールを使用してデータを処理
  - 手順4: 生成的AIアプリケーションを作成し、テスト・最適化

### 専門用語:

| カテゴリー  | 専門用語             | 簡潔な説明                                                                                                                                                        |
|-------------|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| データレイク  | Amazon SageMaker Lakehouse | Amazon S3データレイクとRedshiftデータウェアハウス、サードパーティのデータソースを統合して利用できる。                                                              |

## [Announcing the general availability of data lineage in the next generation of Amazon SageMaker and Amazon DataZone](https://aws.amazon.com/jp/blogs/aws/announcing-the-general-availability-of-data-lineage-in-the-next-generation-of-amazon-sagemaker-and-amazon-datazone/)

- **機能概要**:  
  Amazon DataZoneと次世代Amazon SageMakerにおいて、データの出所を可視化するデータリネージュ機能が正式に一般提供開始されました。この機能は、AWS GlueやAmazon Redshiftからデータ変換の履歴を自動的に収集し、データのトレーサビリティを強化します。これにより、ビジネスアナリストやデータエンジニア、データガバナンス担当者がデータの影響範囲を即座に把握し、信頼性の高いデータ駆動型の意思決定を行うことが可能になります。

- **アップデート日付**: 2024/12/03

- **特徴**:
  - データの自動リネージュ収集をAWS GlueおよびAmazon Redshiftでサポートし、手動作業を削減。
  - データ変換履歴、スナップショット、カラムマッピングを可視化し、影響分析やトラブルシューティングを容易に。
  - OpenLineage互換のイベントを使用して、カスタムパイプラインからリネージュ情報をプログラム的に登録可能。
  - Amazon SageMaker Unified Studioのカタログ機能としてリネージュが統合され、データユーザーは同一プラットフォーム内でリネージュ情報を管理可能。

- **利用ケース**:
  - ビジネスアナリストがデータの出所を確認し、データの信頼性を担保するために利用。
  - ダッシュボードの異常な数値変動の原因を調査する際、データエンジニアが影響分析を行うために活用。
  - 監査人からのデータの移動履歴や変換履歴に関する質問に対して、データスチュワードが迅速に回答するために使用。

- **注意事項**:
  - AWS GlueやAmazon Redshiftからのリネージュイベント収集はオプトイン設定が必要。
  - リネージュ情報の収集には、ストレージとAPIリクエストに基づくコストが発生。詳細はAmazon DataZoneの料金ページを参照。
  - 自動収集されるイベントは、テーブル作成、スキーマ変更、変換クエリなどのデータ変換操作を含む。

- **対応リージョン**:  
  東京リージョンを含む、Amazon DataZoneが利用可能な全てのリージョンで対応。

- **簡単な利用手順の概要**:
  1. AWS Glue Data CatalogやAmazon Redshiftのデータソース実行ジョブをAmazon DataZoneに設定し、定期的にメタデータを収集。
  2. カスタムリネージュ情報をAPI経由でプログラム的に登録。
  3. Amazon DataZoneポータル内でリネージュタブを利用して、データの出所や変換履歴を確認。

- **専門用語**:

| カテゴリー            | 専門用語           | 説明                                        |
|-----------------------|-------------------|---------------------------------------------|
| APIイベント           | OpenLineage       | データリネージュ情報を標準化された形式で提供するイベントプロトコル。 |

### Notes
- Next Genration Next Genration SageMaker が来ることはあるのか・・
- もはや次世代過ぎてついていけてないんだけど個人的には Notebook の AL2023 対応ほしい、Studio Notebook だと DinD だから開発環境としては使いづらいし、正直 Notebook が一番使いやすい・・

## [New capabilities from Amazon Q Business enable ISVs to enhance generative AI experiences]()

- **機能概要**:  
  Amazon Q Businessが新たに提供する機能により、ISV (Independent Software Vendors) は、複数のSaaSアプリケーションからデータを一元的に取得し、企業の知識とユーザーのコンテキストを活用したAI機能を統合できます。これにより、より個別化されたユーザー体験が可能になり、業務効率の向上とユーザーエンゲージメントの強化が期待されます。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **Amazon Qインデックスによるデータ統合**: 複数の外部データソースを一つのAPIを通じて取得し、ISVの既存AI機能を強化可能。  
  - **データ所有権とアクセス制御**: ユーザーはインデックスに対するデータ所有権を保持し、アクセス権を管理可能。  
  - **エンベッド型AIアシスタント**: Amazon Q Embeddedにより、ISVはユーザーインターフェースにAIアシスタントを埋め込むことができ、カスタマイズされた外観を設定可能。  
  - **API経由でのデータ検索機能**: `SearchRelevantContent` APIを活用し、関連データを効率的に検索。  
  - **カスタマイズ可能なUI**: ブランドに合わせたUIの外観、アシスタント名、ウェルカムメッセージなどを設定可能。

- **利用ケース**:  
  - SaaSアプリケーションにおけるユーザーの業務支援や自動化。  
  - 複数の企業アプリケーション間で一貫性のある情報提供。  
  - 企業のナレッジデータを活用したカスタマーサポートや業務効率化。

- **注意事項**:  
  - データアクセスにはユーザーの明示的な許可が必要。  
  - 対応リージョンに制限があり、東京リージョンでのサポートは現在未対応。

- **対応リージョン**:  
  - **対応済み**: 米国東部（N.バージニア）、米国西部（オレゴン）。  
  - **東京リージョン**: 未対応。今後の対応予定。

- **簡単な利用手順の概要**:  
  - **手順1**: ISVがAmazon Qインデックスにアプリケーションを登録し、ユーザーにデータソース接続の認証情報を提供。  
  - **手順2**: AWSマネジメントコンソールでユーザーがインデックスを作成し、ISVにアクセス権を付与。  
  - **手順3**: ISVは`SearchRelevantContent` APIを使用してデータを取得し、機能を強化。  
  - **手順4**: Amazon Q EmbeddedでUIをカスタマイズし、ブランドに最適化したアシスタントを提供。

- **専門用語**:  

| カテゴリー       | 専門用語               | 説明                                                                                 |
| ---------------- | ---------------------- | ------------------------------------------------------------------------------------ |
| データ管理       | Amazon Q インデックス   | 複数のSaaSアプリケーションからデータを一元的に管理・取得するための仕組み。               |
| API              | SearchRelevantContent  | インデックス内の関連コンテンツを検索するためのAPI。                                   |
| UIカスタマイズ   | Amazon Q Embedded      | アプリケーションにAIアシスタントを埋め込む機能。外観や機能をカスタマイズ可能。         |
| データアクセス   | Data Accessors         | ISVがデータへのアクセス権を取得する際に必要な認証情報の設定。                         |

### Notes
- Q 関連大杉、、力入れとる

## [Investigate and remediate operational issues with Amazon Q Developer (in preview)]()

- **機能概要**:  
Amazon Q Developerの新しい機能がプレビューとして公開され、運用上の問題を自動的に調査し、診断から根本原因分析、そして修正までをサポートします。AWSリソース間の関係を自動的に検出し、アプリケーショントポロジーを作成することで、迅速な障害復旧が可能になります。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **運用調査と修復のガイド機能**: CloudWatchやAWS Systems Managerと統合し、運用問題を調査し、修復手順を自動的に提示。  
  - **仮説生成と提案機能**: DynamoDB、Lambda、ECSなど、AWSのさまざまなサービスから収集したメトリクスを基に、問題に関する仮説を生成。ユーザーは仮説を受け入れて調査を進めることが可能。  
  - **自動修復の推奨**: AWS Systems Managerのオートメーションランブックを提案し、対応する問題に対する修正手順を実行可能。  
  - **ドキュメント参照**: AWS re:Post記事や公式ドキュメントへのリンクを提供し、問題解決を支援。  

- **利用ケース**:  
  - 監視対象のアプリケーションでCloudWatchアラームが発生した場合に、根本原因を特定して迅速に問題を修正するための運用支援ツールとして活用。  
  - 複雑なマイクロサービス環境における問題調査やリソース間の依存関係の把握。  
  - 業務時間外や緊急時における運用対応を自動化して、オペレーションの効率を向上。  

- **注意事項**:  
  - 現在はプレビュー版であり、正式リリース前に仕様変更される可能性がある。  
  - サポート対象リージョンは限定されており、現時点では **US East (N. Virginia)** のみ対応。  

- **対応リージョン**:  
  - 東京リージョンは現時点で未対応。

- **簡単な利用手順の概要**:  
  - 手順1: CloudWatchアラームを設定し、対象アプリケーションのメトリクスを監視する。  
  - 手順2: アラーム通知を受信したら、CloudWatchから **Investigate** を選択し、新規調査を開始する。  
  - 手順3: Amazon Q Developerが提示する仮説と関連メトリクスを確認し、適切な仮説を選択。  
  - 手順4: 提案されたランブックを確認し、必要なパラメータを入力して実行する。  
  - 手順5: 実行結果を確認し、調査の進行状況を **Feed** で管理する。

### カテゴリーと専門用語

| カテゴリー                | 専門用語                      | 簡潔な説明                                                                 |
|--------------------------|------------------------------|---------------------------------------------------------------------------|
| トポロジーマップ           | Topology Map                 | アプリケーション内のリソース間の関係を可視化したマップ。                   |

### Notes
- めっちゃよさそう、対応リージョンでの調査しかできないのか？

## [Introducing Amazon Nova foundation models: Frontier intelligence and industry leading price performance](https://aws.amazon.com/jp/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/)

- **機能概要**:  
  Amazon Novaは、Amazon Bedrock上で提供される次世代のファウンデーションモデルで、生成AIタスクにおけるコストとレイテンシーを削減しつつ、最先端の知能を活用することができます。企業の多様なワークロードに対応し、複雑なドキュメントや動画の解析、AIエージェントの構築、魅力的なコンテンツの生成が可能です。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **メインの機能特徴**:  
    Amazon Novaは、テキスト、画像、動画を入力として処理し、テキストやマルチモーダル出力を生成できる複数のモデルを提供します。  
  - **性能**:  
    従来のモデルと比較して、低レイテンシー、高精度、そして高コストパフォーマンスを実現しています。特に、300Kトークンまでの長文処理や、最大30分の動画解析が可能です。  
  - **サポートモデル**:  
    - **Amazon Nova Micro**: テキストのみを対象とした高速・低コストモデル。  
    - **Amazon Nova Lite**: テキスト、画像、動画の入力を処理する低コスト・マルチモーダルモデル。  
    - **Amazon Nova Pro**: 高精度かつマルチモーダル処理に優れたモデル。  
    - **Amazon Nova Premier**: 2025年初頭にリリース予定の高度なマルチモーダルモデル。  
  - **オプション機能**:  
    各モデルはカスタマイズが可能で、業界特化型の用語やドキュメント構造に適応するように調整できます。また、生成された画像や動画にはウォーターマークが自動的に付加されます。

- **利用ケース**:  
  - 長文ドキュメントの要約、翻訳、分類。  
  - 画像・動画からの情報抽出や可視化。  
  - マーケティングや広告向けの動画コンテンツ生成。  
  - APIやツールを用いたエージェントによる複雑なワークフローの自動化。

- **注意事項**:  
  - 現時点では動画内のオーディオ解析には対応していません。  
  - すべての生成コンテンツには安全管理と責任あるAI利用を促進するための制御機能が組み込まれています。

- **対応リージョン**:  
  - 東京リージョンでの対応は現在未確認ですが、US East (N. Virginia)、US West (Oregon)、US East (Ohio)で利用可能です。

- **簡単な利用手順の概要**:  
  1. Amazon BedrockコンソールでAmazon Novaモデルへのアクセスをリクエストします。  
  2. Playgroundでモデルを選択し、テキストやファイルを入力して応答を確認します。  
  3. SDKやAWS CLIを使用して、API経由でモデルに入力を送信し、出力を取得します。  

- **専門用語**:  
  - **ファウンデーションモデル** (Foundation Model): 複数のタスクに対応可能な大規模AIモデル。  
  - **マルチモーダル** (Multimodal): テキスト、画像、動画など複数のデータ形式を統合して処理する技術。  
  - **モデルディスティレーション** (Model Distillation): 大規模モデルから小規模モデルに知識を転移して効率を最適化する技術。


# 20241204(JST) 編集

## Related to Amazon Bedrock

- [Introducing latency-optimized inference for foundation models in Amazon Bedrock](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/latency-optimized-inference-foundation-models-amazon-bedrock/)

## Related to Amazon Q

- [Announcing Amazon Q Developer transformation capabilities for .NET, mainframe, and VMware workloads in a web experience (preview)](https://aws.amazon.com/jp/blogs/aws/announcing-amazon-q-developer-transformation-capabilities-for-net-mainframe-and-vmware-workloads-preview/)
- [Amazon Q Business is adding new workflow automation capability and 50+ action integrations](https://aws.amazon.com/jp/blogs/aws/amazon-q-business-is-adding-new-workflow-automation-capability-and-50-action-integrations/)
- [Amazon Q Business adds support to extract insights from visual elements within documents](https://aws.amazon.com/about-aws/whats-new/2024/12/amazon-q-business-extract-insights-visual-elements-documents)
  - This new feature enables users to query information embedded in various types of visual, including diagrams, infographics, charts, and image-based content
- [Announcing Amazon Q Developer transformation capabilities for .NET in IDE (preview)](https://aws.amazon.com/blogs/aws/announcing-amazon-q-developer-transformation-capabilities-for-net-preview/)
- [New Amazon Q Developer agent capabilities include generating documentation, code reviews, and unit tests](https://aws.amazon.com/jp/blogs/aws/new-amazon-q-developer-agent-capabilities-include-generating-documentation-code-reviews-and-unit-tests/)

### Notes

## [Introducing multi-agent collaboration capability for Amazon Bedrock (preview)](https://aws.amazon.com/jp/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/)

- **機能概要**:  
Amazon Bedrockの新機能である「マルチエージェントコラボレーション」により、複数のAIエージェントが協力して、専門的なスキルを活かしながら複雑なマルチステップのタスクを効率的に処理することが可能になります。従来、開発者はオープンソースソリューションでエージェントのオーケストレーションやメモリ管理などを手動で実装する必要がありましたが、この機能により、これらの作業が大幅に簡略化されます。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **簡単なセットアップ**: 複雑なコーディングを必要とせずに、数分でエージェントを作成、デプロイ、管理可能。  
  - **コンポーザビリティ**: 既存のエージェントをサブエージェントとして統合し、シームレスに協力できる。  
  - **効率的なエージェント間通信**: スーパーバイザーエージェントが一貫したインターフェースを介してサブエージェントと通信し、タスク完了を効率化。  
  - **最適化されたコラボレーションモード**:  
    - スーパーバイザーモード: 複雑な問題を分析し、サブエージェントを順次または並列に呼び出す。  
    - スーパーバイザーとルーティングモード: 単純なリクエストは直接サブエージェントにルーティングし、複雑なものはスーパーバイザーモードに切り替える。  
  - **統合トレース＆デバッグコンソール**: マルチエージェントの相互作用を可視化・分析できる。  

- **利用ケース**:  
  - 投資アドバイザリーシステム: 財務データ分析、調査、予測、投資推奨などの専門エージェントが協力してタスクを遂行する。  
  - 小売業の運用システム: 需要予測、在庫配分、サプライチェーンの調整、価格最適化などを複数エージェントで管理する。  
  - ソーシャルメディアキャンペーン管理: コンテンツ戦略エージェントとエンゲージメント予測エージェントを組み合わせて最適な投稿内容とタイミングを提案する。  

- **注意事項**:  
  - プレビュー期間中はリアルタイムチャットアシスタントなどの同期型ユースケースに対応。  
  - サブエージェントのコラボレーションは最大3階層までのエージェントチーム構成が可能。  
  - エージェント間の会話履歴共有機能は、簡単なタスクを処理する際に無効化することが推奨される。  

- **対応リージョン**:  
  東京リージョンを含むAmazon Bedrock AgentsがサポートされているすべてのAWSリージョンで利用可能（AWS GovCloud（US-West）は除く）。  

- **簡単な利用手順の概要**:  
  - **手順1**: Amazon Bedrockコンソールで「エージェント作成」から専門エージェント（例: コンテンツ戦略エージェント、エンゲージメント予測エージェント）を個別に作成。  
  - **手順2**: スーパーバイザーエージェントを作成し、マルチエージェントコラボレーションを有効化。  
  - **手順3**: 作成したサブエージェントをスーパーバイザーエージェントに関連付けて、チームとしてタスクを実行。  
  - **手順4**: エージェントの動作をテストし、統合トレースコンソールでワークフローを確認。  

- **専門用語**:  

| **カテゴリー**                | **専門用語**                 | **説明**                                                                                 |
|---------------------------|--------------------------|------------------------------------------------------------------------------------------|
| マルチエージェントシステム        | スーパーバイザーエージェント         | サブエージェントを統括し、タスクを分割・調整する中心的な役割を担うエージェント。                                                |
| マルチエージェントシステム        | サブエージェント                   | 特定のタスクやスキルに特化したエージェント。スーパーバイザーにより調整されて動作する。                                          |
| コラボレーションモード           | スーパーバイザーモード             | スーパーバイザーが入力を分析し、サブエージェントを順次または並列に呼び出してタスクを処理するモード。                          |
| コラボレーションモード           | ルーティングモード                 | 単純なリクエストはサブエージェントに直接ルーティングし、複雑なリクエストはスーパーバイザーモードに切り替えるモード。               |

### Notes
- 後で検証

## [Investigate and remediate operational issues with Amazon Q Developer (in preview)](https://aws.amazon.com/jp/blogs/aws/investigate-and-remediate-operational-issues-with-amazon-q-developer/)

- **機能概要**:  
Amazon Q Developerは、AWSのワークロードにおける運用上の問題を診断し、根本原因を特定して解決するためのジェネレーティブAIを活用した機能を提供します。CloudWatchやAWS Systems Managerと統合されており、リソース間の関係を自動的に発見し、問題を迅速に解決できるようサポートします。

- **アップデート日付**: 2024/12/03

- **特徴**:  
  - **問題の調査と解決の自動化**: Amazon Q Developerは、アプリケーションのトポロジーマップを作成し、アラームの原因となったコンポーネントを特定します。  
  - **仮説生成と提案**: DynamoDB、Lambda、ECSなどのサービスから関連するメトリクスを基に仮説を提示し、その理由も確認可能です。  
  - **リメディエーションの自動化**: AWS Systems Managerのオートメーションランブックを提案し、過去の実行履歴も確認できます。  
  - **統合された操作環境**: CloudWatchやLambdaメトリクスから直接インシデントを調査し、フィードに追加できます。  

- **利用ケース**:  
  - DynamoDBのスロットリングやLambdaのパフォーマンス低下など、クラウドアプリケーションで発生するパフォーマンス問題の診断と解決。  
  - システム管理者が複数のAWSサービスにまたがる複雑な問題を迅速に調査し、影響を最小限に抑える。

- **注意事項**:  
  - 現在プレビュー版であり、US East (N. Virginia) リージョンのみで提供されています。  
  - トラブルシューティングは、AWSサービスの構成やメトリクスの正確な設定に依存します。  

- **対応リージョン**:  
  - **東京リージョン**: 現時点では未対応

- **簡単な利用手順の概要**:  
  - **手順1**: CloudWatchアラームを設定し、メトリクスを監視します。  
  - **手順2**: アラームが発生した際にAmazon Q Developerを使用して新しい調査を開始します。  
  - **手順3**: 提案された仮説と修復アクションを確認し、適用するランブックを選択します。  
  - **手順4**: パラメータを入力し、実行結果を確認してフィードに追加します。

## [Introducing GitLab Duo with Amazon Q](https://aws.amazon.com/jp/blogs/aws/introducing-gitlab-duo-with-amazon-q/)

- **機能概要**:  
GitLab Duo with Amazon Q は、AWS の Amazon Q Developer エージェントを GitLab に統合し、AI を活用した開発支援機能を提供することで、DevSecOps の効率化と開発ワークフローの変革を実現します。これにより、開発者はコードレビューや機能開発、レガシーコードの移行を GitLab 内でシームレスに行えるようになります。

- **アップデート日付**: 2024/12/03  

- **特徴**:  
  - **統合型開発支援**: Amazon Q Developer を GitLab のクイックアクション `/q` コマンドを通じて操作可能。  
  - **コード生成とマージリクエストの自動化**: 既存コードベースの解析に基づき、コードを生成し、自動的にマージリクエストを作成。  
  - **コードレビューの自動化**: セキュリティ脆弱性や品質問題をスキャンし、修正提案を自動生成。  
  - **レガシーコードの移行支援**: Java 8 や 11 から Java 17 へのコード移行を自動化し、移行プランや依存関係の変更を報告。  

- **利用ケース**:  
  - **新機能の開発**: Web アプリケーションの新規サインアップ機能をコード生成機能で素早く実装。  
  - **コードレビューの効率化**: セキュリティやベストプラクティスに従ったコードレビューを AI が補助。  
  - **レガシーコードのアップグレード**: Java 17 への移行タスクを自動化し、移行作業の効率を向上。  

- **注意事項**:  
  - 現在プレビュー版として提供されており、GitLab Ultimate サブスクリプションを持つセルフマネージド環境でのみ利用可能。  
  - 生成されたコードには第三者のオープンソースコードが含まれる場合があり、利用者が責任を持ってレビューする必要がある。  

- **対応リージョン**: 東京リージョンを含むすべての AWS リージョンで対応。  

- **簡単な利用手順の概要**:  
  1. GitLab の Issue、コメント、またはマージリクエスト内で `/q dev` コマンドを使用して Amazon Q Developer を起動。  
  2. 自動生成されたコードをレビューし、コメントを追加。必要に応じて `/q dev` や `/q fix` でコードを修正。  
  3. レガシーコードの移行では、Issue の説明欄に `/q transform` コマンドを記載して移行タスクを自動化。  

### Notes
- GitLab 買収を座して待つ・・

## [Prevent factual errors from LLM hallucinations with mathematically sound Automated Reasoning checks (preview)](https://aws.amazon.com/jp/blogs/aws/prevent-factual-errors-from-llm-hallucinations-with-mathematically-sound-automated-reasoning-checks-preview/)  

- **機能概要**:  
  Amazon Bedrock Guardrailsに「Automated Reasoning Checks」が追加され、生成された回答が幻覚（hallucination）による事実誤認を防ぐための数学的な検証が可能になりました。これにより、回答が既知の事実と整合していることを論理的に証明し、信頼性の高い出力を提供できます。  

- **アップデート日付**: 2024/12/03  

- **特徴**:  
  - **事実誤認防止**: LLMが生成する回答を形式論理に基づいて検証し、誤った情報が含まれていないか確認します。  
  - **唯一の機能**: 他の主要クラウドプロバイダーにはない、生成AIの安全性、プライバシー、正確性を統合的に提供するソリューションです。  
  - **Amazon Bedrock Guardrails対応**: コンテキストベースの検証やPII（個人識別情報）のフィルタリングなど、他のガードレール機能と組み合わせて利用可能です。  
  - **ポリシー管理**: ユーザーのドメイン知識を形式論理で定義し、ポリシーとしてシステムに登録できます。  

- **利用ケース**:  
  - **人事ポリシーの確認**: 従業員からの問い合わせに対する回答が正しいかを検証。  
  - **製品情報の検証**: 製品仕様や販売条件について生成された回答の正確性を保証。  
  - **業務フローの正確性**: オペレーションマニュアルに基づいた回答が適切であるか確認。  

- **注意事項**:  
  - **プレビュー版**: 現在、米国西部（オレゴン）リージョンでのみプレビュー版が提供されています。正式版提供前に、AWSアカウントチームに問い合わせる必要があります。  

- **対応リージョン**:  
  - 東京リージョンは未対応（2024年12月時点）。  

- **簡単な利用手順の概要**:  
  - 手順1: Amazon Bedrockコンソールにアクセスし、ガードレール設定から新しいポリシーを作成。  
  - 手順2: 組織のルールや手順を記載したドキュメントをアップロード。  
  - 手順3: 自動生成されたポリシーをレビューし、精度を確認後、ガードレールに適用。  
  - 手順4: テスト環境でポリシーを使用し、LLMの回答が正しいかを検証。  

### Notes
- 数学的に検証、の部分が気になる、調べる
- 後で検証

## [Build faster, more cost-efficient, highly accurate models with Amazon Bedrock Model Distillation (preview)](https://aws.amazon.com/jp/blogs/aws/build-faster-more-cost-efficient-highly-accurate-models-with-amazon-bedrock-model-distillation-preview/)

- 機能概要: Amazon Bedrock Model Distillationは、特定のユースケースに合わせて高精度で高速かつコスト効率の良いモデルを構築するための機能で、教師モデルから生成された応答を使用して、より小さい学生モデルをファインチューニングすることにより、知識移転を行います。これにより、大規模な基盤モデルを使うよりも最大5倍速く、最大75%コスト削減が可能になりますが、精度の低下はわずか2%未満です。
- アップデート日付: 2024/12/03
- 特徴:
  - 教師モデル（大規模な基盤モデル）から生成された応答を使って、学生モデルをファインチューニングするプロセスを自動化。
  - より小さなモデルでも、教師モデルに近い精度を維持しつつ、最大で5倍の高速化と75%のコスト削減を実現。
  - 対応するサービスはAnthropic、Meta、Amazonのモデル。
  - 合成データ生成技術を活用し、トレーニングデータを強化。
- 利用ケース:
  - 膨大なユーザーインタラクションを扱う生成AIアプリケーションで、モデルの遅延を減らし、コスト効率を高める。
  - Retrieval Augmented Generation（RAG）やその他のタスクで、精度をほとんど損なうことなくモデルのサイズを削減したい場合。
- 注意事項:
  - 教師モデルと学生モデルは同じモデルファミリーから選択する必要がある（例：Meta Llama 3.1 405B Instructを教師モデルとして選択した場合、学生モデルはLlama 3.1 70Bまたは8B Instructに制限される）。
  - 東京リージョンでは利用不可、米国東部（バージニア北部）および米国西部（オレゴン）でプレビュー対応中。
- 対応リージョン: 米国東部（バージニア北部）、米国西部（オレゴン）【東京リージョン未対応】
- 簡単な利用手順の概要
  - 手順1: Amazon Bedrockコンソールにアクセスし、「カスタムモデル」を選択。
  - 手順2: 「ディスティレーションジョブの作成」を選び、教師モデルと学生モデルを選択。
  - 手順3: Amazon S3からデータセットをアップロードし、ディスティレーションジョブを作成。
  - 手順4: 進行状況を「ジョブ」タブで追跡し、モデルを「モデル」タブで確認。

### 専門用語:

| カテゴリー        | 専門用語             | 説明                                                             |
|-------------------|----------------------|------------------------------------------------------------------|
| モデル関連       | 教師モデル（Teacher Model） | より大規模で精度が高い基盤モデル。学生モデルに知識を移転する役割を担う。  |
| モデル関連       | 学生モデル（Student Model） | より小さなモデルで、教師モデルに近い精度を持つようにファインチューニングされる。 |
| データ処理        | 知識移転（Knowledge Transfer） | 教師モデルから学生モデルへ精度を維持しつつ学習内容を移すプロセス。          |
| データ処理        | 合成データ（Synthetic Data） | データセットを強化するために生成されるデータ。教師モデルの応答を基にする。   |

### Notes
- 後で検証
- フィルタしたログを使って微調整可能

## [Introducing Amazon Aurora DSQL](https://aws.amazon.com/jp/blogs/database/introducing-amazon-aurora-dsql/)

- 機能概要: Amazon Aurora DSQLは、常に可用性が求められるアプリケーション向けに設計された最速のサーバーレス分散SQLデータベースです。サーバーレスの設計により、インフラ管理が不要で、データベースのシャーディングやインスタンスのアップグレードなしで、ワークロードに合わせて無制限にスケールします。また、アクティブ-アクティブ分散アーキテクチャを採用しており、単一リージョン構成で99.99%、複数リージョン構成で99.999%の可用性を提供します。PostgreSQL互換で、開発者は既存のツールやフレームワークを活用できます。
- アップデート日付: 2024/12/03
- 特徴:
  - サーバーレス設計でインフラ管理が不要、スケーラビリティと高可用性を提供。
  - 単一リージョン構成で99.99%、複数リージョン構成で99.999%の可用性を実現。
  - PostgreSQL互換で、PostgreSQLドライバー、ツール、フレームワークをサポート。
  - オプティミスティック・コンカレンシー・コントロール（OCC）を使用して、スケーリング時のパフォーマンスを最適化。
- 利用ケース:
  - 高可用性と強いデータ一貫性が求められるアプリケーションの構築。
  - 複数リージョンに跨るデータセンター間の同期と冗長性の確保。
  - クラウド環境でのサーバーレスアーキテクチャを活用したデータベースのスケーリング。
- 注意事項:
  - 現在はプレビュー版として提供されているため、使用には注意が必要。
  - サポートされるリージョンについては公式ガイドを参照する必要がある。
- 対応リージョン: 東京リージョンは現在対応していない可能性があり、公式ガイドで確認が必要。
- 簡単な利用手順の概要:
  - 手順1: Aurora DSQLコンソールまたはAWS CLIを使って、クラスタの作成を開始。
  - 手順2: クラスタを設定し、PostgreSQL互換のデータベースとして利用を開始。
  - 手順3: 必要に応じてマルチリージョン設定やセキュリティ設定を行う。

### 専門用語:

| カテゴリー           | 専門用語                  | 説明                                               |
|--------------------|------------------------|----------------------------------------------------|
| データベース管理   | サーバーレス             | サーバーの管理をユーザーが行わないデータベース運用方式。自動でスケールし、インフラ管理が不要。|
| データベースアーキテクチャ | アクティブ-アクティブ分散アーキテクチャ | データベースノードが複数のアクティブな状態で動作し、障害発生時もダウンタイムなく処理を続ける仕組み。 |
| 同期処理           | オプティミスティック・コンカレンシー・コントロール (OCC) | 競合を検出する前提でトランザクションを処理し、長時間のトランザクションでも他のトランザクションに影響を与えない手法。 |

### Notes
- 今回のトップクラスの What's new
- [Amazon Aurora DSQLのUser Guideに沿ってNode.jsで基本的な操作を試してみた](https://dev.classmethod.jp/articles/trying-aurora-dsql-crud-with-nodejs/)

## [New Amazon S3 Tables: Storage optimized for analytics workloads](https://aws.amazon.com/jp/blogs/aws/new-amazon-s3-tables-storage-optimized-for-analytics-workloads/)

- 機能概要: Amazon S3 Tablesは、日次購入トランザクションやセンサーのストリーミングデータ、広告インプレッションなどのタブラデータを効率よく保存するために最適化されたストレージサービスです。これにより、Amazon AthenaやAmazon EMR、Apache Sparkなどのクエリエンジンで簡単にクエリを実行できます。自己管理型のテーブルストレージと比較して、最大3倍のクエリ性能向上と10倍の取引速度向上が期待でき、完全に管理されたサービスとして運用効率も向上します。
- アップデート日付: 2024/12/03
- 特徴:
  - Apache Icebergフォーマットでのデータ保存とクエリの最適化。
  - クエリパフォーマンスは自己管理型ストレージに対して最大3倍、取引速度は最大10倍向上。
  - Amazon AthenaやAmazon Redshift、EMRなどとの統合が可能。
  - 自動的なデータコンパクション、スナップショット管理、未参照ファイルの削除機能。
- 利用ケース:
  - 日次トランザクションやセンサーデータのクエリに適したストレージ。
  - ビッグデータ解析やストリーミングデータの分析を高速化。
  - データ保管と運用の効率化が求められる大規模なデータセットの管理。
- 注意事項:
  - 現在、AWS Glue Data Catalogとの統合はプレビュー版であり、全てのAWS Analyticsサービスで利用可能というわけではない。
  - 対応するAWS CLIは最新版に更新する必要がある場合がある。
- 対応リージョン: 東京リージョン未対応（US East (Ohio, N. Virginia)およびUS West (Oregon)のみ対応）
- 簡単な利用手順の概要
  - 手順1: AWS CLIを使用してテーブルバケットを作成する。
  - 手順2: Apache Sparkを利用してIcebergテーブルを作成し、データを挿入する。
- 専門用語:

| カテゴリー       | 専門用語          | 説明                                                                                                                                                        |
|----------------|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ストレージ      | Iceberg          | Parquetファイルを管理するためのオープンソースフォーマット。大規模データセットのクエリを効率化するために広く使われている。                                          |
| コンパクション  | Compaction       | 小さなテーブルオブジェクトを結合して、クエリ性能を向上させるためのプロセス。対象となるファイルサイズを設定可能で、新しいスナップショットとして書き直される。     |

### Notes
- よさげ

## [Amazon DynamoDB global tables previews multi-Region strong consistency](https://aws.amazon.com/about-aws/whats-new/2024/12/amazon-dynamodb-global-tables-previews-multi-region-strong-consistency)

- 機能概要: Amazon DynamoDB global tablesは、完全に管理されたサーバーレスなマルチリージョン・マルチアクティブデータベースで、今後の強力な一貫性をサポートします。この新機能により、ゼロの回復時点目標(RPO)で、高可用性を備えたマルチリージョンアプリケーションを構築でき、最も高いレベルのレジリエンスを実現します。
- アップデート日付: 2024/12/03
- 特徴:
  - DynamoDB global tablesにおけるマルチリージョン強い一貫性が利用可能になる。
  - アプリケーションは、どのリージョンからでも最新のデータを読み取ることができ、複数のリージョンにわたる一貫性の管理を不要にする。
  - 高い一貫性を必要とするグローバルアプリケーションの構築に最適で、ユーザープロファイル管理、在庫管理、金融取引処理などに利用可能。
  - DynamoDB global tablesの価格設定に基づいて課金される。
- 利用ケース:
  - グローバルアプリケーションの構築で、強い一貫性が必要な場合に使用。
  - ユーザープロファイル管理、在庫追跡、金融取引処理などに最適。
- 注意事項:
  - この機能はプレビュー段階であり、利用可能なリージョンに制限がある。
- 対応リージョン: 東京リージョンには未対応。利用可能なリージョンは、米国東部（バージニア北部）、米国東部（オハイオ）、および米国西部（オレゴン）。
- 簡単な利用手順の概要:
  - 手順1: DynamoDBコンソールにログイン。
  - 手順2: global tables設定を選択。
  - 手順3: マルチリージョン強い一貫性を有効にして、必要なリージョンを選択。

| カテゴリー        | 専門用語             | 説明                                                       |
|-----------------|---------------------|----------------------------------------------------------|
| 一貫性の概念      | 強い一貫性           | システム全体でデータの整合性を保証し、どのリージョンからも最新データを読み取れる状態。  |
| 設定             | RPO（回復時点目標）   | システムの障害発生後に許容されるデータ損失量の指標。                |
| アーキテクチャ     | マルチアクティブ      | 複数のリージョンで同時にアクティブなデータを保持するアーキテクチャ。           |

### Notes
- [[アップデート] Amazon DynamoDB Global Tableがマルチリージョンの強い整合性をサポートしました (プレビュー) #AWSreinvent](https://dev.classmethod.jp/articles/amazon-dynamodb-global-tables-previews-multi-region-strong-consistency/)

## [Introducing queryable object metadata for Amazon S3 buckets (preview)](https://aws.amazon.com/jp/blogs/aws/introducing-queryable-object-metadata-for-amazon-s3-buckets-preview/)

- 機能概要: Amazon S3では、大規模なデータを扱う顧客が多いため、特定の条件に一致するオブジェクトを迅速に検索できる新機能が追加されました。この新しい機能は、S3オブジェクトのメタデータを自動的に生成し、Apache Icebergを使用して完全に管理されたテーブルに格納します。これにより、AthenaやRedshift、QuickSight、Apache Sparkなどのツールを使用して、スケーラブルにメタデータを照会し、オブジェクトを特定することができます。
- アップデート日付: 2024/12/03
- 特徴:
  - S3オブジェクトに関連するメタデータ（オブジェクトのキー、サイズ、作成/変更時間、ストレージクラスなど）を自動生成し、Icebergテーブルとして格納。
  - Apache Iceberg互換のツール（Athena、Redshift、Spark）でメタデータを効率的に照会可能。
  - メタデータは自動的にキャプチャされ、オブジェクトの作成・削除・メタデータの変更が追跡され、数分以内にテーブルに反映される。
  - S3に保存された動画の推論レスポンスには、生成されたコンテンツをAI生成物として識別するためのメタデータが付与される。
- 利用ケース:
  - 大量のS3オブジェクトから特定の条件に一致するデータを迅速に検索する必要がある分析やデータ処理、AIトレーニングのワークロードに活用される。
  - S3のデータ更新履歴を追跡し、オブジェクトごとの履歴データを簡単に管理するユースケースに適用可能。
- 注意事項:
  - メタデータの生成とストレージには追加料金がかかる。
  - 現在は米国東部（オハイオ、ノースバージニア）および米国西部（オレゴン）リージョンでのみ利用可能。
  - AWS Glue Data Catalogとの統合はプレビュー段階。
- 対応リージョン: 東京リージョン（ap-northeast-1）は対応していないが、米国東部（オハイオ、ノースバージニア）および米国西部（オレゴン）で対応。
- 簡単な利用手順の概要:
  - 手順1: S3メタデータテーブルを保存するためのバケットを作成。
  - 手順2: メタデータテーブル設定を作成し、データバケットに関連付け。
  - 手順3: Apache Sparkを使用して、S3テーブルからメタデータをクエリ。
- 専門用語:

| カテゴリー         | 専門用語         | 説明                                                       |
|------------------|----------------|----------------------------------------------------------|
| メタデータ       | S3オブジェクトメタデータ | S3オブジェクトに関連する情報（キー、サイズ、作成日など）を指し、検索や管理に活用される。 |
| クエリツール     | Apache Spark    | 大規模データ処理に使用される分散コンピューティングフレームワーク。                    |
| データ管理      | AWS Glue Data Catalog | データカタログサービス、データセットのメタデータを一元管理する。                    |

### Notes
- 後で検証

## [New Amazon S3 Tables: Storage optimized for analytics workloads](https://aws.amazon.com/jp/blogs/aws/new-amazon-s3-tables-storage-optimized-for-analytics-workloads/)

- 12/03
- **Reading** / Investigation / Verification

### Features

### Notes
- 後で検証

## [Amazon EC2 Trn2 Instances and Trn2 UltraServers for AI/ML training and inference are now available](https://aws.amazon.com/jp/blogs/aws/amazon-ec2-trn2-instances-and-trn2-ultraservers-for-aiml-training-and-inference-is-now-available/)

- 12/03
- **Reading** / Investigation / Verification

### Features

### Notes
- 後で検証

## [Blog: Amazon VPC Lattice: modernize and simplify your enterprise network architectures](https://aws.amazon.com/jp/blogs/networking-and-content-delivery/amazon-vpc-vattice-modernize-and-simplify-your-enterprise-network-architectures/)

- 12/02
- **Reading** / Investigation / Verification

### Features

### Notes
- 後で検証
- なにやら VPC Lattice でいい感じでアプリケーション全般をつなげようとしている感じ。EKS Hybrid Node のアップデート含めてアカウントやらネットワークまたいでいろいろなリソースに閉じてアクセスしたり、管理したりがやりやすくなってそう。
- WebSocket で通信する推論専用サーバ (DJL Serving on SageMaker とか)と前段のアプリケーションサーバを VPC Lattice(PrivateLink) 使って WebSocket 通信させるサンプルとかいいかもしれん。

## [AWS Clean Rooms now supports multiple clouds and data sources](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/aws-clean-rooms-multiple-clouds-data-sources/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [[アップデート] AWS Clean RoomsがデータソースとしてSnowflakeとAmazon Athenaをサポートしました](https://dev.classmethod.jp/articles/aws-clean-rooms-support-multi-clouds-data-sources/)
- Clean Rooms よいじゃん、、

## [Streamline Kubernetes cluster management with new Amazon EKS Auto Mode](https://aws.amazon.com/jp/blogs/aws/streamline-kubernetes-cluster-management-with-new-amazon-eks-auto-mode/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [[アップデート] EKS で Auto Mode が追加されたので試してみた#AWSreInvent](https://dev.classmethod.jp/articles/eks-auto-mode/)

## [Use your on-premises infrastructure in Amazon EKS clusters with Amazon EKS Hybrid Nodes](https://aws.amazon.com/jp/blogs/aws/use-your-on-premises-infrastructure-in-amazon-eks-clusters-with-amazon-eks-hybrid-nodes/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [EKSハイブリッドノードの一般提供開始。EKSのコントロールプレーンのみをAWSに移譲できるようになりました！](https://dev.classmethod.jp/articles/eks-hybrid-node/)
- 待ってたやつ
- 後で試す(VPC Endpoint も併用したい)

## [New APIs in Amazon Bedrock to enhance RAG applications, now available](https://aws.amazon.com/jp/blogs/aws/new-apis-in-amazon-bedrock-to-enhance-rag-applications-now-available/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [[アップデート] Amazon BedrockにRerankモデルが追加されました #AWSreInvent](https://dev.classmethod.jp/articles/update-amazon-bedrock-rerank-model-added-aws-reinvent/)
- 後で検証
- 調査: リランキングはどう実装しているのだろうか、ラベルデータはどう集めている、トレーニング

## [Securely share AWS resources across VPC and account boundaries with PrivateLink, VPC Lattice, EventBridge, and Step Functions](https://aws.amazon.com/jp/blogs/aws/securely-share-aws-resources-across-vpc-and-account-boundaries-with-privatelink-vpc-lattice-eventbridge-and-step-functions/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [【アップデート】AWS PrivateLinkでNLBを介さずにVPC内リソースにアクセスできるようになりました！ #AWSreInvent](https://dev.classmethod.jp/articles/privatelink-vpc-endpoint-direct-access-update/)


## [Blog: New RAG evaluation and LLM-as-a-judge capabilities in Amazon Bedrock](https://aws.amazon.com/jp/blogs/aws/new-rag-evaluation-and-llm-as-a-judge-capabilities-in-amazon-bedrock/)

- 12/01
- **Reading** / Investigation / Verification

### Features
- Preview: RAG eval, LLM-as-a-judge の機能追加

### Notes
- 後で検証
- [[新機能] Amazon Bedrock Knowledge BasesにRAG評価機能が追加されました(プレビュー版) #AWSreInvent](https://dev.classmethod.jp/articles/amazon-bedrock-knowledge-bases-rag-evaluation-preview/)

## [Amazon Bedrock Knowledge Bases now provides auto-generated query filters for improved retrieval](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-bedrock-knowledge-bases-auto-generated-query-filters-improved-retrieval/)

- 12/01
- **Reading** / Investigation / Verification

### Features
-  This feature extends the existing capability of manual metadata filtering, by allowing customers to narrow down search results without the need to manually construct complex filter expressions.

### Notes
- 後で検証
- [Knowledge Bases for Amazon Bedrock がメタデータフィルタリングをサポートし検索精度向上](https://aws.amazon.com/jp/blogs/news/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/)
- The implicitFilterConfiguration is specified in the vectorSearchConfiguration of the Retrieve request body. Include the following fields: これか？

## [Amazon Bedrock Knowledge Bases now supports streaming responses](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-bedrock-knowledge-bases-streaming-retrieveandgeneratestream-api/)

- 12/01
- **Reading** / Investigation / Verification

### Features
- [[アップデート] Amazon Bedrock Knowledge bases がストリーミングレスポンスをサポートしました #AWSreInvent](https://dev.classmethod.jp/articles/amazon-bedrock-knowledge-bases-streaming-retrieveandgeneratestream-api/)
- support of RetrieveAndGenerateStream API in Bedrock Knowledge Bases

### Notes
- 東京リージョン対応
- The feature currently only works with Anthropic Claude 3.5 Sonnet.


## [AWS Marketplace now offers EC2 Image Builder components from independent software vendors](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/aws-marketplace-ec2-image-builder-components-software-vendors/)

- 12/01
- **Reading** / Investigation / Verification

### Features

### Notes
- [AWS Marketplace で EC2 Image Builder で利用できるコンポーネントが提供されるようになりました #AWSreInvent](https://dev.classmethod.jp/articles/marketplace-ec2-image-builder-component/)

## [Blog: New Amazon EC2 P5en instances with NVIDIA H200 Tensor Core GPUs and EFAv3 networking](https://aws.amazon.com/jp/blogs/aws/new-amazon-ec2-p5en-instances-with-nvidia-h200-tensor-core-gpus-and-efav3-networking/)

- 12/02
- **Reading** / Investigation / Verification

### Features
- NVIDIA H200 Tensor Core GPUs
- custom 4th generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.2 GHz
-  with up to 3200 Gbps of third generation of Elastic Fabric Adapter (EFAv3) using Nitro v5
- . P5en instances increases local storage performance by up to two times and Amazon Elastic Block Store (Amazon EBS) bandwidth by up to 25 percent compared with P5 instances, which will further improve inference latency performance for those of you who are using local storage for caching model weights.
-  With PCIe Gen 5 providing up to four times bandwidth between CPU and GPU

### Notes
- [NVIDIA H200 Tensor Core GPU を搭載した EC2 インスタンスが東京リージョンに初登場 P5en インスタンス一般提供開始されました](https://dev.classmethod.jp/articles/nvidia-h200-tensor-core-gpu-ec2-p5en/)
- [AWS Nitro System](https://docs.aws.amazon.com/ja_jp/ec2/latest/instancetypes/ec2-nitro-instances.html)
- EFAv3 using Nitro v5
- ローカルストレージのパフォーマンスが上がってるので推論処理も効果あるよ
- 東京リージョン対応 through EC2 Capacity Blocks for ML, On Demand, and Savings Plan purchase options

# 20241125

## [TBD: Accelerating Mixtral MoE fine-tuning on Amazon SageMaker with QLoRA](https://aws.amazon.com/blogs/machine-learning/accelerating-mixtral-moe-fine-tuning-on-amazon-sagemaker-with-qlora/)

- 11/22
- **Reading** / Investigation / Verification

### Features
- Mixtral employs a sparse mixture of experts (SMoE) architecture

### Notes
- 


## [TBD: Blog: Amazon SageMaker Inference now supports G6e instances](https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-inference-now-supports-g6e-instances/)

- 11/22
- **Reading** / Investigation / Verification

### Features
- G6e instances powered by NVIDIA’s L40S Tensor Core GPUs
- each GPU providing 48 GB of high bandwidth memory
- Up to 400 Gbps of networking throughput
- Up to 384 GB GPU Memory
- G6e instances are ideal for fine-tuning and deploying open large language models

### Notes
- 