---
title: "Use custom metrics to evaluate"
emoji: "🤖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

Translation: https://aws.amazon.com/jp/blogs/machine-learning/use-custom-metrics-to-evaluate-your-generative-ai-application-with-amazon-bedrock/

# Amazon Bedrockを使用して生成AIアプリケーションをカスタムメトリクスで評価する

Shreyas Subramanian、Adewale Akinfaderin、Ishan Singh、Jesse Manders著（2025年5月6日）
[Amazon Bedrock](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/ "Amazon Bedrockのすべての投稿を表示")、[生成AI](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/ "生成AIのすべての投稿を表示")

[Amazon Bedrock Evaluations](https://aws.amazon.com/bedrock/evaluations/)を使用すると、[Amazon Bedrock](https://aws.amazon.com/bedrock/)でホストされているファンデーションモデル（FM）や検索拡張生成（RAG）システム、あるいは他の場所でホストされているモデルやRAGシステム（[Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/)やマルチクラウド、オンプレミス環境を含む）を評価できます。最近、モデル評価におけるLLM-as-a-judgeテクニックと、同様にLLM-as-a-judgeを活用した新しいRAG評価ツールの[一般提供開始を発表しました](https://aws.amazon.com/blogs/machine-learning/evaluate-models-or-rag-systems-using-amazon-bedrock-evaluations-now-generally-available/)。これらのツールはすでに、組織がエンタープライズグレードのツールを使用してFMとRAGシステムを体系的に評価できるようにしています。また、これらの評価ツールはAmazon BedrockでホストされているモデルやRAGシステムに限定されるものではなく、独自の推論（BYOI）レスポンス機能を使用すれば、[入力フォーマット要件](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets-judge.html)に従うことで、どちらのオファリングでもモデルやアプリケーションを評価できます。

これらの評価を支えるLLM-as-a-judgeテクニックにより、手動介入なしに、FMを使用して品質と責任あるAIの側面を評価する、自動化された人間のような評価品質を大規模に実現できます。正確性（事実の正確さ）、完全性（回答の徹底度）、忠実性（ハルシネーション検出）、有害性や回答拒否などの責任あるAIメトリクスなどの組み込みメトリクスにより、あなたとチームはAmazon Bedrockでホストされているモデルとナレッジベースをネイティブに、またはカスタムビルドシステムからのBYOIレスポンスを使用して評価できます。

Amazon Bedrock Evaluationsは両方の評価ツールに対して広範な組み込みメトリクスを提供していますが、これらの評価メトリクスを異なる方法で定義したり、ユースケースに関連する全く新しいメトリクスを作成したりしたい場合があります。例えば、アプリケーションの応答が特定のブランドボイスにどれだけ準拠しているかを評価するメトリクスを定義したり、カスタムカテゴリ別ルーブリックに従って応答を分類したりすることが考えられます。様々な目的で数値スコアリングやカテゴリスコアリングを使用したい場合もあるでしょう。これらの理由から、評価にカスタムメトリクスを使用する方法が必要です。

現在、Amazon Bedrockではモデル評価とRAG評価の両方にカスタム評価メトリクスを開発できるようになりました。この機能は、Amazon Bedrock Evaluationsを駆動するLLM-as-a-judgeフレームワークを拡張するものです。

この記事では、Amazon Bedrock Evaluationsでカスタムメトリクスを使用して、特定のビジネス要件や評価基準に従って生成AIアプリケーションのパフォーマンスを測定し改善する方法を紹介します。

## 概要

Amazon Bedrock Evaluationsのカスタムメトリクスは以下の機能を提供します：

* **簡素化された開始エクスペリエンス** – 業界でテスト済みの組み込みメトリクスに基づく事前構築されたスターターテンプレートが[AWSマネジメントコンソール](http://aws.amazon.com/console)で利用可能で、特定の評価基準に合わせてゼロから作成するオプションもあります。
* **柔軟なスコアリングシステム** – 順序メトリクス、名義メトリクスの作成、あるいは分類タスクのための評価ツールの使用のために、定量的（数値）および定性的（カテゴリ別）スコアリングの両方をサポートしています。
* **合理化されたワークフロー管理** – カスタムメトリクスを保存して複数の評価ジョブで再利用したり、以前に定義したメトリクスをJSONファイルからインポートしたりできます。
* **動的コンテンツ統合** – 組み込みテンプレート変数（例：`{{prompt}}`、`{{prediction}}`、`{{context}}`）により、データセットのコンテンツとモデル出力を評価プロンプトにシームレスに挿入できます。
* **カスタマイズ可能な出力制御** – 一貫した結果を得るための推奨出力スキーマを使用でき、特殊なユースケース向けにカスタム出力フォーマットを定義する高度なオプションも用意されています。

カスタムメトリクスにより、AIシステムのパフォーマンスを測定する方法を前例のないレベルで制御でき、特定のビジネス要件やユースケースに合わせて評価を調整できます。事実性、一貫性、有用性、あるいはドメイン固有の基準を評価する場合でも、Amazon Bedrockのカスタムメトリクスにより、より意味のある実用的な評価洞察が得られます。

以下のセクションでは、Amazon Bedrockコンソールと Python SDKおよびAPIの両方を使用して、モデル評価とカスタムメトリクスを含むジョブを作成する手順を説明します。

## サポートされるデータ形式

このセクションでは、いくつかの重要なデータ形式について説明します。

### ジャッジプロンプトのアップロード

以前に保存したカスタムメトリクスを評価ジョブにアップロードするには、以下の例のようなJSON形式に従ってください。

以下のコードは数値スケールを持つ定義を示しています：

```
{
    "customMetricDefinition": {
        "metricName": "my_custom_metric",
        "instructions": "少なくとも1つの{{入力変数}}を含む完全なカスタムメトリクスプロンプト",
        "ratingScale": [
            {
                "definition": "最初の評価定義",
                "value": {
                    "floatValue": 3
                }
            },
            {
                "definition": "2番目の評価定義",
                "value": {
                    "floatValue": 2
                }
            },
            {
                "definition": "3番目の評価定義",
                "value": {
                    "floatValue": 1
                }
            }
        ]
    }
}
```

以下のコードは文字列スケールを持つ定義を示しています：

```
{
    "customMetricDefinition": {
        "metricName": "my_custom_metric",
        "instructions": "少なくとも1つの{{入力変数}}を含む完全なカスタムメトリクスプロンプト",
        "ratingScale": [
            {
                "definition": "最初の評価定義",
                "value": {
                    "stringValue": "最初の値"
                }
            },
            {
                "definition": "2番目の評価定義",
                "value": {
                    "stringValue": "2番目の値"
                }
            },
            {
                "definition": "3番目の評価定義",
                "value": {
                    "stringValue": "3番目の値"
                }
            }
        ]
    }
}
```

以下のコードはスケールを持たない定義を示しています：

```
{
    "customMetricDefinition": {
        "metricName": "my_custom_metric",
        "instructions": "少なくとも1つの{{入力変数}}を含む完全なカスタムメトリクスプロンプト"
    }
}
```

スケールを持たないジャッジプロンプトの定義については、後述のベストプラクティスセクションを参照してください。

### モデル評価データセット形式

LLM-as-a-judgeを使用する場合、1つの評価ジョブで評価できるモデルは1つだけです。したがって、各評価に対して`modelResponses`リストに1つのエントリを提供する必要がありますが、異なるモデルを比較するために複数の評価ジョブを実行することはできます。`modelResponses`フィールドはBYOIジョブでは必須ですが、非BYOIジョブでは不要です。以下はモデル評価におけるLLM-as-a-judgeのための入力JSONL形式です。`?`でマークされたフィールドはオプションです。

```
{
    "prompt": string
    "referenceResponse"?: string
    "category"?: string
     "modelResponses"?: [
        {
            "response": string
            "modelIdentifier": string
        }
    ]
}
```

### RAG評価データセット形式

RAG評価のための評価ジョブ入力データセット形式をさらに柔軟にアップデートしました。現在、期待される取得パッセージである`referenceContexts`を提供できるようになり、実際に取得されたコンテキストと期待される取得コンテキストを比較できます。RAG評価の更新されたJSONLスキーマで新しい`referenceContexts`フィールドを確認できます：

```
{
    "conversationTurns": [{
            "prompt": {
                "content": [{
                    "text": string
                }]
            },
            "referenceResponses" ?: [{
                "content": [{
                    "text": string
                }]
            }],
            "referenceContexts" ? : [{
                "content": [{
                    "text": string
                }]
            }],
            "output" ?: {
                "text": string
                "modelIdentifier" ? : string 
                "knowledgeBaseIdentifier": string 
                "retrievedPassages": {
                    "retrievalResults": [{
                        "name" ? : string 
                        "content": {
                            "text": string
                        },
                        "metadata" ? : {
                            [key: string]: string
                        }
                    }]
                }
            }]
    }
}
```

### ジャッジプロンプトへのデータ注入のための変数

データがジャッジプロンプトの適切な場所に注入されるようにするために、以下の表の変数を使用してください。また、該当する場合、評価ツールが入力ファイルからどのデータを取得するかを示すガイドも含めています。独自の推論レスポンスを評価ジョブに持ち込む場合、入力ファイルからそのデータを使用します。独自の推論レスポンスを使用しない場合は、Amazon Bedrockモデルまたはナレッジベースを呼び出し、レスポンスを準備します。

以下の表はモデル評価のための変数をまとめたものです。

| **プレーン名** | **変数** | **入力データセットJSONLキー** | **必須またはオプション** |
| --------------------- | ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| プロンプト | {{prompt}} | prompt | オプション |
| レスポンス | {{prediction}} | BYOIジョブの場合：modelResponses.response 独自の推論レスポンスを持ち込まない場合、評価ジョブがモデルを呼び出してこのデータを準備します。 | 必須 |
| 正解レスポンス | {{ground\_truth}} | referenceResponse | オプション |

以下の表はRAG評価（検索のみ）のための変数をまとめたものです。

| **プレーン名** | **変数** | **入力データセットJSONLキー** | **必須またはオプション** |
| ------------------------------ | ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| プロンプト | {{prompt}} | prompt | オプション |
| 正解レスポンス | {{ground\_truth}} | BYOIジョブの場合：output.retrievedResults.retrievalResults 独自の推論レスポンスを持ち込まない場合、評価ジョブがAmazon Bedrockナレッジベースを呼び出してこのデータを準備します。 | オプション |
| 取得されたパッセージ | {{context}} | BYOIジョブの場合：output.retrievedResults.retrievalResults 独自の推論レスポンスを持ち込まない場合、評価ジョブがAmazon Bedrockナレッジベースを呼び出してこのデータを準備します。 | 必須 |
| 正解取得パッセージ | {{reference\_contexts}} | referenceContexts | オプション |

以下の表はRAG評価（検索と生成）のための変数をまとめたものです。

| **プレーン名** | **変数** | **入力データセットJSONLキー** | **必須またはオプション** |
| ------------------------------ | ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| プロンプト | {{prompt}} | prompt | オプション |
| レスポンス | {{prediction}} | BYOIジョブの場合：Output.text 独自の推論レスポンスを持ち込まない場合、評価ジョブがAmazon Bedrockナレッジベースを呼び出してこのデータを準備します。 | 必須 |
| 正解レスポンス | {{ground\_truth}} | referenceResponses | オプション |
| 取得されたパッセージ | {{context}} | BYOIジョブの場合：Output.retrievedResults.retrievalResults 独自の推論レスポンスを持ち込まない場合、評価ジョブがAmazon Bedrockナレッジベースを呼び出してこのデータを準備します。 | オプション |
| 正解取得パッセージ | {{reference\_contexts}} | referenceContexts | オプション |

## 前提条件

BYOIを使用したLLM-as-a-judgeモデル評価およびRAG評価機能を使用するには、以下の前提条件が必要です：

* AWSアカウントとモデルアクセス：  
   * アクティブな[AWSアカウント](https://signin.aws.amazon.com/signin?redirect%5Furi=https%3A%2F%2Fportal.aws.amazon.com%2Fbilling%2Fsignup%2Fresume&client%5Fid=signup)  
   * Amazon Bedrockで有効化された評価モデルと生成モデル（Amazon Bedrockコンソールの**モデルアクセス**ページで確認）  
   * モデルが[利用可能な[AWSリージョン](https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region)とそのクォータ](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html)の確認
* [AWS Identity and Access Management](https://aws.amazon.com/iam/)（IAM）と[Amazon Simple Storage Service](http://aws.amazon.com/s3)（Amazon S3）の設定：  
   * モデル評価とRAG評価の両方に対するIAMセットアップと[権限](https://docs.aws.amazon.com/bedrock/latest/userguide/judge-service-roles.html)の完了  
   * 出力データへのアクセスと書き込みのための適切な権限を持つ[S3バケット](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-policy-language-overview.html)の設定  
   * S3バケットでの[CORS](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security-cors.html)の有効化

## Amazon Bedrock Evaluationsを使用したカスタムメトリクスによるモデル評価ジョブの作成

Amazon Bedrock Evaluationsを使用してモデル評価とカスタムメトリクスを含むジョブを作成するには、以下の手順を実行します：

1. Amazon Bedrockコンソールで、ナビゲーションペインの**評価**を選択し、**モデル**タブを選択します。
2. **モデル評価**セクションの**作成**ドロップダウンメニューから、**自動：モデルをジャッジとして**を選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image001.jpg)
3. **モデル評価の詳細**に、評価名とオプションの説明を入力します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image003.jpg)
4. **評価モデル**で、自動評価に使用するモデルを選択します。
5. **推論ソース**で、ソースを選択し、評価するモデルを選択します。

この例では、評価モデルとして**Claude 3.5 Sonnet**、推論ソースとして**Bedrockモデル**、評価するモデルとして**Claude 3.5 Haiku**を選択しました。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image005.jpg)

1. コンソールには、選択した評価モデルのデフォルトメトリクスが表示されます。必要に応じて他のメトリクスを選択できます。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image007.jpg)
2. **カスタムメトリクス**セクションで、「Comprehensiveness（包括性）」という新しいメトリクスを作成します。提供されたテンプレートを使用し、メトリクスに基づいて修正します。メトリクスを定義するために以下の変数を使用できます（`{{prediction}}`のみ必須）：  
   1. `prompt`  
   2. `prediction`  
   3. `ground_truth`

以下は完全に定義したメトリクスです：

```
あなたの役割は、質問と予測に基づいて回答の包括性を判断することです。言語モデルの応答の品質、
正確性、有用性を評価し、これらを使用して応答がどれだけ包括的かを判断してください。詳細で
思慮深い応答には高いスコアを与えてください。

指定されたすべての基準に対して、与えられたクエリ（プロンプト）に対するLLM応答の包括性を
慎重に評価してください。包括性を最もよく表す単一の総合スコアを割り当て、観察された特定の
長所と短所を参照して、評価を正当化する簡潔な説明を提供してください。

応答の品質を評価する際には、以下のルーブリックを考慮してください：
- 正確性：提供された情報の事実的正確さ
- 完全性：クエリの重要な側面のカバレッジ
- 明確さ：情報の明確な整理と提示
- 有用性：ユーザーにとっての応答の実用的な有用性

以下を評価してください：

クエリ：
{{prompt}}

評価する応答：
{{prediction}}
```

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image009.jpg)

1. 出力スキーマと追加のメトリクスを作成します。ここでは、応答が非常に包括的な場合に最大ポイント（10）を与え、まったく包括的でない場合に1を与えるスケールを定義します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image011.jpg)
2. **データセット**で、Amazon S3の入力および出力の場所を入力します。
3. **Amazon Bedrock IAMロール – 権限**で、**既存のサービスロールを使用する**を選択し、ロールを選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image013.jpg)
4. **作成**を選択し、ジョブが完了するのを待ちます。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image015.jpg)

## 考慮事項とベストプラクティス

カスタムメトリクスの出力スキーマを使用する際には、以下の点に注意してください：

* 組み込みの出力スキーマを使用する場合（推奨）、メインのジャッジプロンプトに評価スケールを追加しないでください。評価サービスは、ジャッジプロンプトの指示と定義された出力スキーマの評価スケール、および一部の構造化された出力指示（各ジャッジモデルに固有）を自動的に連結します。これにより、評価サービスはジャッジモデルの結果を解析し、コンソールにグラフで表示して数値スコアの平均値を計算できます。
* 完全に連結されたジャッジプロンプトは、Amazon Bedrockコンソールを使用してカスタムメトリクスを構築している場合、**プレビュー**ウィンドウで確認できます。ジャッジLLMは本質的に確率的であるため、解析してコンソールに表示したり、平均スコア計算に使用したりできない応答がある場合があります。ただし、評価サービスがジャッジモデルからの応答スコアを解析できない場合でも、生のジャッジ応答は常にS3出力ファイルにロードされます。
* 組み込みの出力スキーマ機能を使用しない場合（代わりに使用することをお勧めします）、ジャッジプロンプトの指示本文に評価スケールを提供する責任があります。ただし、評価サービスは構造化された出力指示を追加せず、結果を解析してグラフを表示しません。グラフなしでコンソールに完全なジャッジ出力プレーンテキスト結果が表示され、生データは引き続きS3バケットに保存されます。

## Python SDKとAPIを使用したカスタムメトリクスによるモデル評価ジョブの作成

Python SDKを使用してカスタムメトリクスを含むモデル評価ジョブを作成するには、以下の手順に従います（または[サンプルノートブック](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/evaluation-observe/bedrock-eval-custom-metrics)を参照してください）：

1. デフォルトメトリクスとカスタムメトリクス評価のためのモデル識別子、適切な権限を持つIAMロール、推論レスポンスを含む入力データのAmazon S3パス、結果の出力場所など、必要な設定を行います：  
```  
import boto3  
import time  
from datetime import datetime  
# ナレッジベースとモデル設定の構成  
evaluator_model = "anthropic.claude-3-5-sonnet-20240620-v1:0"  
generator_model = "amazon.nova-lite-v1:0"  
custom_metrics_evaluator_model = "anthropic.claude-3-5-sonnet-20240620-v1:0"  
role_arn = "arn:aws:iam::<YOUR_ACCOUNT_ID>:role/<YOUR_IAM_ROLE>"  
BUCKET_NAME = "<YOUR_BUCKET_NAME>"  
# S3の場所を指定  
input_data = f"s3://{BUCKET_NAME}/evaluation_data/input.jsonl"  
output_path = f"s3://{BUCKET_NAME}/evaluation_output/"  
# Bedrockクライアントを作成  
# 注：リージョン名は任意のリージョンに変更できます。  
bedrock_client = boto3.client('bedrock', region_name='us-east-1')  
```
2. モデル評価用のカスタムメトリクスを定義するには、`customMetricDefinition`を含むJSON構造を作成します。メトリクスの名前を含め、テンプレート変数（`{{prompt}}`や`{{prediction}}`など）を組み込んだ詳細な評価指示を書き、数値スコア（`floatValue`）またはカテゴリラベル（`stringValue`）のいずれかを使用して評価値を持つ`ratingScale`配列を定義します。この適切にフォーマットされたJSONスキーマにより、Amazon Bedrockは特定の基準に従ってモデル出力を一貫して評価できます。  
```  
comprehensiveness_metric ={  
    "customMetricDefinition": {  
        "name": "comprehensiveness",  
        "instructions": """あなたの役割は、質問と予測に基づいて回答の包括性を判断することです。  
言語モデルの応答の品質、正確性、有用性を評価し、これらを使用して応答がどれだけ包括的かを  
判断してください。詳細で思慮深い応答には高いスコアを与えてください。  
指定されたすべての基準に対して、与えられたクエリ（プロンプト）に対するLLM応答の包括性を  
慎重に評価してください。包括性を最もよく表す単一の総合スコアを割り当て、観察された特定の  
長所と短所を参照して、評価を正当化する簡潔な説明を提供してください。  
応答の品質を評価する際には、以下のルーブリックを考慮してください：  
- 正確性：提供された情報の事実的正確さ  
- 完全性：クエリの重要な側面のカバレッジ  
- 明確さ：情報の明確な整理と提示  
- 有用性：ユーザーにとっての応答の実用的な有用性  
以下を評価してください：  
クエリ：  
{{prompt}}  
評価する応答：  
{{prediction}}""",  
        "ratingScale": [  
            {  
                "definition": "非常に包括的",  
                "value": {  
                    "floatValue": 10  
                }  
            },  
            {  
                "definition": "やや包括的",  
                "value": {  
                    "floatValue": 3  
                }  
            },  
            {  
                "definition": "まったく包括的でない",  
                "value": {  
                    "floatValue": 1  
                }  
            }  
        ]  
    }  
}  
```
3. カスタムメトリクスを含むモデル評価ジョブを作成するには、`create_evaluation_job` APIを使用し、`customMetricConfig`セクションにカスタムメトリクスを含め、`metricNames`配列に組み込みメトリクス（`Builtin.Correctness`など）とカスタムメトリクスの両方を指定します。ジョブを生成モデル、評価モデル、入力データセットと出力結果のための適切なAmazon S3パスで構成します。  
```  
# モデル評価ジョブを作成  
model_eval_job_name = f"model-evaluation-custom-metrics{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}"  
model_eval_job = bedrock_client.create_evaluation_job(  
    jobName=model_eval_job_name,  
    jobDescription="カスタム包括性メトリクスによるモデルパフォーマンスの評価",  
    roleArn=role_arn,  
    applicationType="ModelEvaluation",  
    inferenceConfig={  
        "models": [{  
            "bedrockModel": {  
                "modelIdentifier": generator_model  
            }  
        }]  
    },  
    outputDataConfig={  
        "s3Uri": output_path  
    },  
    evaluationConfig={  
        "automated": {  
            "datasetMetricConfigs": [{  
                "taskType": "General",  
                "dataset": {  
                    "name": "ModelEvalDataset",  
                    "datasetLocation": {  
                        "s3Uri": input_data  
                    }  
                },  
                "metricNames": [  
                    "Builtin.Correctness",  
                    "Builtin.Completeness",  
                    "Builtin.Coherence",  
                    "Builtin.Relevance",  
                    "Builtin.FollowingInstructions",  
                    "comprehensiveness"  
                ]  
            }],  
            "customMetricConfig": {  
                "customMetrics": [  
                    comprehensiveness_metric  
                ],  
                "evaluatorModelConfig": {  
                    "bedrockEvaluatorModels": [{  
                        "modelIdentifier": custom_metrics_evaluator_model  
                    }]  
                }  
            },  
            "evaluatorModelConfig": {  
                "bedrockEvaluatorModels": [{  
                    "modelIdentifier": evaluator_model  
                }]  
            }  
        }  
    }  
)  
print(f"モデル評価ジョブを作成しました: {model_eval_job_name}")  
print(f"ジョブID: {model_eval_job['jobArn']}")  
```
4. 評価ジョブを送信した後、`get_evaluation_job`を使用してそのステータスを監視し、完了したら指定したAmazon S3の場所で標準およびカスタムメトリクスのパフォーマンスデータを含む結果にアクセスします。

## Amazon Bedrock Evaluationsを使用したカスタムメトリクスによるRAGシステム評価の作成

この例では、Amazon Bedrockコンソールで組み込みメトリクスとカスタム評価メトリクスを組み合わせたRAGシステム評価の手順を説明します：

1. Amazon Bedrockコンソールで、ナビゲーションペインの**評価**を選択します。
2. **RAG**タブで、**作成**を選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image017.jpg)
3. **RAG評価の詳細**に、評価名とオプションの説明を入力します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image019.jpg)
4. **評価モデル**で、自動評価に使用するモデルを選択します。ここで選択した評価モデルは、選択した場合にデフォルトメトリクスを計算するために使用されます。この例では、評価モデルとして**Claude 3.5 Sonnet**を選択しました。
5. オプションのタグを含めます。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image021.jpg)
6. **推論ソース**で、ソースを選択します。ここでは、**Bedrock Knowledge Bases**と**独自の推論レスポンスを持ち込む**の間で選択できます。[Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/)を使用している場合は、以前に作成したナレッジベースを選択するか、新しいナレッジベースを作成する必要があります。BYOIレスポンスの場合、RAGシステムからのプロンプトデータセット、コンテキスト、出力を持ち込むことができます。この例では、推論ソースとして**Bedrock Knowledge Base**を選択しました。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image023.jpg)
7. 評価タイプ、レスポンス生成モデル、組み込みメトリクスを指定します。検索とレスポンスの組み合わせ評価または検索のみの評価を選択でき、RAG評価にデフォルトメトリクス、カスタムメトリクス、またはその両方を使用するオプションがあります。レスポンス生成モデルは、Amazon Bedrockナレッジベースを推論ソースとして使用する場合にのみ必要です。BYOI構成の場合、レスポンス生成モデルなしで進めることができます。この例では、評価タイプとして**検索とレスポンス生成**を選択し、レスポンス生成モデルとして**Nova Lite 1.0**を選択しました。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image025.jpg)
8. **カスタムメトリクス**セクションで、評価モデルを選択します。カスタムメトリクスの評価モデルとして**Claude 3.5 Sonnet v1**を選択しました。
9. **カスタムメトリクスを追加**を選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image027.jpg)
10. 新しいメトリクスを作成します。この例では、RAG評価のための`information_comprehensiveness`（情報の包括性）という新しいカスタムメトリクスを作成します。このメトリクスは、レスポンスが取得された情報を使用してクエリにどれだけ徹底的かつ完全に対応しているかを評価します。これは、レスポンスが取得されたパッセージから関連情報をどの程度抽出し、包括的な回答を提供するために組み込んでいるかを測定します。
11. JSONファイルのインポート、事前設定されたテンプレートの使用、または完全な構成制御を持つカスタムメトリクスの作成から選択できます。例えば、デフォルトメトリクスの事前設定されたテンプレートを選択し、スコアリングシステムやルーブリックを変更することができます。`information_comprehensiveness`メトリクスでは、評価プロンプトを直接入力できるカスタムオプションを選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image029.jpg)
12. **指示**に、プロンプトを入力します。例：  
```  
あなたの役割は、レスポンスが取得された情報を使用してクエリにどれだけ包括的に対応しているかを  
評価することです。レスポンスが利用可能な取得パッセージを効果的に活用して、主題を徹底的に  
扱っているかどうかを評価してください。  
指定されたすべての基準に対して、与えられたクエリに対するRAGレスポンスの包括性を慎重に  
評価してください。包括性を最もよく表す単一の総合スコアを割り当て、観察された特定の長所と  
短所を参照して、評価を正当化する簡潔な説明を提供してください。  
レスポンスの包括性を評価する際には、以下のルーブリックを考慮してください：  
- カバレッジ：レスポンスは取得されたパッセージからの重要な関連情報を活用していますか？  
- 深さ：レスポンスは取得された情報の重要な側面について十分な詳細を提供していますか？  
- コンテキスト活用：レスポンスは利用可能な取得パッセージをどれだけ効果的に活用していますか？  
- 情報統合：レスポンスは取得された情報を組み合わせて徹底的な扱いを作成していますか？  
以下を評価してください：  
クエリ：{{prompt}}  
取得されたパッセージ：{{context}}  
評価するレスポンス：{{prediction}}  
```
13. カスタムメトリクスの結果がどのように構造化され、視覚化され、正規化され（該当する場合）、モデルによって説明されるかを定義する出力スキーマを入力します。

組み込みの出力スキーマを使用する場合（推奨）、メインのジャッジプロンプトに評価スケールを追加しないでください。評価サービスは、ジャッジプロンプトの指示と定義された出力スキーマの評価スケール、およびジャッジモデルの結果を解析できるように、一部の構造化された出力指示（各ジャッジモデルに固有）を自動的に連結します。完全に連結されたジャッジプロンプトは、Amazon Bedrockコンソールを使用してカスタムメトリクスを構築している場合、**プレビュー**ウィンドウで確認できます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image031.jpg)

1. **データセットと評価結果のS3の場所**で、Amazon S3の入力および出力の場所を入力します。
2. **Amazon Bedrock IAMロール – 権限**で、**既存のサービスロールを使用する**を選択し、ロールを選択します。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image033.jpg)
3. **作成**を選択し、ジョブが完了するのを待ちます。  
![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/ML-18787-image035.jpg)

## Python SDKとAPIを使用したカスタムメトリクスによるRAG評価ジョブの開始

Python SDKを使用してカスタムメトリクスを含むRAG評価ジョブを作成するには、以下の手順に従います（または[サンプルノートブック](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/evaluation-observe/bedrock-eval-custom-metrics)を参照してください）：

1. デフォルトメトリクスとカスタムメトリクス評価のためのモデル識別子、適切な権限を持つIAMロール、ナレッジベースID、推論レスポンスを含む入力データのAmazon S3パス、結果の出力場所など、必要な設定を行います：  
```  
import boto3  
import time  
from datetime import datetime  
# ナレッジベースとモデル設定の構成  
knowledge_base_id = "<YOUR_KB_ID>"  
evaluator_model = "anthropic.claude-3-5-sonnet-20240620-v1:0"  
generator_model = "amazon.nova-lite-v1:0"  
custom_metrics_evaluator_model = "anthropic.claude-3-5-sonnet-20240620-v1:0"  
role_arn = "arn:aws:iam::<YOUR_ACCOUNT_ID>:role/<YOUR_IAM_ROLE>"  
BUCKET_NAME = "<YOUR_BUCKET_NAME>"  
# S3の場所を指定  
input_data = f"s3://{BUCKET_NAME}/evaluation_data/input.jsonl"  
output_path = f"s3://{BUCKET_NAME}/evaluation_output/"  
# 検索設定を構成  
num_results = 10  
search_type = "HYBRID"  
# Bedrockクライアントを作成  
# 注：リージョン名は任意のリージョンに変更できます  
bedrock_client = boto3.client('bedrock', region_name='us-east-1')  
```
2. RAG評価用のカスタムメトリクスを定義するには、`customMetricDefinition`を含むJSON構造を作成します。メトリクスの名前を含め、テンプレート変数（`{{prompt}}`、`{{context}}`、`{{prediction}}`など）を組み込んだ詳細な評価指示を書き、数値スコア（`floatValue`）またはカテゴリラベル（`stringValue`）のいずれかを使用して評価値を持つ`ratingScale`配列を定義します。この適切にフォーマットされたJSONスキーマにより、Amazon Bedrockは特定の基準に従ってレスポンスを一貫して評価できます。  
```  
# カスタムinformation_comprehensivenessメトリクスを定義  
information_comprehensiveness_metric = {  
    "customMetricDefinition": {  
        "name": "information_comprehensiveness",  
        "instructions": """  
        あなたの役割は、レスポンスが取得された情報を使用してクエリにどれだけ包括的に対応しているかを  
評価することです。  
        レスポンスが利用可能な取得パッセージを効果的に活用して、主題を徹底的に扱っているかどうかを  
評価してください。  
指定されたすべての基準に対して、与えられたクエリに対するRAGレスポンスの包括性を慎重に評価してください。  
包括性を最もよく表す単一の総合スコアを割り当て、観察された特定の長所と短所を参照して、評価を  
正当化する簡潔な説明を提供してください。  
レスポンスの包括性を評価する際には、以下のルーブリックを考慮してください：  
- カバレッジ：レスポンスは取得されたパッセージからの重要な関連情報を活用していますか？  
- 深さ：レスポンスは取得された情報の重要な側面について十分な詳細を提供していますか？  
- コンテキスト活用：レスポンスは利用可能な取得パッセージをどれだけ効果的に活用していますか？  
- 情報統合：レスポンスは取得された情報を組み合わせて徹底的な扱いを作成していますか？  
以下を使用して評価してください：  
クエリ：{{prompt}}  
取得されたパッセージ：{{context}}  
評価するレスポンス：{{prediction}}  
""",  
        "ratingScale": [  
            {  
                "definition": "非常に包括的",  
                "value": {  
                    "floatValue": 3  
                }  
            },  
            {  
                "definition": "適度に包括的",  
                "value": {  
                    "floatValue": 2  
                }  
            },  
            {  
                "definition": "最小限に包括的",  
                "value": {  
                    "floatValue": 1  
                }  
            },  
            {  
                "definition": "まったく包括的でない",  
                "value": {  
                    "floatValue": 0  
                }  
            }  
        ]  
    }  
}  
```
3. カスタムメトリクスを含むRAG評価ジョブを作成するには、`create_evaluation_job` APIを使用し、`customMetricConfig`セクションにカスタムメトリクスを含め、`metricNames`配列に組み込みメトリクス（`Builtin.Correctness`）とカスタムメトリクスの両方を指定します。ジョブをナレッジベースID、生成モデル、評価モデル、入力データセットと出力結果のための適切なAmazon S3パスで構成します。  
```  
# 評価ジョブを作成  
retrieve_generate_job_name = f"rag-evaluation-generate-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}"  
retrieve_generate_job = bedrock_client.create_evaluation_job(  
    jobName=retrieve_generate_job_name,  
    jobDescription="カスタムメトリクスによる検索と生成の評価",  
    roleArn=role_arn,  
    applicationType="RagEvaluation",  
    inferenceConfig={  
        "ragConfigs": [{  
            "knowledgeBaseConfig": {  
                "retrieveAndGenerateConfig": {  
                    "type": "KNOWLEDGE_BASE",  
                    "knowledgeBaseConfiguration": {  
                        "knowledgeBaseId": knowledge_base_id,  
                        "modelArn": generator_model,  
                        "retrievalConfiguration": {  
                            "vectorSearchConfiguration": {  
                                "numberOfResults": num_results  
                            }  
                        }  
                    }  
                }  
            }  
        }]  
    },  
    outputDataConfig={  
        "s3Uri": output_path  
    },  
    evaluationConfig={  
        "automated": {  
            "datasetMetricConfigs": [{  
                "taskType": "General",  
                "dataset": {  
                    "name": "RagDataset",  
                    "datasetLocation": {  
                        "s3Uri": input_data  
                    }  
                },  
                "metricNames": [  
                    "Builtin.Correctness",  
                    "Builtin.Completeness",  
                    "Builtin.Helpfulness",  
                    "information_comprehensiveness"  
                ]  
            }],  
            "evaluatorModelConfig": {  
                "bedrockEvaluatorModels": [{  
                    "modelIdentifier": evaluator_model  
                }]  
            },  
            "customMetricConfig": {  
                "customMetrics": [  
                    information_comprehensiveness_metric  
                ],  
                "evaluatorModelConfig": {  
                    "bedrockEvaluatorModels": [{  
                        "modelIdentifier": custom_metrics_evaluator_model  
                    }]  
                }  
            }  
        }  
    }  
)  
print(f"評価ジョブを作成しました: {retrieve_generate_job_name}")  
print(f"ジョブID: {retrieve_generate_job['jobArn']}")  
```
4. 評価ジョブを送信した後、`get_evaluation_job`メソッドを使用してそのステータスを確認し、ジョブが完了したら結果を取得できます。出力は`output_path`パラメータで指定したAmazon S3の場所に保存され、カスタムメトリクスを含む評価次元全体でRAGシステムがどのようにパフォーマンスを発揮したかに関する詳細なメトリクスが含まれています。

カスタムメトリクスはLLM-as-a-judgeでのみ利用可能です。執筆時点では、コードベースのカスタムメトリクス評価のためのカスタム[AWS Lambda](http://aws.amazon.com/lambda)関数やエンドポイントは受け付けていません。人間によるモデル評価は、2023年11月の発表以来、[カスタムメトリクス定義](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-jobs-management-create-human.html)をサポートしています。

## クリーンアップ

将来の料金が発生しないようにするには、この記事の一部としてデプロイされたS3バケット、ノートブックインスタンス、その他のリソースを削除してください。

## 結論

Amazon Bedrock Evaluationsへのカスタムメトリクスの追加により、組織は生成AIシステムに対して独自の評価基準を定義できるようになりました。LLM-as-a-judgeフレームワークをカスタムメトリクスで拡張することで、企業は組み込みメトリクスと並んで、特定のユースケースに重要な要素を測定できるようになりました。数値とカテゴリ別のスコアリングシステムの両方をサポートするこれらのカスタムメトリクスにより、組織の標準と目標に沿った一貫した評価が可能になります。

生成AIがビジネスプロセスにますます統合されるにつれて、カスタム定義の基準に対して出力を評価する能力は、品質を維持し継続的な改善を推進するために不可欠です。提供されたAmazon BedrockコンソールとAPIの例を通じてこれらの新機能を探索し、[パーソナライズされた評価フレームワーク](https://aws.amazon.com/bedrock/evaluations/)がAIシステムのパフォーマンスとビジネスへの影響をどのように向上させるかを発見することをお勧めします。

---

### 著者について

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/11/20/image7-1-100x100.jpeg)**Shreyas Subramanian**はプリンシパルデータサイエンティストであり、生成AIとディープラーニングを使用してAWSサービスを活用したビジネス課題の解決を支援しています。Shreyasは大規模最適化とMLの背景を持ち、最適化タスクを加速するためのMLと強化学習の使用に精通しています。

[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/wale_picture_blog.png)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/wale%5Fpicture%5Fblog.png)**Adewale Akinfaderin**はシニアデータサイエンティスト–生成AI、Amazon Bedrockで、AWSでのファンデーションモデルと生成AIアプリケーションの最先端イノベーションに貢献しています。彼の専門知識は、再現可能でエンドツーエンドのAI/ML手法、実用的な実装、グローバルな顧客が学際的な問題に対してスケーラブルなソリューションを策定・開発するのを支援することです。物理学で2つの大学院学位と工学の博士号を持っています。

[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/Badgephoto-1.jpeg)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/Badgephoto-1.jpeg)**Jesse Manders**はAWS生成AI開発者サービスであるAmazon Bedrockのシニアプロダクトマネージャーです。彼はAIと人間の相互作用の交差点で働き、私たちのニーズを満たす生成AIプロダクトとサービスを作成・改善することを目標としています。以前はAppleとLumiledsでエンジニアリングチームのリーダーシップ役割を務め、シリコンバレーのスタートアップでシニアサイエンティストでした。フロリダ大学で修士号と博士号を取得し、カリフォルニア大学バークレー校ハース・スクール・オブ・ビジネスでMBAを取得しています。

[![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/blog-image-ishansin-1.jpeg)](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/03/06/blog-image-ishansin-1.jpeg)**Ishan Singh**はAmazon Web Servicesのシニア生成AIデータサイエンティストで、顧客が革新的で責任ある生成AIソリューションと製品を構築するのを支援しています。AI/MLの強力な背景を持つIshanは、ビジネス価値を推進する生成AIソリューションの構築を専門としています。仕事以外では、バレーボールをしたり、地元の自転車道を探索したり、妻と犬のBeauと時間を過ごすことを楽しんでいます。
