---
title: "Detect hallucinations for RAG-based systems"
emoji: "✨"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

Translation: https://aws.amazon.com/jp/blogs/machine-learning/detect-hallucinations-for-rag-based-systems/

# RAG ベースシステムにおけるハルシネーションの検出

Zainab Afolabi、Aiham Taleb、Nikita Kozodoi、Liza (Elizaveta) Zinovyeva 著、2025年5月16日 [Amazon Bedrock](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/ "Amazon Bedrockのすべての投稿を表示")、[Amazon Bedrock Guardrails](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/amazon-bedrock-guardrails/ "Amazon Bedrock Guardrailsのすべての投稿を表示")、[ベストプラクティス](https://aws.amazon.com/blogs/machine-learning/category/post-types/best-practices/ "ベストプラクティスのすべての投稿を表示")、[生成 AI](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/ "生成 AIのすべての投稿を表示") [パーマリンク](https://aws.amazon.com/blogs/machine-learning/detect-hallucinations-for-rag-based-systems/) [コメント](https://aws.amazon.com/blogs/machine-learning/detect-hallucinations-for-rag-based-systems/#Comments) [シェア](#)

[生成 AI](https://aws.amazon.com/generative-ai/) と AI システムにおける知識抽出の台頭により、[検索拡張生成（Retrieval Augmented Generation: RAG）](https://aws.amazon.com/awstv/watch/f461b0b2e4d/)は AI 生成レスポンスの正確性と信頼性を向上させるための重要なツールとなっています。RAG は、大規模言語モデル（LLM）が学習していない追加データを組み込む方法として機能します。これにより、虚偽または誤解を招く情報（ハルシネーション）の生成を減らすことにも役立ちます。しかし、RAG の機能があっても、AI ハルシネーションの課題は依然として重大な懸念事項です。

AI システムが日常生活や重要な意思決定プロセスにますます統合されるにつれて、ハルシネーションを検出し軽減する能力は最も重要です。ほとんどのハルシネーション検出技術は、プロンプトとレスポンスのみに焦点を当てています。しかし、RAG ベースのアプリケーションのように追加のコンテキストが利用可能な場合、ハルシネーション問題をより効果的に軽減するための新しい技術を導入することができます。

この記事では、RAG ベースのアプリケーション向けの基本的なハルシネーション検出システムを作成する方法について説明します。また、精度、適合率、再現率、コストの観点から異なる手法の長所と短所を比較します。

現在、多くの最先端技術が存在しますが、この記事で概説するアプローチは、RAG パイプラインに迅速に組み込んで RAG システムの出力品質を向上させることができる、シンプルでユーザーフレンドリーな技術を提供することを目的としています。

## ソリューション概要

ハルシネーションは、以下の図に示すように3つのタイプに分類できます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/hallucination_image.jpg)

科学文献では、複数のハルシネーション検出技術が提案されています。以下のセクションでは、ハルシネーションを検出するための4つの主要なアプローチについて説明し実装します：LLM プロンプトベースの検出器、意味的類似性検出器、BERT 確率的チェッカー、トークン類似性検出器です。最後に、パフォーマンスとレイテンシーの観点からアプローチを比較します。

## 前提条件

この記事で紹介する手法を使用するには、[Amazon SageMaker](https://aws.amazon.com/sagemaker/)、[Amazon Bedrock](https://aws.amazon.com/bedrock/)、および [Amazon Simple Storage Service](https://aws.amazon.com/s3/)（Amazon S3）へのアクセス権を持つ AWS アカウントが必要です。

RAG システムから、以下の3つの情報を保存する必要があります：

* **コンテキスト** – ユーザーのクエリに関連するテキスト領域
* **質問** – ユーザーのクエリ
* **回答** – LLM が提供する回答

結果のテーブルは、以下の例のようになります。

| **質問**           | **コンテキスト**                | **回答**                          |
| ------------------- | ------------------------------ | ----------------------------------- |
| カクテルとは何ですか？ | カクテルはアルコール混合… | カクテルはアルコール混合…      |
| カクテルとは何ですか？ | カクテルはアルコール混合… | それらには独自の歴史があります…       |
| フォートナイトとは何ですか？ | フォートナイトは人気のあるビデオ… | フォートナイトはオンラインマルチ…        |
| フォートナイトとは何ですか？ | フォートナイトは人気のあるビデオ… | 平均的なフォートナイトプレイヤーは… |

## アプローチ1：LLM ベースのハルシネーション検出

RAG システムからのレスポンスをコンテキスト矛盾ハルシネーションと事実に分類するために LLM を使用できます。目的は、どのレスポンスがコンテキストに基づいているか、あるいはハルシネーションを含んでいるかを識別することです。

このアプローチは以下のステップで構成されています：

1. 質問、コンテキスト、および分類したいレスポンスを含むデータセットを作成します。
2. 以下の情報を含めて LLM に呼び出しを送信します：  
   1. ステートメント（分類したい LLM からの回答）を提供します。  
   2. LLM が回答を作成したコンテキストを提供します。  
   3. LLM にコンテキストに直接基づいているステートメント内の文をタグ付けするよう指示します。
3. 出力を解析し、0～1の間の文レベルの数値スコアを取得します。
4. Q&A に使用されたものとは独立した LLM、メモリ、およびパラメータを維持します（これにより、LLM が結論を導くために以前のチャット履歴にアクセスできないようにします）。
5. ドメインなどの特定のデータセットに基づいてハルシネーションスコアの決定しきい値を調整します。
6. しきい値を使用してステートメントをハルシネーションまたは事実として分類します。

### プロンプトテンプレートの作成

質問への回答を分類するために LLM を使用するには、プロンプトを設定する必要があります。LLM にコンテキストと回答を取り込ませ、与えられたコンテキストからハルシネーションスコアを決定させたいと考えています。スコアは 0 から 1 の間でエンコードされ、0 はコンテキストから直接得られた回答、1 はコンテキストに基づかない回答を表します。

以下は、LLM が期待される回答の形式と内容を理解できるようにするための few-shot 例を含むプロンプトです：

```
prompt = """\n\nHuman: You are an expert assistant helping human to check if statements are based on the context.
 Your task is to read context and statement and indicate which sentences in the statement are based directly on the context.

Provide response as a number, where the number represents a hallucination score, which is a float between 0 and 1.
Set the float to 0 if you are confident that the sentence is directly based on the context.
Set the float to 1 if you are confident that the sentence is not based on the context.
If you are not confident, set the score to a float number between 0 and 1. Higher numbers represent higher confidence that the sentence is not based on the context.

Do not include any other information except for the the score in the response. There is no need to explain your thinking.

<example>
Context: Amazon Web Services, Inc. (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered, pay-as-you-go basis. Clients will often use this in combination with autoscaling (a process that allows a client to use more computing in times of high application usage, and then scale down to reduce costs when there is less traffic). These cloud computing web services provide various services related to networking, compute, storage, middleware, IoT and other processing capacity, as well as software tools via AWS server farms. This frees clients from managing, scaling, and patching hardware and operating systems. One of the foundational services is Amazon Elastic Compute Cloud (EC2), which allows users to have at their disposal a virtual cluster of computers, with extremely high availability, which can be interacted with over the internet via REST APIs, a CLI or the AWS console. AWS's virtual computers emulate most of the attributes of a real computer, including hardware central processing units (CPUs) and graphics processing units (GPUs) for processing; local/RAM memory; hard-disk/SSD storage; a choice of operating systems; networking; and pre-loaded application software such as web servers, databases, and customer relationship management (CRM).
Statement: 'AWS is Amazon subsidiary that provides cloud computing services.'
Assistant: 0.05
</example>

<example>
Context: Amazon Web Services, Inc. (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered, pay-as-you-go basis. Clients will often use this in combination with autoscaling (a process that allows a client to use more computing in times of high application usage, and then scale down to reduce costs when there is less traffic). These cloud computing web services provide various services related to networking, compute, storage, middleware, IoT and other processing capacity, as well as software tools via AWS server farms. This frees clients from managing, scaling, and patching hardware and operating systems. One of the foundational services is Amazon Elastic Compute Cloud (EC2), which allows users to have at their disposal a virtual cluster of computers, with extremely high availability, which can be interacted with over the internet via REST APIs, a CLI or the AWS console. AWS's virtual computers emulate most of the attributes of a real computer, including hardware central processing units (CPUs) and graphics processing units (GPUs) for processing; local/RAM memory; hard-disk/SSD storage; a choice of operating systems; networking; and pre-loaded application software such as web servers, databases, and customer relationship management (CRM).
Statement: 'AWS revenue in 2022 was $80 billion.'
Assistant: 1
</example>

<example>
Context: Monkey is a common name that may refer to most mammals of the infraorder Simiiformes, also known as the simians. Traditionally, all animals in the group now known as simians are counted as monkeys except the apes, which constitutes an incomplete paraphyletic grouping; however, in the broader sense based on cladistics, apes (Hominoidea) are also included, making the terms monkeys and simians synonyms in regard to their scope. On average, monkeys are 150 cm tall.
Statement:'Average monkey is 2 meters high and weights 100 kilograms.'
Assistant: 0.9
</example>

Context: {context}
Statement: {statement}

\n\nAssistant: [
    """
    ### LANGCHAIN CONSTRUCTS
    # prompt template
    prompt_template = PromptTemplate(
        template=prompt,
        input_variables=["context", "statement"],
    )
```

### LLM の設定

LLM からレスポンスを取得するには、以下のコードのように Amazon Bedrock を使用して LLM を設定する必要があります：

```
def configure_llm() -> Bedrock:

    model_params= { "answer_length": 100, # max number of tokens in the answer
        "temperature": 0.0, # temperature during inference
        "top_p": 1, # cumulative probability of sampled tokens
        "stop_words": [ "\n\nHuman:", "]", ], # words after which the generation is stopped 
                    } 
    bedrock_client = boto3.client( 
            service_name="bedrock-runtime",
            region_name="us-east-1", 
            )
            
    MODEL_ID = "anthropic.claude-3-5-sonnet-20240620-v1:0"
    
    llm = Bedrock( 
        client=bedrock_client, 
        model_id=MODEL_ID, 
        model_kwargs=model_params, 
        )
                        
    return llm 
```

### LLM からハルシネーション分類を取得する

次のステップは、プロンプト、データセット、および LLM を使用して RAG システムからの各レスポンスのハルシネーションスコアを取得することです。さらに一歩進んで、しきい値を使用してレスポンスがハルシネーションかどうかを判断することができます。以下のコードをご覧ください：

```
def get_response_from_claude(context: str, answer: str, prompt_template: PromptTemplate, llm: Bedrock) -> float:
    
    llm_chain = LLMChain(llm=llm, prompt=prompt_template, verbose=False)
    # compute scores
    response = llm_chain(
        {"context": context, "statement": str(answer)}
    )
    try:
        scores = float(scores)
    except Exception:
        print(f"Could not parse LLM response: {scores}")
        scores = 0
    return scores
```

## アプローチ2：意味的類似性に基づく検出

ステートメントが事実である場合、コンテキストとの類似性が高いという仮定のもと、意味的類似性を使用して、ステートメントが入力矛盾ハルシネーションであるかどうかを判断することができます。

このアプローチは以下のステップで構成されています：

1. LLM を使用して回答とコンテキストの埋め込みを作成します（この例では、Amazon Titan Embeddings モデルを使用します）。
2. 埋め込みを使用して、回答内の各文とコンテキストの間の類似性スコアを計算します（この場合、距離メトリックとしてコサイン類似度を使用します）。コンテキスト外（ハルシネーション）の文は、コンテキストとの類似性が低いはずです。
3. 特定のデータセット（ドメイン依存など）の決定しきい値を調整して、ハルシネーションステートメントを分類します。

### LLM で埋め込みを作成し類似性を計算する

LLM を使用して、コンテキストと質問への初期レスポンスの埋め込みを作成できます。埋め込みを取得した後、2つのコサイン類似性を計算できます。コサイン類似性スコアは、1が完全な類似性、0が類似性なしを表す0から1の間の数値を返します。これをハルシネーションスコアに変換するには、1からコサイン類似性を引く必要があります。以下のコードをご覧ください：

```
def similarity_detector(
    context: str,
    answer: str,
    llm: BedrockEmbeddings,
) -> float:
    """
    Check hallucinations using semantic similarity methods based on embeddings<br /><br />

    Parameters
    ----------
    context : str
        Context provided for RAG
    answer : str
        Answer from an LLM
    llm : BedrockEmbeddings
        Embeddings model

    Returns
    -------
    float
        Semantic similarity score
    """

    if len(context) == 0 or len(answer) == 0:
        return 0.0
    # calculate embeddings
    context_emb = llm.embed_query(context)
    answer_emb = llm.embed_query(answer)
    context_emb = np.array(context_emb).reshape(1, -1)
    answer_emb = np.array(answer_emb).reshape(1, -1)
    sim_score = cosine_similarity(context_emb, answer_emb)
    return 1 - sim_score[0][0]
```

## アプローチ3：BERT 確率的チェッカー

BERT スコアは、BERT などの事前学習された言語モデルからの事前学習された文脈的埋め込みを使用し、候補文と参照文の単語をコサイン類似性によってマッチングします。自然言語処理（NLP）における従来の評価指標の1つは BLEU スコアです。BLEU スコアは主に、候補文からの n-gram（連続トークン）が参照文にどれだけ出現するかを計算することで精度を測定します。これは、候補文と参照文の間のこれらの連続トークンシーケンスのマッチングに焦点を当てながら、人為的に高いスコアを受け取ることを防ぐために過度に短い翻訳にペナルティを組み込んでいます。BLEU スコアがトークンレベルの比較に焦点を当てているのとは異なり、BERT スコアは単語または完全な文の間の意味的類似性を捉えるために文脈的埋め込みを使用します。これは、文レベルおよびシステムレベルの評価に関する人間の判断と相関することが示されています。さらに、BERT スコアは精度、再現率、F1 測定値を計算し、これはさまざまな言語生成タスクの評価に役立ちます。

私たちのアプローチでは、BERT スコアをハルシネーション検出のための確率的チェッカーとして使用します。アイデアは、LLM から複数の回答を生成し、それらの間に大きなバリエーション（不一致）がある場合、これらの回答はハルシネーションである可能性が高いということです。まず、LLM からランダムなサンプル（文）を N 個生成します。次に、元の生成された段落内の各文を、N 個の新しく生成された確率的サンプル全体の対応する文と比較することで BERT スコアを計算します。これは、LLM ベースの埋め込みモデルを使用してすべての文を埋め込み、コサイン類似性を計算することによって行われます。私たちの仮説は、事実に基づく文は複数の生成にわたって一貫性を保ち、高い BERT スコア（類似性を示す）をもたらすというものです。逆に、ハルシネーションされたコンテンツは、異なる生成間で変化する可能性が高く、元の文とその確率的バリエーション間の BERT スコアが低くなります。これらの類似性スコアのしきい値を確立することで、一貫して低い BERT スコアを持つ文を潜在的なハルシネーションとしてフラグ付けすることができます。これは、同じモデルからの複数の生成にわたって意味的な不一致を示すためです。

## アプローチ4：トークン類似性検出

トークン類似性検出器では、回答とコンテキストから一意のトークンセットを抽出します。ここでは、LLM トークナイザーの1つを使用するか、単にテキストを個々の単語に分割することができます。次に、回答内の各文とコンテキストの間の類似性を計算します。トークン類似性には、異なる n-gram にわたる BLEU スコア、異なる n-gram にわたる ROUGE スコア（BLEU に似た NLP メトリックですが、精度ではなく再現率を計算します）、または単に2つのテキスト間の共有トークンの割合など、複数のメトリックを使用できます。コンテキスト外（ハルシネーション）の文は、コンテキストとの類似性が低いはずです。

```
def intersection_detector(
    context: str,
    answer: str,
    length_cutoff: int = 3,
) -> dict[str, float]:
    """
    Check hallucinations using token intersection metrics

    Parameters
    ----------
    context : str
        Context provided for RAG
    answer : str
        Answer from an LLM
    length_cutoff : int
        If no. tokens in the answer is smaller than length_cutoff, return scores of 1.0

    Returns
    -------
    dict[str, float]
        Token intersection and BLEU scores
    """

    # populate with relevant stopwords such as articles
    stopword_set = {}

    # remove punctuation and lowercase
    context = re.sub(r"[^\w\s]", "", context).lower()
    answer = re.sub(r"[^\w\s]", "", answer).lower()

    # calculate  metrics
    if len(answer) >= length_cutoff:
        # calculate token intersection
        context_split = {term for term in context if term not in stopword_set}
        answer_split = re.compile(r"\w+").findall(answer)
        answer_split = {term for term in answer_split if term not in stopword_set}
        intersection = sum([term in context_split for term in answer_split]) / len(answer_split)

        # calculate BLEU score
        bleu = evaluate.load("bleu")
        bleu_score = bleu.compute(predictions=[answer], references=[context])["precisions"]
        bleu_score = sum(bleu_score) / len(bleu_score)

        return {
            "intersection": 1 - intersection,
            "bleu": 1 - bleu_score,
        }

    return {"intersection": 0, "bleu": 0}
```

## アプローチの比較：評価結果

このセクションでは、記事で説明したハルシネーション検出アプローチを比較します。Wikipedia 記事データと2つの合成生成データセットを含む3つの RAG データセットで実験を実行しました。データセット内の各例には、コンテキスト、ユーザーの質問、および正確またはハルシネーションとしてラベル付けされた LLM の回答が含まれています。各ハルシネーション検出方法をすべての質問に対して実行し、データセット全体で精度メトリックを集計しました。

最高の精度（ハルシネーションと事実として正しく分類された文の数）は、BERT 確率的チェッカーと LLM プロンプトベースの検出器によって示されています。LLM プロンプトベースの検出器は適合率で BERT チェッカーを上回り、BERT 確率的チェッカーは再現率が高くなっています。意味的類似性とトークン類似性検出器は、精度と再現率が非常に低いですが、適合率に関しては良好なパフォーマンスを示しています。これは、これらの検出器が最も明白なハルシネーションを識別するためにのみ有用である可能性があることを示しています。

トークン類似性検出器を除いて、LLM プロンプトベースの検出器は LLM 呼び出しの数の点で最もコスト効率の高いオプションです。これはコンテキストとレスポンスのサイズに対して一定ですが（ただし、コストは入力トークンの数によって異なります）。意味的類似性検出器のコストは、コンテキストとレスポンス内の文の数に比例するため、コンテキストが大きくなるにつれてますます高価になる可能性があります。

以下の表は、各手法間で比較されたメトリックをまとめたものです。適合率が最優先される使用ケースでは、トークン類似性、LLM プロンプトベース、および意味的類似性手法をお勧めします。一方、高い再現率を提供するためには、BERT 確率的手法が他の手法よりも優れています。

以下の表は、各手法間で比較されたメトリックをまとめたものです。

| **手法**                    | **精度\*** | **適合率\*** | **再現率\*** | **コスト（LLM 呼び出し数）** | **説明可能性** |
| -------------------------------- | -------------- | --------------- | ------------ | ------------------------------ | ------------------ |
| **トークン類似性検出器**    | 0.47           | **0.96**        | 0.03         | 0                              | あり                |
| **意味的類似性検出器** | 0.48           | 0.90            | 0.02         | K\*\*\*                        | あり                |
| **LLM プロンプトベース検出器**    | 0.75           | 0.94            | 0.53         | 1                              | あり                |
| **BERT 確率的チェッカー**      | **0.76**       | 0.72            | **0.90**     | N+1\*\*                        | あり                |

\*Wikipedia データセットと生成 AI 合成データセットにわたる平均  
 \*\*N = ランダムサンプルの数  
 \*\*\*K = 文の数

これらの結果は、LLM ベースの検出器が精度とコスト（追加の回答レイテンシー）の間で良いトレードオフを示していることを示唆しています。最も明白なハルシネーションをフィルタリングするためのトークン類似性検出器と、より難しいものを識別するための LLM ベースの検出器の組み合わせを使用することをお勧めします。

## 結論

RAG システムが進化し、AI アプリケーションでますます重要な役割を果たすにつれて、ハルシネーションを検出し防止する能力は依然として重要です。LLM プロンプトベースの検出、意味的類似性検出、BERT 確率的チェック、およびトークン類似性検出という4つの異なるアプローチの探索を通じて、この課題に対処するためのさまざまな方法を示しました。各アプローチには精度、適合率、再現率、およびコストの点で長所と短所がありますが、LLM プロンプトベースの検出器は特に75％を超える精度率と比較的低い追加コストで有望な結果を示しています。組織は、計算リソース、精度要件、コスト制約などの要因を考慮して、特定のニーズに基づいて最も適切な方法を選択できます。この分野が進化し続けるにつれて、これらの基本的な技術は、より信頼性の高い信頼できる RAG システムを構築するための出発点を提供します。

---

### 著者について

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/zafolabi.jpg) **Zainab Afolabi** はロンドンの生成 AI イノベーションセンターのシニアデータサイエンティストで、多様な業界にわたって変革的な AI ソリューションを開発するために広範な専門知識を活用しています。彼女は人工知能と機械学習の分野で8年以上の専門的な経験を持ち、複雑な技術概念を実用的なビジネスアプリケーションに変換することに情熱を持っています。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/05/06/aitaleb.png)**Aiham Taleb, PhD** は生成 AI イノベーションセンターのシニア応用科学者で、AWS エンタープライズ顧客と直接
