---
title: "vllm-neuron ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã§å¾—ãŸçŸ¥è¦‹"
emoji: "ğŸ”"
type: "tech"
topics: ["vllm", "AWSNeuron", "Profiler", "Python", "æ€§èƒ½æœ€é©åŒ–"]
published: false
---

## ã¯ã˜ã‚ã«

[å‰å›ã®è¨˜äº‹](https://zenn.dev/tosshi/articles/d68bd091d1934d) ã§ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®é–‹ç™ºã«ã»ã¼è¶£å‘³ã§é›†ä¸­ã—ã¦ã—ã¾ã—ãŸãŒã€ä»Šå›ã¯ï¼ˆçœŸé¢ç›®ã«ï¼‰ AWS Inferentia2 ä¸Šã§ vllm-neuron ã‚’ä½¿ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°åˆ†æã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¾ã™ã€‚

https://zenn.dev/tosshi/articles/ef61e14fe73399

æœ¬è¨˜äº‹ã§ã¯ã€ä¸Šè¨˜ã®è¨˜äº‹ã§å¾—ã‚‰ã‚ŒãŸ bucketing ã¨ prefix caching ã®è¨­å®šã«ã‚ˆã‚‹å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®çµæœã«ã¤ã„ã¦ãªãœãã†ãªã‚‹ã®ã‹ã‚’è€ƒå¯Ÿã™ã‚‹ã“ã¨ãŒä¸»ãªç›®çš„ã§ã™ã€‚

å®Ÿæ–½ã—ãŸèª¿æŸ»ã‚’ 4 ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«åˆ†ã‘ã¾ã™ã€‚ã¾ãš Phase 1 ã§ã¯ AWS Neuron Profiler ã«ã‚ˆã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’è©¦è¡ŒéŒ¯èª¤ã—ã¾ã—ãŸã€‚æ¬¡ã« Phase 2 ã§ã¯ Python ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚Phase 3 ã§ã¯ NxD Inference ã‚’ç›´æ¥ä½¿ç”¨ã—ãŸæ¸¬å®šã‚’è¡Œã„ã€vLLM ã¨ã®æ¯”è¼ƒã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚æœ€å¾Œã« Phase 4 ã§ã¯ vLLM ã® bucketing ON/OFF ã®å†…éƒ¨å‹•ä½œã‚’åˆ†æã—ã¾ã—ãŸã€‚

:::message
**ä»Šå›ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®é€²ã‚æ–¹ã¯çµæœçš„ã«ã‹ãªã‚Šé–“é•ã£ã¦ã„ã¾ã—ãŸï¼** è‰²ã€…è©¦è¡ŒéŒ¯èª¤ã—ãŸã‚“ã ãªã€ã¨æ€ã„ãªãŒã‚‰æœ¬è¨˜äº‹ã‚’èª­ã‚“ã§ãã ã•ã„ã€‚
:::

:::message alert
æœ¬è¨˜äº‹ã¯åˆå­¦è€…å‘ã‘ã§ã¯ãªã„ãŸã‚ LLM æ¨è«–ã®åŸºç¤çŸ¥è­˜ã€vLLM ã®åŸºç¤çŸ¥è­˜ã€AWS Neuron ã®åŸºç¤çŸ¥è­˜ãŒã‚ã‚‹ã“ã¨ãŒå‰æã§ã™ã€‚
:::

## Phase 1: AWS Neuron Profiler ã§ã®è©¦è¡ŒéŒ¯èª¤

### 1.1 ãªãœãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‹ã‚‰å§‹ã‚ã‚‹ã®ã‹

æ€§èƒ½æœ€é©åŒ–ã‚’è¡Œã†éš›ã€ã¾ãšç¾çŠ¶ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã§ã¯æ€§èƒ½ã®çµæœã¯åˆ†ã‹ã‚Šã¾ã™ãŒã€æ€§èƒ½ã®ç†ç”±ã€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®å ´æ‰€ã€ãã—ã¦æ”¹å–„ã®ä½™åœ°ã¯åˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚

ä»¥ä¸‹ã«å®Ÿé¨“ç’°å¢ƒã¨è¨­å®šæƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãŠãã¾ã™ã€‚ä»¥å‰ã® Zenn è¨˜äº‹ã®å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æœ€é©å€¤ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚

::::details å®Ÿé¨“ç’°å¢ƒã¨è¨­å®šæƒ…å ±

æœ¬èª¿æŸ»ã§ä½¿ç”¨ã—ãŸå®Ÿé¨“ç’°å¢ƒã¨è¨­å®šã®è©³ç´°ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ç’°å¢ƒ**:
- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: `inf2.xlarge`

**ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒãƒ¼ã‚¸ãƒ§ãƒ³**:
- Neuron SDK: 2.27.x
- vLLM: 0.13.0ï¼ˆNeuron å¯¾å¿œç‰ˆï¼‰
- neuronx-distributed-inference (NxD Inference): 0.7.0
- Python: 3.12

**ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿**:
- ãƒ¢ãƒ‡ãƒ«: Qwen3-0.6B-Reranker
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·:
  - Phase 1-3 åˆæœŸæ¸¬å®š: 97 ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå›ºå®šé•·ï¼‰
  - è¿½åŠ èª¿æŸ»: 18-125 ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå¯å¤‰é•·ã€16 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
- ã‚¿ã‚¹ã‚¯: Rerankerï¼ˆæ–‡æ›¸ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 4

**vLLM è¨­å®šï¼ˆéå»ã® Zenn è¨˜äº‹ã®å®Ÿé¨“ã§ã®æœ€é©å€¤ï¼‰**:
```yaml
vllm:
  tensor_parallel_size: 2           # 2 NeuronCore ä½¿ç”¨
  max_num_seqs: 4                   # åŒæ™‚å‡¦ç†æ•°
  block_size: 32                    # KV cache block size
  max_model_len: 2048
  max_num_batched_tokens: 256
  num_gpu_blocks_override: 512
  enable_prefix_caching: false      # Phase 1-5 ã§ã¯ç„¡åŠ¹
  dtype: "bfloat16"

  additional_config:
    override_neuron_config:
      skip_warmup: True
      enable_bucketing: true        # å‹•çš„ãƒãƒƒãƒãƒ³ã‚°æœ‰åŠ¹
      pa_num_blocks: 512
      pa_block_size: 32
```

ã“ã‚Œã‚‰ã®è¨­å®šã¯ã€[å‰å›ã® Zenn è¨˜äº‹](https://zenn.dev/tosshi/articles/ef61e14fe73399) ã§æœ€é©åŒ–ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

æœ¬èª¿æŸ»ã§ã¯ã€ã“ã®ç‰¹å®šã®è¨­å®šã«ãŠã‘ã‚‹ vllm-neuron ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã¯ã€ç•°ãªã‚‹æ€§èƒ½ç‰¹æ€§ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
::::

### 1.2 Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã®åŸºæœ¬åˆ†æ

å‰å›ã‚‚å°‘ã—ç´¹ä»‹ã—ãŸ Perfetto ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ãˆã¾ã™ã€‚ã¾ãšä»¥ä¸‹ã®ã‚ˆã†ãªåˆ†æã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚

:::details Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚³ãƒ¼ãƒ‰

```python
from perfetto.trace_processor import TraceProcessor
tp = TraceProcessor(trace='profile_output/trace.perfetto-trace')

# Operation ã”ã¨ã®é›†è¨ˆ
sql = """
SELECT name, COUNT(*) as count,
       SUM(dur) / 1e9 as total_seconds,
       AVG(dur) / 1e9 as avg_seconds
FROM slice WHERE dur > 0
GROUP BY name ORDER BY total_seconds DESC LIMIT 10
"""
```

**çµæœã®ä¸€éƒ¨**:
```
                  name   count total_seconds avg_seconds
0              unknown  156427      0.038387         0.0
1               MATMUL   21582      0.010941    0.000001
2 custom_call.17_sg0002      36      0.007028    0.000195
3            LDWEIGHTS   21212      0.004914         0.0
```

**ã‚¯ã‚¨ãƒªã®è¦‹æ–¹**:
`slice` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯å„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œè¨˜éŒ²ãŒæ ¼ç´ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚¯ã‚¨ãƒªã¯ä»¥ä¸‹ã‚’å–å¾—ã—ã¾ã™ã€‚
- `name`: ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åï¼ˆMATMUL ãªã©ã€Neuron ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒç”Ÿæˆã—ãŸæ¼”ç®—ã®ç¨®é¡ï¼‰
- `count`: ãã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œã•ã‚ŒãŸå›æ•°
- `dur`: å„å®Ÿè¡Œã®ç¶™ç¶šæ™‚é–“ï¼ˆãƒŠãƒç§’å˜ä½ã§è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€1e9 ã§å‰²ã£ã¦ç§’ã«å¤‰æ›ï¼‰
- `total_seconds`: ãã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆè¨ˆå®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰
- `avg_seconds`: 1 å›ã‚ãŸã‚Šã®å¹³å‡å®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰
:::

çµæœã¨ã—ã¦ã€ã¾ãšã€`custom_call.17_sg0002` ã¨ã„ã†æ“ä½œãŒãŸã£ãŸ 36 å›ã®å®Ÿè¡Œã§ 7ms ã‚‚æ¶ˆè²»ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚æ¬¡ã«ã€MATMUL ã¨ LDWEIGHTS ãŒã»ã¼åŒã˜å›æ•°å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€`unknown` ã¨ã„ã†åˆ†é¡ã®æ“ä½œãŒ 38ms ã§æœ€å¤§ã®æ™‚é–“ã‚’æ¶ˆè²»ã—ã¦ã„ã¾ã—ãŸã€‚

`custom_call.17_sg0002`ã€‚ã€‚ã€‚ä½•ã§ã™ã‹ã­ã“ã‚Œã¯ã€‚ã€‚

:::details [ç™ºå±•çš„å†…å®¹] NEFF ã«ã‚ˆã‚‹ custom_call ã®èª¿æŸ»

**ç–‘å•**: `custom_call.17_sg0002` ã¨ã¯ä½•ã‹ï¼ŸRoPEï¼Ÿæ´»æ€§åŒ–é–¢æ•°ï¼Ÿä½•ã‚‰ã‹ã®ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ï¼Ÿ

Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã§ã¯å®Ÿè¡Œå›æ•°ã¨æ™‚é–“ã—ã‹åˆ†ã‹ã‚‰ãªã„ãŸã‚ã€NEFF (Neuron Executable File Format) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ [unpacking](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html) ã—ã¦é™çš„ãªæ§‹é€ ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚(uppack ã«ã¯ `neuron-packager unpack` ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ©ç”¨ã—ã¦ã‚‚è‰¯ã„ã§ã™)

**NEFF ã‹ã‚‰åˆ¤æ˜ã—ãŸã“ã¨**:

```bash
# NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ unpacking
$ dd if=neff_322059935237836.neff of=neff.tar.gz bs=1024 skip=1
$ tar -xzf neff.tar.gz

# tensor_map.json ã‚’ç¢ºèª
$ cat sg00/tensor_map.json | jq '.["custom_call.17_sg0002"]'
{
  "dtype": "float32",
  "sim_shape": [256, 1, 1],
  "kind": null,
  "is_const": false,
  "layer_name": "custom_call.17"
}
```

**åˆ†ã‹ã‚‹ã“ã¨**:
- ãƒ‡ãƒ¼ã‚¿å‹: `float32`ï¼ˆç²¾åº¦é‡è¦–ã®æ¼”ç®—ï¼‰
- ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: `[256, 1, 1]`ï¼ˆæ¯”è¼ƒçš„å°ã•ã„ï¼‰
- ã‚µãƒ–ã‚°ãƒ©ãƒ•: `sg0002`
- å‹•çš„ã«è¨ˆç®—ã•ã‚Œã‚‹ä¸­é–“ãƒ†ãƒ³ã‚½ãƒ«
- `custom_call.14` ï½ `17` ã®é€£ç¶šã—ãŸæ¼”ç®—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹

**Qwen3 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰æ¨æ¸¬**:

å½¢çŠ¶ `[256, 1, 1]` ã¨å‘¨è¾ºã® `dot` (MATMUL) æ“ä½œã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ“ä½œã¨æ¨æ¸¬
- **RoPE (Rotary Position Embedding)**: ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨ˆç®—
- **RMSNorm**: æ­£è¦åŒ–å±¤ã®çµ±è¨ˆå€¤è¨ˆç®—
- **ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹**: Softmax å‰ã®ä¸­é–“è¨ˆç®—

NEFF ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã®é™çš„ãªæƒ…å ±ï¼ˆã‚°ãƒ©ãƒ•æ§‹é€ ã€ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ã€ãƒ‡ãƒ¼ã‚¿å‹ï¼‰ã‚’å«ã¿ã¾ã™ãŒã€ä»¥ä¸‹ã¯åˆ¤æ˜ã—ãªã„ã‚ˆã†ã§ã™ã€‚
- å…·ä½“çš„ãªæ¼”ç®—ãƒ­ã‚¸ãƒƒã‚¯
- å®Ÿè¡Œå›æ•°
- å®Ÿè¡Œæ™‚é–“
- åˆå›å®Ÿè¡Œæ™‚ã®é…å»¶

NEFF åˆ†æã‹ã‚‰ã¯ã€ä½•ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã¯åˆ†ã‹ã‚Šã¾ã™ãŒã€ã©ã†å‹•ãã‹ã¯ Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã§å®Ÿè¡Œæ™‚ã«æ¸¬å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
:::

### 1.3 skip_warmup è¨­å®šã®å½±éŸ¿

è©¦è¡ŒéŒ¯èª¤ã—ãªãŒã‚‰å®Ÿè¡Œã—ãŸã‚¯ã‚¨ãƒªã‚’å…¨ã¦ç´¹ä»‹ã—ã¦ã„ã‚‹ã¨è†¨å¤§ã«ãªã£ã¦ã—ã¾ã†ãŸã‚å‰²æ„›ã—ã¾ã™ãŒ custom_call ãŒåˆå›å®Ÿè¡Œæ™‚ã«å¤§ããªé…å»¶ã‚’èµ·ã“ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸãŸã‚ã€NxD Inference ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ `skip_warmup=False` ã‚’è©¦ã—ã¦ã¿ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ `False` ãªã®ã§ã™ãŒä»¥å‰ã®å®Ÿé¨“ã®è©¦è¡ŒéŒ¯èª¤ã§ `True` ã«ã—ã¦ã„ã¾ã—ãŸã€‚ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¾Œã« 1 å›ã® forward å®Ÿè¡Œã‚’è¡Œã„ã€é…å»¶åˆæœŸåŒ–ã‚’å®Œäº†ã•ã›ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚
                                                                                                                  
| è¨­å®š | å¹³å‡æ™‚é–“ |
|------|---------|
| Baseline (skip_warmup=True) | 2.992ç§’ |
| Warmup (skip_warmup=False) | 3.110ç§’ (+3.9%) |

ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã™ã‚Œã°é€Ÿããªã‚‹ã¨äºˆæƒ³ã—ã¦ã„ã¾ã—ãŸãŒã€å®Ÿéš›ã«ã¯ç´„ 4% é…ããªã‚Šã¾ã—ãŸã€‚å†åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¤‰åŒ–ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

:::details Operation æ•°ã®å¤‰åŒ–

```
Baseline (skip_warmup=True):
  MATMUL: 21,582å›, 10.94ms
  LDWEIGHTS: 21,212å›, 4.91ms
  ACTIVATE: 4,702å›, 1.65ms
  COPY: 83å›, 0.03ms

Warmup (skip_warmup=False):
  MATMUL: 13,497å› (-37%), 2.64ms (-76%)
  LDWEIGHTS: 13,497å› (-36%), 1.17ms (-76%)
  ACTIVATE: 4,207å› (-11%), 2.94ms (+78%)
  COPY: 554å› (+567%), 1.01ms (+3,267%)
```
:::

`skip_warmup=False` ã§ MATMUL/LDWEIGHTS ã®ä¸»è¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯å®Ÿè¡Œæ™‚é–“ãŒ 76% æ¸›å°‘ã—ãŸã‚‚ã®ã®ã€ACTIVATE ã®å®Ÿè¡Œæ™‚é–“ãŒ +78%ã€COPY ã®å®Ÿè¡Œæ™‚é–“ãŒ +3,267% å¢—åŠ ã—ã€ãƒˆãƒ¼ã‚¿ãƒ«ã§ã¯é…ããªã‚Šã¾ã—ãŸã€‚


### 1.4 Neuron Profiler ã®æ¸¬å®šç¯„å›²ã®é™ç•Œ

:::message alert
**ã“ã“ã§é‡è¦ãªæ°—ã¥ã**ï¼šNeuron Profiler ã®ãƒˆãƒ¬ãƒ¼ã‚¹æ™‚é–“ã¯ 16-17ms ãªã®ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å…¨ä½“ã¯ç´„ 3 ç§’ã‹ã‹ã£ã¦ã„ã‚‹ã€‚**ã“ã® 16-17ms ã£ã¦ã©ã“ã‹ã‚‰ã©ã“ã¾ã§ã®ãªã‚“ã®å€¤ï¼Ÿ**
:::

æ¶™ã®èª¿æŸ»ã®çµæœã€Neuron Profiler ã®æ¸¬å®šç¯„å›²ã«é–¢ã™ã‚‹é‡è¦ãªç‰¹æ€§ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚Neuron Profiler ã¯å®Ÿè¡Œæ™‚ã« NTFF (Neuron Trace File Format) ã¨ã„ã†ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã«å¤‰æ›ã—ã¾ã™ã€‚å„ NTFF ãƒ•ã‚¡ã‚¤ãƒ«ã¯ 1 ã¤ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œè¨˜éŒ²ã‚’è¡¨ã—ã¦ãŠã‚Šã€ç•°ãªã‚‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚„ sequence length ç”¨ã®è¤‡æ•°ã‚°ãƒ©ãƒ•ãŒå­˜åœ¨ã—ã¾ã™ã€‚ãã®ãŸã‚ã“ã‚Œã ã‘ã‚’è¦‹ã‚Œã° NeuronCore ã®ãƒˆãƒ¼ã‚¿ãƒ«ã®å®Ÿè¡Œæ™‚é–“ãŒç¢ºå®Ÿã«ã‚ã‹ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

```bash
$ find profile_output -name "*.ntff" | wc -l
22  # 11ç¨®é¡ã®ã‚°ãƒ©ãƒ• Ã— 2ã‚³ã‚¢(tensor_parallel_size=2)

# NTFF ã¯ Perfetto ã«å¤‰æ›ã•ã‚Œã‚‹
$ ls profile_output/trace.perfetto-trace
trace.perfetto-trace  # ã“ã‚Œã‚’ TraceProcessor ã‚„ Perfetto UI ã§åˆ†æ
```

:::message alert
**ä»Šå›ã®éã¡ã‹ã‚‰ã®å­¦ã³**: Neuron Profiler ã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®åˆ†æã«ã¯æœ‰ç”¨ã ãŒã€vllm-neuron å…¨ä½“ã®æœ€é©åŒ–ã«ãŠã„ã¦åˆæ‰‹ã§ä½¿ã†ã‚‚ã®ã§ã¯ãªã„ã€‚
:::

ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã‚’å®Ÿè£…ã™ã‚‹ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã¯ Neuron Profiler ã¯å¿…é ˆã¨è¨€ãˆã¾ã™ãŒã€æœ€é©ãªè¨­å®šã‚’æ¢ã™éš›ã®åˆæ‰‹ã§å®Ÿæ–½ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãã—ã¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®æ”¹å–„ã‚’ã™ã‚‹å‰ã« vllm-neuron å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã®å†…ã®ã©ã®ç¨‹åº¦ã‚’ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢å´ã®æ¨è«–å‡¦ç†ãŒå ã‚ã¦ã„ã‚‹ã®ã‹ã«ã‚ˆã£ã¦æ”¹å–„ã®å„ªå…ˆåº¦ãŒå¤‰ã‚ã£ã¦ãã‚‹ã®ã§ vllm-neuron å…¨ä½“ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’ã—ãªã„ã¨æ„å‘³ãªã„ãã€ã¨æ€ã„ã¾ã—ãŸã€‚ã€‚ã¨ã¯ã„ãˆã€ä»Šå›å¾—ãŸ Neuron Profiler ã«é–¢ã™ã‚‹çŸ¥è¦‹ã¯æœ‰ç”¨ãªãŸã‚ã‚·ã‚§ã‚¢ã®æ„å‘³ã‚’è¾¼ã‚ã¦ Phase 1 ã‚’æ¶ˆã•ãšã«ãã®ã¾ã¾å…¬é–‹ã—ã¾ã™ã€‚

### 1.5 NEFFã€Perfetto ã¨ã¯

Phase 1 ã§ç™»å ´ã—ãŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦æ•´ç†ã—ã¾ã™ã€‚

:::message
NEFFï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ï¼‰ â†’ NTFFï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œæ™‚ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ â†’ **Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹**ï¼ˆåˆ†æã«ä½¿ç”¨ï¼‰
:::

#### NEFF (Neuron Executable File Format)

[å‚è€ƒ: Work with NEFF Files](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html)

**å½¹å‰²**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«

```bash
# NEFF ã®æ§‹é€ 
neff_322059935237836.neff (801KB)
â”œâ”€â”€ [1024 byte header]
â””â”€â”€ [tar.gz archive]
    â”œâ”€â”€ info.json              # ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æƒ…å ±
    â”œâ”€â”€ hlo_stats.json         # æ¼”ç®—çµ±è¨ˆï¼ˆHloMacCount: 29.2B ãªã©ï¼‰
    â”œâ”€â”€ metrics.json           # æ¨å®šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
    â”œâ”€â”€ neff.json              # ã‚°ãƒ©ãƒ•å®šç¾©ï¼ˆ373 ãƒãƒ¼ãƒ‰ï¼‰
    â””â”€â”€ sg00/                  # ã‚µãƒ–ã‚°ãƒ©ãƒ• 0
        â”œâ”€â”€ tensor_map.json    # ãƒ†ãƒ³ã‚½ãƒ«æƒ…å ±ï¼ˆ458 ãƒ†ãƒ³ã‚½ãƒ«ï¼‰
        â”œâ”€â”€ PE.bin             # Processing Element å‘½ä»¤
        â”œâ”€â”€ Activation.bin     # æ´»æ€§åŒ–é–¢æ•°å‘½ä»¤
        â”œâ”€â”€ DVE.bin            # Data Vector Engine å‘½ä»¤
        â””â”€â”€ debug_info_*.dbg   # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
```

::::details NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã¨ bucketing ã®é–¢ä¿‚

**NEFF (Neuron Executable File Format)** ã¯ã€AWS NeuronCore ä¸Šã§å®Ÿè¡Œã•ã‚Œã‚‹ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚bucketing ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€è¤‡æ•°ã® (batch_size, sequence_length) ã®çµ„ã¿åˆã‚ã›ã«å¯¾å¿œã™ã‚‹è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ãŒäº‹å‰ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã™ã€‚

```bash
# NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
$ find profile_output -name "*.neff" | wc -l
77  # è¤‡æ•°ã® PID ã‹ã‚‰ 11 ç¨®é¡ã®ã‚°ãƒ©ãƒ• Ã— è¤‡æ•°å›ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

$ ls -lh profile_output/*/neff_*.neff | awk '{print $5}' | sort -u
801K   # Graph 1: æœ€å°ãƒã‚±ãƒƒãƒˆ
881K   # Graph 2
991K   # Graph 3
1.1M   # Graph 4
1.3M   # Graph 5
2.1M   # Graph 6
2.3M   # Graph 7
2.4M   # Graph 8
2.6M   # Graph 9
3.0M   # Graph 10
       # (åˆè¨ˆ 11 ç¨®é¡ã€124 MB)
```

bucketing ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã€è¤‡æ•°ã®ã‚µã‚¤ã‚ºã®ã‚°ãƒ©ãƒ•ã‚’äº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ãŠãã€ãã‚Œã‚‰ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–ã«åˆ©ç”¨ã—ã¾ã™ã€‚å®Ÿè¡Œæ™‚ã«å…¥åŠ›ã‚µã‚¤ã‚ºã«å¿œã˜ãŸæœ€é©ã‚°ãƒ©ãƒ•ã‚’é¸æŠã™ã‚‹ã“ã¨ã‹ã‚‰ã€ã‚°ãƒ©ãƒ•é¸æŠã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã©ãŒç™ºç”Ÿã—ã¾ã™ã€‚å›ºå®šé•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã€å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã®ã¯è¤‡æ•°ã‚°ãƒ©ãƒ•ã®ã†ã¡ 1 ã¤ã ã‘ã§ã‚ã‚Šã€ç‰¹ã« bucketing ã®æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãªãã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒè¿½åŠ ã•ã‚Œã‚‹ã¨æ€ã‚ã‚Œã¾ã™ã€‚ä¸€èˆ¬çš„ãª LLM ã®ç”Ÿæˆã®ã‚ˆã†ãªå¯å¤‰é•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯ç•°ãªã‚‹é•·ã•ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¤‡æ•°ã‚°ãƒ©ãƒ•ã«åˆ†æ•£ã•ã‚Œã‚‹ã®ã§å†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ã“ã¨ãªãåŠ¹ç‡çš„ãªãƒãƒƒãƒãƒ³ã‚°ãŒå¯èƒ½ãªãŸã‚ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å·®ã—å¼•ã„ã¦ã‚‚é«˜é€ŸåŒ–ã«è²¢çŒ®ã™ã‚‹ã¨æ€ã‚ã‚Œã¾ã™ã€‚

:::message
**ã“ã®ã‚ˆã†ã«ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ bucketing ã®æ€§èƒ½ã¯ ON/OFF ã§ã©ã¡ã‚‰ãŒè‰¯ã„ã‹å¤‰å‹•ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’è¦šãˆã¦ãŠã„ã¦ãã ã•ã„ï¼**
:::
::::

#### NTFF (Neuron Trace File Format) - ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«

**å½¹å‰²**: Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã«å¤‰æ›ã•ã‚Œã‚‹å‰ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«

```bash
# NTFF ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ï¼ˆNeuron Profiler ãŒç”Ÿæˆï¼‰
profile_output/i-0049acfde6046f237_pid_520024/
â”œâ”€â”€ 322059935237836_instid_0_vnc_0.ntff  # Graph 1, Core 0
â”œâ”€â”€ 322059935237836_instid_0_vnc_1.ntff  # Graph 1, Core 1
â”œâ”€â”€ 729292360268366_instid_0_vnc_0.ntff  # Graph 4, Core 0
â”œâ”€â”€ 729292360268366_instid_0_vnc_1.ntff  # Graph 4, Core 1
...
â””â”€â”€ (22 files = 11 graphs Ã— 2 cores)

# Neuron Profiler ã§ Perfetto ã«å¤‰æ›
$ neuron-profile view --output-format perfetto profile_output
```

#### Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹

**å½¹å‰²**: NeuronCore ä¸Šã®ä½ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹

```bash
# Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹
trace.perfetto-trace (110 MB)
â””â”€â”€ SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    â”œâ”€â”€ slice ãƒ†ãƒ¼ãƒ–ãƒ«          # ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œè¨˜éŒ²
    â”‚   â””â”€â”€ MATMUL: 21,582å›, 10.94ms
    â”‚       COPY: 83å›, 0.03ms
    â”‚       custom_call.17: 36å›, 7ms
    â”œâ”€â”€ thread ãƒ†ãƒ¼ãƒ–ãƒ«         # ã‚¹ãƒ¬ãƒƒãƒ‰æƒ…å ±
    â””â”€â”€ process ãƒ†ãƒ¼ãƒ–ãƒ«        # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±
```

::::details NEFF ã¨ Perfetto ã®æ¯”è¼ƒ

ä»¥ä¸‹ã¯ã¾ã å®Œå…¨ã«ã¯æ•´ç†ã—ãã‚Œã¦ã„ãªã„ãŸã‚å‚è€ƒç¨‹åº¦ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚

| æƒ…å ± | NEFF | Perfetto | å‚™è€ƒ |
|------|------|----------|------|
| **é™çš„æ§‹é€ ** | | | |
| ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆãƒãƒ¼ãƒ‰ã€ãƒ†ãƒ³ã‚½ãƒ«æ•°ï¼‰ | âœ… | âŒ | NEFF unpacking ã§å–å¾— |
| ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ãƒ»ãƒ‡ãƒ¼ã‚¿å‹ | âœ… | âŒ | tensor_map.json |
| æ¼”ç®—é‡ï¼ˆç†è«–å€¤ï¼‰ | âœ… | âŒ | hlo_stats.json |
| ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆç†è«–å€¤ï¼‰ | âœ… | âŒ | IfmapSizeã€OfmapSize |
| DMA ã‚­ãƒ¥ãƒ¼æ§‹æˆ | âœ… | âŒ | def.json |
| **ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œ** | | | |
| ã‚°ãƒ©ãƒ•ã”ã¨ã®å®Ÿè¡Œæ™‚é–“ | âŒ | âš ï¸ | SQL é›†è¨ˆã§è¨ˆç®—å¯èƒ½ |
| NeuronCore ã”ã¨ã®å†…è¨³ | âŒ | âš ï¸ | ã‚¹ãƒ¬ãƒƒãƒ‰åˆ¥ã«é›†è¨ˆ |
| ä½¿ç”¨ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã®è­˜åˆ¥ | âŒ | âš ï¸ | slice åã‹ã‚‰æ¨å®š |
| ã‚°ãƒ©ãƒ•é–“ã®é·ç§»æ™‚é–“ | âŒ | âš ï¸ | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰æ¨å®š |
| **ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œ** | | | |
| å®Ÿè¡Œæ™‚é–“ï¼ˆå®Ÿæ¸¬å€¤ï¼‰ | âŒ | âœ… | slice.dur |
| å®Ÿè¡Œå›æ•° | âŒ | âœ… | COUNT(*) |
| ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©³ç´°ï¼ˆMATMULã€COPY ãªã©ï¼‰ | âŒ | âœ… | slice.name |
| ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨å®Ÿè¡Œé †åº | âŒ | âœ… | slice.ts |
| ä¸¦åˆ—å®Ÿè¡Œã®å¯è¦–åŒ– | âŒ | âœ… | Perfetto UI |
| åˆæœŸåŒ–é…å»¶ï¼ˆskip_warmup åŠ¹æœï¼‰ | âŒ | âœ… | åˆå›å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒ |
| **é«˜ãƒ¬ãƒ™ãƒ«æƒ…å ±** | | | |
| Python ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | âŒ | âŒ | line_profiler ãªã©ãŒå¿…è¦ |
| æ¼”ç®—å†…å®¹ã®æ„å‘³ï¼ˆRoPEã€RMSNorm ãªã©ï¼‰ | âš ï¸ | âŒ | å½¢çŠ¶ã‹ã‚‰æ¨æ¸¬ã®ã¿ |

**å‡¡ä¾‹**: âœ… ç›´æ¥å–å¾—å¯èƒ½ã€âš ï¸ æ¨æ¸¬ãƒ»è¨ˆç®—ãŒå¿…è¦ã€âŒ å–å¾—ä¸å¯èƒ½
::::

## Phase 2: line_profiler ã«ã‚ˆã‚‹ Python ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

Phase 1 ã§ã¯ Neuron Profiler ã«ã‚ˆã‚Š NeuronCore ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ãªåˆ†æã‚’è¡Œã„ã¾ã—ãŸãŒã€Python ãƒ¬ãƒ™ãƒ«ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ¼ã‚¿æº–å‚™ãªã©ï¼‰ã®æ¸¬å®šã«ã¯åˆ¥ã®ãƒ„ãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚ãã“ã§ line_profiler ã‚’ä½¿ç”¨ã—ã¦ Python ã‚³ãƒ¼ãƒ‰ã®è¡Œã”ã¨ã®å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®šã—ã¾ã™ã€‚

### æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æº–å‚™

Phase 1 ã§ä½¿ç”¨ã—ãŸ `test_reranker.py` ã¯ pytest + benchmark_capture ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€line_profiler ã¨çµ„ã¿åˆã‚ã›ã‚‹ã¨å‡ºåŠ›ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãã“ã§ã€line_profiler å°‚ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ `profile_line.py` ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ï¼ˆã“ã®è¾ºã‚Šã‚‚ vllm-neuron ã® Python ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã†ã¾ãå–ã‚Œã‚‹ã‚ˆã†ã«ä»Šå¾Œ benchmark_capture ã®å®Ÿè£…ã‚’æ”¹å–„ã—ã¾ã™ï¼‰

::::details ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ§‹é€ 

```python:profile_line.py
try:
    profile
except NameError:
    def profile(func):
        return func

# config.yaml ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆtest_reranker.py ã¨åŒã˜ï¼‰
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# æ¸¬å®šå¯¾è±¡ã®é–¢æ•°ã« @profile ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
    # ... (test_reranker.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)

@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id,
                 prefix_tokens, suffix_tokens):
    """ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ... (test_reranker.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆpytest éä¾å­˜ï¼‰"""
    llm = vllm.LLM(model=model_path, **vllm_config)
    # ... åˆæœŸåŒ–ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ

if __name__ == "__main__":
    main()
```

::::

::::details ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Œå…¨ç‰ˆ
```python:profile_line.py
"""
Line profiler script for vLLM-Neuron Reranker

Run with:
    kernprof -l -v profile_line.py

Or for more detailed output:
    kernprof -l profile_line.py
    python -m line_profiler profile_line.py.lprof
"""

# line_profiler compatibility: make @profile decorator optional
try:
    profile
except NameError:
    # If not running under kernprof, @profile is a no-op
    def profile(func):
        return func

import csv
import gc
import logging
import os
import sys
from pathlib import Path

import yaml

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load configuration
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# Get model path
model_path = config['model']['path']

# Get vLLM config
vllm_config = {
    "tensor_parallel_size": config['vllm']['tensor_parallel_size'],
    "max_num_seqs": config['vllm']['max_num_seqs'],
    "block_size": config['vllm']['block_size'],
    "max_model_len": config['vllm']['max_model_len'],
    "max_num_batched_tokens": config['vllm']['max_num_batched_tokens'],
    "num_gpu_blocks_override": config['vllm']['num_gpu_blocks_override'],
    "enable_prefix_caching": config['vllm']['enable_prefix_caching'],
    "dtype": config['vllm']['dtype'],
    "disable_log_stats": config['vllm'].get('disable_log_stats', False),
}

# Add additional_config if present (Zenn article optimal settings)
if 'additional_config' in config['vllm']:
    vllm_config['additional_config'] = config['vllm']['additional_config']

# Get reranker config
reranker_config = config['reranker']
benchmark_config = config['benchmark']

# Reranker prompts
reranker_prompts = {
    'instruction': reranker_config['instruction'],
    'prefix': reranker_config['prefix'],
    'suffix': reranker_config['suffix']
}

# Token IDs
token_ids = {
    'true': reranker_config['token_true'],
    'false': reranker_config['token_false']
}

# Load CSV data
csv_file = Path(__file__).parent / reranker_config['input_file']
with open(csv_file, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    rows = list(reader)

num_queries = min(len(rows), benchmark_config['num_test_queries'])
search_num = reranker_config['search_num']
batch_size = reranker_config['batch_size']
max_length = reranker_config['max_length']

logger.info(f"Loaded {len(rows)} queries from {csv_file}")
logger.info(f"Testing with first {num_queries} queries")


def format_instruction(query: str, doc: str) -> str:
    """Format instruction for reranker"""
    instruction = reranker_prompts['instruction']
    output = f"<Instruct>: {instruction}\n<Query>: {query}\n<Document>: {doc}"
    # Truncate if too long
    if len(output) >= 2000:
        output = output[:2000]
    return output


@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """Build prompts with proper tokenization - PROFILING TARGET"""
    prompts = []
    budget = max_length - len(prefix_tokens) - len(suffix_tokens)

    # Tokenize pairs
    enc = tokenizer(
        list(pairs),
        padding=False,
        truncation="longest_first",
        return_attention_mask=False,
        add_special_tokens=False,
        max_length=max(8, budget),
    )

    # Build final prompts: prefix + content + suffix
    for ids in enc["input_ids"]:
        final_ids = prefix_tokens + ids + suffix_tokens
        text = tokenizer.decode(final_ids, skip_special_tokens=False)
        prompts.append(text)

    return prompts


@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens):
    """Run reranker on queries - MAIN PROFILING TARGET"""

    import vllm
    from vllm import SamplingParams

    # Get use_tqdm setting from benchmark config
    use_tqdm = benchmark_config.get('use_tqdm', True)

    # Create SamplingParams
    sampling_params = SamplingParams(
        max_tokens=1,
        temperature=0.0,
        logprobs=20,
        detokenize=True,
        allowed_token_ids=[token_true_id, token_false_id]
    )

    logger.info(f"SamplingParams configured: max_tokens=1, "
                f"allowed_tokens=[{token_ids['true']}, {token_ids['false']}]")

    # Process each query
    total_processed = 0
    for query_idx, row in enumerate(rows[:num_queries]):
        query = row["query"]

        # Get candidates
        candidates = [
            row[f"answer_{i}"]
            for i in range(search_num)
            if f"answer_{i}" in row
        ]

        # Format query-document pairs
        pairs = [format_instruction(query, doc) for doc in candidates[:search_num]]

        # Build prompts with tokenization
        prompts = build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens)

        # Process in batches
        query_outputs = []
        for s in range(0, len(prompts), batch_size):
            batch_prompts = prompts[s:s + batch_size]
            outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=use_tqdm)
            query_outputs.extend(outputs)

        total_processed += len(query_outputs)

        if query_idx == 0:
            # Show first result for verification
            logger.info(f"Query 1: {query[:80]}...")
            logger.info(f"Generated {len(query_outputs)} scores for "
                       f"{len(candidates[:search_num])} candidates")
            if query_outputs:
                first_output = query_outputs[0]
                logger.info(f"First output: {first_output.outputs[0].text} "
                           f"(token_ids={first_output.outputs[0].token_ids})")

    logger.info(f"Profiling completed: processed {total_processed} reranker pairs")
    return total_processed


def main():
    """Main profiling function"""
    import vllm

    logger.info("Initializing vLLM-Neuron reranker...")
    logger.info(f"Model: {model_path}")
    logger.info(f"Config: block_size={vllm_config['block_size']}, "
               f"max_num_seqs={vllm_config['max_num_seqs']}, "
               f"tensor_parallel_size={vllm_config['tensor_parallel_size']}")

    # Initialize vLLM
    llm = vllm.LLM(model=model_path, **vllm_config)

    # Get tokenizer and token IDs
    tokenizer = llm.get_tokenizer()
    token_false_id = tokenizer.convert_tokens_to_ids(token_ids['false'])
    token_true_id = tokenizer.convert_tokens_to_ids(token_ids['true'])

    logger.info(f"Token IDs: {token_ids['true']}={token_true_id}, "
               f"{token_ids['false']}={token_false_id}")

    # Encode prompt templates
    prefix_tokens = tokenizer.encode(
        reranker_prompts['prefix'], add_special_tokens=False
    )
    suffix_tokens = tokenizer.encode(
        reranker_prompts['suffix'], add_special_tokens=False
    )

    logger.info(f"Prefix tokens: {len(prefix_tokens)}, Suffix tokens: {len(suffix_tokens)}")

    # Run profiling
    logger.info("Starting profiling run...")
    total = run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens)

    logger.info(f"Profiling complete. Processed {total} pairs.")

    # Cleanup
    del llm
    gc.collect()


if __name__ == "__main__":
    main()
````

```yaml:config.yaml
# vLLM-Neuron Reranker Benchmark Configuration

# Model configuration
model:
  # Path to the reranker model
  # Example: "/path/to/models/Qwen3-0.6B-Reranker"
  # Use environment variable: export RERANKER_MODEL_PATH="/your/model/path"
  path: "/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker"

# vLLM-Neuron engine settings
vllm:
  tensor_parallel_size: 2           # Number of NeuronCores
  max_num_seqs: 4                   # Batch size
  block_size: 32                    # KV cache block size (32 for Zenn best case, 128 for stability)
  max_model_len: 2048               # Maximum sequence length
  max_num_batched_tokens: 256       # Performance optimization
  num_gpu_blocks_override: 512      # pa_num_blocks equivalent
  enable_prefix_caching: false      # Explicit disable
  dtype: "bfloat16"                 # Data type

  # Neuron-specific overrides (Zenn article optimal settings)
  additional_config:
    override_neuron_config:
      skip_warmup: true             # Phase 1-5 ã®è¨­å®šï¼ˆè¨˜äº‹ã¨ä¸€è‡´ï¼‰
      enable_bucketing: true        # å‹•çš„ãƒãƒƒãƒãƒ³ã‚°æœ‰åŠ¹
      pa_num_blocks: 512
      pa_block_size: 32

# Reranker-specific settings
reranker:
  # Input data
  input_file: "input_sample.csv"    # CSV file with queries and candidates

  # Processing parameters
  search_num: 20                    # Number of candidates per query to process
  batch_size: 8                     # Batch size for processing prompts
  max_length: 1500                  # Maximum prompt length

  # Model-specific tokens (for Qwen3-Reranker)
  # Change these for other reranker models
  token_true: "yes"
  token_false: "no"

  # Prompt templates (for Qwen3-Reranker)
  # Customize these for your model
  prefix: |
    <|im_start|>system
    Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be "yes" or "no".<|im_end|>
    <|im_start|>user

  # Note: "assitant" typo is intentional for Qwen3-Reranker compatibility
  suffix: |
    <|im_end|>
    <|im_start|>assitant
    <think>

    </think>


  instruction: "Given a web search query, retrieve relevant passages that answer the query"

# Benchmark settings
benchmark:
  rounds: 5                         # Number of benchmark rounds
  warmup_rounds: 1                  # Number of warmup rounds
  num_test_queries: 10              # Number of queries to use for testing (è¨˜äº‹ã¨åŒã˜æ¡ä»¶)

# Profiler settings (optional)
profiler:
  # Clear Neuron compilation cache before benchmark
  # WARNING: First run after clearing will recompile (10-15 minutes)
  # Useful when:
  # - Model configuration changed (batch size, sequence length, etc.)
  # - Neuron SDK version changed
  # - Testing clean compilation performance
  clear_cache_before: false

  # Clear cache after benchmark (useful for CI/CD to save disk space)
  clear_cache_after: false
```
::::

ã“ã‚Œã«ã‚ˆã‚Šã€**Phase 1 ã¨åŒã˜æ¸¬å®šæ¡ä»¶**ï¼ˆåŒã˜ config.yamlã€åŒã˜å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã‚’ç¶­æŒã—ãªãŒã‚‰ã€line_profiler ã«ã‚ˆã‚‹è©³ç´°ãª Python ãƒ¬ãƒ™ãƒ«ã®åˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

### 2.1 æ¸¬å®šå¯¾è±¡ã®ç†è§£

**æ¸¬å®šå¯¾è±¡**: 1 ã‚¯ã‚¨ãƒªï¼ˆ20 å€™è£œæ–‡æ›¸ã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ã‚’å‡¦ç†ã™ã‚‹æ™‚é–“

```yaml
reranker:
  search_num: 20        # 1 ã‚¯ã‚¨ãƒªã‚ãŸã‚Š 20 å€™è£œæ–‡æ›¸
  batch_size: 8         # 8 ãƒšã‚¢ãšã¤ãƒãƒƒãƒå‡¦ç†

vllm:
  max_num_seqs: 4       # vLLM ã®åŒæ™‚å‡¦ç†æ•°
```

```
1  ã‚¯ã‚¨ãƒª = 20 ãƒšã‚¢ Ã· batch_size=8 = 3 ãƒãƒƒãƒ
10 ã‚¯ã‚¨ãƒª = 30 ãƒãƒƒãƒ
åˆè¨ˆæ™‚é–“ = 2,992ms â†’ 1 ã‚¯ã‚¨ãƒªã‚ãŸã‚Šç´„ 300ms
```

### 2.2 line_profiler æ¸¬å®šçµæœ

::::details line_profiler ã®å®Ÿè¡Œ

**å®Ÿè¡Œç’°å¢ƒã®æº–å‚™**:

```bash
# vLLM-Neuron ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin/activate

# PATH ã« Neuron SDK ã®ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ 
export PATH="/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin:$PATH"

# line_profiler ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ
pip install line-profiler
```

**ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ**:

```bash
cd /path/to/my-reranker
kernprof -l -v -p vllm.v1.engine profile_line.py
```

:::message
**kernprof ã‚ªãƒ—ã‚·ãƒ§ãƒ³èª¬æ˜**:
- `-l` (--line-by-line): è¡Œã”ã¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
- `-v` (--view): çµæœã‚’å³åº§ã«è¡¨ç¤º
- `-p vllm.v1.engine` (--prof-mod): **vllm.v1.engine ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è‡ªå‹•ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯¾è±¡ã«æŒ‡å®š**ï¼ˆã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®å…¨é–¢æ•°ã‚’è‡ªå‹•çš„ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼‰
:::

å®Ÿè¡Œå¾Œã€`profile_line.py.lprof` ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°ãªè¡Œã”ã¨ã®å®Ÿè¡Œæ™‚é–“ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
::::

ä»¥ä¸‹ã«å®Ÿéš›ã« line_profiler ã®çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’ç¤ºã—ã¾ã™ã€‚

```python
# llm.generate() - 30 ãƒãƒƒãƒå‡¦ç†
Line 157: outputs = llm.generate(batch_prompts, sampling_params)
  - Hits: 30 batches
  - Time: 3781.560 ms (3.78 ç§’)
  - Per Hit: 126.052 ms/batch
  - % Time: 99.1%

# LLMEngine.step() ã®å†…è¨³
Line 293: outputs = self.engine_core.get_output()
  - Hits: 229 steps (7.6 steps/batch)
  - Time: 3197.372 ms
  - Per Hit: 13.962 ms/step
  - % Time: 95.3%
```

line_profiler ã«ã‚ˆã‚‹æ¸¬å®šã®çµæœã€10 ã‚¯ã‚¨ãƒªï¼ˆ30 ãƒãƒƒãƒï¼‰ã®å‡¦ç†ã«åˆè¨ˆ 3.78 ç§’ã‹ã‹ã‚Šã€ãã®ã†ã¡ `llm.generate()` ã®å‘¼ã³å‡ºã—ã ã‘ã§ **99.1%ï¼ˆ3.78 ç§’ï¼‰** ã‚’å ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚ç´„ 3 ç§’ã‹ã‚‰æ™‚é–“ãŒå¢—ãˆã¦ã„ã‚‹ã®ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§ã™ã€‚

ã•ã‚‰ã«é‡è¦ãªç™ºè¦‹ã¨ã—ã¦ã€**1 ãƒãƒƒãƒã‚ãŸã‚Šã®å‡¦ç†æ™‚é–“ãŒ 126.052ms** ã¨ã„ã†æ¸¬å®šå€¤ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ãŸã ã—ã€ã“ã®å€¤ã¯ **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å«ã‚€** ãŸã‚ã€Phase 3 ã§ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã‚’åˆ¥é€”å®Ÿæ–½ã—ã¾ã™ã€‚ã¾ãŸã€vLLM ã®å†…éƒ¨å‡¦ç†ã‚’è¦‹ã‚‹ã¨ã€`LLMEngine.step()` ãŒ 229 å›å‘¼ã°ã‚Œã¦ãŠã‚Šã€30 ãƒãƒƒãƒã«å¯¾ã—ã¦ **å¹³å‡ 7.6 steps/batch** ã¨ã„ã†è¬ã®å€¤ãŒè¦³æ¸¬ã•ã‚Œã¾ã—ãŸã€‚ãªãœ 1 ãƒãƒƒãƒã®å‡¦ç†ã« 7.6 å›ã‚‚ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦ãªã®ã‹ã€ã“ã®æ™‚ç‚¹ã§ã¯ç†è§£ã§ãã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚

### 2.3 7.6 steps/batch ã®ç†ç”±ã‚’è¿½ã†

ã“ã®æ•°å€¤ã®è§£æ˜ã™ã‚‹ãŸã‚ã€`LLMEngine.step()` ã®ä¸­èº«ã‚’ã•ã‚‰ã«è©³ã—ãèª¿ã¹ã¾ã—ãŸã€‚line_profiler ã® `-p vllm.v1.engine` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šã€vLLM å†…éƒ¨ã®ã‚³ãƒ¼ãƒ‰ã‚‚è‡ªå‹•ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚

`LLMEngine.step()` ã®å‡¦ç†æ™‚é–“ã®ã»ã¼å…¨ã¦ï¼ˆ95.3%ï¼‰ãŒ `engine_core.get_output()` ã¨ã„ã†å˜ä¸€ã®é–¢æ•°å‘¼ã³å‡ºã—ã§è²»ã‚„ã•ã‚Œã¦ã„ã¾ã—ãŸã€‚ã•ã‚‰ã«ãã® `get_output()` é–¢æ•°ã®ä¸­èº«ã‚’è¦‹ã‚‹ã¨ã€**100% ãŒ `outputs_queue.get()` ã¨ã„ã†ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†**ã§ã—ãŸã€‚

```python
# LLMEngine.step() ã®ä¸­èº«
Line 293: outputs = self.engine_core.get_output()
  - Time: 3197.372 ms (95.3% of step())

# get_output() ã®ä¸­èº«
Line 715: outputs = self.outputs_queue.get()
  - Time: 3194.6 ms
  - % Time: 100.0% of get_output()
```

ã¤ã¾ã‚Šã€ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¯ `outputs_queue.get()` ã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰çµæœãŒé€ã‚‰ã‚Œã¦ãã‚‹ã®ã‚’ãŸã **å¾…ã£ã¦ã„ã‚‹ã ã‘**ã§ã—ãŸã€‚ã“ã‚Œã¯å®Ÿéš›ã®æ¨è«–å‡¦ç†ãŒåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§è¡Œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã“ã“ã§ vLLM v1 ã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å­˜åœ¨ã‚’æ€ã„å‡ºã—ã¾ã—ãŸã€‚

ï¼ˆä»¥ä¸‹ã®è¨˜äº‹ã«å†…éƒ¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è§£èª¬ãŒã‚ã‚Šã¾ã™ï¼‰

https://zenn.dev/tosshi/articles/f64ba0b86e330b

vLLM v1 ã§ã¯ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘å–ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¨ã€å®Ÿéš›ã«æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ Worker ãƒ—ãƒ­ã‚»ã‚¹ãŒåˆ†é›¢ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¯ `llm.generate()` ã‚’å‘¼ã³å‡ºã™ã¨ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ Worker ãƒ—ãƒ­ã‚»ã‚¹ã«é€ä¿¡ã—ã€`outputs_queue.get()` ã§ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦çµæœã‚’å¾…ã¡ã¾ã™ã€‚ä¸€æ–¹ã€Worker ãƒ—ãƒ­ã‚»ã‚¹ã¯ NeuronCore ã§ã®æ¨è«–å®Ÿè¡Œã€çµæœã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ã‚’é€šã˜ã¦ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã«çµæœã‚’è¿”ã—ã¾ã™ã€‚ã“ã®æ§‹é€ ã‚’å›³ç¤ºã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

**vLLM v1 ã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (vllm-neuron)**

```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    subgraph MainProcess["Main Process"]
        A[LLMEngine.step] --> B[get_output]
        B --> C[outputs_queue.get<br/>13.962 ms/step]
    end

    subgraph WorkerProcess["Worker Process"]
        D[EngineCore] --> E[execute_model]
        E --> F[Neuron å®Ÿè¡Œ]
        F --> G[ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³]
        G --> H[ZMQ é€ä¿¡]
    end

    H -->|IPC| C

    style MainProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style WorkerProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style C fill:#0f3460,stroke:#16213e,color:#fff
    style F fill:#0f3460,stroke:#16213e,color:#fff
```

line_profiler ã¯ Python ã®æ¨™æº–çš„ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ã¨åŒæ§˜ã«ã€**å®Ÿè¡Œä¸­ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ã‚³ãƒ¼ãƒ‰ã—ã‹æ¸¬å®šã§ãã¾ã›ã‚“**ã€‚ã¤ã¾ã‚Šã€Worker ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œã•ã‚Œã‚‹ `execute_model()` ã‚„ NeuronCore ã§ã®æ¨è«–å‡¦ç†ã¯ã€ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã™ã€‚

æ¸¬å®šã§ããŸã®ã¯ `outputs_queue.get()` ã§å¾…æ©Ÿã—ã¦ã„ã‚‹æ™‚é–“ï¼ˆ13.962ms/stepï¼‰ã ã‘ã§ã‚ã‚Šã€ã“ã®æ™‚é–“ã«ã¯æ¨è«–ã€IPC ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã©ã®ã™ã¹ã¦ã®æ™‚é–“ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

ã§ã¯ã€ãªãœ 1 ãƒãƒƒãƒã®å‡¦ç†ã«å¹³å‡ 7.6 å›ã‚‚ `step()` ãŒå‘¼ã°ã‚Œã‚‹ã®ã§ã—ã‚‡ã†ã‹ã€‚ã“ã‚Œã¯ vLLM v1 ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å‹•ä½œæ–¹æ³•ã¨ã—ã¦ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ãŒä½•åº¦ã‚‚ `step()` ã‚’ç¢ºèªã—ã¦ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ç¶šã‘ã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€‚1 ãƒãƒƒãƒã‚ãŸã‚Šå¹³å‡ã—ã¦ 7.6 å›ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚

è¬ã¯è§£ã‘ã¾ã—ãŸãŒã€è‚å¿ƒã® **Worker ãƒ—ãƒ­ã‚»ã‚¹å†…ã§ã® NeuronCore ã®æ¨è«–å‡¦ç†æ™‚é–“**ã‚’åˆ†è§£ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚`outputs_queue.get()` ã® 13.962 ms ã«ã¯ã€æ¨è«–å®Ÿè¡Œã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€IPC é€šä¿¡ã®ã™ã¹ã¦ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€line_profiler ã§ã¯ã“ã‚Œä»¥ä¸Šåˆ†è§£ã‚’ã™ã‚‹ã®ã¯é›£ã—ãã†ã§ã™ã€‚

:::message alert
**ä»Šå›ã®éã¡ã‹ã‚‰ã®å­¦ã³**: line_profiler ã§ã¯ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«é™ç•ŒãŒã‚ã‚‹ãŸã‚ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£ã—ãŸä¸Šã§æ¬²ã—ã„æƒ…å ±ã‚’å–å¾—ã§ãã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’é¸å®šã—ãŸæ–¹ãŒè‰¯ã„ã€‚py-spy ã¯ Worker å´ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¾ã§å®Ÿæ–½ã§ãã¾ã™ã€‚
:::

### 2.4 æ¸¬å®šã®é™ç•Œã¨ä»Šå¾Œã®æ–¹å‘æ€§

line_profiler ã«ã‚ˆã‚‹æ¸¬å®šã§åˆ¤æ˜ã—ãŸã“ã¨ã‚’æ•´ç†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹é€ ã«ãªã‚Šã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ 126.052 ms/batch ã¨ã„ã†å‡¦ç†æ™‚é–“ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¾¼ã¿ï¼‰ã¯æ¸¬å®šã§ãã¾ã—ãŸãŒã€ãã®å†…è¨³ã®å¤§éƒ¨åˆ†ï¼ˆ84.2%ï¼‰ã®è©³ç´°ãŒä¸æ˜ã¨ã„ã†çŠ¶æ³ã§ã™ã€‚

ã“ã®çŠ¶æ³ã‚’æ‰“é–‹ã™ã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å«ã¾ãªã„ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã¨ã€NxD Inference ã‚’ç›´æ¥ä½¿ã£ãŸæ¸¬å®šã‚’è©¦ã¿ã¾ã—ãŸã€‚
## Phase 3: NxD Inference ç›´æ¥æ¸¬å®šã¨åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

Worker ãƒ—ãƒ­ã‚»ã‚¹ã®ç›´æ¥æ¸¬å®šãŒå›°é›£ãªãŸã‚ã€**vLLM ã‚’ä½¿ã‚ãšã« NxD Inference ã‚’ç›´æ¥ä½¿ç”¨**ã—ã¦ç´”ç²‹ãªæ¨è«–å®Ÿè¡Œæ™‚é–“ã‚‚æ¸¬å®šã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€Bucketing ã¨ Prefix Caching ã®å…¨çµ„ã¿åˆã‚ã›ã‚’æ¸¬å®šã—ã¾ã—ãŸã€‚

:::message alert
**Phase 1-2 ã¨ã®æ¸¬å®šæ–¹æ³•ã®é•ã„ã«ã¤ã„ã¦:**

Phase 1-2 ã§ã¯ä¸»ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¤œè¨¼ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€å®šé‡çš„ãªæ€§èƒ½å€¤ã®æ¸¬å®šç²¾åº¦ã¯ Phase 3 ãŒæœ€ã‚‚é«˜ããªã£ã¦ã„ã¾ã™ã€‚

- **Phase 1**: Neuron Profiler ã«ã‚ˆã‚‹è©¦è¡ŒéŒ¯èª¤ï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ï¼‰
- **Phase 2**: line_profiler åˆ†æï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¾¼ã¿ã€126.052 ms/batchï¼‰
- **Phase 3**: ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è»½å¾®ã€çµ±ä¸€æ¡ä»¶ï¼‰

Phase 3 ã§ã¯å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ä»¥ä¸‹ã®æ¡ä»¶ã‚’çµ±ä¸€ã—ã¦ã„ã¾ã™ã€‚
- æ¸¬å®šã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 100 å›ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— 3 å›å¾Œï¼‰
- çµ±ä¸€ vLLM è¨­å®šï¼ˆmax_num_batched_tokens=256, num_gpu_blocks_override=512ï¼‰
- åŒä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒãƒƒãƒã‚µã‚¤ã‚º

Phase 1-2 ã®å®Ÿé¨“çµæœã¯ã€Œãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã®æœ‰ç”¨æ€§æ¤œè¨¼ã€ã¨ã—ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚**å®šé‡çš„ãªæ€§èƒ½æ¯”è¼ƒã«ã¯ Phase 3 ã®çµæœã‚’ä½¿ç”¨ã—ã¾ã™ã€‚**
:::

### 3.0 æ¸¬å®šçµæœã‚µãƒãƒªãƒ¼ï¼ˆå…¨ 16 ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

ä»¥ä¸‹ã®è¡¨ã¯ã€NxD Inference ã¨ vllm-neuron ã®ä¸¡æ–¹ã§ã€Bucketing ON/OFFã€Prefix Caching ON/OFFã€å›ºå®šé•·ï¼ˆ97 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰/ å¯å¤‰é•·ï¼ˆ18-125 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€ã®å…¨çµ„ã¿åˆã‚ã›ã§ã™ã€‚

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | vs No.1 | å‚™è€ƒ |
|----|---------|-----------|----------------|------------|-------------------|----------------|------|
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **49.14** | - | **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³** |
| 02 | NxD | ON | OFF | å›ºå®šé•· | **47.24** | -3.9% | ã‚ãšã‹ã«æ”¹å–„ |
| 03 | NxD | OFF | ON | å›ºå®šé•· | - | - | âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| 04 | NxD | ON | ON | å›ºå®šé•· | - | - | âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| 05 | NxD | OFF | OFF | å¯å¤‰é•· | **48.93** | -0.4% | ã»ã¼åŒç­‰ |
| 06 | NxD | ON | OFF | å¯å¤‰é•· | **48.89** | -0.5% | ã»ã¼åŒç­‰ |
| 07 | NxD | OFF | ON | å¯å¤‰é•· | - | - | âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| 08 | NxD | ON | ON | å¯å¤‰é•· | - | - | âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ |
| 09 | vLLM | OFF | OFF | å›ºå®šé•· | **252.42** | +413.8% | Bucketing OFF ã§å¤§å¹…æ‚ªåŒ– |
| 10 | vLLM | ON | OFF | å›ºå®šé•· | **59.23** | +20.5% | vLLM ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ |
| 11 | vLLM | OFF | ON | å›ºå®šé•· | **237.54** | +383.5% | Prefix Caching ã®æ©æµãªã— |
| 12 | vLLM | ON | ON | å›ºå®šé•· | **85.92** | +74.9% | Prefix Caching ã§æ‚ªåŒ– |
| 13 | vLLM | OFF | OFF | å¯å¤‰é•· | **252.10** | +413.1% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |
| 14 | vLLM | ON | OFF | å¯å¤‰é•· | **59.33** | +20.7% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |
| 15 | vLLM | OFF | ON | å¯å¤‰é•· | **238.08** | +384.6% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |
| 16 | vLLM | ON | ON | å¯å¤‰é•· | **86.12** | +75.3% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |

### 3.1 ãƒ‘ã‚¿ãƒ¼ãƒ³è¨ˆæ¸¬ã‹ã‚‰è¦³æ¸¬ã§ãã‚‹äº‹å®Ÿ

#### 3.1.1 NxD Inference vs vllm-neuron ã®æ€§èƒ½å·®

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | vs No.1 | å‚™è€ƒ |
|----|---------|-----------|----------------|------------|-------------------|----------------|------|
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **49.14** | - | **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³** |
| 02 | NxD | ON | OFF | å›ºå®šé•· | **47.24** | -3.9% | ã‚ãšã‹ã«æ”¹å–„ |
| 10 | vLLM | ON | OFF | å›ºå®šé•· | **59.23** | +20.5% | vLLM ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ |

**No.02 ã¨ No10 ã®æ¯”è¼ƒã‹ã‚‰ NxD Inference ãŒ vllm-neuron ã‚ˆã‚Šç´„ 20% é«˜é€Ÿ**ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚Main Process ã¨ Worker Process é–“ã® ZMQ é€šä¿¡ã€ãƒ‡ãƒ¼ã‚¿ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ãªã©ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒç´„ 12ms (20%) ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ ã¨ã—ã¦ç¾ã‚Œã¦ã„ã¾ã™ã€‚

#### 3.1.2 Bucketing ã®åŠ‡çš„ãªåŠ¹æœï¼ˆvllm-neuron ã®ã¿ï¼‰

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | vs No.1 | å‚™è€ƒ |
|----|---------|-----------|----------------|------------|-------------------|----------------|------|
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **49.14** | - | **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³** |
| 09 | vLLM | OFF | OFF | å›ºå®šé•· | **252.42** | +413.8% | Bucketing OFF ã§å¤§å¹…æ‚ªåŒ– |
| 10 | vLLM | ON | OFF | å›ºå®šé•· | **59.23** | +20.5% | vLLM ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ |
| 13 | vLLM | OFF | OFF | å¯å¤‰é•· | **252.10** | +413.1% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |
| 14 | vLLM | ON | OFF | å¯å¤‰é•· | **59.33** | +20.7% | å›ºå®šé•·ã¨ã»ã¼åŒã˜ |

vllm-neuron ã§ã¯ **No.09 ã¨ 10ã€No.13 ã¨ 14 ã®æ¯”è¼ƒã‹ã‚‰ Bucketing ON/OFF ã§ 4.3 å€ã®æ€§èƒ½å·®**ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚å›ºå®šé•·ã¨å¯å¤‰é•·ã®é•ã„ã«ã‚ˆã‚‰ãšã©ã¡ã‚‰ã‚‚åŒã˜ãã‚‰ã„ã®æ”¹å–„ç‡ã§ã™ã€‚

:::message alert
ãªãœã“ã‚Œã»ã©ã®å·®ãŒç™ºç”Ÿã™ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿã—ã‹ã‚‚ NxD Inference ã§ã¯ Bucketing ã®åŠ¹æœã¯è–„ã„ã“ã¨ãŒå®šé‡ãƒ»å®šæ€§çš„è¦–ç‚¹ã‹ã‚‰ã‚ã‹ã£ã¦ã„ã¾ã™ã€‚
:::

Bucketing OFF ã®å ´åˆã€97 ãƒˆãƒ¼ã‚¯ãƒ³ã®å…¥åŠ›ã«å¯¾ã—ã¦ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ç”¨ã® HLO ã‚°ãƒ©ãƒ•ãŒå®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€1951 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŒç™ºç”Ÿã—ã¾ã™ã€‚Bucketing ON ã§ã¯ 128 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆãŒé¸æŠã•ã‚Œã‚‹ãŸã‚ã€31 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ã¿ã§æ¸ˆã¿ã¾ã™ã€‚è©³ç´°ãªçµè«–ã«è‡³ã‚‹ã¾ã§ã®èª¿æŸ»ã¯ä»¥ä¸‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

::::details ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹æ€§èƒ½åŠ£åŒ–ã®èª¿æŸ»

ã“ã®çµè«–ã«è‡³ã‚‹ã¾ã§ã€vLLM ã®è©³ç´°ãƒ­ã‚°ã¨è¤‡æ•°ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ãŸæ®µéšçš„ãªèª¿æŸ»ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚

## èª¿æŸ»ã®å‹•æ©Ÿ

Phase 2 ã® line_profiler ã«ã‚ˆã‚‹åˆ†æã§ã€Worker ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã‚ã‚‹ã“ã¨ã¯åˆ¤æ˜ã—ã¦ã„ã¾ã—ãŸãŒã€ãã®å†…éƒ¨ã§**ãªãœ Bucketing OFF ãŒé…ã„ã®ã‹**ã¯ä¸æ˜ã§ã—ãŸã€‚Worker ãƒ—ãƒ­ã‚»ã‚¹å†…éƒ¨ã‚’ç›´æ¥ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã™ã‚‹ã“ã¨ãŒã§ããªã„ãŸã‚ã€vLLM ã®è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¦ HLO ç”Ÿæˆã¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ†æã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚

## å®Ÿé¨“è¨­å®š

vLLM ã®è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¦ Bucketing ON/OFF ã®ä¸¡æ–¹ã‚’æ¸¬å®šã—ã¾ã™ã€‚

```python
import logging
logging.basicConfig(level=logging.DEBUG)

vllm_config = {
    "disable_log_stats": False,  # çµ±è¨ˆæƒ…å ±ã‚’æœ‰åŠ¹åŒ–
    "additional_config": {
        "override_neuron_config": {
            "enable_bucketing": True  # or False
        }
    }
}
```

## HLO ç”Ÿæˆã®è¦³æ¸¬çµæœ

**Bucketing ON ã®å ´åˆ:**
```
Generating 5 hlos for key: context_encoding_model
- torch.Size([1, 128]) in 1.71s
- torch.Size([1, 256]) in 1.62s
- torch.Size([1, 512]) in 1.74s
- torch.Size([1, 1024]) in 1.97s
- torch.Size([1, 2048]) in 2.41s

Generating 5 hlos for key: token_generation_model
- 5 Ã— torch.Size([4, 1]) in ~1.8s each
```
â†’ åˆè¨ˆ **10 å€‹ã® HLO** ãŒç”Ÿæˆã•ã‚Œã€è¤‡æ•°ã®ãƒã‚±ãƒƒãƒˆã‚µã‚¤ã‚ºã«å¯¾å¿œ

**Bucketing OFF ã®å ´åˆ:**
```
Generating 1 hlos for key: context_encoding_model
- torch.Size([1, 2048]) in 2.56s

Generating 1 hlos for key: token_generation_model
- 1 Ã— torch.Size([4, 1]) in ~2.0s
```
â†’ åˆè¨ˆ **2 å€‹ã® HLO** ã®ã¿ç”Ÿæˆã•ã‚Œã€2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆã®ã¿ä½¿ç”¨

## æ ¹æœ¬åŸå› : å…¥åŠ›ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

vLLM ã®ãƒ­ã‚°ã‹ã‚‰ã€å®Ÿéš›ã®æ¨è«–æ™‚ã®ãƒã‚±ãƒƒãƒˆé¸æŠã‚’ç¢ºèªã—ã¾ã—ãŸã€‚

**Bucketing OFF ã®æŒ™å‹•:**
```python
# 97 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã™ã‚‹å ´åˆ
available_buckets = [2048]  # 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆã®ã¿

# æœ€å°ã®é©åˆãƒã‚±ãƒƒãƒˆ = 2048
selected_bucket = 2048
padded_input = pad(input_97_tokens, target_length=2048)
# â†’ 1951 ãƒˆãƒ¼ã‚¯ãƒ³ã®ç„¡é§„ãªãƒ‘ãƒ‡ã‚£ãƒ³ã‚° (95.3%)
# â†’ AWS NeuronCore ã¯ 2048 ãƒˆãƒ¼ã‚¯ãƒ³å…¨ã¦ã‚’è¨ˆç®—
```

**Bucketing ON ã®æŒ™å‹•:**
```python
# 97 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã™ã‚‹å ´åˆ
available_buckets = [128, 256, 512, 1024, 2048]

# æœ€å°ã®é©åˆãƒã‚±ãƒƒãƒˆ = 128
selected_bucket = 128
padded_input = pad(input_97_tokens, target_length=128)
# â†’ 31 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ã¿ (24.2%)
# â†’ AWS NeuronCore ã¯ 128 ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨ˆç®—
```

## è¨ˆç®—é‡ã®æ¯”è¼ƒ

| æŒ‡æ¨™ | Bucketing ON | Bucketing OFF | æ¯”ç‡ |
|------|--------------|---------------|------|
| **å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°** | 97 | 97 | - |
| **é¸æŠã•ã‚ŒãŸãƒã‚±ãƒƒãƒˆ** | 128 | 2048 | - |
| **ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡** | +31 (32%) | +1951 (2009%) | **63 å€** |
| **NeuronCore è¨ˆç®—é‡** | 128 ãƒˆãƒ¼ã‚¯ãƒ³ | 2048 ãƒˆãƒ¼ã‚¯ãƒ³ | **16 å€** |
| **å®Ÿæ¸¬æ¨è«–æ™‚é–“** | 59.23 ms | 252.42 ms | **4.26 å€** |

## ãªãœè¨ˆç®—é‡ã¯ 16 å€ãªã®ã«å®Ÿæ¸¬ã¯ 4.26 å€ãªã®ã‹ï¼Ÿ

ç†è«–çš„ã«ã¯ Attention æ¼”ç®—ã¯ O(nÂ²) ãªã®ã§ã€16 å€ã®è¨ˆç®—é‡å·®ã«ãªã‚‹ã¯ãšã§ã™ãŒã€å®Ÿæ¸¬ã§ã¯ 4.26 å€ã§ã—ãŸã€‚ã“ã‚Œã¯ä»¥ä¸‹ã®è¦å› ã«ã‚ˆã‚‹ã‚‚ã®ã¨æ€ã‚ã‚Œã¾ã™ã€‚

1. **ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ã®æ¼”ç®—**: Feed-Forward Networkã€Layer Normalization ãªã©ã¯ O(n) ã§ã‚¹ã‚±ãƒ¼ãƒ«
2. **ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã®åˆ¶ç´„**: AWS NeuronCore ã®å®Ÿè¡Œæ™‚é–“ã¯ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã«ã‚‚ä¾å­˜
3. **å›ºå®šã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã€å‡ºåŠ›ç”Ÿæˆãªã©ã®å›ºå®šã‚³ã‚¹ãƒˆ
4. **Python ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**: ç´„ 12 ms ã® vLLM ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯ Bucketing ã«ä¾å­˜ã—ãªã„

## Worker Process ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹æ¤œè¨¼

py-spy ã«ã‚ˆã‚‹è¿½åŠ æ¤œè¨¼ã§ã€Python å±¤ã¨ AWS NeuronCore å±¤ã‚’åˆ†é›¢ã—ã¾ã—ãŸã€‚

**Bucketing ON (59.23 ms):**
- Python å‡¦ç†: ç´„ 60 ms (ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ¼ã‚¿æº–å‚™)
- AWS NeuronCore å®Ÿè¡Œ: çŸ­æ™‚é–“

**Bucketing OFF (252.42 ms):**
- Python å‡¦ç†: ç´„ 60 ms (Bucketing ON ã¨åŒã˜)
- AWS NeuronCore å®Ÿè¡Œ: +194 ms å¢—åŠ  â† **ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**

ã¤ã¾ã‚Šã€**æ€§èƒ½å·®ã® 194 ms ã¯å…¨ã¦ AWS NeuronCore ã§ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°è¨ˆç®—æ™‚é–“**ã§ã‚ã‚Šã€Python ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯ Bucketing ON/OFF ã§å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚

## Attention æ¼”ç®—ã®è¨ˆç®—é‡åˆ†æ

Self-Attention ã®è¨ˆç®—é‡ã¯ O(nÂ²) ã§ã™:

**Bucketing ON (128 ãƒˆãƒ¼ã‚¯ãƒ³):**
```
è¨ˆç®—é‡ = 128Â² = 16,384 æ¼”ç®—
```

**Bucketing OFF (2048 ãƒˆãƒ¼ã‚¯ãƒ³):**
```
è¨ˆç®—é‡ = 2048Â² = 4,194,304 æ¼”ç®—
```

**ç†è«–çš„ãªæ¯”ç‡:**
```
4,194,304 / 16,384 = 256 å€
```

å®Ÿæ¸¬ãŒ 4.26 å€ã«ç•™ã¾ã‚‹ã®ã¯ã€Attention ä»¥å¤–ã®æ¼”ç®—ï¼ˆç·šå½¢å±¤ã€æ­£è¦åŒ–å±¤ãªã©ï¼‰ãŒ O(n) ã§ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã“ã‚Œä»¥ä¸Šã®æ·±æ˜ã‚Šã¯ HP ãŒæ¯æ¸‡ã—ãŸã®ã§æ–­å¿µã—ã¾ã—ãŸãŒå®Ÿéš›ã® Operation æ•°ã‚’ Neuron Profiler ã§ç¢ºèªã™ã‚Œã°ã‚·ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚¢ãƒ¬ã‚¤ã®åˆ©ç”¨åŠ¹ç‡ãªã©ã‹ã‚‰å®Ÿæ¸¬ãŒã“ã®ç¨‹åº¦ã«åã¾ã‚‹ã“ã¨ãŒã¿ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã§ã‚‚ç§ã«ã¯ã‚‚ã† HP ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã«ã‚ƒãƒ¼ã‚“ã€‚

## åˆæœŸåŒ–æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

èˆˆå‘³æ·±ã„ã“ã¨ã«ã€**åˆæœŸåŒ–æ™‚é–“ã¯ Bucketing OFF ã®æ–¹ãŒé«˜é€Ÿ**ã§ã—ãŸã€‚

| é …ç›® | Bucketing ON | Bucketing OFF | å·® |
|------|--------------|---------------|-----|
| **åˆæœŸåŒ–æ™‚é–“** | 385.5 ç§’ | 152.5 ç§’ | **-60%** |
| **HLO æ•°** | 10 å€‹ | 2 å€‹ | -80% |
| **ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“** | 249.1 ç§’ (9 HLO ä¸¦åˆ—) | 18.5 ç§’ (1 HLO) | -93% |
| **æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | 59.23 ms | 252.42 ms | **+326%** |

Bucketing OFF ã¯åˆæœŸåŒ–ãŒé«˜é€Ÿã§ã™ãŒã€æ¨è«–ãŒé…ã„ãŸã‚ã€**æœ¬ç•ªç’°å¢ƒã§ã¯ Bucketing ON ãŒå¿…é ˆ**ã§ã™ã€‚

## çµè«–

âœ… **Bucketing OFF ãŒ 4.26 å€é…ã„æ ¹æœ¬åŸå›  = å…¥åŠ›ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰**

97 ãƒˆãƒ¼ã‚¯ãƒ³ã®å…¥åŠ›ã‚’ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€1951 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®ç„¡é§„ãªè¨ˆç®—ãŒç™ºç”Ÿã—ã¾ã™ã€‚AWS NeuronCore ãŒ 2048 ãƒˆãƒ¼ã‚¯ãƒ³å…¨ã¦ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã€å¤§å¹…ãªæ€§èƒ½åŠ£åŒ–ãŒç™ºç”Ÿã—ã¾ã™ã€‚

vllm-neuron ã¯ Bucketing ON ãŒå‰æã®è¨­è¨ˆã¨æ€ã‚ã‚Œã‚‹ãŸã‚ã€åŸºæœ¬çš„ã«ã¯**å…¥åŠ›é•·ãŒå›ºå®šã§ã‚‚ Bucketing ON ã‚’ä½¿ç”¨ã™ã¹ã**ã§ã—ã‚‡ã†ã€‚
::::

:::message
**NxD Inference ã§ã¯ Bucketing ã®åŠ¹æœãŒã»ã¼è¦‹ã‚‰ã‚Œãªã„:**
- No.1 (Bucketing OFF): 49.14 ms/batch
- No.2 (Bucketing ON): 47.24 ms/batch
- **å·®**: ã‚ãšã‹ 3.9%
:::

ã“ã‚Œã¯ NxD Inference è‡ªä½“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå°ã•ãã€ç´”ç²‹ãªæ¨è«–å®Ÿè¡Œæ™‚é–“ãŒæ”¯é…çš„ã§ã‚ã‚‹ãŸã‚ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

#### 3.1.3 Prefix Caching ã®äºˆæƒ³å¤–ã®æ€§èƒ½åŠ£åŒ–

Prefix Caching ON ã«ã‚ˆã‚Š **45% ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ **ãŒè¦³æ¸¬ã•ã‚Œã¾ã—ãŸã€‚

**Bucketing ON ã§ã®æ¯”è¼ƒ:**
- Prefix Caching OFF (No.10): **59.23 ms**
- Prefix Caching ON (No.12): **85.92 ms**
- **æ‚ªåŒ–ç‡**: +45.0%

**Bucketing OFF ã§ã®æ¯”è¼ƒ:**
- Prefix Caching OFF (No.9): **252.42 ms**
- Prefix Caching ON (No.11): **237.54 ms**
- **æ”¹å–„ç‡**: -5.9%ï¼ˆã‚ãšã‹ã«æ”¹å–„ï¼‰

Prefix Caching ON ã§æ€§èƒ½ãŒæ‚ªåŒ–ã™ã‚‹ç†ç”±ã¯ã€ä»Šå›ã®æ¸¬å®šã§ã¯ **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãŒç™ºç”Ÿã—ãªã„**ãŸã‚ã§ã™ã€‚å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€Prefix ãŒä¸€è‡´ã—ãªã„ãŸã‚ã€KV ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®ã¿ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹çŠ¶æ³ã§ã™ã€‚

å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§å…±é€šã® System Prompt ã‚„ Few-shot Examples ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€Prefix Caching ã®æ©æµã‚’å—ã‘ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

#### 3.1.4 å›ºå®šé•· vs å¯å¤‰é•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å½±éŸ¿

**å›ºå®šé•·ã¨å¯å¤‰é•·ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã«ã»ã¼å·®ãŒãªã„**ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | Bucketing | Prefix | å›ºå®šé•· | å¯å¤‰é•· | å·® |
|---------|-----------|--------|--------|--------|-----|
| vLLM | ON | OFF | 59.23 ms | 59.33 ms | +0.2% |
| vLLM | ON | ON | 85.92 ms | 86.12 ms | +0.2% |
| vLLM | OFF | OFF | 252.42 ms | 252.10 ms | -0.1% |
| vLLM | OFF | ON | 237.54 ms | 238.08 ms | +0.2% |
| NxD | ON | OFF | 47.24 ms | 48.89 ms | +3.5% |
| NxD | OFF | OFF | 49.14 ms | 48.93 ms | -0.4% |

ã“ã‚Œã¯ Bucketing ON ã®å ´åˆã€å¯å¤‰é•·ã®å…¥åŠ›ï¼ˆ18-125 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚‚åŒã˜ãƒã‚±ãƒƒãƒˆï¼ˆ128 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã«åã¾ã‚‹ãŸã‚ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡ã®å·®ãŒå°ã•ã„ã“ã¨ãŒç†ç”±ã§ã™ã€‚Bucketing OFF ã®å ´åˆã¯å…¨ã¦ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆãŒä½¿ç”¨ã•ã‚Œã‚‹ãŸã‚ã€å…¥åŠ›é•·ã®é•ã„ã¯ã»ã¼ç„¡è¦–ã§ãã¾ã™ã€‚

### 3.2 æ¸¬å®šæ¡ä»¶ã®çµ±ä¸€

å…¨ 16 ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ä»¥ä¸‹ã®æ¡ä»¶ã‚’çµ±ä¸€ã—ã¾ã—ãŸã€‚

**å…±é€šè¨­å®š:**
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 4
- Tensor Parallelism (TP): 2
- max_model_len: 2048
- max_num_batched_tokens: 256 (vLLM)
- num_gpu_blocks_override: 512 (vLLM)
- pa_num_blocks: 512 (NxD)
- pa_block_size: 32
- dtype: bfloat16
- æ¸¬å®šã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 100å›ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—3å›å¾Œï¼‰

**å›ºå®šé•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰:**
- 97ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¹°ã‚Šè¿”ã—

**å¯å¤‰é•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰:**
- 18-125ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¯„å›²ã§ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ

#### 3.2.1 æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨çµæœãƒ•ã‚¡ã‚¤ãƒ«

ä»Šå›ã®æ¸¬å®šã«ä½¿ç”¨ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹æƒ…å ±ã§ã™ã€‚å†ç¾å®Ÿé¨“æ™‚ã«å¿…è¦ã«ãªã‚Šã¾ã™ã€‚

<details>
<summary>ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ</summary>

##### ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«

**å…ƒãƒ¢ãƒ‡ãƒ«:**
```
/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker/
```

**ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (vLLMç”¨):**
```
/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker/neuron-compiled-artifacts/
```
- vLLM No.9-16 ã§ä½¿ç”¨
- Bucketing ON/OFFã€Prefix Caching ON/OFF ã®å…¨çµ„ã¿åˆã‚ã›ã‚’å«ã‚€

**ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (NxDç”¨ - Bucketing OFF):**
```
/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker/nxd-compiled-bucketing-off/
```
- NxD No.1, No.5 ã§ä½¿ç”¨

**ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« (NxDç”¨ - Bucketing ON):**
```
/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker/nxd-compiled-bucketing-on/
```
- NxD No.2, No.6 ã§ä½¿ç”¨

##### vLLM æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**ãƒ™ãƒ¼ã‚¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:**
```
/home/coder/test2/my-reranker/benchmark_single_pattern_with_pyspy.py
```
- å˜ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸¬å®šç”¨
- py-spy PID ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›æ©Ÿèƒ½ä»˜ã
- å¼•æ•°ã§ Bucketing/Prefix Caching/ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç¨®åˆ¥ã‚’æŒ‡å®š

**è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:**
```
/home/coder/test2/my-reranker/run_all_patterns_with_pyspy.sh
```
- vLLM No.9-16 ã‚’ä¸€æ‹¬æ¸¬å®š
- å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ py-spy ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’è©¦è¡Œï¼ˆä»Šå›ã¯ py-spy æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®ãŸã‚çœç•¥ï¼‰
- æ¸¬å®šçµæœã‚’è‡ªå‹•çš„ã« JSON ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

**ä½¿ç”¨æ–¹æ³•:**
```bash
source /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin/activate
cd /home/coder/test2/my-reranker
bash run_all_patterns_with_pyspy.sh
```

##### NxD Inference ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**Bucketing OFF ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«:**
```
/home/coder/test2/my-reranker/compile_nxd_bucketing_off.py
```
```bash
source /opt/aws_neuronx_venv_pytorch_2_9_nxd_inference/bin/activate
python3 compile_nxd_bucketing_off.py > /tmp/compile_nxd_bucketing_off.log 2>&1
```

**Bucketing ON ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«:**
```
/home/coder/test2/my-reranker/compile_nxd_bucketing_on.py
```
```bash
source /opt/aws_neuronx_venv_pytorch_2_9_nxd_inference/bin/activate
python3 compile_nxd_bucketing_on.py > /tmp/compile_nxd_bucketing_on.log 2>&1
```

##### NxD Inference æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**No.1 (Bucketing OFF, å›ºå®šé•·):**
```
/home/coder/test2/my-reranker/test_nxd_no1.sh
```
```bash
source /opt/aws_neuronx_venv_pytorch_2_9_nxd_inference/bin/activate
bash test_nxd_no1.sh
```

**No.2 (Bucketing ON, å›ºå®šé•·):**
```
/home/coder/test2/my-reranker/test_nxd_no2.sh
```

**No.5 (Bucketing OFF, å¯å¤‰é•·):**
```
/home/coder/test2/my-reranker/test_nxd_no5.sh
```

**No.6 (Bucketing ON, å¯å¤‰é•·):**
```
/home/coder/test2/my-reranker/test_nxd_no6.sh
```

##### æ¸¬å®šçµæœãƒ•ã‚¡ã‚¤ãƒ«

**vLLM çµæœ (No.9-16):**
```
/home/coder/test2/my-reranker/benchmark_results_20260206_013113/
â”œâ”€â”€ result_no9.json   # Bucketing OFF, Prefix OFF, å›ºå®šé•· (252.42 ms)
â”œâ”€â”€ result_no10.json  # Bucketing ON,  Prefix OFF, å›ºå®šé•· (59.23 ms)
â”œâ”€â”€ result_no11.json  # Bucketing OFF, Prefix ON,  å›ºå®šé•· (237.54 ms)
â”œâ”€â”€ result_no12.json  # Bucketing ON,  Prefix ON,  å›ºå®šé•· (85.92 ms)
â”œâ”€â”€ result_no13.json  # Bucketing OFF, Prefix OFF, å¯å¤‰é•· (252.10 ms)
â”œâ”€â”€ result_no14.json  # Bucketing ON,  Prefix OFF, å¯å¤‰é•· (59.33 ms)
â”œâ”€â”€ result_no15.json  # Bucketing OFF, Prefix ON,  å¯å¤‰é•· (238.08 ms)
â””â”€â”€ result_no16.json  # Bucketing ON,  Prefix ON,  å¯å¤‰é•· (86.12 ms)
```

**NxD çµæœ (No.1, 2, 5, 6):**
```
/tmp/benchmark_nxd_no1.json  # Bucketing OFF, å›ºå®šé•· (49.14 ms/batch)
/tmp/benchmark_nxd_no2.json  # Bucketing ON,  å›ºå®šé•· (47.24 ms/batch)
/tmp/benchmark_nxd_no5.json  # Bucketing OFF, å¯å¤‰é•· (48.93 ms/batch)
/tmp/benchmark_nxd_no6.json  # Bucketing ON,  å¯å¤‰é•· (48.89 ms/batch)
```

**NxD ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ­ã‚°:**
```
/tmp/compile_nxd_bucketing_off.log  # Bucketing OFF ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ­ã‚°
/tmp/compile_nxd_bucketing_on.log   # Bucketing ON ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ­ã‚°
```

##### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

**æ¸¬å®šæ‰‹é †æ›¸:**
```
/home/coder/test2/my-reranker/BENCHMARK_ALL_PATTERNS_README.md
```
- å…¨ 16 ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¸¬å®šæ‰‹é †
- ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½¿ã„æ–¹
- æ³¨æ„äº‹é …

**æ¸¬å®šçµæœã¾ã¨ã‚ (ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«):**
```
/home/coder/vllm-neuron-profiling-blog2.md
```

</details>

#### 3.2.2 çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼

**vLLM çµæœ JSON å½¢å¼:**
```json
{
  "pattern_no": 10,
  "bucketing": "ON",
  "prefix_caching": "OFF",
  "workload": "fixed",
  "iterations": 100,
  "results": {
    "average_ms": 59.23,
    "min_ms": 58.71,
    "max_ms": 60.5,
    "total_seconds": 5.92,
    "all_times": [59.09, 59.15, ...]
  }
}
```

**NxD çµæœ JSON å½¢å¼:**
```json
{
  "e2e_model": {
    "latency_ms_avg": 8609.612798690796,
    "throughput": 951.4945900059176
  },
  "context_encoding_model": {
    "latency_ms_avg": 188.973867893219,
    "throughput": 43349.90912409618
  },
  "token_generation_model": {
    "latency_ms_avg": 7.663827336312273,
    "throughput": 522.4426246472332
  }
}
```

**NxD ã®è¨ˆç®—æ–¹æ³•:**

NxD Inference ã® `--benchmark` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã€ãƒãƒƒãƒã‚µã‚¤ã‚º 4 ã§è¤‡æ•°ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã—ãŸå¹³å‡å€¤ã‚’è¿”ã—ã¾ã™ã€‚

```
latency_per_batch = context_encoding_model.latency_ms_avg / batch_size
```

ä¾‹: No.2 (Bucketing ON, å›ºå®šé•·) ã®å ´åˆ
```json
{
  "context_encoding_model": {
    "latency_ms_avg": 188.973867893219  // 4ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†ã®åˆè¨ˆæ™‚é–“
  }
}
```
```
188.97 ms / 4 sequences = 47.24 ms/batch
```

:::message
**Phase 1-2 ã® NxD æ¸¬å®šå€¤ã¨ã®æ¯”è¼ƒ:**

å…ƒã®ãƒ–ãƒ­ã‚° (Phase 3) ã§ã¯ NxD Inference ã§ä»¥ä¸‹ã®å€¤ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã—ãŸ:
- No.1 (Bucketing OFF): 11.97 ms
- No.2 (Bucketing ON): 12.02 ms

ä»Šå›ã® Phase 3 æ¸¬å®šã§ã¯:
- No.1 (Bucketing OFF): 49.14 ms/batch
- No.2 (Bucketing ON): 47.24 ms/batch

ç´„ 4 å€ã®å·®ãŒã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã¯**æ¸¬å®šæ–¹æ³•ã®é•ã„**ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™:

1. **å…ƒã®ãƒ–ãƒ­ã‚°**: `context_encoding_model.latency_ms_avg` ã‚’ç›´æ¥å ±å‘Šï¼ˆå˜ä¸€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç›¸å½“ã®å‡¦ç†æ™‚é–“ï¼‰
2. **ä»Šå›ã®æ¸¬å®š**: åŒã˜å€¤ã‚’ãƒãƒƒãƒã‚µã‚¤ã‚º 4 ã§å‰²ã£ãŸå€¤ã‚’å ±å‘Šï¼ˆ1ãƒãƒƒãƒã‚ãŸã‚Šã®æ™‚é–“ï¼‰

vLLM ã¨ã®æ¯”è¼ƒã«ãŠã„ã¦ã€ä»Šå›ã®æ¸¬å®šæ–¹æ³•ï¼ˆãƒãƒƒãƒã‚ãŸã‚Šã®æ™‚é–“ï¼‰ã®æ–¹ãŒå®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«è¿‘ã„æŒ‡æ¨™ã¨ãªã‚Šã¾ã™ã€‚å…ƒã®ãƒ–ãƒ­ã‚°ã® Phase 3 ã® NxD å€¤ã¯ã€Œå‚è€ƒå€¤ã€ã¨ã—ã¦æ‰±ã„ã€å®šé‡çš„ãªæ¯”è¼ƒã«ã¯ä»Šå›ã® Phase 3 ã®å€¤ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

**æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯:**
- ä»Šå›ã® No.2 ã®ç”Ÿãƒ‡ãƒ¼ã‚¿: 188.97 ms
- å…ƒã®ãƒ–ãƒ­ã‚°ã® No.2: 12.02 ms
- æ¯”ç‡: 188.97 / 12.02 = 15.72x â‰ˆ 16x

ã“ã®å·®ã¯æ¸¬å®šæ¡ä»¶ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã€ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ï¼‰ã¨ãƒ¬ãƒãƒ¼ãƒˆæ–¹æ³•ã®é•ã„ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚
:::

### 3.3 æŠ€è¡“çš„ãªæ·±æ˜ã‚Š

#### 3.3.1 ãªãœ vLLM ã§ Bucketing OFF ãŒã“ã‚Œã»ã©é…ã„ã®ã‹

vLLM-Neuron ã§ã¯ Bucketing OFF (No.9) ãŒ Bucketing ON (No.10) ã«æ¯”ã¹ã¦ **4.26 å€é…ã„**ã¨ã„ã†æ¥µç«¯ãªçµæœãŒå‡ºã¾ã—ãŸã€‚ã“ã‚Œã¯ä»¥ä¸‹ã®è¦å› ãŒé‡ãªã£ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚

**1. ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®è¨ˆç®—ã‚³ã‚¹ãƒˆ**

97 ãƒˆãƒ¼ã‚¯ãƒ³ã®å…¥åŠ›ã«å¯¾ã—ã¦:
- Bucketing OFF: 2048 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®è¨ˆç®— â†’ **1951 ãƒˆãƒ¼ã‚¯ãƒ³ (95.3%) ãŒç„¡é§„ãªãƒ‘ãƒ‡ã‚£ãƒ³ã‚°**
- Bucketing ON: 128 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®è¨ˆç®— â†’ **31 ãƒˆãƒ¼ã‚¯ãƒ³ (24.2%) ãŒãƒ‘ãƒ‡ã‚£ãƒ³ã‚°**

**2. Attention æ¼”ç®—ã®è¨ˆç®—é‡**

Self-Attention ã®è¨ˆç®—é‡ã¯ O(nÂ²) ã§ã‚ã‚Šã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«å¯¾ã—ã¦äºŒæ¬¡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¾ã™ã€‚

- 2048 ãƒˆãƒ¼ã‚¯ãƒ³: 2048Â² = 4,194,304 æ¼”ç®—
- 128 ãƒˆãƒ¼ã‚¯ãƒ³: 128Â² = 16,384 æ¼”ç®—
- **è¨ˆç®—é‡æ¯”**: 256 å€

å®Ÿéš›ã®æ€§èƒ½å·®ãŒ 4.26 å€ã«ç•™ã¾ã£ã¦ã„ã‚‹ã®ã¯ã€ä»–ã®æ¼”ç®—ï¼ˆFFNã€Layer Norm ãªã©ï¼‰ãŒç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ã§ã‚ã‚‹ã“ã¨ã¨ã€ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã®åˆ¶ç´„ãŒã‚ã‚‹ãŸã‚ã§ã™ã€‚

**3. NxD Inference ã§ã“ã®å·®ãŒå°ã•ã„ç†ç”±**

NxD Inference (No.1 vs No.2) ã§ã¯ Bucketing ON/OFF ã®å·®ãŒã‚ãšã‹ 3.9% ã§ã—ãŸã€‚ã“ã‚Œã¯ä»¥ä¸‹ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

- **æœ€é©åŒ–ã•ã‚ŒãŸã‚«ãƒ¼ãƒãƒ«**: NxD Inference ã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æœ€é©åŒ–ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§
- **ãƒãƒƒãƒå‡¦ç†ã®åŠ¹ç‡**: vLLM ã® ZMQ é€šä¿¡ã‚„ Main Process ã§ã®ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ãŒ Bucketing OFF ã§éåŠ¹ç‡ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§
- **æ¸¬å®šæ–¹æ³•ã®é•ã„**: NxD ã¯ context_encoding_model ã®æ™‚é–“ã®ã¿ã€vLLM ã¯ E2E æ™‚é–“ã‚’æ¸¬å®š

#### 3.3.2 Prefix Caching ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰åˆ†æ

Prefix Caching ON (No.12) ãŒ OFF (No.10) ã«æ¯”ã¹ã¦ **45% é…ã„**ã¨ã„ã†çµæœã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãŒç™ºç”Ÿã—ãªã„å ´åˆã®ç´”ç²‹ãªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

**ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å†…è¨³ï¼ˆæ¨å®šï¼‰:**

1. **KV ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†**: å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ Prefix ãƒãƒƒãƒãƒ³ã‚°ã‚’è©¦è¡Œ
2. **ãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®è¿½åŠ ãƒ¡ãƒ¢ãƒªé ˜åŸŸã®ç¢ºä¿
3. **ãƒãƒƒã‚·ãƒ¥è¨ˆç®—**: Prefix ã®ä¸€è‡´åˆ¤å®šã®ãŸã‚ã®ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
4. **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®ç®¡ç†ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

**å®Ÿãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ã®åŠ¹æœ:**

ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§ã¯ Prefix Caching ãŒæœ‰åŠ¹ã§ã™ã€‚

- **System Prompt ãŒå…±é€š**: 1000 ãƒˆãƒ¼ã‚¯ãƒ³ã® System Prompt ã‚’å…±æœ‰ã™ã‚‹å ´åˆã€2å›ç›®ä»¥é™ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ 1000 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—
- **Few-shot Examples**: æ•°ç™¾ãƒˆãƒ¼ã‚¯ãƒ³ã® Few-shot Examples ã‚’å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä½¿ç”¨ã™ã‚‹å ´åˆ
- **RAG (Retrieval-Augmented Generation)**: å…±é€šã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¤‡æ•°ã®è³ªå•ã§å†åˆ©ç”¨

ä»Šå›ã®æ¸¬å®šã§ã¯å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå®Œå…¨ã«ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸãŸã‚ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®ã¿ãŒè¦³æ¸¬ã•ã‚Œã¾ã—ãŸã€‚

#### 3.3.3 ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®åŸå› 

No.3, 4, 7, 8 (Prefix Caching ON ã‚’ä½¿ç”¨ã™ã‚‹ NxD ãƒ‘ã‚¿ãƒ¼ãƒ³) ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

**ã‚¨ãƒ©ãƒ¼å†…å®¹:**
```
neuronx-cc failed with exit status 70
```

**æ ¹æœ¬åŸå› :**

AWS Neuron SDK 2.27.0 ã«å«ã¾ã‚Œã‚‹ neuronx-cc ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã®æ—¢çŸ¥ã®ãƒã‚°ã§ã™ã€‚`enable_prefix_caching=True` ã‚’æŒ‡å®šã™ã‚‹ã¨ã€HLO ã‚°ãƒ©ãƒ•ã®æœ€é©åŒ–æ®µéšã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚

vLLM-Neuron ã§ã¯æ—¢ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã® NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ãŸãŸã‚ã€ã“ã®å•é¡Œã‚’å›é¿ã§ãã¾ã—ãŸã€‚NxD Inference ã§ã¯å®Ÿè¡Œæ™‚ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’è©¦ã¿ãŸãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

**å›é¿ç­–:**

- Neuron SDK 2.28.0 ä»¥é™ã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆã¾ã ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ï¼‰
- Prefix Caching OFF ã§é‹ç”¨
- vLLM-Neuron ã‚’ä½¿ç”¨ï¼ˆæ—¢ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ï¼‰

### 3.4 ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã¸ã®æ¨å¥¨äº‹é …

#### 3.4.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å„ªå…ˆã®å ´åˆ

**æ¨å¥¨æ§‹æˆ: NxD Inference + Bucketing ON**

- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: **47.24 ms/batch** (æœ€é€Ÿ)
- vLLM-Neuron (Bucketing ON) ã«æ¯”ã¹ã¦ **20% é«˜é€Ÿ**
- å®Ÿè£…ã®è¤‡é›‘ã•: ä¸­ï¼ˆvLLM ã®ã‚ˆã†ãªé«˜ãƒ¬ãƒ™ãƒ« API ãŒãªã„ï¼‰

**é©ç”¨ã‚±ãƒ¼ã‚¹:**
- é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒ
- æ—¢å­˜ã®æ¨è«–ã‚µãƒ¼ãƒ“ã‚¹ã‚’é«˜é€ŸåŒ–ã—ãŸã„å ´åˆ
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹å ´åˆ

#### 3.4.2 é–‹ç™ºé€Ÿåº¦ãƒ»é‹ç”¨æ€§å„ªå…ˆã®å ´åˆ

**æ¨å¥¨æ§‹æˆ: vLLM-Neuron + Bucketing ON + Prefix Caching OFF**

- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: **59.23 ms/batch** (è¨±å®¹ç¯„å›²)
- NxD ã«æ¯”ã¹ã¦ 20% é…ã„ãŒã€é–‹ç™ºåŠ¹ç‡ãŒé«˜ã„
- OpenAI äº’æ› APIã€éåŒæœŸå‡¦ç†ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
- å®Ÿè£…ã®è¤‡é›‘ã•: ä½ï¼ˆé«˜ãƒ¬ãƒ™ãƒ« APIï¼‰

**é©ç”¨ã‚±ãƒ¼ã‚¹:**
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™ºã‚„ MVP æ§‹ç¯‰
- OpenAI API ã¨ã®äº’æ›æ€§ãŒå¿…è¦ãªå ´åˆ
- é‹ç”¨ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„å ´åˆ

#### 3.4.3 Prefix Caching ã‚’æœ‰åŠ¹ã«ã™ã¹ãã‚±ãƒ¼ã‚¹

ä»¥ä¸‹ã®æ¡ä»¶ã‚’**ä¸¡æ–¹ã¨ã‚‚**æº€ãŸã™å ´åˆã®ã¿ã€Prefix Caching ON ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

**æ¡ä»¶ 1: å…±é€š Prefix ãŒå­˜åœ¨**
- System Prompt ã®é•·ã•ãŒ 200 ãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Š
- Few-shot Examples ãŒ 300 ãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Š
- RAG ã§å…±é€šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨

**æ¡ä»¶ 2: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„**
- åŒã˜ Prefix ã‚’æŒã¤ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒ 3 å›ä»¥ä¸Šç™ºç”Ÿ
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ > 50% ãŒè¦‹è¾¼ã‚ã‚‹

**è¨ˆç®—ä¾‹:**

1000 ãƒˆãƒ¼ã‚¯ãƒ³ã® System Prompt ã‚’ä½¿ç”¨ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ 80% ã®å ´åˆ:

- åˆå›ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: 85.92 ms (Prefix Caching ON ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¾¼ã¿)
- 2å›ç›®ä»¥é™ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ): æ¨å®š 35-40 ms (1000 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®è¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—)
- å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 0.2 Ã— 85.92 + 0.8 Ã— 37.5 = **47.18 ms**

ã“ã®å ´åˆã€Bucketing ON + Prefix Caching OFF (59.23 ms) ã‚ˆã‚Šé«˜é€Ÿã«ãªã‚Šã¾ã™ã€‚

#### 3.4.4 Bucketing ã¯å¿…é ˆ

**Bucketing OFF ã¯æœ¬ç•ªç’°å¢ƒã§ä½¿ç”¨ã™ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚**

- Bucketing OFF ã¯ Bucketing ON ã«æ¯”ã¹ã¦ **4.26 å€é…ã„**
- ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚Šç„¡é§„ãªè¨ˆç®—ãŒç™ºç”Ÿ
- ã‚³ã‚¹ãƒˆï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è²»ç”¨ï¼‰ãŒ 4 å€ä»¥ä¸Šã«ãªã‚‹å¯èƒ½æ€§

**Bucketing ON ã®ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ã»ã¼ã‚¼ãƒ­:**
- é–‹ç™ºæ™‚ã®è¿½åŠ å®Ÿè£…ã‚³ã‚¹ãƒˆãªã—
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¸ã®æ‚ªå½±éŸ¿ãªã—ï¼ˆã‚€ã—ã‚é«˜é€ŸåŒ–ï¼‰
- ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“ãŒã‚ãšã‹ã«å¢—åŠ ã™ã‚‹ã®ã¿ï¼ˆè¨±å®¹ç¯„å›²ï¼‰

### 3.5 ã¾ã¨ã‚

#### 3.5.1 å®šé‡çš„ãªçµæœ

| é …ç›® | çµæœ | å‚™è€ƒ |
|------|------|------|
| **æœ€é€Ÿæ§‹æˆ** | NxD Inference + Bucketing ON | 47.24 ms/batch |
| **vLLM ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰** | +20.5% | ZMQ é€šä¿¡ã€ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† |
| **Bucketing ã®åŠ¹æœ** | 4.26 å€é«˜é€ŸåŒ– | vLLM-Neuron ã®ã¿ã€‚NxD ã§ã¯ 3.9% |
| **Prefix Caching ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰** | +45.0% | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãªã—ã®å ´åˆ |
| **å›ºå®šé•· vs å¯å¤‰é•·** | Â±0.2% | ã»ã¼å·®ãªã— |

#### 3.5.2 ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨è¨­å®š

**é«˜æ€§èƒ½é‡è¦–:**
```python
# NxD Inference
neuron_config = NeuronConfig(
    enable_bucketing=True,      # å¿…é ˆ
    enable_prefix_caching=False, # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡æ¬¡ç¬¬
    batch_size=4,
    tp_degree=2,
)
```

**é–‹ç™ºé€Ÿåº¦é‡è¦–:**
```python
# vLLM-Neuron
engine_config = VLLMEngineConfig(
    enable_chunked_prefill=True,  # Bucketing ON
    enable_prefix_caching=False,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡æ¬¡ç¬¬
    max_num_batched_tokens=256,
    num_gpu_blocks_override=512,
)
```

#### 3.5.3 ä»Šå¾Œã®èª²é¡Œ

**1. py-spy ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®å®Œå…¨å®Ÿæ–½**

ä»Šå›ã®æ¸¬å®šã§ã¯ py-spy ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šã€Worker ãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚FlameGraph ã«ã‚ˆã‚‹å¯è¦–åŒ–ãŒã§ãã‚Œã°ã€vLLM ã® 20% ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å†…è¨³ã‚’ç‰¹å®šã§ãã¾ã™ã€‚

**2. Prefix Caching ã®å®Ÿãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¸¬å®š**

å…±é€š System Prompt ã‚’ä½¿ç”¨ã—ãŸæ¸¬å®šã«ã‚ˆã‚Šã€Prefix Caching ã®å®Ÿéš›ã®åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

**3. ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã®æ¤œè¨¼**

ä»Šå›ã¯ Qwen3-0.6B (å°å‹) ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚Llama-3-70B ã‚„ Llama-3-405B ãªã©ã®å¤§å‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Bucketing ã‚„ Prefix Caching ã®åŠ¹æœãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

**4. Neuron SDK ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰å¾Œã®å†æ¸¬å®š**

Prefix Caching ON ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ãŒè§£æ¶ˆã•ã‚Œã‚‹ Neuron SDK 2.28.0 ä»¥é™ã§ã€NxD Inference + Prefix Caching ON ã®æ¸¬å®šã‚’å®Ÿæ–½ã™ã¹ãã§ã™ã€‚

**5. Phase 1-2 ã¨ã®æ•´åˆæ€§ã«ã¤ã„ã¦**

Phase 1-2 ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¤œè¨¼ãŒä¸»ç›®çš„ã§ã‚ã‚Šã€å®šé‡çš„ãªæ€§èƒ½æ¸¬å®šã¯ Phase 3 ã§çµ±ä¸€æ¡ä»¶ã®ã‚‚ã¨å®Ÿæ–½ã—ã¦ã„ã¾ã™ã€‚Phase 1-2 ã®å®Ÿé¨“çµæœã¯ã€Œã©ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ãŒæœ‰åŠ¹ã‹ã€ã‚’åˆ¤æ–­ã™ã‚‹ææ–™ã¨ã—ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

**æ¸¬å®šæ—¥**: 2026å¹´2æœˆ6æ—¥
**ç’°å¢ƒ**: AWS Inf2.xlarge (Inferentia2 ãƒãƒƒãƒ— Ã— 1)
**Neuron SDK**: 2.27.0
**vLLM-Neuron**: 0.13.0
**NxD Inference**: neuronx-distributed-inference 0.7.0

**Phase 3 æ¸¬å®šæ¡ä»¶ (çµ±ä¸€è¨­å®š):**
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 4
- Tensor Parallelism: 2
- max_model_len: 2048
- max_num_batched_tokens: 256 (vLLM)
- num_gpu_blocks_override: 512 (vLLM)
- pa_num_blocks: 512 (NxD)
- pa_block_size: 32
- æ¸¬å®šã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 100å› (ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— 3å›å¾Œ)
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: å›ºå®šé•· 97ãƒˆãƒ¼ã‚¯ãƒ³ / å¯å¤‰é•· 18-125ãƒˆãƒ¼ã‚¯ãƒ³
