---
title: "vllm-neuron „Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÅßÂæó„ÅüÁü•Ë¶ã"
emoji: "üîç"
type: "tech"
topics: ["vllm", "AWSNeuron", "Profiler", "Python", "ÊÄßËÉΩÊúÄÈÅ©Âåñ"]
published: false
---

## „ÅØ„Åò„ÇÅ„Å´

[ÂâçÂõû„ÅÆË®ò‰∫ã](https://zenn.dev/tosshi/articles/d68bd091d1934d) „Åß„ÅØ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÉÑ„Éº„É´„ÅÆÈñãÁô∫„Å´„Åª„ÅºË∂£Âë≥„ÅßÈõÜ‰∏≠„Åó„Å¶„Åó„Åæ„Åó„Åü„Åå„ÄÅ‰ªäÂõû„ÅØÔºàÁúüÈù¢ÁõÆ„Å´Ôºâ AWS Inferentia2 ‰∏ä„Åß vllm-neuron „Çí‰ΩøÁî®„Åó„Åü„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÂàÜÊûê„Å´„ÉÅ„É£„É¨„É≥„Ç∏„Åó„Åæ„Åô„ÄÇ

:::message
**Ë®ò‰∫ã„ÅÆÁõÆÁöÑ„ÇíÊòéÁ¢∫„Å´„Åô„Çã**: 1. vllm-neuron „ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Çí„ÇÑ„Å£„Å¶„Åø„Å¶Áü•Ë¶ã„ÇíÂæó„Çã„ÄÇ2. ÂâçÂõû„ÅÆÊ∏¨ÂÆöÁµêÊûú„Åß vllm-neuron „Åß„ÅØ Bucketing ON „ÅÆÊôÇ„Å´ Prefix Caching „Çí ON „Å´„Åô„Çã„Å®„É¨„Ç§„ÉÜ„É≥„Ç∑„ÅåÊÇ™Âåñ„Åó„Åæ„Åó„Åü„ÄÇ„Åù„ÅÆÂéüÂõ†„ÇíÁü•„Çä„Åü„ÅÑ„Åß„Åô„ÄÇ
:::

https://zenn.dev/tosshi/articles/ef61e14fe73399

Êú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅ‰∏äË®ò„ÅÆË®ò‰∫ã„ÅßÂæó„Çâ„Çå„Åü Bucketing „Å® Prefix caching „ÅÆË®≠ÂÆö„Å´„Çà„ÇãÂπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑„ÅÆÁµêÊûú„Å´„Å§„ÅÑ„Å¶„Å™„Åú„Åù„ÅÜ„Å™„Çã„ÅÆ„Åã„ÇíËÄÉÂØü„Åô„Çã„Åì„Å®„Åå‰∏ª„Å™ÁõÆÁöÑ„Åß„Åô„ÄÇ

:::message
**‰ªäÂõû„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÅÆÈÄ≤„ÇÅÊñπ„ÅØÁµêÊûúÁöÑ„Å´„Åã„Å™„ÇäÈñìÈÅï„Å£„Å¶„ÅÑ„Åæ„Åó„ÅüÔºÅ** Ëâ≤„ÄÖË©¶Ë°åÈåØË™§„Åó„Åü„Çì„Å†„Å™„ÄÅ„Å®ÊÄù„ÅÑ„Å™„Åå„ÇâÊú¨Ë®ò‰∫ã„ÇíË™≠„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇÁ¥çË±Ü„ÅÆ 10ÂÄç„Åè„Çâ„ÅÑÁ≤ò„Å£„Å¶Ê∏¨ÂÆöÁµêÊûú„Å´ÂØæ„Åô„ÇãÈÅïÂíåÊÑü„ÇíÊç®„Å¶„Åö„Å´„ÅÑ„Åè„Å§„Åã„ÅÆÂïèÈ°å„ÅÆËß£Êòé„Å´Ëá≥„Å£„ÅüÁÇπ„ÅØËâØ„Åã„Å£„Åü„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ**„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÅØÁ≤ò„Çä**„Å†„Å®„ÅÑ„ÅÜ„Åì„Å®„ÇíÂ≠¶„Å≥„Åæ„Åó„Åü„ÄÇ
:::

:::message alert
Êú¨Ë®ò‰∫ã„ÅØÂ§öÂàÜ‰∏äÁ¥öËÄÖÂêë„Åë„ÅÆ„Åü„ÇÅ LLM Êé®Ë´ñ„ÅÆÁü•Ë≠ò„ÄÅvLLM „ÅÆÁü•Ë≠ò„ÄÅAWS Neuron „ÅÆÁü•Ë≠ò„Åå„ÅÇ„Çã„Åì„Å®„ÅåÂâçÊèê„Åß„Åô„ÄÇ
:::

## Phase 1: AWS Neuron Profiler „Åß„ÅÆË©¶Ë°åÈåØË™§

### 1.1 „Å™„Åú„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Åã„ÇâÂßã„ÇÅ„Çã„ÅÆ„Åã

ÊÄßËÉΩÊúÄÈÅ©Âåñ„ÇíË°å„ÅÜÈöõ„ÄÅ„Åæ„ÅöÁèæÁä∂„ÇíÊääÊè°„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Åß„Åô„ÄÇ„Éô„É≥„ÉÅ„Éû„Éº„ÇØÊ∏¨ÂÆö„Åß„ÅØÊÄßËÉΩ„ÅÆÁµêÊûú„ÅØÂàÜ„Åã„Çä„Åæ„Åô„Åå„ÄÅÊÄßËÉΩ„ÅÆÁêÜÁî±„ÄÅ„Éú„Éà„É´„Éç„ÉÉ„ÇØ„ÅÆÂ†¥ÊâÄ„ÄÅ„Åù„Åó„Å¶ÊîπÂñÑ„ÅÆ‰ΩôÂú∞„ÅØÂàÜ„Åã„Çä„Åæ„Åõ„Çì„ÄÇ

‰ª•‰∏ã„Å´ÂÆüÈ®ìÁí∞Â¢É„Å®Ë®≠ÂÆöÊÉÖÂ†±„Çí„Åæ„Å®„ÇÅ„Å¶„Åä„Åç„Åæ„Åô„ÄÇ‰ª•Ââç„ÅÆ Zenn Ë®ò‰∫ã„ÅÆÂπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑„ÉºÊúÄÈÅ©ÂÄ§„Åã„Çâ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÇíÈñãÂßã„Åó„Åæ„Åô„ÄÇ

::::details ÂÆüÈ®ìÁí∞Â¢É„Å®Ë®≠ÂÆöÊÉÖÂ†±

Êú¨Ë™øÊüª„Åß‰ΩøÁî®„Åó„ÅüÂÆüÈ®ìÁí∞Â¢É„Å®Ë®≠ÂÆö„ÅÆË©≥Á¥∞„ÇíË®òËºâ„Åó„Åæ„Åô„ÄÇ

**„Éè„Éº„Éâ„Ç¶„Çß„Ç¢Áí∞Â¢É**:
- „Ç§„É≥„Çπ„Çø„É≥„Çπ„Çø„Ç§„Éó: `inf2.xlarge`

**„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢„Éê„Éº„Ç∏„Éß„É≥**:
- Neuron SDK: 2.27.x
- vLLM: 0.13.0ÔºàNeuron ÂØæÂøúÁâàÔºâ
- neuronx-distributed-inference (NxD Inference): 0.7.0
- Python: 3.12

**„É¢„Éá„É´„Å®„Éá„Éº„Çø**:
- „É¢„Éá„É´: Qwen3-0.6B-Reranker
- „Éó„É≠„É≥„Éó„ÉàÈï∑:
  - Phase 1-3 ÂàùÊúüÊ∏¨ÂÆö: 97 „Éà„Éº„ÇØ„É≥ÔºàÂõ∫ÂÆöÈï∑Ôºâ
  - ËøΩÂä†Ë™øÊüª: 18-125 „Éà„Éº„ÇØ„É≥ÔºàÂèØÂ§âÈï∑„ÄÅ16 „Éó„É≠„É≥„Éó„ÉàÔºâ
- „Çø„Çπ„ÇØ: RerankerÔºàÊñáÊõ∏„É©„É≥„Ç≠„É≥„Ç∞Ôºâ
- „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: 4

**vLLM Ë®≠ÂÆöÔºàÈÅéÂéª„ÅÆ Zenn Ë®ò‰∫ã„ÅÆÂÆüÈ®ì„Åß„ÅÆÊúÄÈÅ©ÂÄ§Ôºâ**:
```yaml
vllm:
  tensor_parallel_size: 2           # 2 NeuronCore ‰ΩøÁî®
  max_num_seqs: 4                   # ÂêåÊôÇÂá¶ÁêÜÊï∞
  block_size: 32                    # KV cache block size
  max_model_len: 2048
  max_num_batched_tokens: 256
  num_gpu_blocks_override: 512
  enable_prefix_caching: false      # Phase 1-5 „Åß„ÅØÁÑ°Âäπ
  dtype: "bfloat16"

  additional_config:
    override_neuron_config:
      skip_warmup: True
      enable_bucketing: true        # ÂãïÁöÑ„Éê„ÉÉ„ÉÅ„É≥„Ç∞ÊúâÂäπ
      pa_num_blocks: 512
      pa_block_size: 32
```

„Åì„Çå„Çâ„ÅÆË®≠ÂÆö„ÅØ„ÄÅ[ÂâçÂõû„ÅÆ Zenn Ë®ò‰∫ã](https://zenn.dev/tosshi/articles/ef61e14fe73399) „ÅßÊúÄÈÅ©Âåñ„Åó„Åü„Éë„É©„É°„Éº„Çø„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

Êú¨Ë™øÊüª„Åß„ÅØ„ÄÅ„Åì„ÅÆÁâπÂÆö„ÅÆË®≠ÂÆö„Å´„Åä„Åë„Çã vllm-neuron „ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„Å¶„ÅÑ„Åæ„Åô„ÄÇÁï∞„Å™„Çã„É¢„Éá„É´„Çµ„Ç§„Ç∫„ÄÅ„Çà„ÇäÂ§ßË¶èÊ®°„Å™„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„Åß„ÅØ„ÄÅÁï∞„Å™„ÇãÊÄßËÉΩÁâπÊÄß„ÇíÁ§∫„ÅôÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ
::::

### 1.2 Perfetto „Éà„É¨„Éº„Çπ„ÅÆÂü∫Êú¨ÂàÜÊûê

ÂâçÂõû„ÇÇÂ∞ë„ÅóÁ¥π‰ªã„Åó„Åü Perfetto „Å´„Å§„ÅÑ„Å¶Á¥π‰ªã„Åó„Åæ„Åô„ÄÇPerfetto „Éà„É¨„Éº„Çπ„Éï„Ç°„Ç§„É´„ÅØ SQLite „Éá„Éº„Çø„Éô„Éº„Çπ„Å®„Åó„Å¶Êâ±„Åà„Åæ„Åô„ÄÇ„Åæ„Åö‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™ÂàÜÊûê„ÇØ„Ç®„É™„ÇíÂÆüË°å„Åó„Åæ„Åó„Åü„ÄÇ

:::details Perfetto „Éà„É¨„Éº„ÇπÂàÜÊûê„Ç≥„Éº„Éâ

```python
from perfetto.trace_processor import TraceProcessor
tp = TraceProcessor(trace='profile_output/trace.perfetto-trace')

# Operation „Åî„Å®„ÅÆÈõÜË®à
sql = """
SELECT name, COUNT(*) as count,
       SUM(dur) / 1e9 as total_seconds,
       AVG(dur) / 1e9 as avg_seconds
FROM slice WHERE dur > 0
GROUP BY name ORDER BY total_seconds DESC LIMIT 10
"""
```

**ÁµêÊûú„ÅÆ‰∏ÄÈÉ®**:
```
                  name   count total_seconds avg_seconds
0              unknown  156427      0.038387         0.0
1               MATMUL   21582      0.010941    0.000001
2 custom_call.17_sg0002      36      0.007028    0.000195
3            LDWEIGHTS   21212      0.004914         0.0
```

**„ÇØ„Ç®„É™„ÅÆË¶ãÊñπ**:
`slice` „ÉÜ„Éº„Éñ„É´„Å´„ÅØÂêÑ„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„ÅÆÂÆüË°åË®òÈå≤„ÅåÊ†ºÁ¥ç„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÆ„ÇØ„Ç®„É™„ÅØ‰ª•‰∏ã„ÇíÂèñÂæó„Åó„Åæ„Åô„ÄÇ
- `name`: „Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥ÂêçÔºàMATMUL „Å™„Å©„ÄÅNeuron „Ç≥„É≥„Éë„Ç§„É©„ÅåÁîüÊàê„Åó„ÅüÊºîÁÆó„ÅÆÁ®ÆÈ°ûÔºâ
- `count`: „Åù„ÅÆ„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„ÅåÂÆüË°å„Åï„Çå„ÅüÂõûÊï∞
- `dur`: ÂêÑÂÆüË°å„ÅÆÁ∂ôÁ∂öÊôÇÈñìÔºà„Éä„ÉéÁßíÂçò‰Ωç„ÅßË®òÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ1e9 „ÅßÂâ≤„Å£„Å¶Áßí„Å´Â§âÊèõÔºâ
- `total_seconds`: „Åù„ÅÆ„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„ÅÆÂêàË®àÂÆüË°åÊôÇÈñìÔºàÁßíÂçò‰ΩçÔºâ
- `avg_seconds`: 1 Âõû„ÅÇ„Åü„Çä„ÅÆÂπ≥ÂùáÂÆüË°åÊôÇÈñìÔºàÁßíÂçò‰ΩçÔºâ
:::

ÁµêÊûú„Å®„Åó„Å¶„ÄÅ„Åæ„Åö„ÄÅ`custom_call.17_sg0002` „Å®„ÅÑ„ÅÜÊìç‰Ωú„Åå„Åü„Å£„Åü 36 Âõû„ÅÆÂÆüË°å„Åß 7ms „ÇÇÊ∂àË≤ª„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂà§Êòé„Åó„Åæ„Åó„Åü„ÄÇÊ¨°„Å´„ÄÅMATMUL „Å® LDWEIGHTS „Åå„Åª„ÅºÂêå„ÅòÂõûÊï∞ÂÆüË°å„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åï„Çâ„Å´„ÄÅ`unknown` „Å®„ÅÑ„ÅÜÂàÜÈ°û„ÅÆÊìç‰Ωú„Åå 38ms „ÅßÊúÄÂ§ß„ÅÆÊôÇÈñì„ÇíÊ∂àË≤ª„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ

`custom_call.17_sg0002`„ÄÇ„ÄÇ„ÄÇ‰Ωï„Åß„Åô„Åã„Å≠„Åì„Çå„ÅØ„ÄÇ„ÄÇ

:::details [Áô∫Â±ïÁöÑÂÜÖÂÆπ] NEFF „Å´„Çà„Çã custom_call „ÅÆË™øÊüª

**ÁñëÂïè**: `custom_call.17_sg0002` „Å®„ÅØ‰Ωï„ÅãÔºüRoPEÔºüÊ¥ªÊÄßÂåñÈñ¢Êï∞Ôºü‰Ωï„Çâ„Åã„ÅÆ„Ç´„Çπ„Çø„É†„Ç´„Éº„Éç„É´Ôºü

Perfetto „Éà„É¨„Éº„Çπ„Åß„ÅØÂÆüË°åÂõûÊï∞„Å®ÊôÇÈñì„Åó„ÅãÂàÜ„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅ„ÄÅNEFF (Neuron Executable File Format) „Éï„Ç°„Ç§„É´„Çí [unpacking](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html) „Åó„Å¶ÈùôÁöÑ„Å™ÊßãÈÄ†„ÇíË™øÊüª„Åó„Åæ„Åó„Åü„ÄÇ(uppack „Å´„ÅØ `neuron-packager unpack` „Ç≥„Éû„É≥„Éâ„ÇíÂà©Áî®„Åó„Å¶„ÇÇËâØ„ÅÑ„Åß„Åô)

**NEFF „Åã„ÇâÂà§Êòé„Åó„Åü„Åì„Å®**:

```bash
# NEFF „Éï„Ç°„Ç§„É´„Çí unpacking
$ dd if=neff_322059935237836.neff of=neff.tar.gz bs=1024 skip=1
$ tar -xzf neff.tar.gz

# tensor_map.json „ÇíÁ¢∫Ë™ç
$ cat sg00/tensor_map.json | jq '.["custom_call.17_sg0002"]'
{
  "dtype": "float32",
  "sim_shape": [256, 1, 1],
  "kind": null,
  "is_const": false,
  "layer_name": "custom_call.17"
}
```

**ÂàÜ„Åã„Çã„Åì„Å®**:
- „Éá„Éº„ÇøÂûã: `float32`ÔºàÁ≤æÂ∫¶ÈáçË¶ñ„ÅÆÊºîÁÆóÔºâ
- „ÉÜ„É≥„ÇΩ„É´ÂΩ¢Áä∂: `[256, 1, 1]`ÔºàÊØîËºÉÁöÑÂ∞è„Åï„ÅÑÔºâ
- „Çµ„Éñ„Ç∞„É©„Éï: `sg0002`
- ÂãïÁöÑ„Å´Ë®àÁÆó„Åï„Çå„Çã‰∏≠Èñì„ÉÜ„É≥„ÇΩ„É´
- `custom_call.14` ÔΩû `17` „ÅÆÈÄ£Á∂ö„Åó„ÅüÊºîÁÆó„Ç∑„Éº„Ç±„É≥„Çπ

**Qwen3 „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Åã„ÇâÊé®Ê∏¨**:

ÂΩ¢Áä∂ `[256, 1, 1]` „Å®Âë®Ëæ∫„ÅÆ `dot` (MATMUL) Êìç‰Ωú„Åã„Çâ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Êìç‰Ωú„Å®Êé®Ê∏¨
- **RoPE (Rotary Position Embedding)**: ‰ΩçÁΩÆ„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞Ë®àÁÆó
- **RMSNorm**: Ê≠£Ë¶èÂåñÂ±§„ÅÆÁµ±Ë®àÂÄ§Ë®àÁÆó
- **„Ç¢„ÉÜ„É≥„Ç∑„Éß„É≥Ê©üÊßã**: Softmax Ââç„ÅÆ‰∏≠ÈñìË®àÁÆó

NEFF „ÅØ„Ç≥„É≥„Éë„Ç§„É´ÊôÇ„ÅÆÈùôÁöÑ„Å™ÊÉÖÂ†±Ôºà„Ç∞„É©„ÉïÊßãÈÄ†„ÄÅ„ÉÜ„É≥„ÇΩ„É´ÂΩ¢Áä∂„ÄÅ„Éá„Éº„ÇøÂûãÔºâ„ÇíÂê´„Åø„Åæ„Åô„Åå„ÄÅ‰ª•‰∏ã„ÅØÂà§Êòé„Åó„Å™„ÅÑ„Çà„ÅÜ„Åß„Åô„ÄÇ
- ÂÖ∑‰ΩìÁöÑ„Å™ÊºîÁÆó„É≠„Ç∏„ÉÉ„ÇØ
- ÂÆüË°åÂõûÊï∞
- ÂÆüË°åÊôÇÈñì
- ÂàùÂõûÂÆüË°åÊôÇ„ÅÆÈÅÖÂª∂

NEFF ÂàÜÊûê„Åã„Çâ„ÅØ„ÄÅ‰Ωï„Åå‰Ωø„Çè„Çå„Å¶„ÅÑ„Çã„Åã„ÅØÂàÜ„Åã„Çä„Åæ„Åô„Åå„ÄÅ„Å©„ÅÜÂãï„Åè„Åã„ÅØ Perfetto „Éà„É¨„Éº„Çπ„ÅßÂÆüË°åÊôÇ„Å´Ê∏¨ÂÆö„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ
:::

### 1.3 skip_warmup Ë®≠ÂÆö„ÅÆÂΩ±Èüø

Ë©¶Ë°åÈåØË™§„Åó„Å™„Åå„ÇâÂÆüË°å„Åó„Åü„ÇØ„Ç®„É™„ÇíÂÖ®„Å¶Á¥π‰ªã„Åó„Å¶„ÅÑ„Çã„Å®ËÜ®Â§ß„Å´„Å™„Å£„Å¶„Åó„Åæ„ÅÜ„Åü„ÇÅÂâ≤ÊÑõ„Åó„Åæ„Åô„Åå custom_call „ÅåÂàùÂõûÂÆüË°åÊôÇ„Å´Â§ß„Åç„Å™ÈÅÖÂª∂„ÇíËµ∑„Åì„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂàÜ„Åã„Å£„Åü„Åü„ÇÅ„ÄÅNxD Inference „ÅÆ„Éë„É©„É°„Éº„Çø„Åß„ÅÇ„Çã `skip_warmup=False` „ÇíË©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ„Éá„Éï„Ç©„É´„ÉàÂÄ§„ÅØ `False` „Å™„ÅÆ„Åß„Åô„Åå‰ª•Ââç„ÅÆÂÆüÈ®ì„ÅÆË©¶Ë°åÈåØË™§„Åß `True` „Å´„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ„Åì„ÅÆ„Éë„É©„É°„Éº„Çø„ÅØ„É¢„Éá„É´„É≠„Éº„ÉâÂæå„Å´ 1 Âõû„ÅÆ forward ÂÆüË°å„ÇíË°å„ÅÑ„ÄÅÈÅÖÂª∂ÂàùÊúüÂåñ„ÇíÂÆå‰∫Ü„Åï„Åõ„Çã„Å®„ÅÑ„ÅÜ„ÇÇ„ÅÆ„Åß„Åô„ÄÇ
                                                                                                                  
| Ë®≠ÂÆö | Âπ≥ÂùáÊôÇÈñì |
|------|---------|
| Baseline (skip_warmup=True) | 2.992Áßí |
| Warmup (skip_warmup=False) | 3.110Áßí (+3.9%) |

„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó„Åô„Çå„Å∞ÈÄü„Åè„Å™„Çã„Å®‰∫àÊÉ≥„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„Åå„ÄÅÂÆüÈöõ„Å´„ÅØÁ¥Ñ 4% ÈÅÖ„Åè„Å™„Çä„Åæ„Åó„Åü„ÄÇÂÜçÂ∫¶„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Åó„Å¶„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„ÅÆÂ§âÂåñ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ

:::details Operation Êï∞„ÅÆÂ§âÂåñ

```
Baseline (skip_warmup=True):
  MATMUL: 21,582Âõû, 10.94ms
  LDWEIGHTS: 21,212Âõû, 4.91ms
  ACTIVATE: 4,702Âõû, 1.65ms
  COPY: 83Âõû, 0.03ms

Warmup (skip_warmup=False):
  MATMUL: 13,497Âõû (-37%), 2.64ms (-76%)
  LDWEIGHTS: 13,497Âõû (-36%), 1.17ms (-76%)
  ACTIVATE: 4,207Âõû (-11%), 2.94ms (+78%)
  COPY: 554Âõû (+567%), 1.01ms (+3,267%)
```
:::

`skip_warmup=False` „Åß MATMUL/LDWEIGHTS „ÅÆ‰∏ªË¶Å„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„ÅØÂÆüË°åÊôÇÈñì„Åå 76% Ê∏õÂ∞ë„Åó„Åü„ÇÇ„ÅÆ„ÅÆ„ÄÅACTIVATE „ÅÆÂÆüË°åÊôÇÈñì„Åå +78%„ÄÅCOPY „ÅÆÂÆüË°åÊôÇÈñì„Åå +3,267% Â¢óÂä†„Åó„ÄÅ„Éà„Éº„Çø„É´„Åß„ÅØÈÅÖ„Åè„Å™„Çä„Åæ„Åó„Åü„ÄÇ


### 1.4 Neuron Profiler „ÅÆÊ∏¨ÂÆöÁØÑÂõ≤„ÅÆÈôêÁïå

:::message alert
**„Åì„Åì„ÅßÈáçË¶Å„Å™Ê∞ó„Å•„Åç**ÔºöNeuron Profiler „ÅÆ„Éà„É¨„Éº„ÇπÊôÇÈñì„ÅØ 16-17ms „Å™„ÅÆ„Å´„ÄÅ„Éô„É≥„ÉÅ„Éû„Éº„ÇØÂÖ®‰Ωì„ÅØÁ¥Ñ 3 Áßí„Åã„Åã„Å£„Å¶„ÅÑ„Çã„ÄÇ**„Åì„ÅÆ 16-17ms „Å£„Å¶„Å©„Åì„Åã„Çâ„Å©„Åì„Åæ„Åß„ÅÆ„Å™„Çì„ÅÆÂÄ§Ôºü**
:::

Ê∂ô„ÅÆË™øÊüª„ÅÆÁµêÊûú„ÄÅNeuron Profiler „ÅÆÊ∏¨ÂÆöÁØÑÂõ≤„Å´Èñ¢„Åô„ÇãÈáçË¶Å„Å™ÁâπÊÄß„ÅåÂà§Êòé„Åó„Åæ„Åó„Åü„ÄÇNeuron Profiler „ÅØÂÆüË°åÊôÇ„Å´ NTFF (Neuron Trace File Format) „Å®„ÅÑ„ÅÜ‰∏≠Èñì„Éï„Ç°„Ç§„É´„ÇíÁîüÊàê„Åó„ÄÅ„Åù„Çå„Çí Perfetto „Éà„É¨„Éº„Çπ„Å´Â§âÊèõ„Åó„Åæ„Åô„ÄÇÂêÑ NTFF „Éï„Ç°„Ç§„É´„ÅØ 1 „Å§„ÅÆ„Ç≥„É≥„Éë„Ç§„É´Ê∏à„Åø„Ç∞„É©„Éï„ÅÆÂÆüË°åË®òÈå≤„ÇíË°®„Åó„Å¶„Åä„Çä„ÄÅÁï∞„Å™„Çã„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÇÑ sequence length Áî®„ÅÆË§áÊï∞„Ç∞„É©„Éï„ÅåÂ≠òÂú®„Åó„Åæ„Åô„ÄÇ„Åù„ÅÆ„Åü„ÇÅ„Åì„Çå„Å†„Åë„ÇíË¶ã„Çå„Å∞ NeuronCore „ÅÆ„Éà„Éº„Çø„É´„ÅÆÂÆüË°åÊôÇÈñì„ÅåÁ¢∫ÂÆü„Å´„Çè„Åã„Çã„Å®„ÅÑ„ÅÜ„ÇÇ„ÅÆ„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ

```bash
$ find profile_output -name "*.ntff" | wc -l
22  # 11Á®ÆÈ°û„ÅÆ„Ç∞„É©„Éï √ó 2„Ç≥„Ç¢(tensor_parallel_size=2)

# NTFF „ÅØ Perfetto „Å´Â§âÊèõ„Åï„Çå„Çã
$ ls profile_output/trace.perfetto-trace
trace.perfetto-trace  # „Åì„Çå„Çí TraceProcessor „ÇÑ Perfetto UI „ÅßÂàÜÊûê
```

:::message alert
**‰ªäÂõû„ÅÆÈÅé„Å°„Åã„Çâ„ÅÆÂ≠¶„Å≥**: Neuron Profiler „ÅØ„Éè„Éº„Éâ„Ç¶„Çß„Ç¢„É¨„Éô„É´„ÅÆÂàÜÊûê„Å´„ÅØÊúâÁî®„Å†„Åå„ÄÅvllm-neuron ÂÖ®‰Ωì„ÅÆÊúÄÈÅ©Âåñ„Å´„Åä„ÅÑ„Å¶ÂàùÊâã„Åß‰Ωø„ÅÜ„ÇÇ„ÅÆ„Åß„ÅØ„Å™„ÅÑ„ÄÇ
:::

„Ç´„Çπ„Çø„É†„Ç´„Éº„Éç„É´„ÇíÂÆüË£Ö„Åô„Çã„Çà„ÅÜ„Å™„Ç±„Éº„Çπ„Åß„ÅØ Neuron Profiler „ÅØÂøÖÈ†à„Å®Ë®Ä„Åà„Åæ„Åô„Åå„ÄÅÊúÄÈÅ©„Å™Ë®≠ÂÆö„ÇíÊé¢„ÅôÈöõ„ÅÆÂàùÊâã„ÅßÂÆüÊñΩ„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÇÇ„ÅÆ„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ„Åù„Åó„Å¶„Éè„Éº„Éâ„Ç¶„Çß„Ç¢„É¨„Éô„É´„ÅÆÊîπÂñÑ„Çí„Åô„ÇãÂâç„Å´ vllm-neuron ÂÖ®‰Ωì„ÅÆÂÆüË°åÊôÇÈñì„ÅÆÂÜÖ„ÅÆ„Å©„ÅÆÁ®ãÂ∫¶„Çí„Éè„Éº„Éâ„Ç¶„Çß„Ç¢ÂÅ¥„ÅÆÊé®Ë´ñÂá¶ÁêÜ„ÅåÂç†„ÇÅ„Å¶„ÅÑ„Çã„ÅÆ„Åã„Å´„Çà„Å£„Å¶ÊîπÂñÑ„ÅÆÂÑ™ÂÖàÂ∫¶„ÅåÂ§â„Çè„Å£„Å¶„Åè„Çã„ÅÆ„Åß vllm-neuron ÂÖ®‰Ωì„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Çí„Åó„Å™„ÅÑ„Å®ÊÑèÂë≥„Å™„ÅÑ„Åû„ÄÅ„Å®ÊÄù„ÅÑ„Åæ„Åó„Åü„ÄÇ„ÄÇ„Å®„ÅØ„ÅÑ„Åà„ÄÅ‰ªäÂõûÂæó„Åü Neuron Profiler „Å´Èñ¢„Åô„ÇãÁü•Ë¶ã„ÅØÊúâÁî®„Å™„Åü„ÇÅ„Ç∑„Çß„Ç¢„ÅÆÊÑèÂë≥„ÇíËæº„ÇÅ„Å¶ Phase 1 „ÇíÊ∂à„Åï„Åö„Å´„Åù„ÅÆ„Åæ„ÅæÂÖ¨Èñã„Åó„Åæ„Åô„ÄÇ

### 1.5 NEFF„ÄÅPerfetto „Å®„ÅØ

Phase 1 „ÅßÁôªÂ†¥„Åó„Åü„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Éï„Ç°„Ç§„É´„Å´„Å§„ÅÑ„Å¶Êï¥ÁêÜ„Åó„Åæ„Åô„ÄÇ

:::message
NEFFÔºà„Ç≥„É≥„Éë„Ç§„É´ÊôÇÔºâ ‚Üí NTFFÔºà„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÂÆüË°åÊôÇ„ÅÆ‰∏≠Èñì„Éï„Ç°„Ç§„É´Ôºâ ‚Üí **Perfetto „Éà„É¨„Éº„Çπ**ÔºàÂàÜÊûê„Å´‰ΩøÁî®Ôºâ
:::

#### NEFF (Neuron Executable File Format)

[ÂèÇËÄÉ: Work with NEFF Files](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html)

**ÂΩπÂâ≤**: „Ç≥„É≥„Éë„Ç§„É´Ê∏à„Åø„Ç∞„É©„Éï„ÅÆÂÆüË°å„Éï„Ç°„Ç§„É´

```bash
# NEFF „ÅÆÊßãÈÄ†
neff_322059935237836.neff (801KB)
‚îú‚îÄ‚îÄ [1024 byte header]
‚îî‚îÄ‚îÄ [tar.gz archive]
    ‚îú‚îÄ‚îÄ info.json              # „Ç≥„É≥„Éë„Ç§„É´ÊÉÖÂ†±
    ‚îú‚îÄ‚îÄ hlo_stats.json         # ÊºîÁÆóÁµ±Ë®àÔºàHloMacCount: 29.2B „Å™„Å©Ôºâ
    ‚îú‚îÄ‚îÄ metrics.json           # Êé®ÂÆö„É¨„Ç§„ÉÜ„É≥„Ç∑
    ‚îú‚îÄ‚îÄ neff.json              # „Ç∞„É©„ÉïÂÆöÁæ©Ôºà373 „Éé„Éº„ÉâÔºâ
    ‚îî‚îÄ‚îÄ sg00/                  # „Çµ„Éñ„Ç∞„É©„Éï 0
        ‚îú‚îÄ‚îÄ tensor_map.json    # „ÉÜ„É≥„ÇΩ„É´ÊÉÖÂ†±Ôºà458 „ÉÜ„É≥„ÇΩ„É´Ôºâ
        ‚îú‚îÄ‚îÄ PE.bin             # Processing Element ÂëΩ‰ª§
        ‚îú‚îÄ‚îÄ Activation.bin     # Ê¥ªÊÄßÂåñÈñ¢Êï∞ÂëΩ‰ª§
        ‚îú‚îÄ‚îÄ DVE.bin            # Data Vector Engine ÂëΩ‰ª§
        ‚îî‚îÄ‚îÄ debug_info_*.dbg   # „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±
```

::::details NEFF „Éï„Ç°„Ç§„É´„Å® bucketing „ÅÆÈñ¢‰øÇ

**NEFF (Neuron Executable File Format)** „ÅØ„ÄÅAWS NeuronCore ‰∏ä„ÅßÂÆüË°å„Åï„Çå„Çã„Ç≥„É≥„Éë„Ç§„É´Ê∏à„Åø„Ç∞„É©„Éï„ÅÆÂÆüË°å„Éï„Ç°„Ç§„É´„Åß„Åô„ÄÇbucketing „ÇíÊúâÂäπ„Å´„Åô„Çã„Å®„ÄÅË§áÊï∞„ÅÆ (batch_size, sequence_length) „ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„Å´ÂØæÂøú„Åô„ÇãË§áÊï∞„ÅÆ„Ç∞„É©„Éï„Åå‰∫ãÂâç„Å´„Ç≥„É≥„Éë„Ç§„É´„Åï„Çå„Åæ„Åô„ÄÇ

```bash
# NEFF „Éï„Ç°„Ç§„É´„ÅÆÂàÜÊûê
$ find profile_output -name "*.neff" | wc -l
77  # Ë§áÊï∞„ÅÆ PID „Åã„Çâ 11 Á®ÆÈ°û„ÅÆ„Ç∞„É©„Éï √ó Ë§áÊï∞Âõû„Ç≥„É≥„Éë„Ç§„É´

$ ls -lh profile_output/*/neff_*.neff | awk '{print $5}' | sort -u
801K   # Graph 1: ÊúÄÂ∞è„Éê„Ç±„ÉÉ„Éà
881K   # Graph 2
991K   # Graph 3
1.1M   # Graph 4
1.3M   # Graph 5
2.1M   # Graph 6
2.3M   # Graph 7
2.4M   # Graph 8
2.6M   # Graph 9
3.0M   # Graph 10
       # (ÂêàË®à 11 Á®ÆÈ°û„ÄÅ124 MB)
```

bucketing „ÇíÊúâÂäπ„Å´„Åô„ÇãÂ†¥Âêà„ÄÅË§áÊï∞„ÅÆ„Çµ„Ç§„Ç∫„ÅÆ„Ç∞„É©„Éï„Çí‰∫ãÂâç„Ç≥„É≥„Éë„Ç§„É´„Åó„Å¶„Åä„Åç„ÄÅ„Åù„Çå„Çâ„Çí„É≠„Éº„Éâ„Åó„Å¶Êé®Ë´ñ„Å´Âà©Áî®„Åó„Åæ„Åô„ÄÇÂÆüË°åÊôÇ„Å´ÂÖ•Âäõ„Çµ„Ç§„Ç∫„Å´Âøú„Åò„ÅüÊúÄÈÅ©„Ç∞„É©„Éï„ÇíÈÅ∏Êäû„Åô„Çã„Åì„Å®„Åã„Çâ„ÄÅ„Ç∞„É©„ÉïÈÅ∏Êäû„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Å™„Å©„ÅåÁô∫Áîü„Åó„Åæ„Åô„ÄÇÂõ∫ÂÆöÈï∑„ÉØ„Éº„ÇØ„É≠„Éº„Éâ„ÅÆÂ†¥Âêà„ÄÅÂÆüÈöõ„Å´‰ΩøÁî®„Åô„Çã„ÅÆ„ÅØË§áÊï∞„Ç∞„É©„Éï„ÅÆ„ÅÜ„Å° 1 „Å§„Å†„Åë„Åß„ÅÇ„Çä„ÄÅÁâπ„Å´ bucketing „ÅÆÊÅ©ÊÅµ„ÇíÂèó„Åë„Çã„Åì„Å®„Å™„Åè„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„ÅåËøΩÂä†„Åï„Çå„Çã„Å®ÊÄù„Çè„Çå„Åæ„Åô„ÄÇ‰∏ÄËà¨ÁöÑ„Å™ LLM „ÅÆÁîüÊàê„ÅÆ„Çà„ÅÜ„Å™ÂèØÂ§âÈï∑„ÉØ„Éº„ÇØ„É≠„Éº„Éâ„ÅÆÂ†¥Âêà„ÅØÁï∞„Å™„ÇãÈï∑„Åï„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÅåË§áÊï∞„Ç∞„É©„Éï„Å´ÂàÜÊï£„Åï„Çå„Çã„ÅÆ„ÅßÂÜç„Ç≥„É≥„Éë„Ç§„É´„Åô„Çã„Åì„Å®„Å™„ÅèÂäπÁéáÁöÑ„Å™„Éê„ÉÉ„ÉÅ„É≥„Ç∞„ÅåÂèØËÉΩ„Å™„Åü„ÇÅ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„ÇíÂ∑Æ„ÅóÂºï„ÅÑ„Å¶„ÇÇÈ´òÈÄüÂåñ„Å´Ë≤¢ÁåÆ„Åô„Çã„Å®ÊÄù„Çè„Çå„Åæ„Åô„ÄÇ

:::message
**„Åì„ÅÆ„Çà„ÅÜ„Å´„ÉØ„Éº„ÇØ„É≠„Éº„Éâ„Å´„Çà„Å£„Å¶ bucketing „ÅÆÊÄßËÉΩ„ÅØ ON/OFF „Åß„Å©„Å°„Çâ„ÅåËâØ„ÅÑ„ÅãÂ§âÂãï„Åô„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Åì„Å®„ÇíË¶ö„Åà„Å¶„Åä„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑÔºÅ**
:::
::::

#### NTFF (Neuron Trace File Format) - ‰∏≠Èñì„Éï„Ç°„Ç§„É´

**ÂΩπÂâ≤**: Perfetto „Éà„É¨„Éº„Çπ„Å´Â§âÊèõ„Åï„Çå„ÇãÂâç„ÅÆ‰∏≠Èñì„Éï„Ç°„Ç§„É´

```bash
# NTFF „Éï„Ç°„Ç§„É´„ÅÆ‰æãÔºàNeuron Profiler „ÅåÁîüÊàêÔºâ
profile_output/i-0049acfde6046f237_pid_520024/
‚îú‚îÄ‚îÄ 322059935237836_instid_0_vnc_0.ntff  # Graph 1, Core 0
‚îú‚îÄ‚îÄ 322059935237836_instid_0_vnc_1.ntff  # Graph 1, Core 1
‚îú‚îÄ‚îÄ 729292360268366_instid_0_vnc_0.ntff  # Graph 4, Core 0
‚îú‚îÄ‚îÄ 729292360268366_instid_0_vnc_1.ntff  # Graph 4, Core 1
...
‚îî‚îÄ‚îÄ (22 files = 11 graphs √ó 2 cores)

# Neuron Profiler „Åß Perfetto „Å´Â§âÊèõ
$ neuron-profile view --output-format perfetto profile_output
```

#### Perfetto „Éà„É¨„Éº„Çπ

**ÂΩπÂâ≤**: NeuronCore ‰∏ä„ÅÆ‰Ωé„É¨„Éô„É´ÂÆüË°å„Éà„É¨„Éº„Çπ

```bash
# Perfetto „Éà„É¨„Éº„Çπ
trace.perfetto-trace (110 MB)
‚îî‚îÄ‚îÄ SQLite „Éá„Éº„Çø„Éô„Éº„Çπ
    ‚îú‚îÄ‚îÄ slice „ÉÜ„Éº„Éñ„É´          # „Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥ÂÆüË°åË®òÈå≤
    ‚îÇ   ‚îî‚îÄ‚îÄ MATMUL: 21,582Âõû, 10.94ms
    ‚îÇ       COPY: 83Âõû, 0.03ms
    ‚îÇ       custom_call.17: 36Âõû, 7ms
    ‚îú‚îÄ‚îÄ thread „ÉÜ„Éº„Éñ„É´         # „Çπ„É¨„ÉÉ„ÉâÊÉÖÂ†±
    ‚îî‚îÄ‚îÄ process „ÉÜ„Éº„Éñ„É´        # „Éó„É≠„Çª„ÇπÊÉÖÂ†±
```

::::details NEFF „Å® Perfetto „ÅÆÊØîËºÉ

‰ª•‰∏ã„ÅØ„Åæ„Å†ÂÆåÂÖ®„Å´„ÅØÊï¥ÁêÜ„Åó„Åç„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅÂèÇËÄÉÁ®ãÂ∫¶„Å´Á¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

| ÊÉÖÂ†± | NEFF | Perfetto |
|------|------|----------|
| **ÈùôÁöÑÊßãÈÄ†** | | |
| „Ç∞„É©„ÉïÊßãÈÄ†Ôºà„Éé„Éº„Éâ„ÄÅ„ÉÜ„É≥„ÇΩ„É´Êï∞Ôºâ | ‚úÖ | ‚ùå |
| „ÉÜ„É≥„ÇΩ„É´ÂΩ¢Áä∂„Éª„Éá„Éº„ÇøÂûã | ‚úÖ | ‚ùå |
| ÊºîÁÆóÈáèÔºàÁêÜË´ñÂÄ§Ôºâ | ‚úÖ | ‚ùå |
| „É°„É¢„É™‰ΩøÁî®ÈáèÔºàÁêÜË´ñÂÄ§Ôºâ | ‚úÖ | ‚ùå |
| DMA „Ç≠„É•„ÉºÊßãÊàê | ‚úÖ | ‚ùå |
| **„Ç∞„É©„Éï„É¨„Éô„É´ÂÆüË°å** | | |
| „Ç∞„É©„Éï„Åî„Å®„ÅÆÂÆüË°åÊôÇÈñì | ‚ùå | ‚ö†Ô∏è |
| NeuronCore „Åî„Å®„ÅÆÂÜÖË®≥ | ‚ùå | ‚ö†Ô∏è |
| ‰ΩøÁî®„Åï„Çå„Åü„Ç∞„É©„Éï„ÅÆË≠òÂà• | ‚ùå | ‚ö†Ô∏è |
| „Ç∞„É©„ÉïÈñì„ÅÆÈÅ∑ÁßªÊôÇÈñì | ‚ùå | ‚ö†Ô∏è | „Çø„Ç§„É†„Çπ„Çø„É≥„Éó„Åã„ÇâÊé®ÂÆö |
| **„Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥„É¨„Éô„É´ÂÆüË°å** | | | |
| ÂÆüË°åÊôÇÈñìÔºàÂÆüÊ∏¨ÂÄ§Ôºâ | ‚ùå | ‚úÖ | slice.dur |
| ÂÆüË°åÂõûÊï∞ | ‚ùå | ‚úÖ | COUNT(*) |
| „Ç™„Éö„É¨„Éº„Ç∑„Éß„É≥Ë©≥Á¥∞ÔºàMATMUL„ÄÅCOPY „Å™„Å©Ôºâ | ‚ùå | ‚úÖ | slice.name |
| „Çø„Ç§„É†„Çπ„Çø„É≥„Éó„Å®ÂÆüË°åÈ†ÜÂ∫è | ‚ùå | ‚úÖ | slice.ts |
| ‰∏¶ÂàóÂÆüË°å„ÅÆÂèØË¶ñÂåñ | ‚ùå | ‚úÖ | Perfetto UI |
| ÂàùÊúüÂåñÈÅÖÂª∂Ôºàskip_warmup ÂäπÊûúÔºâ | ‚ùå | ‚úÖ | ÂàùÂõûÂÆüË°åÊôÇÈñì„ÅÆÊØîËºÉ |
| **È´ò„É¨„Éô„É´ÊÉÖÂ†±** | | | |
| Python „É¨„Ç§„É§„Éº„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ | ‚ùå | ‚ùå | line_profiler „Å™„Å©„ÅåÂøÖË¶Å |
| ÊºîÁÆóÂÜÖÂÆπ„ÅÆÊÑèÂë≥ÔºàRoPE„ÄÅRMSNorm „Å™„Å©Ôºâ | ‚ö†Ô∏è | ‚ùå | ÂΩ¢Áä∂„Åã„ÇâÊé®Ê∏¨„ÅÆ„Åø |

**Âá°‰æã**: ‚úÖ Áõ¥Êé•ÂèñÂæóÂèØËÉΩ„ÄÅ‚ö†Ô∏è Êé®Ê∏¨„ÉªË®àÁÆó„ÅåÂøÖË¶Å„ÄÅ‚ùå ÂèñÂæó‰∏çÂèØËÉΩ
::::

## Phase 2: line_profiler „Å´„Çà„Çã Python „Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞

Phase 1 „Åß„ÅØ Neuron Profiler „Å´„Çà„Çä NeuronCore „É¨„Éô„É´„ÅÆË©≥Á¥∞„Å™ÂàÜÊûê„ÇíË°å„ÅÑ„Åæ„Åó„Åü„Åå„ÄÅPython „É¨„Éô„É´„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâÔºà„Éà„Éº„ÇØ„Éä„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÄÅ„Éá„Éº„ÇøÊ∫ñÂÇô„Å™„Å©Ôºâ„ÅÆÊ∏¨ÂÆö„Å´„ÅØÂà•„ÅÆ„ÉÑ„Éº„É´„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ„Åù„Åì„Åß line_profiler „Çí‰ΩøÁî®„Åó„Å¶ Python „Ç≥„Éº„Éâ„ÅÆË°å„Åî„Å®„ÅÆÂÆüË°åÊôÇÈñì„ÇíÊ∏¨ÂÆö„Åó„Åæ„Åô„ÄÇ

### Ê∏¨ÂÆö„Çπ„ÇØ„É™„Éó„Éà„ÅÆÊ∫ñÂÇô

Phase 1 „Åß‰ΩøÁî®„Åó„Åü `test_reranker.py` „ÅØ pytest + benchmark_capture „Éá„Ç≥„É¨„Éº„Çø„Éº„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅline_profiler „Å®ÁµÑ„ÅøÂêà„Çè„Åõ„Çã„Å®Âá∫Âäõ„ÅåË§áÈõë„Å´„Å™„Çä„Åæ„Åô„ÄÇ„Åù„Åì„Åß„ÄÅline_profiler Â∞ÇÁî®„ÅÆ„Ç∑„É≥„Éó„É´„Å™„Çπ„ÇØ„É™„Éó„Éà `profile_line.py` „Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü„ÄÇÔºà„Åì„ÅÆËæ∫„Çä„ÇÇ vllm-neuron „ÅÆ Python „Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÅÆ„Åü„ÇÅ„Å´„ÅÜ„Åæ„ÅèÂèñ„Çå„Çã„Çà„ÅÜ„Å´‰ªäÂæå benchmark_capture „ÅÆÂÆüË£Ö„ÇíÊîπÂñÑ„Åó„Åæ„ÅôÔºâ

::::details „Çπ„ÇØ„É™„Éó„Éà„ÅÆÊßãÈÄ†

```python:profile_line.py
try:
    profile
except NameError:
    def profile(func):
        return func

# config.yaml „Åã„ÇâË®≠ÂÆö„ÇíË™≠„ÅøËæº„ÅøÔºàtest_reranker.py „Å®Âêå„ÅòÔºâ
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# Ê∏¨ÂÆöÂØæË±°„ÅÆÈñ¢Êï∞„Å´ @profile „Éá„Ç≥„É¨„Éº„Çø„Éº„ÇíËøΩÂä†
@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """„Éà„Éº„ÇØ„É≥Âåñ„Å®„Éó„É≠„É≥„Éó„ÉàÊßãÁØâ"""
    # ... (test_reranker.py „Å®Âêå„Åò„É≠„Ç∏„ÉÉ„ÇØ)

@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id,
                 prefix_tokens, suffix_tokens):
    """„É™„É©„É≥„Ç´„Éº„ÅÆ„É°„Ç§„É≥Âá¶ÁêÜ"""
    # ... (test_reranker.py „Å®Âêå„Åò„É≠„Ç∏„ÉÉ„ÇØ)

def main():
    """„É°„Ç§„É≥Èñ¢Êï∞Ôºàpytest Èùû‰æùÂ≠òÔºâ"""
    llm = vllm.LLM(model=model_path, **vllm_config)
    # ... ÂàùÊúüÂåñ„Å®„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÂÆüË°å

if __name__ == "__main__":
    main()
```

::::

::::details „Çπ„ÇØ„É™„Éó„ÉàÂÆåÂÖ®Áâà
```python:profile_line.py
"""
Line profiler script for vLLM-Neuron Reranker

Run with:
    kernprof -l -v profile_line.py

Or for more detailed output:
    kernprof -l profile_line.py
    python -m line_profiler profile_line.py.lprof
"""

# line_profiler compatibility: make @profile decorator optional
try:
    profile
except NameError:
    # If not running under kernprof, @profile is a no-op
    def profile(func):
        return func

import csv
import gc
import logging
import os
import sys
from pathlib import Path

import yaml

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load configuration
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# Get model path
model_path = config['model']['path']

# Get vLLM config
vllm_config = {
    "tensor_parallel_size": config['vllm']['tensor_parallel_size'],
    "max_num_seqs": config['vllm']['max_num_seqs'],
    "block_size": config['vllm']['block_size'],
    "max_model_len": config['vllm']['max_model_len'],
    "max_num_batched_tokens": config['vllm']['max_num_batched_tokens'],
    "num_gpu_blocks_override": config['vllm']['num_gpu_blocks_override'],
    "enable_prefix_caching": config['vllm']['enable_prefix_caching'],
    "dtype": config['vllm']['dtype'],
    "disable_log_stats": config['vllm'].get('disable_log_stats', False),
}

# Add additional_config if present (Zenn article optimal settings)
if 'additional_config' in config['vllm']:
    vllm_config['additional_config'] = config['vllm']['additional_config']

# Get reranker config
reranker_config = config['reranker']
benchmark_config = config['benchmark']

# Reranker prompts
reranker_prompts = {
    'instruction': reranker_config['instruction'],
    'prefix': reranker_config['prefix'],
    'suffix': reranker_config['suffix']
}

# Token IDs
token_ids = {
    'true': reranker_config['token_true'],
    'false': reranker_config['token_false']
}

# Load CSV data
csv_file = Path(__file__).parent / reranker_config['input_file']
with open(csv_file, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    rows = list(reader)

num_queries = min(len(rows), benchmark_config['num_test_queries'])
search_num = reranker_config['search_num']
batch_size = reranker_config['batch_size']
max_length = reranker_config['max_length']

logger.info(f"Loaded {len(rows)} queries from {csv_file}")
logger.info(f"Testing with first {num_queries} queries")


def format_instruction(query: str, doc: str) -> str:
    """Format instruction for reranker"""
    instruction = reranker_prompts['instruction']
    output = f"<Instruct>: {instruction}\n<Query>: {query}\n<Document>: {doc}"
    # Truncate if too long
    if len(output) >= 2000:
        output = output[:2000]
    return output


@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """Build prompts with proper tokenization - PROFILING TARGET"""
    prompts = []
    budget = max_length - len(prefix_tokens) - len(suffix_tokens)

    # Tokenize pairs
    enc = tokenizer(
        list(pairs),
        padding=False,
        truncation="longest_first",
        return_attention_mask=False,
        add_special_tokens=False,
        max_length=max(8, budget),
    )

    # Build final prompts: prefix + content + suffix
    for ids in enc["input_ids"]:
        final_ids = prefix_tokens + ids + suffix_tokens
        text = tokenizer.decode(final_ids, skip_special_tokens=False)
        prompts.append(text)

    return prompts


@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens):
    """Run reranker on queries - MAIN PROFILING TARGET"""

    import vllm
    from vllm import SamplingParams

    # Get use_tqdm setting from benchmark config
    use_tqdm = benchmark_config.get('use_tqdm', True)

    # Create SamplingParams
    sampling_params = SamplingParams(
        max_tokens=1,
        temperature=0.0,
        logprobs=20,
        detokenize=True,
        allowed_token_ids=[token_true_id, token_false_id]
    )

    logger.info(f"SamplingParams configured: max_tokens=1, "
                f"allowed_tokens=[{token_ids['true']}, {token_ids['false']}]")

    # Process each query
    total_processed = 0
    for query_idx, row in enumerate(rows[:num_queries]):
        query = row["query"]

        # Get candidates
        candidates = [
            row[f"answer_{i}"]
            for i in range(search_num)
            if f"answer_{i}" in row
        ]

        # Format query-document pairs
        pairs = [format_instruction(query, doc) for doc in candidates[:search_num]]

        # Build prompts with tokenization
        prompts = build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens)

        # Process in batches
        query_outputs = []
        for s in range(0, len(prompts), batch_size):
            batch_prompts = prompts[s:s + batch_size]
            outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=use_tqdm)
            query_outputs.extend(outputs)

        total_processed += len(query_outputs)

        if query_idx == 0:
            # Show first result for verification
            logger.info(f"Query 1: {query[:80]}...")
            logger.info(f"Generated {len(query_outputs)} scores for "
                       f"{len(candidates[:search_num])} candidates")
            if query_outputs:
                first_output = query_outputs[0]
                logger.info(f"First output: {first_output.outputs[0].text} "
                           f"(token_ids={first_output.outputs[0].token_ids})")

    logger.info(f"Profiling completed: processed {total_processed} reranker pairs")
    return total_processed


def main():
    """Main profiling function"""
    import vllm

    logger.info("Initializing vLLM-Neuron reranker...")
    logger.info(f"Model: {model_path}")
    logger.info(f"Config: block_size={vllm_config['block_size']}, "
               f"max_num_seqs={vllm_config['max_num_seqs']}, "
               f"tensor_parallel_size={vllm_config['tensor_parallel_size']}")

    # Initialize vLLM
    llm = vllm.LLM(model=model_path, **vllm_config)

    # Get tokenizer and token IDs
    tokenizer = llm.get_tokenizer()
    token_false_id = tokenizer.convert_tokens_to_ids(token_ids['false'])
    token_true_id = tokenizer.convert_tokens_to_ids(token_ids['true'])

    logger.info(f"Token IDs: {token_ids['true']}={token_true_id}, "
               f"{token_ids['false']}={token_false_id}")

    # Encode prompt templates
    prefix_tokens = tokenizer.encode(
        reranker_prompts['prefix'], add_special_tokens=False
    )
    suffix_tokens = tokenizer.encode(
        reranker_prompts['suffix'], add_special_tokens=False
    )

    logger.info(f"Prefix tokens: {len(prefix_tokens)}, Suffix tokens: {len(suffix_tokens)}")

    # Run profiling
    logger.info("Starting profiling run...")
    total = run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens)

    logger.info(f"Profiling complete. Processed {total} pairs.")

    # Cleanup
    del llm
    gc.collect()


if __name__ == "__main__":
    main()
````

```yaml:config.yaml
# vLLM-Neuron Reranker Benchmark Configuration

# Model configuration
model:
  # Path to the reranker model
  # Example: "/path/to/models/Qwen3-0.6B-Reranker"
  # Use environment variable: export RERANKER_MODEL_PATH="/your/model/path"
  path: "/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker"

# vLLM-Neuron engine settings
vllm:
  tensor_parallel_size: 2           # Number of NeuronCores
  max_num_seqs: 4                   # Batch size
  block_size: 32                    # KV cache block size (32 for Zenn best case, 128 for stability)
  max_model_len: 2048               # Maximum sequence length
  max_num_batched_tokens: 256       # Performance optimization
  num_gpu_blocks_override: 512      # pa_num_blocks equivalent
  enable_prefix_caching: false      # Explicit disable
  dtype: "bfloat16"                 # Data type

  # Neuron-specific overrides (Zenn article optimal settings)
  additional_config:
    override_neuron_config:
      skip_warmup: true             # Phase 1-5 „ÅÆË®≠ÂÆöÔºàË®ò‰∫ã„Å®‰∏ÄËá¥Ôºâ
      enable_bucketing: true        # ÂãïÁöÑ„Éê„ÉÉ„ÉÅ„É≥„Ç∞ÊúâÂäπ
      pa_num_blocks: 512
      pa_block_size: 32

# Reranker-specific settings
reranker:
  # Input data
  input_file: "input_sample.csv"    # CSV file with queries and candidates

  # Processing parameters
  search_num: 20                    # Number of candidates per query to process
  batch_size: 8                     # Batch size for processing prompts
  max_length: 1500                  # Maximum prompt length

  # Model-specific tokens (for Qwen3-Reranker)
  # Change these for other reranker models
  token_true: "yes"
  token_false: "no"

  # Prompt templates (for Qwen3-Reranker)
  # Customize these for your model
  prefix: |
    <|im_start|>system
    Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be "yes" or "no".<|im_end|>
    <|im_start|>user

  # Note: "assitant" typo is intentional for Qwen3-Reranker compatibility
  suffix: |
    <|im_end|>
    <|im_start|>assitant
    <think>

    </think>


  instruction: "Given a web search query, retrieve relevant passages that answer the query"

# Benchmark settings
benchmark:
  rounds: 5                         # Number of benchmark rounds
  warmup_rounds: 1                  # Number of warmup rounds
  num_test_queries: 10              # Number of queries to use for testing (Ë®ò‰∫ã„Å®Âêå„ÅòÊù°‰ª∂)

# Profiler settings (optional)
profiler:
  # Clear Neuron compilation cache before benchmark
  # WARNING: First run after clearing will recompile (10-15 minutes)
  # Useful when:
  # - Model configuration changed (batch size, sequence length, etc.)
  # - Neuron SDK version changed
  # - Testing clean compilation performance
  clear_cache_before: false

  # Clear cache after benchmark (useful for CI/CD to save disk space)
  clear_cache_after: false
```
::::

„Åì„Çå„Å´„Çà„Çä„ÄÅ**Phase 1 „Å®Âêå„ÅòÊ∏¨ÂÆöÊù°‰ª∂**ÔºàÂêå„Åò config.yaml„ÄÅÂêå„ÅòÂá¶ÁêÜ„É≠„Ç∏„ÉÉ„ÇØÔºâ„ÇíÁ∂≠ÊåÅ„Åó„Å™„Åå„Çâ„ÄÅline_profiler „Å´„Çà„ÇãË©≥Á¥∞„Å™ Python „É¨„Éô„É´„ÅÆÂàÜÊûê„ÅåÂèØËÉΩ„Å´„Å™„Çä„Åæ„Åô„ÄÇ

### 2.1 Ê∏¨ÂÆöÂØæË±°„ÅÆÁêÜËß£

**Ê∏¨ÂÆöÂØæË±°**: 1 „ÇØ„Ç®„É™Ôºà20 ÂÄôË£úÊñáÊõ∏„ÅÆ„É™„É©„É≥„Ç≠„É≥„Ç∞Ôºâ„ÇíÂá¶ÁêÜ„Åô„ÇãÊôÇÈñì

```yaml
reranker:
  search_num: 20        # 1 „ÇØ„Ç®„É™„ÅÇ„Åü„Çä 20 ÂÄôË£úÊñáÊõ∏
  batch_size: 8         # 8 „Éö„Ç¢„Åö„Å§„Éê„ÉÉ„ÉÅÂá¶ÁêÜ

vllm:
  max_num_seqs: 4       # vLLM „ÅÆÂêåÊôÇÂá¶ÁêÜÊï∞
```

```
1  „ÇØ„Ç®„É™ = 20 „Éö„Ç¢ √∑ batch_size=8 = 3 „Éê„ÉÉ„ÉÅ
10 „ÇØ„Ç®„É™ = 30 „Éê„ÉÉ„ÉÅ
ÂêàË®àÊôÇÈñì = 2,992ms ‚Üí 1 „ÇØ„Ç®„É™„ÅÇ„Åü„ÇäÁ¥Ñ 300ms
```

### 2.2 line_profiler Ê∏¨ÂÆöÁµêÊûú

::::details line_profiler „ÅÆÂÆüË°å

**ÂÆüË°åÁí∞Â¢É„ÅÆÊ∫ñÂÇô**:

```bash
# vLLM-Neuron Áí∞Â¢É„Çí„Ç¢„ÇØ„ÉÜ„Ç£„Éô„Éº„Éà
source /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin/activate

# PATH „Å´ Neuron SDK „ÅÆ„ÉÑ„Éº„É´„ÇíËøΩÂä†
export PATH="/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin:$PATH"

# line_profiler „Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà
pip install line-profiler
```

**„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÂÆüË°å**:

```bash
cd /path/to/my-reranker
kernprof -l -v -p vllm.v1.engine profile_line.py
```

:::message
**kernprof „Ç™„Éó„Ç∑„Éß„É≥Ë™¨Êòé**:
- `-l` (--line-by-line): Ë°å„Åî„Å®„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÇíÊúâÂäπÂåñ
- `-v` (--view): ÁµêÊûú„ÇíÂç≥Â∫ß„Å´Ë°®Á§∫
- `-p vllm.v1.engine` (--prof-mod): **vllm.v1.engine „É¢„Ç∏„É•„Éº„É´„ÇíËá™Âãï„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÂØæË±°„Å´ÊåáÂÆö**Ôºà„Åì„ÅÆ„É¢„Ç∏„É•„Éº„É´ÂÜÖ„ÅÆÂÖ®Èñ¢Êï∞„ÇíËá™ÂãïÁöÑ„Å´„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞Ôºâ
:::

ÂÆüË°åÂæå„ÄÅ`profile_line.py.lprof` „Éï„Ç°„Ç§„É´„ÅåÁîüÊàê„Åï„Çå„ÄÅ„Ç≥„É≥„ÇΩ„Éº„É´„Å´Ë©≥Á¥∞„Å™Ë°å„Åî„Å®„ÅÆÂÆüË°åÊôÇÈñì„ÅåË°®Á§∫„Åï„Çå„Åæ„Åô„ÄÇ
::::

‰ª•‰∏ã„Å´ÂÆüÈöõ„Å´ line_profiler „ÅÆÁµêÊûú„Åã„ÇâÂæó„Çâ„Çå„ÅüÊÉÖÂ†±„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ

```python
# llm.generate() - 30 „Éê„ÉÉ„ÉÅÂá¶ÁêÜ
Line 157: outputs = llm.generate(batch_prompts, sampling_params)
  - Hits: 30 batches
  - Time: 3781.560 ms (3.78 Áßí)
  - Per Hit: 126.052 ms/batch
  - % Time: 99.1%

# LLMEngine.step() „ÅÆÂÜÖË®≥
Line 293: outputs = self.engine_core.get_output()
  - Hits: 229 steps (7.6 steps/batch)
  - Time: 3197.372 ms
  - Per Hit: 13.962 ms/step
  - % Time: 95.3%
```

line_profiler „Å´„Çà„ÇãÊ∏¨ÂÆö„ÅÆÁµêÊûú„ÄÅ10 „ÇØ„Ç®„É™Ôºà30 „Éê„ÉÉ„ÉÅÔºâ„ÅÆÂá¶ÁêÜ„Å´ÂêàË®à 3.78 Áßí„Åã„Åã„Çä„ÄÅ„Åù„ÅÆ„ÅÜ„Å° `llm.generate()` „ÅÆÂëº„Å≥Âá∫„Åó„Å†„Åë„Åß **99.1%Ôºà3.78 ÁßíÔºâ** „ÇíÂç†„ÇÅ„Çã„Åì„Å®„ÅåÂà§Êòé„Åó„Åæ„Åó„Åü„ÄÇÁ¥Ñ 3 Áßí„Åã„ÇâÊôÇÈñì„ÅåÂ¢ó„Åà„Å¶„ÅÑ„Çã„ÅÆ„ÅØ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Åß„Åô„ÄÇ

„Åï„Çâ„Å´ÈáçË¶Å„Å™Áô∫Ë¶ã„Å®„Åó„Å¶„ÄÅ**1 „Éê„ÉÉ„ÉÅ„ÅÇ„Åü„Çä„ÅÆÂá¶ÁêÜÊôÇÈñì„Åå 126.052ms** „Å®„ÅÑ„ÅÜÊ∏¨ÂÆöÂÄ§„ÅåÂæó„Çâ„Çå„Åæ„Åó„Åü„ÄÇ„Åü„Å†„Åó„ÄÅ„Åì„ÅÆÂÄ§„ÅØ **„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„ÇíÂê´„ÇÄ** „Åü„ÇÅ„ÄÅPhase 3 „ÅßÁ¥îÁ≤ã„Å™„Éô„É≥„ÉÅ„Éû„Éº„ÇØÊ∏¨ÂÆö„ÇíÂà•ÈÄîÂÆüÊñΩ„Åó„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅvLLM „ÅÆÂÜÖÈÉ®Âá¶ÁêÜ„ÇíË¶ã„Çã„Å®„ÄÅ`LLMEngine.step()` „Åå 229 ÂõûÂëº„Å∞„Çå„Å¶„Åä„Çä„ÄÅ30 „Éê„ÉÉ„ÉÅ„Å´ÂØæ„Åó„Å¶ **Âπ≥Âùá 7.6 steps/batch** „Å®„ÅÑ„ÅÜË¨é„ÅÆÂÄ§„ÅåË¶≥Ê∏¨„Åï„Çå„Åæ„Åó„Åü„ÄÇ„Å™„Åú 1 „Éê„ÉÉ„ÉÅ„ÅÆÂá¶ÁêÜ„Å´ 7.6 Âõû„ÇÇ„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÅåÂøÖË¶Å„Å™„ÅÆ„Åã„ÄÅ„Åì„ÅÆÊôÇÁÇπ„Åß„ÅØÁêÜËß£„Åß„Åç„Å¶„ÅÑ„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ

### 2.3 7.6 steps/batch „ÅÆÁêÜÁî±„ÇíËøΩ„ÅÜ

„Åì„ÅÆÊï∞ÂÄ§„ÅÆËß£Êòé„Åô„Çã„Åü„ÇÅ„ÄÅ`LLMEngine.step()` „ÅÆ‰∏≠Ë∫´„Çí„Åï„Çâ„Å´Ë©≥„Åó„ÅèË™ø„Åπ„Åæ„Åó„Åü„ÄÇline_profiler „ÅÆ `-p vllm.v1.engine` „Ç™„Éó„Ç∑„Éß„É≥„Å´„Çà„Çä„ÄÅvLLM ÂÜÖÈÉ®„ÅÆ„Ç≥„Éº„Éâ„ÇÇËá™Âãï„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

`LLMEngine.step()` „ÅÆÂá¶ÁêÜÊôÇÈñì„ÅÆ„Åª„ÅºÂÖ®„Å¶Ôºà95.3%Ôºâ„Åå `engine_core.get_output()` „Å®„ÅÑ„ÅÜÂçò‰∏Ä„ÅÆÈñ¢Êï∞Âëº„Å≥Âá∫„Åó„ÅßË≤ª„ÇÑ„Åï„Çå„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ„Åï„Çâ„Å´„Åù„ÅÆ `get_output()` Èñ¢Êï∞„ÅÆ‰∏≠Ë∫´„ÇíË¶ã„Çã„Å®„ÄÅ**100% „Åå `outputs_queue.get()` „Å®„ÅÑ„ÅÜ„Ç≠„É•„Éº„Åã„Çâ„ÅÆ„Éá„Éº„ÇøÂèñÂæóÂá¶ÁêÜ**„Åß„Åó„Åü„ÄÇ

```python
# LLMEngine.step() „ÅÆ‰∏≠Ë∫´
Line 293: outputs = self.engine_core.get_output()
  - Time: 3197.372 ms (95.3% of step())

# get_output() „ÅÆ‰∏≠Ë∫´
Line 715: outputs = self.outputs_queue.get()
  - Time: 3194.6 ms
  - % Time: 100.0% of get_output()
```

„Å§„Åæ„Çä„ÄÅ„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„ÅØ `outputs_queue.get()` „Åß„Ç≠„É•„Éº„Åã„ÇâÁµêÊûú„ÅåÈÄÅ„Çâ„Çå„Å¶„Åè„Çã„ÅÆ„Çí„Åü„Å†**ÂæÖ„Å£„Å¶„ÅÑ„Çã„Å†„Åë**„Åß„Åó„Åü„ÄÇ„Åì„Çå„ÅØÂÆüÈöõ„ÅÆÊé®Ë´ñÂá¶ÁêÜ„ÅåÂà•„Éó„É≠„Çª„Çπ„ÅßË°å„Çè„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÇíÊÑèÂë≥„Åó„Åæ„Åô„ÄÇ„Åì„Åì„Åß vLLM v1 „ÅÆ„Éû„É´„ÉÅ„Éó„É≠„Çª„Çπ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÂ≠òÂú®„ÇíÊÄù„ÅÑÂá∫„Åó„Åæ„Åó„Åü„ÄÇ

Ôºà‰ª•‰∏ã„ÅÆË®ò‰∫ã„Å´ÂÜÖÈÉ®„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆËß£Ë™¨„Åå„ÅÇ„Çä„Åæ„ÅôÔºâ

https://zenn.dev/tosshi/articles/f64ba0b86e330b

vLLM v1 „Åß„ÅØ„ÄÅ„É™„ÇØ„Ç®„Çπ„Éà„ÇíÂèó„ÅëÂèñ„Çã„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„Å®„ÄÅÂÆüÈöõ„Å´Êé®Ë´ñ„ÇíÂÆüË°å„Åô„Çã Worker „Éó„É≠„Çª„Çπ„ÅåÂàÜÈõ¢„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„ÅØ `llm.generate()` „ÇíÂëº„Å≥Âá∫„Åô„Å®„ÄÅ„É™„ÇØ„Ç®„Çπ„Éà„Çí Worker „Éó„É≠„Çª„Çπ„Å´ÈÄÅ‰ø°„Åó„ÄÅ`outputs_queue.get()` „Åß„Éñ„É≠„ÉÉ„ÇØ„Åó„Å¶ÁµêÊûú„ÇíÂæÖ„Å°„Åæ„Åô„ÄÇ‰∏ÄÊñπ„ÄÅWorker „Éó„É≠„Çª„Çπ„ÅØ NeuronCore „Åß„ÅÆÊé®Ë´ñÂÆüË°å„ÄÅÁµêÊûú„ÅÆ„Ç∑„É™„Ç¢„É©„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÄÅ„Åù„Åó„Å¶„Éó„É≠„Çª„ÇπÈñìÈÄö‰ø°„ÇíÈÄö„Åò„Å¶„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„Å´ÁµêÊûú„ÇíËøî„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆÊßãÈÄ†„ÇíÂõ≥Á§∫„Åô„Çã„Å®‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ

**vLLM v1 „ÅÆ„Éû„É´„ÉÅ„Éó„É≠„Çª„Çπ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ (vllm-neuron)**

```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    subgraph MainProcess["Main Process"]
        A[LLMEngine.step] --> B[get_output]
        B --> C[outputs_queue.get<br/>13.962 ms/step]
    end

    subgraph WorkerProcess["Worker Process"]
        D[EngineCore] --> E[execute_model]
        E --> F[Neuron ÂÆüË°å]
        F --> G[„Ç∑„É™„Ç¢„É©„Ç§„Çº„Éº„Ç∑„Éß„É≥]
        G --> H[ZMQ ÈÄÅ‰ø°]
    end

    H -->|IPC| C

    style MainProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style WorkerProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style C fill:#0f3460,stroke:#16213e,color:#fff
    style F fill:#0f3460,stroke:#16213e,color:#fff
```

line_profiler „ÅØ Python „ÅÆÊ®ôÊ∫ñÁöÑ„Å™„Éó„É≠„Éï„Ç°„Ç§„É©„Å®ÂêåÊßò„Å´„ÄÅ**ÂÆüË°å‰∏≠„ÅÆ„Éó„É≠„Çª„Çπ„ÅÆ„Ç≥„Éº„Éâ„Åó„ÅãÊ∏¨ÂÆö„Åß„Åç„Åæ„Åõ„Çì**„ÄÇ„Å§„Åæ„Çä„ÄÅWorker „Éó„É≠„Çª„Çπ„ÅßÂÆüË°å„Åï„Çå„Çã `execute_model()` „ÇÑ NeuronCore „Åß„ÅÆÊé®Ë´ñÂá¶ÁêÜ„ÅØ„ÄÅ„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„Åã„ÇâË¶ã„Çã„Å®„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ„Åß„Åô„ÄÇ

Ê∏¨ÂÆö„Åß„Åç„Åü„ÅÆ„ÅØ `outputs_queue.get()` „ÅßÂæÖÊ©ü„Åó„Å¶„ÅÑ„ÇãÊôÇÈñìÔºà13.962ms/stepÔºâ„Å†„Åë„Åß„ÅÇ„Çä„ÄÅ„Åì„ÅÆÊôÇÈñì„Å´„ÅØÊé®Ë´ñ„ÄÅIPC „Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Å™„Å©„ÅÆ„Åô„Åπ„Å¶„ÅÆÊôÇÈñì„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

„Åß„ÅØ„ÄÅ„Å™„Åú 1 „Éê„ÉÉ„ÉÅ„ÅÆÂá¶ÁêÜ„Å´Âπ≥Âùá 7.6 Âõû„ÇÇ `step()` „ÅåÂëº„Å∞„Çå„Çã„ÅÆ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ„Åì„Çå„ÅØ vLLM v1 „ÅÆ„Ç§„Éô„É≥„Éà„É´„Éº„Éó„ÅÆÂãï‰ΩúÊñπÊ≥ï„Å®„Åó„Å¶„É°„Ç§„É≥„Éó„É≠„Çª„Çπ„Åå‰ΩïÂ∫¶„ÇÇ `step()` „ÇíÁ¢∫Ë™ç„Åó„Å¶„Ç≠„É•„Éº„Çí„ÉÅ„Çß„ÉÉ„ÇØ„ÅóÁ∂ö„Åë„Å¶„ÅÑ„Çã„Åã„Çâ„Åß„Åô„ÄÇ1 „Éê„ÉÉ„ÉÅ„ÅÇ„Åü„ÇäÂπ≥Âùá„Åó„Å¶ 7.6 Âõû„Ç≠„É•„Éº„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶„ÅÑ„Åü„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„Åô„ÄÇ

Ë¨é„ÅØËß£„Åë„Åæ„Åó„Åü„Åå„ÄÅËÇùÂøÉ„ÅÆ **Worker „Éó„É≠„Çª„ÇπÂÜÖ„Åß„ÅÆ NeuronCore „ÅÆÊé®Ë´ñÂá¶ÁêÜÊôÇÈñì**„ÇíÂàÜËß£„Åô„Çã„Åì„Å®„ÅØ„Åß„Åç„Åæ„Åõ„Çì„ÄÇ`outputs_queue.get()` „ÅÆ 13.962 ms „Å´„ÅØ„ÄÅÊé®Ë´ñÂÆüË°å„ÄÅ„Ç∑„É™„Ç¢„É©„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÄÅIPC ÈÄö‰ø°„ÅÆ„Åô„Åπ„Å¶„ÅåÂê´„Åæ„Çå„Å¶„Åä„Çä„ÄÅline_profiler „Åß„ÅØ„Åì„Çå‰ª•‰∏äÂàÜËß£„Çí„Åô„Çã„ÅÆ„ÅØÈõ£„Åó„Åù„ÅÜ„Åß„Åô„ÄÇ

:::message alert
**‰ªäÂõû„ÅÆÈÅé„Å°„Åã„Çâ„ÅÆÂ≠¶„Å≥**: line_profiler „Åß„ÅØ„Éû„É´„ÉÅ„Éó„É≠„Çª„Çπ„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Å´ÈôêÁïå„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÁêÜËß£„Åó„Åü‰∏ä„ÅßÊ¨≤„Åó„ÅÑÊÉÖÂ†±„ÇíÂèñÂæó„Åß„Åç„Çã„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÉÑ„Éº„É´„ÇíÈÅ∏ÂÆö„Åó„ÅüÊñπ„ÅåËâØ„ÅÑ„ÄÇpy-spy „ÅØ Worker ÂÅ¥„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Åæ„ÅßÂÆüÊñΩ„Åß„Åç„Åæ„Åô„ÄÇ
:::

### 2.4 Ê∏¨ÂÆö„ÅÆÈôêÁïå„Å®‰ªäÂæå„ÅÆÊñπÂêëÊÄß

line_profiler „Å´„Çà„ÇãÊ∏¨ÂÆö„ÅßÂà§Êòé„Åó„Åü„Åì„Å®„ÇíÊï¥ÁêÜ„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™ÊßãÈÄ†„Å´„Å™„Çä„Åæ„Åô„ÄÇÂÖ®‰Ωì„Å®„Åó„Å¶ 126.052 ms/batch „Å®„ÅÑ„ÅÜÂá¶ÁêÜÊôÇÈñìÔºà„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâËæº„ÅøÔºâ„ÅØÊ∏¨ÂÆö„Åß„Åç„Åæ„Åó„Åü„Åå„ÄÅ„Åù„ÅÆÂÜÖË®≥„ÅÆÂ§ßÈÉ®ÂàÜÔºà84.2%Ôºâ„ÅÆË©≥Á¥∞„Åå‰∏çÊòé„Å®„ÅÑ„ÅÜÁä∂Ê≥Å„Åß„Åô„ÄÇ

„Åì„ÅÆÁä∂Ê≥Å„ÇíÊâìÈñã„Åô„Çã„Åü„ÇÅ„ÄÅ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„ÇíÂê´„Åæ„Å™„ÅÑÁ¥îÁ≤ã„Å™„Éô„É≥„ÉÅ„Éû„Éº„ÇØÊ∏¨ÂÆö„Å®„ÄÅNxD Inference „ÇíÁõ¥Êé•‰Ωø„Å£„ÅüÊ∏¨ÂÆö„ÇíË©¶„Åø„Åæ„Åó„Åü„ÄÇ
## Phase 3: NxD Inference Ê∏¨ÂÆö

Worker „Éó„É≠„Çª„Çπ„ÅÆÁõ¥Êé•Ê∏¨ÂÆö„ÅåÂõ∞Èõ£„Å™„Åü„ÇÅ„ÄÅ**vLLM „Çí‰Ωø„Çè„Åö„Å´ NxD Inference „ÇíÁõ¥Êé•‰ΩøÁî®**„Åó„Å¶Á¥îÁ≤ã„Å™Êé®Ë´ñÂÆüË°åÊôÇÈñì„ÇÇÊ∏¨ÂÆö„Åô„Çã„Åì„Å®„Å´„Åó„Åæ„Åó„Åü„ÄÇ„Åæ„Åü„ÄÅBucketing „Å® Prefix Caching „ÅÆÂÖ®ÁµÑ„ÅøÂêà„Çè„Åõ„ÇíÊ∏¨ÂÆö„Åó„Åæ„Åó„Åü„ÄÇ

:::message alert
**Phase 1-2 „Å®„ÅÆÊ∏¨ÂÆöÊñπÊ≥ï„ÅÆÈÅï„ÅÑ„Å´„Å§„ÅÑ„Å¶:**

Phase 1-2 „Åß„ÅØ‰∏ª„Å´„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÊâãÊ≥ï„ÅÆÊ§úË®º„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„Å¶„Åä„Çä„ÄÅÂÆöÈáèÁöÑ„Å™ÊÄßËÉΩÂÄ§„ÅÆÊ∏¨ÂÆöÁ≤æÂ∫¶„ÅØ Phase 3 „ÅåÊúÄ„ÇÇÈ´ò„Åè„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ

- **Phase 1**: Neuron Profiler „Å´„Çà„ÇãË©¶Ë°åÈåØË™§Ôºà„Éè„Éº„Éâ„Ç¶„Çß„Ç¢„É¨„Éô„É´Ôºâ
- **Phase 2**: line_profiler ÂàÜÊûêÔºà„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâËæº„Åø„ÄÅ126.052 ms/batchÔºâ
- **Phase 3**: Á¥îÁ≤ã„Å™„Éô„É≥„ÉÅ„Éû„Éº„ÇØÊ∏¨ÂÆöÔºà„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâËªΩÂæÆ„ÄÅÁµ±‰∏ÄÊù°‰ª∂Ôºâ

Phase 3 „Åß„ÅØÂÖ®„Éë„Çø„Éº„É≥„Åß‰ª•‰∏ã„ÅÆÊù°‰ª∂„ÇíÁµ±‰∏Ä„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ
- Ê∏¨ÂÆö„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥: 100 ÂõûÔºà„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó 3 ÂõûÂæåÔºâ
- Áµ±‰∏Ä vLLM Ë®≠ÂÆöÔºàmax_num_batched_tokens=256, num_gpu_blocks_override=512Ôºâ
- Âêå‰∏Ä„ÅÆ„Éó„É≠„É≥„Éó„Éà„Å®„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫

Phase 1-2 „ÅÆÂÆüÈ®ìÁµêÊûú„ÅØ„Äå„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÊâãÊ≥ï„ÅÆÊúâÁî®ÊÄßÊ§úË®º„Äç„Å®„Åó„Å¶ÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ**ÂÆöÈáèÁöÑ„Å™ÊÄßËÉΩÊØîËºÉ„Å´„ÅØ Phase 3 „ÅÆÁµêÊûú„Çí‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ**
:::

### 3.0 Ê∏¨ÂÆöÁµêÊûú„Çµ„Éû„É™„ÉºÔºàÂÖ® 16 „Éë„Çø„Éº„É≥Ôºâ

‰ª•‰∏ã„ÅÆË°®„ÅØ„ÄÅNxD Inference „Å® vllm-neuron „ÅÆ‰∏°Êñπ„Åß„ÄÅBucketing ON/OFF„ÄÅPrefix Caching ON/OFF„ÄÅÂõ∫ÂÆöÈï∑Ôºà97 „Éà„Éº„ÇØ„É≥Ôºâ/ ÂèØÂ§âÈï∑Ôºà81-126 „Éà„Éº„ÇØ„É≥Ôºâ„ÄÅ„ÅÆÂÖ®ÁµÑ„ÅøÂêà„Çè„Åõ„Åß„Åô„ÄÇ

| No | Áí∞Â¢É | Bucketing | Prefix Caching | „ÉØ„Éº„ÇØ„É≠„Éº„Éâ | Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ (ms) | BucketingÂäπÊûú |
|----|---------|-----------|----------------|------------|-------------------|-------------|
| |
| 01 | NxD | OFF | OFF | Âõ∫ÂÆöÈï∑ | **196.56** | - |
| 02 | NxD | ON | OFF | Âõ∫ÂÆöÈï∑ | **188.97** | -3.9% |
| 03 | NxD | OFF | ON | Âõ∫ÂÆöÈï∑ | - | - |
| 04 | NxD | ON | ON | Âõ∫ÂÆöÈï∑ | - | - |
| 09 | vLLM | OFF | OFF | Âõ∫ÂÆöÈï∑ | **252.42** | - |
| 10 | vLLM | ON | OFF | Âõ∫ÂÆöÈï∑ | **59.23** | -76.5% |
| 11 | vLLM | OFF | ON | Âõ∫ÂÆöÈï∑ | **237.54** | - |
| 12 | vLLM | ON | ON | Âõ∫ÂÆöÈï∑ | **85.92** | - |
| |
| 05 | NxD | OFF | OFF | ÂèØÂ§âÈï∑ | **194.73** | - |
| 06 | NxD | ON | OFF | ÂèØÂ§âÈï∑ | **20.42** | **-89.5%** |
| 07 | NxD | OFF | ON | ÂèØÂ§âÈï∑ | - | - |
| 08 | NxD | ON | ON | ÂèØÂ§âÈï∑ | - | - |
| 13 | vLLM | OFF | OFF | ÂèØÂ§âÈï∑ | **254.80** | - |
| 14 | vLLM | ON | OFF | ÂèØÂ§âÈï∑ | **60.62** | **-76.2%** |
| 15 | vLLM | OFF | ON | ÂèØÂ§âÈï∑ | **239.24** | - |
| 16 | vLLM | ON | ON | ÂèØÂ§âÈï∑ | **85.28** | **-64.4%** |

### 3.1 Bucketing „ÅÆÂäπÊûú

#### Bucketing OFF ÊôÇ„ÅÆÊåôÂãï

| No | Áí∞Â¢É | Bucketing | Prefix Caching | „ÉØ„Éº„ÇØ„É≠„Éº„Éâ | Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ (ms) | BucketingÂäπÊûú |
|----|------|-----------|----------------|------------|-------------------|---------------|
| |
| 01 | NxD | OFF | OFF | Âõ∫ÂÆöÈï∑ | **196.56** | - |
| 09 | vLLM | OFF | OFF | Âõ∫ÂÆöÈï∑ | **252.42** | +326% |
| |
| 05 | NxD | OFF | OFF | ÂèØÂ§âÈï∑ | **194.73** | -0.9% |
| 13 | vLLM | OFF | OFF | ÂèØÂ§âÈï∑ | **254.80** | - |

„Åæ„ÅöÁ¨¨‰∏Ä„Å´„Çè„Åã„Çä„ÇÑ„Åô„ÅèËÄÉÂØü„Åß„Åç„ÇãÁÇπ„Åã„ÇâÁ¢∫Ë™ç„Åó„Åæ„Åô„ÄÇNo.01 „Å® No.05„ÄÅNo.09 „Å® No.13 „ÇíË¶ã„Å¶„Åø„Çã„Å®„ÄÅNxD/vLLM„ÄÅÂõ∫ÂÆöÈï∑/ÂèØÂ§âÈï∑„Å´„Çà„Çâ„Åö `Bucketing=OFF` „ÅÆÂ†¥Âêà„ÅØÁµêÊûú„ÅØ„Åª„ÅºÂ§â„Çè„Çä„Åæ„Åõ„Çì„ÄÇOFF „ÅÆÂ†¥Âêà„ÅØÂçò‰∏Ä„ÅÆ NEFF „ÅåÁîüÊàê„Åï„Çå„ÄÅNeuronCore „ÅåÂ∏∏„Å´Âêå„Åò NEFF „Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÉØ„Éº„ÇØ„É≠„Éº„Éâ„ÅåÂõ∫ÂÆö„Åß„ÅÇ„Çç„ÅÜ„Å®ÂèØÂ§â„Åß„ÅÇ„Çç„ÅÜ„Å®„Åª„ÅºÂêå„ÅòÁµêÊûú„Å´„Å™„Çä„Åæ„Åô„ÄÇ

#### NxD „Å® vLLM „ÅÆ Bucketing ÊåôÂãï„ÅÆÈÅï„ÅÑ

| No | Áí∞Â¢É | Bucketing | Prefix Caching | „ÉØ„Éº„ÇØ„É≠„Éº„Éâ | Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ (ms) | BucketingÂäπÊûú |
|----|------|-----------|----------------|------------|-------------------|---------------|
| |
| 01 | NxD | OFF | OFF | Âõ∫ÂÆöÈï∑ | **196.56** | - |
| 02 | NxD | ON | OFF | Âõ∫ÂÆöÈï∑ | **188.97** | -3.9% |
| 09 | vLLM | OFF | OFF | Âõ∫ÂÆöÈï∑ | **252.42** | +326% |
| 10 | vLLM | ON | OFF | Âõ∫ÂÆöÈï∑ | **59.23** | -76.5% |

Ê¨°„Å´Âõ∫ÂÆöÈï∑„Å´„Åä„ÅÑ„Å¶ Bucketing „ÇíÊúâÂäπ„Å´„Åó„ÅüÂ†¥Âêà„ÅÆÈÅï„ÅÑ„ÇíË¶ã„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇNo.01 „Å® No.02 „Åå **Bucketing „ÇíÊúâÂäπ„Å´„Åó„ÅüÂ†¥Âêà„Åß„ÇÇ„Åª„ÅºÁµêÊûú„Å´Â∑Æ„Åå„Å™„ÅÑ**„Å´„ÇÇÈñ¢„Çè„Çâ„Åö„ÄÅNo.09 „Å® No.10 „Åß„ÅØÂõ∫ÂÆöÈï∑„Å´„ÇÇÈñ¢„Çè„Çâ„ÅöÂ§ßÂπÖ„Å™„É¨„Ç§„ÉÜ„É≥„Ç∑ÂâäÊ∏õ„ÇíÊûú„Åü„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„Å™„Åú„Åß„Åó„Çá„ÅÜ„ÅãÔºü

Á´ØÁöÑ„Å´ No.01 „Å® No.02 „ÅÆÁµêÊûú„Å´Â∑Æ„Åå„Å™„Åã„Å£„ÅüÁêÜÁî±„ÅØ„ÄÅ`--benchmark` „Å®„ÅÑ„ÅÜ NxD Inference „Åß‰∏é„Åà„ÇãÂºïÊï∞„ÅÆÂÆüË£Ö‰∏ä„ÅÆÈùûÊòéÁ§∫ÁöÑ„Å™Âà∂Á¥Ñ„Å´„Çà„Çã„ÇÇ„ÅÆ„Åß„Åó„Åü„ÄÇ

::::details No.01 „Å® No.02 „ÅÆÂπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑„Å´Â∑Æ„Åå„Å™„Åã„Å£„ÅüÁêÜÁî±

:::message alert
Á´ØÁöÑ„Å´ÁµêË´ñ„ÇíËø∞„Åπ„Çã„Å®„ÄÅ`--benchmark` „Éï„É©„Ç∞„ÅÆÂÆüË£Ö„Å´„Çà„ÇäÂ∏∏„Å´ `max_context_length`Ôºà2048 „Éà„Éº„ÇØ„É≥Ôºâ„ÅÆ„ÉÄ„Éü„ÉºÂÖ•Âäõ„ÅåÁîüÊàê„Åï„Çå„Å¶„ÅÑ„Åü„Åü„ÇÅ„ÄÅBucketing ON „Åß„ÇÇ Bucketing OFF „Åß„ÇÇÂêå„Åò 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ
:::

## `--benchmark` „Éï„É©„Ç∞„ÅÆÂÆüË£Ö

neuronx-distributed-inference „É©„Ç§„Éñ„É©„É™„ÅÆ `benchmark.py` „Å´„Åä„ÅÑ„Å¶„ÄÅ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÅåÂïèÈ°å„ÅÆ„Åß„Åó„Åü„ÄÇ

```python
def get_sample_inputs(model_type, config: InferenceConfig, sampling_params, image=False):
    max_context_length = neuron_config.max_context_length
    input_length = max_context_length  # Â∏∏„Å´ 2048 „Éà„Éº„ÇØ„É≥
```

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/utils/benchmark.py#L206-L217

„Åì„ÅÆÂÆüË£Ö„Å´„Çà„Çä„ÄÅ`--benchmark` „Éï„É©„Ç∞„Çí‰ΩøÁî®„Åó„ÅüÊ∏¨ÂÆö„Åß„ÅØÂÆüÈöõ„ÅÆ„Éó„É≠„É≥„Éó„ÉàÈï∑ÔºàÊú¨Ë™øÊüª„Åß„ÅØ 94 „Éà„Éº„ÇØ„É≥Ôºâ„Å´Èñ¢„Çè„Çâ„ÅöÂ∏∏„Å´ 2048 „Éà„Éº„ÇØ„É≥„ÅÆ„ÉÄ„Éü„ÉºÂÖ•Âäõ„ÅåÁîüÊàê„Åï„Çå„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ

## Bucketing „ÅÆ„Éê„Ç±„ÉÉ„ÉàÈÅ∏Êäû„É°„Ç´„Éã„Ç∫„É†

Bucketing „ÅåÊúâÂäπ„Å™Â†¥Âêà„ÄÅ`model_wrapper.py` „Å´ÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Çã `get_target_bucket()` „É°„ÇΩ„ÉÉ„Éâ„ÅåÂÆüË°å„Åï„Çå„Åæ„Åô„ÄÇ

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/models/model_wrapper.py#L1015-L1037

„Åì„ÅÆ first_fit Êà¶Áï•„Åß„ÅØ„ÄÅÂÖ•ÂäõÈï∑„Çà„ÇäÂ§ß„Åç„ÅÑÊúÄÂàù„ÅÆ„Éê„Ç±„ÉÉ„Éà„ÇíÈÅ∏Êäû„Åó„Åæ„Åô„ÄÇ„Åó„Åã„Åó 2048 „Éà„Éº„ÇØ„É≥„ÅÆÂÖ•Âäõ„Å´ÂØæ„Åó„Å¶„ÅØ„ÄÅÊúÄÂ§ß„Éê„Ç±„ÉÉ„ÉàÔºà2048 „Éà„Éº„ÇØ„É≥Ôºâ„ÅåÈÅ∏Êäû„Åï„Çå„Åæ„Åô„ÄÇ

## No.01 „Å® No.02 „ÅßÂêå„ÅòÁµêÊûú„Å´„Å™„Å£„ÅüÁêÜÁî±

```
No.01 (Bucketing OFF):
  ‚Üí Âçò‰∏Ä„ÅÆ 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà‰ΩøÁî®
  ‚Üí „Éë„Éá„Ç£„É≥„Ç∞Èáè: 2048 - 2048 = 0 „Éà„Éº„ÇØ„É≥
  ‚Üí Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑: 196.56 ms

No.02 (Bucketing ON):
  ‚Üí „ÉÄ„Éü„ÉºÂÖ•Âäõ: 2048 „Éà„Éº„ÇØ„É≥
  ‚Üí get_target_bucket(2048) ‚Üí 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„ÉàÈÅ∏Êäû
  ‚Üí „Éë„Éá„Ç£„É≥„Ç∞Èáè: 2048 - 2048 = 0 „Éà„Éº„ÇØ„É≥
  ‚Üí Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑: 188.97 msÔºà„Åª„ÅºÂêå„ÅòÔºâ
```

‰∏°ËÄÖ„Å®„ÇÇÂêå„Åò 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åü„Åü„ÇÅ„ÄÅBucketing „ÅÆÂäπÊûú„ÅåÁèæ„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇÁ¥Ñ 3.9% „ÅÆÂ∑Æ„ÅØ Bucketing „Å´„Çà„Çã„Ç∞„É©„ÉïÈÅ∏Êäû„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Å™„Å©„ÄÅÂâØÊ¨°ÁöÑ„Å™Ë¶ÅÂõ†„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ

## ÂÆüÈöõ„ÅÆ„Éó„É≠„É≥„Éó„ÉàÔºà94 „Éà„Éº„ÇØ„É≥Ôºâ„Åß„ÅÆÊ∏¨ÂÆöÁµêÊûú

„Åì„ÅÆÂïèÈ°å„ÇíÁô∫Ë¶ã„Åó„ÅüÂæå„ÄÅ`--benchmark` „Éï„É©„Ç∞„Çí‰Ωø„Çè„ÅöÂÆüÈöõ„ÅÆ 94 „Éà„Éº„ÇØ„É≥„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÅßÂÜçÊ∏¨ÂÆö„ÇíÂÆüÊñΩ„Åó„Åæ„Åó„Åü„ÄÇ

```
No.01 (Bucketing OFF, ÂÆü„Éó„É≠„É≥„Éó„Éà):
  ‚Üí 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà‰ΩøÁî®
  ‚Üí „Éë„Éá„Ç£„É≥„Ç∞Èáè: 2048 - 94 = 1954 „Éà„Éº„ÇØ„É≥
  ‚Üí Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑: 211.29 ms

No.02 (Bucketing ON, ÂÆü„Éó„É≠„É≥„Éó„Éà):
  ‚Üí get_target_bucket(94) ‚Üí 128 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„ÉàÈÅ∏Êäû
  ‚Üí „Éë„Éá„Ç£„É≥„Ç∞Èáè: 128 - 94 = 34 „Éà„Éº„ÇØ„É≥
  ‚Üí Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑: 13.36 ms
  ‚Üí ÊîπÂñÑÁéá: 93.7%Ôºà15.8 ÂÄçÈ´òÈÄüÂåñÔºâ
```

ÂÆüÈöõ„ÅÆ„Éó„É≠„É≥„Éó„Éà„Çí‰ΩøÁî®„Åó„ÅüÂ†¥Âêà„ÄÅBucketing ON „Åß„ÅØ 128 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà„ÅåÈÅ∏Êäû„Åï„Çå„ÄÅ**93.7% „ÅÆÊîπÂñÑ**„Å®„ÅÑ„ÅÜÂäáÁöÑ„Å™ÊÄßËÉΩÂêë‰∏ä„ÅåÁ¢∫Ë™ç„Åï„Çå„Åæ„Åó„Åü„ÄÇ„Éë„Éá„Ç£„É≥„Ç∞Èáè„Åå 1954 „Éà„Éº„ÇØ„É≥„Åã„Çâ 34 „Éà„Éº„ÇØ„É≥„Å´ÂâäÊ∏õ„Åï„Çå„Åü„Åì„Å®Ôºà57 ÂÄç„ÅÆÂâäÊ∏õÔºâ„Åå„ÄÅ„Åì„ÅÆÂ§ßÂπÖ„Å™ÊÄßËÉΩÂêë‰∏ä„ÅÆ‰∏ªË¶ÅÂõ†„Åß„Åô„ÄÇ

## `--benchmark` „Éï„É©„Ç∞„ÅÆË®≠Ë®àÊÑèÂõ≥„Å®ÈôêÁïå

:::message alert
**Áü•Ë¶ã**: `--benchmark` „Éï„É©„Ç∞„ÅØ‰∏ÄÂÆö„ÅÆÂÖ•ÂäõÈï∑„Åß„ÅÆ„Çπ„É´„Éº„Éó„ÉÉ„Éà„ÇÑ„É¨„Ç§„ÉÜ„É≥„Ç∑„ÇíÊ∏¨ÂÆö„Åô„ÇãÁî®ÈÄî„ÇíÊÉ≥ÂÆö„Åó„Å¶Ë®≠Ë®à„Åï„Çå„Å¶„Åä„Çä„ÄÅÂãïÁöÑ„Å™ÂÖ•ÂäõÈï∑„Å´ÂØæ„Åô„ÇãÊÄßËÉΩË©ï‰æ°„Å´„ÅØÈÅ©„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇBucketing „ÅÆ„Çà„ÅÜ„Å´ÂÖ•ÂäõÈï∑„Å´Âøú„Åò„Å¶ÂãïÁöÑ„Å´ÊúÄÈÅ©Âåñ„ÅåË°å„Çè„Çå„ÇãÊ©üËÉΩ„ÇíË©ï‰æ°„Åô„ÇãÂ†¥Âêà„ÅØ„ÄÅÂÆüÈöõ„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÇíÁî®„ÅÑ„ÅüÊ∏¨ÂÆö„ÅåÂøÖÈ†à„Å®„Å™„Çä„Åæ„Åô„ÄÇ
:::

::::


::::details NxD Inference „ÅÆ„É©„Ç§„Éñ„É©„É™ÂïèÈ°å„ÅÆÁô∫Ë¶ã„Å®‰øÆÊ≠£

`--benchmark` „ÇíÂ§ñ„Åó„Å¶ÂÆüÈöõ„ÅÆ„Éó„É≠„É≥„Éó„Éà„Åß„ÅÆÊ∏¨ÂÆö„ÇíË©¶„Åø„ÅüÈöõ„Å´„ÄÅNeuron SDK 2.27.0 „ÅßÂ∞éÂÖ•„Åï„Çå„Åü tensor_replacement Ê©üËÉΩ„Å´Èñ¢ÈÄ£„Åô„ÇãÂÆüË£Ö„Éê„Ç∞„ÇíÁô∫Ë¶ã„Åó„Åæ„Åó„Åü„ÄÇ

## Áô∫Ë¶ã„Åï„Çå„Åü„Éê„Ç∞

[`hf_adapter.py`](https://github.com/aws-neuron/neuronx-distributed-inference/blob/v0.7.14366/src/neuronx_distributed_inference/utils/hf_adapter.py#L289-L300) „Å´„Åä„ÅÑ„Å¶„ÄÅ‰ª•‰∏ã„ÅÆ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ

```
TypeError: NeuronBaseForCausalLM.forward() got an unexpected keyword argument 'tensor_capture_hook'
```

## „Éê„Ç∞„ÅÆË©≥Á¥∞

`hf_adapter.py` „Åß `tensor_capture_hook` ÂÄ§„Çí„ÄÅ`model_inputs` ËæûÊõ∏„Å´ËøΩÂä†„Åï„Çå„Åæ„Åô„ÄÇ

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/utils/hf_adapter.py#L289-L300

„Åó„Åã„Åó `model_base.py` „ÅßÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„Çã `NeuronBaseForCausalLM.forward()` „É°„ÇΩ„ÉÉ„Éâ„ÅØ `tensor_capture_hook` „Éë„É©„É°„Éº„Çø„ÇíÂèó„Åë‰ªò„Åë„Åæ„Åõ„Çì„ÄÇ

https://github.com/aws-neuron/neuronx-distributed-inference/blob/aa7987ffc66ac2bd9894427621ca9b6f3fc40ed9/src/neuronx_distributed_inference/models/model_base.py#L3373-L3397

## „Éê„Ç∞„ÅÆÂéüÂõ†

**`tensor_capture_hook` „ÅØ**„É¢„Éá„É´„ÅÆ‰∏≠ÈñìÂ±§„ÅÆÂá∫Âäõ„ÇíË®òÈå≤„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç≥„Éº„É´„Éê„ÉÉ„ÇØÈñ¢Êï∞„Åß„Åô„ÄÇ‰∏ª„Å´„Éá„Éê„ÉÉ„Ç∞„ÇÑÁ≤æÂ∫¶Ê§úË®º„Åß‰ΩøÁî®„Åï„Çå„Åæ„Åô„ÄÇ**`forward()` „É°„ÇΩ„ÉÉ„Éâ„ÅØ** PyTorch „É¢„Éá„É´„ÅåÊåÅ„Å§„Äå1 Âõû„ÅÆË®àÁÆó„Äç„ÇíÂÆüË°å„Åô„Çã„É°„ÇΩ„ÉÉ„Éâ„Åß„Åô„ÄÇ

SDK 2.27.0 „Åß„ÅØ„ÄÅ`tensor_capture_hook` „ÇíË™§„Å£„Å¶ `forward()` „Å´Ê∏°„Åó„Å¶„Åó„Åæ„Å£„Åü„Åü„ÇÅ„ÄÅ„Éë„É©„É°„Éº„Çø„ÅåÂ≠òÂú®„Åó„Å™„ÅÑ„Å®„ÅÑ„ÅÜ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ

## Êö´ÂÆö‰øÆÊ≠£

`hf_adapter.py` „ÅÆ `"tensor_capture_hook": tensor_capture_hook` „ÅÆË°å„ÇíÂâäÈô§„Åô„Çã„Åì„Å®„Åß„ÄÅ„Åì„ÅÆÂïèÈ°å„ÇíÂõûÈÅø„Åó„Åæ„Åó„Åü„ÄÇ

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/utils/hf_adapter.py#L289-L300

„Åì„ÅÆ‰øÆÊ≠£„Å´„Çà„Çä„ÄÅSDK 2.27.0 „ÅÆ NxD Inference „ÇíÁõ¥Êé•‰ΩøÁî®„Åô„ÇãÂÆü„Éó„É≠„É≥„Éó„ÉàÊ∏¨ÂÆöÔºàNo.5, No.6Ôºâ„ÅåÂèØËÉΩ„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ

## „Éê„Ç∞„ÅÆÂΩ±ÈüøÁØÑÂõ≤

**ÂΩ±Èüø„ÇíÂèó„Åë„Çã„Ç±„Éº„Çπ:**
- NxD Inference 0.7.0ÔºàSDK 2.27.0Ôºâ„ÅÆ `HuggingFaceGenerationAdapter` „Çí‰ΩøÁî®
- `--benchmark` „Éï„É©„Ç∞„Çí‰Ωø„Çè„ÅöÂÆü„Éó„É≠„É≥„Éó„Éà„Çí `generate()` „Å´Ê∏°„Åô
- Ë©≤ÂΩì: No.5, No.6

**ÂΩ±Èüø„ÇíÂèó„Åë„Å™„ÅÑ„Ç±„Éº„Çπ:**

1. **No.1, No.2**: `--benchmark` „Éï„É©„Ç∞‰ΩøÁî®
2. **No.9-16 (vLLM)**: vllm-neuron „ÅØ `HuggingFaceGenerationAdapter` „Çí‰ΩøÁî®„Åõ„Åö„ÄÅ[vLLM Plugin System](https://github.com/vllm-project/vllm-neuron) „ÇíÈÄö„Åò„Å¶ NxD Inference „ÅÆ„É¢„Éá„É´„ÇíÁõ¥Êé•Âà∂Âæ° „Åô„Çã„ÅÆ„Åß„Éê„Ç∞„ÅÆ„ÅÇ„Çã„Ç≥„Éº„Éâ„Éë„Çπ„ÇíÈÄö„Çâ„Å™„ÅÑ

vLLM „ÅÆÁµ±ÂêàÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„ÅßË™¨Êòé„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

> NxD Inference integrates with vLLM by using vLLM's Plugin System to extend the model execution components responsible for loading and invoking models within vLLM's LLMEngine
>
> Âá∫ÂÖ∏: [vLLM on Neuron - AWS Neuron Documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/nxd-inference/vllm/index.html)

vLLM „ÅØÁã¨Ëá™„ÅÆ model executor „Å® worker „ÇíÊåÅ„Å£„Å¶„Åä„Çä„ÄÅ„ÄÅNxD Inference „ÅÆ„É¢„Éá„É´„ÇØ„É©„ÇπÔºà‰æã: `NeuronQwen3ForCausalLM`Ôºâ„ÇíÁõ¥Êé•„É≠„Éº„Éâ„Åó„Å¶ `forward()` „É°„ÇΩ„ÉÉ„Éâ„ÇíÂëº„Å≥Âá∫„Åó„Åæ„Åô„ÄÇ`HuggingFaceGenerationAdapter` „ÅÆ `prepare_inputs_for_generation()` „É°„ÇΩ„ÉÉ„Éâ„ÅØÁµåÁî±„Åó„Å™„ÅÑ„Åü„ÇÅ„ÄÅ299 Ë°åÁõÆ„ÅÆ„Éê„Ç∞„ÅÆÂΩ±Èüø„ÇíÂèó„Åë„Åæ„Åõ„Çì„ÄÇ

## „Å™„ÅúÁô∫Ë¶ã„Åï„Çå„Å™„Åã„Å£„Åü„ÅÆ„Åã

1. **`--benchmark` „Éï„É©„Ç∞„ÅåÂïèÈ°å„ÇíÈö†ËîΩ**: „Éô„É≥„ÉÅ„Éû„Éº„ÇØ„É¢„Éº„Éâ„Åß„ÅØ„ÉÄ„Éü„ÉºÂÖ•Âäõ„Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÄÅ„Åì„ÅÆ„Éê„Ç∞„ÅåÈ°ïÂú®Âåñ„Åó„Å™„ÅÑ
2. **vLLM „ÅØÂà•„ÅÆÁµ±ÂêàÊñπÊ≥ï**: ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ„Å™‰ΩøÁî®ÊñπÊ≥ïÔºàvLLM ÁµåÁî±Ôºâ„Åß„ÅØ„Éê„Ç∞„ÅÆÂΩ±Èüø„ÇíÂèó„Åë„Å™„ÅÑ
3. **HuggingFaceGenerationAdapter „ÅÆ‰ΩøÁî®È†ªÂ∫¶**: Áõ¥Êé• `HuggingFaceGenerationAdapter` „Çí‰Ωø„ÅÜ„Ç±„Éº„Çπ„ÅØÈôêÂÆöÁöÑ

‰ªäÂõû„ÅÆÁô∫Ë¶ã„ÅØ„ÄÅBucketing „ÅÆÂäπÊûú„ÇíÂÆü„Éó„É≠„É≥„Éó„Éà„ÅßÊ∏¨ÂÆö„Åó„Çà„ÅÜ„Å®„Åó„ÅüÈöõ„ÅÆÂâØÁî£Áâ©„Åß„Åô„ÄÇ‰ªäÂæå„ÄÅ„Çà„ÇäË©≥Á¥∞„Å™Ë™øÊüª„ÇíÁµå„Å¶ GitHub Issue „Å®„Åó„Å¶Â†±Âëä„Åô„Çã‰∫àÂÆö„Åß„Åô„ÄÇ
::::

ÊúÄÂæå„Å´‰ªäÂõû„ÅÆÂïèÈ°å„Å†„Å£„Åü `--benchmark` ÂºïÊï∞„ÇíÂâäÈô§„Åó„Å¶ÂÜçÂÆüË°å„Åó„ÅüÁµêÊûú„ÅØ‰ª•‰∏ã„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ

| No | Áí∞Â¢É | Bucketing | Prefix Caching | „ÉØ„Éº„ÇØ„É≠„Éº„Éâ | Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ (ms) | BucketingÂäπÊûú |
|----|------|-----------|----------------|------------|-------------------|---------------|
| |
| 01 | NxD | OFF | OFF | Âõ∫ÂÆöÈï∑ | **196.56** | - |
| 02 | NxD | ON | OFF | Âõ∫ÂÆöÈï∑ | **188.97** | -3.9% |
| 02 | NxD | ON | OFF | Âõ∫ÂÆöÈï∑ | **13.36 (ÂÜçË©¶)** | -93.7% |

:::message
Bucketing „Çí ON „Å´„Åô„Çã„Åì„Å®„ÅßÂπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑„Åå‰∏ã„Åå„ÇãÁêÜÁî±„ÅØ„Åì„Åì„Åæ„ÅßË™≠„Çì„Å†‰∫∫„Å´„Å®„Å£„Å¶„ÅØ„Åô„Åß„Å´ÁêÜËß£„Åß„Åç„Å¶„ÅÑ„Çã„Å®ÊÄù„Çè„Çå„Åæ„Åô„Åå„ÄÅË§áÊï∞„ÅÆ„Éê„Ç±„ÉÉ„Éà„Çµ„Ç§„Ç∫„Åã„ÇâÊúÄÈÅ©„Å™„Çµ„Ç§„Ç∫„ÅÆ„Éê„Ç±„ÉÉ„Éà„ÇíÈÅ∏„Å∂„Åì„Å®„Åß„Éë„Éá„Ç£„É≥„Ç∞„Å®„Åù„Çå„Å´„Çà„ÇãÁÑ°ÈßÑ„Å™Ë®àÁÆó„ÇíÈô§Â§ñ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Çã„Åì„Å®„Å´Ëµ∑Âõ†„Åó„Åæ„Åô„ÄÇ
:::

### 3.2 Prefix Caching „ÅÆÂäπÊûú

Ê∏¨ÂÆöÁµêÊûú„Çµ„Éû„É™„Éº„ÇíÂÜçÊé≤„Åó„Åæ„Åô„ÄÇ

| No | Áí∞Â¢É | Bucketing | Prefix Caching | „ÉØ„Éº„ÇØ„É≠„Éº„Éâ | Âπ≥Âùá„É¨„Ç§„ÉÜ„É≥„Ç∑ (ms) | Prefix CachingÂäπÊûú |
|----|------|-----------|----------------|------------|-------------------|-------------------|
| |
| 09 | vLLM | OFF | OFF | Âõ∫ÂÆöÈï∑ | **252.42** | - |
| 11 | vLLM | OFF | ON | Âõ∫ÂÆöÈï∑ | **237.54** | -5.9% |
| |
| 10 | vLLM | ON | OFF | Âõ∫ÂÆöÈï∑ | **59.23** | - |
| 12 | vLLM | ON | ON | Âõ∫ÂÆöÈï∑ | **85.92** | +45.0% |
| |
| 13 | vLLM | OFF | OFF | ÂèØÂ§âÈï∑ | **254.80** | - |
| 15 | vLLM | OFF | ON | ÂèØÂ§âÈï∑ | **239.24** | -6.1% |
| |
| 14 | vLLM | ON | OFF | ÂèØÂ§âÈï∑ | **60.62** | - |
| 16 | vLLM | ON | ON | ÂèØÂ§âÈï∑ | **85.28** | +40.7% |

#### NxD „Åß Prefix Caching „ÅåÊ∏¨ÂÆö„Åß„Åç„Å™„Åã„Å£„ÅüÁêÜÁî±

No.03, 04, 07, 08ÔºàNxD + Prefix CachingÔºâ„ÅÆÊ∏¨ÂÆöÁµêÊûú„Åå„Åô„Åπ„Å¶ `-` „Å´„Å™„Å£„Å¶„ÅÑ„Çã„Åì„Å®„Åå„Çè„Åã„Çä„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ**NxD Inference „ÇíÁõ¥Êé• API ÁµåÁî±„Åß‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÄÅPrefix Caching „Çí‰Ωø„ÅÜ„Åü„ÇÅ„ÅÆÂºïÊï∞Ë®àÁÆóÊ©üËÉΩ„ÅåÊú™ÂÆüË£Ö**„ÅÆ„Åü„ÇÅ„Åß„Åô„ÄÇ

::::details NxD + Prefix Caching „Éë„Çø„Éº„É≥„ÅßÁô∫Áîü„Åó„Åü„Ç®„É©„Éº„ÅÆË©≥Á¥∞

## ÂÆüË°åÊôÇ„Ç®„É©„Éº

NxD Inference „Åß Prefix Caching „ÇíÊúâÂäπ„Å´„Åó„Å¶Ê∏¨ÂÆö„ÇíË©¶„Åø„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åô„ÄÇ

```python
TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'

File: neuronx_distributed_inference/models/model_base.py:3679
  num_queries = full_context_lens - computed_context_lens
```

## Ê†πÊú¨ÂéüÂõ†

Prefix Caching „ÅåÊúâÂäπ„Å™Â†¥Âêà„ÄÅNxD Inference „ÅÆ `forward()` „É°„ÇΩ„ÉÉ„Éâ„ÅØ‰ª•‰∏ã„ÅÆ 2 „Å§„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíÂøÖË¶Å„Å®„Åó„Åæ„Åô„ÄÇ

- `full_context_lens`: „É™„ÇØ„Ç®„Çπ„ÉàÂÖ®‰Ωì„ÅÆ„Ç≥„É≥„ÉÜ„Ç≠„Çπ„ÉàÈï∑Ôºà‰æã: 94 tokensÔºâ
- `computed_context_lens`: „Åô„Åß„Å´„Ç≠„É£„ÉÉ„Ç∑„É•Ê∏à„Åø„ÅÆ„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„ÇπÈï∑Ôºà‰æã: 80 tokensÔºâ

```python
# neuronx_distributed_inference/models/model_base.py:3679
num_queries = full_context_lens - computed_context_lens
```

**ÂïèÈ°åÁÇπ:**

`inference_demo.py` „ÇÑ `HuggingFaceGenerationAdapter` „ÅØ„ÄÅ**„Åì„Çå„Çâ„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíË®àÁÆó„ÉªÊèê‰æõ„Åô„ÇãÊ©üËÉΩ„ÇíÂÆüË£Ö„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì**„ÄÇ„Åù„ÅÆ„Åü„ÇÅ„ÄÅ„Åì„Çå„Çâ„ÅÆ API ÁµåÁî±„ÅßÂëº„Å≥Âá∫„Åô„Å® `None - None` „ÅÆË®àÁÆó„ÅåÂÆüË°å„Åï„Çå„Å¶ TypeError „Å´„Å™„Çä„Åæ„Åô„ÄÇ

:::message
NxD Inference „ÅÆ„É¢„Éá„É´Ëá™‰Ωì„ÅØ Prefix Caching „Çí„Çµ„Éù„Éº„Éà„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„É¶„Éº„Ç∂„Éº„ÅåÊâãÂãï„Åß„Åì„Çå„Çâ„ÅÆÂºïÊï∞„ÇíË®àÁÆó„Åó„Å¶Ê∏°„Åõ„Å∞Âãï‰Ωú„Åó„Åæ„Åô„ÄÇvLLM „ÅØ„Åì„ÅÆ„Éó„É≠„Çª„Çπ„ÇíËá™ÂãïÂåñ„Åô„Çã Scheduler „ÇíÂÆüË£Ö„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ"out of the box" „ÅßÂãï‰Ωú„Åó„Åæ„Åô„ÄÇ
:::

## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÈÅï„ÅÑ

**vLLM ÁµåÁî±„Åß NxD Inference „Çí‰ΩøÁî®„Åô„ÇãÂ†¥ÂêàÔºàÂãï‰Ωú„Åô„ÇãÔºâ:**

```
vLLM Scheduler (full_context_lens, computed_context_lens „ÇíË®àÁÆó)
    ‚Üì
vLLM Plugin System
    ‚Üì
Neuron Config Override (prefix caching „É°„Çø„Éá„Éº„Çø„ÇíÊ∏°„Åô)
    ‚Üì
NxD Inference (model_base.py:3679)
    ‚Üì
‚úÖ Prefix Caching ÂÆüË£Ö („Éè„Éº„Éâ„Ç¶„Çß„Ç¢„Ç¢„ÇØ„Çª„É©„É¨„Éº„Ç∑„Éß„É≥)
```

**Áõ¥Êé• NxD API „Çí‰ΩøÁî®„Åô„ÇãÂ†¥ÂêàÔºà„Ç®„É©„Éº„Å´„Å™„ÇãÔºâ:**

```
inference_demo.py „Åæ„Åü„ÅØ HuggingFaceGenerationAdapter
    ‚Üì
‚ùå ÂºïÊï∞Ë®àÁÆóÊ©üËÉΩ„Å™„Åó ‚Üí „Ç≥„É≥„ÉÜ„Ç≠„Çπ„ÉàÈï∑„Éë„É©„É°„Éº„Çø„Åå None
    ‚Üì
NxD Inference (model_base.py:3679)
    ‚Üì
TypeError: None - None  ‚Üê „Åì„Åì„ÅßÂ§±Êïó
```

## SDK „Éê„Éº„Ç∏„Éß„É≥„Å®„Çµ„Éù„Éº„ÉàÁä∂Ê≥Å

| ÂÆüË£ÖÊñπÊ≥ï | „Çµ„Éù„Éº„ÉàÁä∂Ê≥Å | Ë©≥Á¥∞ |
|---|---|---|
| **NxD „É¢„Éá„É´ (`forward()`)** | ‚úÖ **„Çµ„Éù„Éº„Éà** | `full_context_lens`, `computed_context_lens` „ÇíÂèó„ÅëÂèñ„ÇãÂÆüË£Ö„ÅÇ„Çä |
| **vLLM ÁµåÁî±** | ‚úÖ **„Çµ„Éù„Éº„Éà** | vLLM Scheduler „ÅåËá™Âãï„ÅßÂºïÊï∞„ÇíË®àÁÆó„ÉªÊèê‰æõ |
| **inference_demo.py** | ‚ùå **Êú™ÂÆüË£Ö** | ÂºïÊï∞„ÇíË®àÁÆó„ÉªÊèê‰æõ„Åô„ÇãÊ©üËÉΩ„Å™„ÅóÔºàÊâãÂãïÂÆüË£Ö„Åô„Çå„Å∞Âãï‰ΩúÂèØËÉΩÔºâ |
| **HuggingFaceGenerationAdapter** | ‚ùå **Êú™ÂÆüË£Ö** | ÂºïÊï∞„ÇíË®àÁÆó„ÉªÊèê‰æõ„Åô„ÇãÊ©üËÉΩ„Å™„ÅóÔºàÊâãÂãïÂÆüË£Ö„Åô„Çå„Å∞Âãï‰ΩúÂèØËÉΩÔºâ |

## ÊâãÂãïÂÆüË£Ö„Å´„Çà„ÇãÂõûÈÅøÁ≠ñ

Êú™ÂÆüË£Ö„ÅÆ `HuggingFaceGenerationAdapter` „Å™„Å©„ÇÇÂºïÊï∞„ÇíÊâãÂãï„ÅßË®àÁÆó„Åô„Çå„Å∞ Prefix Caching „Çí‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ

„Åü„Å†„Åó„ÄÅ„Åì„ÅÆÊñπÊ≥ï„Å´„ÅØ‰ª•‰∏ã„ÅÆË™≤È°å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ
1. „Ç≠„É£„ÉÉ„Ç∑„É•ÁÆ°ÁêÜÔºàLRU„ÄÅ„Éè„ÉÉ„Ç∑„É•„ÉÜ„Éº„Éñ„É´Ôºâ„ÇíËá™ÂàÜ„ÅßÂÆüË£Ö„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã
2. Ë§áÊï∞„É™„ÇØ„Ç®„Çπ„ÉàÈñì„Åß„ÅÆ„Ç≠„É£„ÉÉ„Ç∑„É•ÂÖ±Êúâ„É≠„Ç∏„ÉÉ„ÇØ„ÅåÂøÖË¶Å
3. „Éê„ÉÉ„ÉÅÂá¶ÁêÜÊôÇ„ÅÆ„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„ÉàÂà§ÂÆö„ÅåË§áÈõë

vLLM „ÅØ„Åì„Çå„Çâ„Åô„Åπ„Å¶„Çí Scheduler „ÅßËá™ÂãïÂåñ„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÂÆüÁî®ÁöÑ„Å´„ÅØ vLLM ÁµåÁî±„Åß„ÅÆÂà©Áî®„ÅåÊé®Â•®„Åï„Çå„Åæ„Åô„ÄÇ

## Èñ¢ÈÄ£„Éï„Ç°„Ç§„É´

- vLLM Áµ±Âêà„Éâ„Ç≠„É•„É°„É≥„Éà: [vLLM on Neuron - AWS Neuron Documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/nxd-inference/vllm/index.html)

::::

#### vLLM „Åß„ÅÆ Prefix Caching „ÅÆÂäπÊûú

vLLM „Çí‰ΩøÁî®„Åó„Åü No.11, 12, 15, 16 „Åß„ÅØ Prefix Caching „ÅåÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÂõ∫ÂÆöÈï∑„ÅãÂèØÂ§âÈï∑„Åã„Åß„Åù„Åì„Åæ„ÅßÂ∑Æ„Åå„Å™„ÅÑ„ÅÆ„Åß‰ªäÂõû„ÅØ„ÉØ„Éº„ÇØ„É≠„Éº„Éâ„ÅØÁâπ„Å´Ê∞ó„Å´„Åõ„Åö„Å´ÂàÜÊûê„ÇíÈÄ≤„ÇÅ„Åæ„Åô„ÄÇ

Bucketing „ÅåÁÑ°Âäπ„Å™Â†¥Âêà„ÄÅPrefix Caching „ÅÆÂäπÊûú„ÅØËªΩÂæÆ„Åß„ÅôÔºàÁ¥Ñ 6% ÊîπÂñÑÔºâ„ÄÇ„Åì„Çå„ÅØ„ÄÅÂÖ®„Éó„É≠„É≥„Éó„Éà„Åå 2048 „Éà„Éº„ÇØ„É≥„Éê„Ç±„ÉÉ„Éà„Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„Éà„Å´„Çà„Çã KV „Ç≠„É£„ÉÉ„Ç∑„É•ÂÜçÂà©Áî®„ÅÆÂäπÊûú„ÅåÁõ∏ÂØæÁöÑ„Å´Â∞è„Åï„ÅÑ„Åü„ÇÅ„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ

ËààÂë≥Ê∑±„ÅÑ„Åì„Å®„Å´„ÄÅBucketing „ÅåÊúâÂäπ„Å™Â†¥Âêà„ÄÅ**Prefix Caching „ÇíÊúâÂäπ„Å´„Åô„Çã„Å®„É¨„Ç§„ÉÜ„É≥„Ç∑„ÅåÂ§ßÂπÖ„Å´Â¢óÂä†**„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆÂâçÂõû„ÅÆË®ò‰∫ã„Åß„ÇÇÂÖ®„ÅèÊÑèÂë≥„Åå„Çè„Åã„Çâ„Å™„Åã„Å£„Åü‰∫àÊÉ≥Â§ñ„ÅÆÁµêÊûú„Å´„Å§„ÅÑ„Å¶Ë™øÊüª„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ

::::details KV „Ç≠„É£„ÉÉ„Ç∑„É•ÂÆπÈáè„ÅÆÊ∏õÂ∞ë„Å®‰∏¶ÂàóÂá¶ÁêÜËÉΩÂäõ„ÅÆÂà∂Á¥Ñ

## KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫„ÅÆÂ§âÂåñ

Ê∏¨ÂÆö„É≠„Ç∞„ÇíË©≥„Åó„ÅèÂàÜÊûê„Åó„ÅüÁµêÊûú„ÄÅPrefix Caching „ÇíÊúâÂäπ„Å´„Åô„Çã„Å® **KV „Ç≠„É£„ÉÉ„Ç∑„É•„ÅÆÂÆüÂäπÂÆπÈáè„ÅåÂäáÁöÑ„Å´Ê∏õÂ∞ë**„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂà§Êòé„Åó„Åæ„Åó„Åü„ÄÇ

| „Éë„Çø„Éº„É≥ | Bucketing | Prefix Caching | KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫ | Maximum Concurrency |
|---------|-----------|----------------|-------------------|---------------------|
| No.9 | OFF | OFF | **1,050,624 tokens** | **513.00x** |
| No.10 | ON | OFF | **1,050,624 tokens** | **513.00x** |
| No.11 | OFF | ON | **16,416 tokens** | **8.02x** |
| No.12 | ON | ON | **16,416 tokens** | **8.02x** |

Prefix Caching „ÇíÊúâÂäπ„Å´„Åô„Çã„Å®„ÄÅKV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫„Åå **64 ÂÄç„ÇÇÊ∏õÂ∞ë**„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

## Maximum Concurrency „ÅÆÊÑèÂë≥„Å®Ë®àÁÆóÊñπÊ≥ï

Maximum Concurrency „ÅØ„ÄÅvLLM „ÅåÂêåÊôÇ„Å´Âá¶ÁêÜ„Åß„Åç„Çã„É™„ÇØ„Ç®„Çπ„ÉàÊï∞„ÅÆ‰∏äÈôê„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆÂÄ§„ÅØ vLLM „ÅÆ Scheduler „Åå„É™„ÇØ„Ç®„Çπ„Éà„Çí„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞„Åô„ÇãÈöõ„ÅÆÈáçË¶Å„Å™Âà∂Á¥Ñ„Å®„Å™„Çä„Åæ„Åô„ÄÇ

**Ë®àÁÆóÂºè**ÔºàvLLM v0.13.0 „ÅÆÂÆüË£Ö„Åã„ÇâÔºâ:

https://github.com/vllm-project/vllm/blob/v0.13.0/vllm/v1/core/kv_cache_utils.py#L778-L796

```python
Maximum Concurrency = num_blocks / num_block_per_request
                    ‚âà (GPU KV cache size) / max_model_len
```

‰ªäÂõû„ÅÆÊ∏¨ÂÆö„Åß„ÅÆÂÆüÈöõ„ÅÆÂÄ§Ôºö

```python
# Prefix Caching OFF
Maximum Concurrency = 1,050,624 / 2,048 = 513.00x

# Prefix Caching ON
Maximum Concurrency = 16,416 / 2,048 = 8.02x
```

‰ªäÂõû„ÅÆÊ∏¨ÂÆöÊù°‰ª∂„Åß„ÅØÔºö
- **„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: 4**Ôºà4 „Å§„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÇíÂêåÊôÇ„Å´Âá¶ÁêÜÔºâ
- Prefix Caching OFF: Maximum Concurrency = 513.00xÔºà**128.2 ÂÄç„ÅÆ‰ΩôË£ï**Ôºâ
- Prefix Caching ON: Maximum Concurrency = 8.02xÔºà**2.0 ÂÄç„ÅÆ‰ΩôË£ï„ÅÆ„Åø**Ôºâ

„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫ 4 „Å´ÂØæ„Åó„Å¶ 2.0 ÂÄç„ÅÆ‰ΩôË£ï„Åó„Åã„Å™„ÅÑ„Åü„ÇÅ„ÄÅvLLM Scheduler „Åå‰∏¶ÂàóÂá¶ÁêÜ„ÇíÂà∂Èôê„Åó„ÄÅÈÄêÊ¨°Âá¶ÁêÜ„Å´Âàá„ÇäÊõø„Åà„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åì„Çå„Åå„É¨„Ç§„ÉÜ„É≥„Ç∑ÊÇ™Âåñ„ÅÆ‰∏ªË¶ÅÂõ†„Åß„Åô„ÄÇ

## „Å™„Åú KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫„ÅåÊ∏õÂ∞ë„Åô„Çã„ÅÆ„Åã

vLLM „ÅÆ„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ„Åã„Çâ„ÄÅ„Åì„ÅÆÁèæË±°„ÅÆÊ†πÊú¨ÂéüÂõ†„ÇíÁâπÂÆö„Åó„Åæ„Åó„Åü„ÄÇ

**vLLM „Å´„Çà„Çã KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫„ÅÆË®àÁÆó**

**‰ΩøÁî®„Éê„Éº„Ç∏„Éß„É≥**: vLLM v0.13.0Ôºà„Ç≥„Éü„ÉÉ„Éà: `72506c98`Ôºâ

„É≠„Ç∞„Å´Âá∫Âäõ„Åï„Çå„Çã "GPU KV cache size" „ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÅßË®àÁÆó„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

**„Éï„Ç°„Ç§„É´**: `vllm/v1/core/kv_cache_utils.py:1274-1291`

https://github.com/vllm-project/vllm/blob/v0.13.0/vllm/v1/core/kv_cache_utils.py#L1274-L1291

**Ë®àÁÆóÂºè**
```python
GPU KV cache size = (num_blocks / num_kv_cache_groups) √ó min_block_size
```

### Maximum Concurrency „ÅÆË®àÁÆó

"Maximum concurrency" „ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÅßË®àÁÆó„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

**„Éï„Ç°„Ç§„É´**: `vllm/v1/core/kv_cache_utils.py:1293-1302`

https://github.com/vllm-project/vllm/blob/v0.13.0/vllm/v1/core/kv_cache_utils.py#L1293-L1302

**Ë®àÁÆóÈñ¢Êï∞**: `vllm/v1/core/kv_cache_utils.py:778-796`

https://github.com/vllm-project/vllm/blob/v0.13.0/vllm/v1/core/kv_cache_utils.py#L778-L796

ÂÆüË≥™ÁöÑ„Å´
```python
Maximum Concurrency ‚âà (GPU KV cache size) / max_model_len
```

### Prefix Caching ON/OFF „Åß„ÅÆÈÅï„ÅÑÔºàÂÆüÊ∏¨ÂÄ§Ôºâ

:::message
‰∏°Êñπ„ÅÆ„Ç±„Éº„Çπ„ÅßÂêå„ÅòË®àÁÆóÂºè„Åå‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅvLLM ÂÜÖÈÉ®„Åß‰ΩøÁî®„Åï„Çå„Çã **`num_blocks` „ÅÆÂÄ§„ÅåÁï∞„Å™„Çã**„Åì„Å®„ÅåÂà§Êòé„Åó„Åæ„Åó„Åü„ÄÇ
:::

**Ê∏¨ÂÆö„É≠„Ç∞„Åã„ÇâÁ¢∫Ë™ç„Åï„Çå„ÅüÂÆüÈöõ„ÅÆÂÄ§**

| Ë®≠ÂÆö | GPU KV cache sizeÔºà„É≠„Ç∞Âá∫ÂäõÔºâ | Maximum ConcurrencyÔºà„É≠„Ç∞Âá∫ÂäõÔºâ | Ë®≠ÂÆöÂÄ§ |
|------|-------------------------------|--------------------------------|--------|
| Prefix Caching OFF | **1,050,624 tokens** | **513.00x** | num_gpu_blocks_override=512 |
| Prefix Caching ON | **16,416 tokens** | **8.02x** | num_gpu_blocks_override=512 |

**Ê∏õÂ∞ëÁéá**: GPU KV cache size „Åå **64 ÂÄçÊ∏õÂ∞ë**Ôºà1,050,624 ‚Üí 16,416 tokensÔºâ

**Prefix Caching OFF „ÅÆÂ†¥Âêà:**
- ÂêÑ„É™„ÇØ„Ç®„Çπ„Éà„ÅåÁã¨Á´ã„Åó„Åü„Éñ„É≠„ÉÉ„ÇØ„Çª„ÉÉ„Éà„Çí‰øùÊúâ„Åô„ÇãÂâçÊèê„Åß„É°„É¢„É™„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞
- vLLM „ÅåÂ†±Âëä„Åô„Çã KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫: **Á¢∫‰øùÂèØËÉΩ„Å™È†òÂüüÂÖ®‰Ωì**„ÇíË°®„Åô
- ÂÜÖÈÉ®ÁöÑ„Å´„ÅØ‰Ωï„Çâ„Åã„ÅÆ‰øÇÊï∞Ôºà64ÂÄçÔºâ„ÅåÈÅ©Áî®„Åï„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„ÅÇ„Çä

**Prefix Caching ON „ÅÆÂ†¥Âêà:**
- ÂÖ±ÈÄö„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ„ÇíÊåÅ„Å§„É™„ÇØ„Ç®„Çπ„ÉàÈñì„Åß„Éñ„É≠„ÉÉ„ÇØ„ÇíÂÖ±Êúâ„Åô„ÇãÂâçÊèê„Åß„É°„É¢„É™„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞
- „Ç≠„É£„ÉÉ„Ç∑„É•ÁÆ°ÁêÜ„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâÔºà„Éè„ÉÉ„Ç∑„É•„ÉÜ„Éº„Éñ„É´„ÄÅLRU ÁÆ°ÁêÜÔºâ„ÇíËÄÉÊÖÆ„Åó„ÅüË®àÁÆó
- vLLM „ÅåÂ†±Âëä„Åô„Çã KV „Ç≠„É£„ÉÉ„Ç∑„É•„Çµ„Ç§„Ç∫: **ÂÆüÈöõ„Å´‰ΩøÁî®ÂèØËÉΩ„Å™„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éñ„É≠„ÉÉ„ÇØ„ÅÆ„Åø**„ÇíË°®„Åô

Âêå„Åò `num_gpu_blocks_override=512` „ÇíË®≠ÂÆö„Åó„Å¶„ÇÇ„ÄÅPrefix Caching ON „ÅÆÂ†¥Âêà„ÅØ„É°„É¢„É™ÁÆ°ÁêÜ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Å´„Çà„Çä„ÄÅvLLM ÂÜÖÈÉ®„ÅßÂÆüÂäπÁöÑ„Å´‰ΩøÁî®„Åï„Çå„Çã `num_blocks` „ÅåÊ∏õÂ∞ë„Åó„ÄÅÁµêÊûú„Å®„Åó„Å¶ GPU KV cache size „Å® Maximum Concurrency „Åå 64ÂàÜ„ÅÆ1 „Å´„Å™„Çä„Åæ„Åô„ÄÇ

## „É¨„Ç§„ÉÜ„É≥„Ç∑ÊÇ™Âåñ„ÅÆ„É°„Ç´„Éã„Ç∫„É†

Maximum Concurrency „Åå 8.02x „Åó„Åã„Å™„ÅÑÁä∂Ê≥Å„Åß„ÄÅ„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫ 4 „ÇíÂá¶ÁêÜ„Åô„Çã„Å®

1. **„É°„É¢„É™„ÅÆ‰ΩôË£ï„Åå„ÇÆ„É™„ÇÆ„É™**Ôºà2.0ÂÄç„ÅÆ‰ΩôË£ï„Åó„Åã„Å™„ÅÑÔºâ
2. **vLLM Scheduler „ÅÆÂà∂Á¥Ñ**
   - Scheduler „ÅØÂà©Áî®ÂèØËÉΩ„Å™ KV „Ç≠„É£„ÉÉ„Ç∑„É•ÂÆπÈáè„Å´Âü∫„Å•„ÅÑ„Å¶„É™„ÇØ„Ç®„Çπ„Éà„Çí„Çπ„Ç±„Ç∏„É•„Éº„É™„É≥„Ç∞
   - ÂÆπÈáè„Åå‰∏çË∂≥„Åô„Çã„Å®„ÄÅ‰∏¶ÂàóÂá¶ÁêÜ„ÇíÂà∂Èôê„Åó„Å¶ÈÄêÊ¨°Âá¶ÁêÜ„Å´Âàá„ÇäÊõø„Åà„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã
3. **Prefix Caching „ÅÆÁÆ°ÁêÜ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ**
   - „Éè„ÉÉ„Ç∑„É•Ë®àÁÆó„Å´„Çà„Çã„Éñ„É≠„ÉÉ„ÇØË≠òÂà•
   - LRU „Ç≠„É£„ÉÉ„Ç∑„É•ÁÆ°ÁêÜ
   - „Éñ„É≠„ÉÉ„ÇØÂÖ±Êúâ„ÅÆË™øÊï¥

„Åì„Çå„Çâ„ÅÆË¶ÅÂõ†„ÅåË§áÂêà„Åó„Å¶„ÄÅÁêÜË´ñÁöÑ„Å´„ÅØ„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„Éà„Å´„Çà„ÇãÈ´òÈÄüÂåñ„ÅåÊúüÂæÖ„Åï„Çå„Çã„Å´„ÇÇÈñ¢„Çè„Çâ„Åö„ÄÅÂÆüÈöõ„Å´„ÅØ **26.69 msÔºà45%Ôºâ„ÅÆ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ**„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

## Ê∏¨ÂÆöÊù°‰ª∂„ÅÆÂΩ±Èüø

‰ªäÂõû„ÅÆÊ∏¨ÂÆö„Åß„ÅØÔºö
- **Âõ∫ÂÆöÈï∑„ÉØ„Éº„ÇØ„É≠„Éº„Éâ**: ÂÖ®„ÅèÂêå„Åò„Éó„É≠„É≥„Éó„Éà 4 „Å§„Çí 100 ÂõûÁπ∞„ÇäËøî„Åó
- **ÂèØÂ§âÈï∑„ÉØ„Éº„ÇØ„É≠„Éº„Éâ**: Âêå„Åò 4 „Å§„ÅÆÁï∞„Å™„Çã„Éó„É≠„É≥„Éó„Éà„Çí 100 ÂõûÁπ∞„ÇäËøî„Åó

„Å§„Åæ„Çä„ÄÅ**2 ÂõûÁõÆ‰ª•Èôç„ÅØÂÆåÂÖ®„Å´„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„Éà„Åô„Çã„ÅØ„Åö**„ÅÆÁêÜÊÉ≥ÁöÑ„Å™Êù°‰ª∂„Åß„Åó„Åü„ÄÇ„Åù„Çå„Å´„ÇÇÈñ¢„Çè„Çâ„Åö„É¨„Ç§„ÉÜ„É≥„Ç∑„ÅåÊÇ™Âåñ„Åó„Åü„Åì„Å®„Åã„Çâ„ÄÅ**Prefix Caching „ÅÆÁÆ°ÁêÜ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Å® Maximum Concurrency „ÅÆÂà∂Á¥Ñ„Åå„ÄÅ„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„Éà„ÅÆÊÅ©ÊÅµ„ÇíÂÆåÂÖ®„Å´Êâì„Å°Ê∂à„Åó„Å¶„ÅÑ„Çã**„Åì„Å®„ÅåÊòé„Çâ„Åã„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ

## Ë®≠ÂÆö„Éë„É©„É°„Éº„Çø„Å®„ÅÆÈñ¢‰øÇ

‰ªäÂõû„ÅÆË®≠ÂÆöÔºö
```python
block_size = 32
num_gpu_blocks_override = 512
max_num_batched_tokens = 256
```

`num_gpu_blocks_override=512` „ÅØ„ÄÅPrefix Caching OFF „ÅÆÂ†¥Âêà„ÅØÈÅ©Âàá„Å™ÂÄ§„Åß„Åô„Åå„ÄÅPrefix Caching ON „ÅÆÂ†¥Âêà„ÅØ**ÂÆüÂäπÁöÑ„Å™ KV „Ç≠„É£„ÉÉ„Ç∑„É•ÂÆπÈáè„ÇíÂ§ßÂπÖ„Å´Âà∂Èôê**„Åó„Å¶„Åó„Åæ„ÅÑ„Åæ„Åô„ÄÇ

::::

Bucketing ON + Prefix Caching ON „Åß„É¨„Ç§„ÉÜ„É≥„Ç∑„ÅåÊÇ™Âåñ„Åô„Çã‰∏ª„Å™ÂéüÂõ†„ÅØ„ÄÅ**Prefix Caching „Å´„Çà„Çã„É°„É¢„É™ÁÆ°ÁêÜÊñπÂºè„ÅÆÂ§âÊõ¥„Åå„ÄÅMaximum Concurrency „Çí 64 ÂàÜ„ÅÆ 1 „Å´Âà∂Èôê„Åó„ÄÅ‰∏¶ÂàóÂá¶ÁêÜËÉΩÂäõ„Çí‰Ωé‰∏ã„Åï„Åõ„Çã**„Åü„ÇÅ„Åß„Åô„ÄÇPrefix Caching „ÅÆ„Éñ„É≠„ÉÉ„ÇØÂÖ±Êúâ„É°„Ç´„Éã„Ç∫„É†„ÅØ„ÄÅÁêÜË´ñÁöÑ„Å´„ÅØ„É°„É¢„É™ÂäπÁéá„ÇíÊîπÂñÑ„Åó„Åæ„Åô„Åå„ÄÅ‰ªäÂõû„ÅÆÊ∏¨ÂÆöÊù°‰ª∂ÔºàÂ∞è„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÄÅÂèçÂæ©ÁöÑ„Å™„ÉØ„Éº„ÇØ„É≠„Éº„ÉâÔºâ„Åß„ÅØ„ÄÅÁÆ°ÁêÜ„Ç™„Éº„Éê„Éº„Éò„ÉÉ„Éâ„Åå„Ç≠„É£„ÉÉ„Ç∑„É•„Éí„ÉÉ„Éà„ÅÆÊÅ©ÊÅµ„Çí‰∏äÂõû„Å£„Å¶„ÅÑ„Çã„Å®ÊÄù„Çè„Çå„Åæ„Åô„ÄÇ

**num_gpu_blocks_override „ÅÆÊúÄÈÅ©Âåñ**

ÁèæÂú®„ÅÆË®≠ÂÆö `num_gpu_blocks_override=512` „ÅØ Prefix Caching OFF „Åß„ÅØÈÅ©Âàá„Åß„Åô„Åå„ÄÅON „Åß„ÅØÂÆüÂäπÂÆπÈáè„ÇíÈÅéÂ∫¶„Å´Âà∂Èôê„Åó„Å¶„ÅÑ„Çã„ÅÆ„Åß„ÄÅÂΩì„Åü„ÇäÂâç„Åß„Åô„Åå ON/OFF „ÅßÊúÄÈÅ©ÂÄ§„ÅåÂ§â„Çè„Çã„Åì„Å®Ë®≠ÂÆö„Åå„ÅÇ„Çã„Åì„Å®„Çí‰ªäÂæåÊÑèË≠ò„Åó„Åü„ÅÑ„Åß„Åô„ÄÇÁêÜË´ñ‰∏ä„ÅØ„Åì„ÅÆË®≠ÂÆöÂÄ§„ÇíÂ¢ó„ÇÑ„Åõ„Å∞ Maximum Concurrency „ÇÇÂ¢ó„Åà„Çã„ÅÆ„ÅßË©¶„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ

```python
# ÁèæÂú®„ÅÆË®≠ÂÆö
num_gpu_blocks_override = 512  # ‚Üí Maximum Concurrency: 8.02x

# ÊîπÂñÑÊ°à: Prefix Caching ON ÊôÇ„ÅØÂ¢ó„ÇÑ„Åô
num_gpu_blocks_override = 4096  # ‚Üí Maximum Concurrency: 64.16x
```

## „Åæ„Å®„ÇÅ

Êú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅvllm-neuron „ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÇíÈÄö„Åò„Å¶Êé®Ë´ñ„Ç®„É≥„Ç∏„É≥„ÅÆ‰ªïÁµÑ„Åø„ÇÑ NxD Inference „ÅÆ‰ªïÁµÑ„Åø„Å´Èñ¢„Åô„ÇãÁêÜËß£„ÇíÊ∑±„ÇÅ„Åæ„Åó„Åü„ÄÇAWS Neuron Profiler „ÅÆ‰Ωø„ÅÑÊâÄ„Åå„Çè„Åã„Å£„Å¶„Å™„Åã„Å£„Åü„ÅÆ„ÅßÈÅ©ÂΩì„Å´‰Ωø„Åä„ÅÜ„Å®„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„Åå„ÄÅÂÆüÈöõ„Å´„ÅØ vllm-neuron „ÅÆ„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞„ÄÅpy-spy „ÅÆ„É©„Ç§„É≥„Éó„É≠„Éï„Ç°„Ç§„É©„ÄÅ„Éá„Éê„ÉÉ„Ç∞‰ªïËæº„Çì„ÅßÂãï„Åã„Åô„ÄÅ„Å™„Å©„Åå‰∏ÄÁï™ÂéüÂõ†ÁâπÂÆö„Å´ÂØÑ‰∏é„Åó„Åæ„Åó„Åü„ÄÇÂºï„ÅçÁ∂ö„Åç„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞Âäõ„Çí„ÅÇ„Åí„Å¶„ÅÑ„Åç„Åü„ÅÑ„Åß„Åô„ÄÇ

:::message alert
‰ªäÂõû„ÅÆÁü•Ë¶ã„Å´„Å§„ÅÑ„Å¶„ÅØ„Åß„Åç„ÇãÈôê„Çä‰ΩïÂ∫¶„ÇÇÂÆüË°å„Åó„Å¶Á¢∫Ë™ç„Åó„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅÂÖ®„Åè„Éü„Çπ„ÅåÊ∑∑ÂÖ•„Åó„Å¶„ÅÑ„Å™„ÅÑ„Å®„ÅØË®Ä„Åà„Åæ„Åõ„Çì„ÄÇ„ÅÇ„Åè„Åæ„ÅßÁ¥∞„Åã„ÅÑÊï∞ÂÄ§„ÅÆÊ≠£Á¢∫ÊÄß„Å´„Åì„Å†„Çè„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„Å©„ÅÆ„Çà„ÅÜ„Å´ vllm-neuron „ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„ÇíÂÆüÊñΩ„Åó„Å¶ÂâçÂõû‰∏çÊòéÁ¢∫„Å†„Å£„ÅüË®àÊ∏¨ÁµêÊûú„Å´ÂØæ„Åó„Å¶„Éá„Éº„Çø„ÇíÂÖÉ„Å´Â¶•ÂΩì„Å™ÁêÜÁî±„Å•„Åë„Åå„Åß„Åç„Çã„Åì„Å®„ÇíÈáçË¶ñ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÂèÇËÄÉÁ®ãÂ∫¶„Å´Ë™≠„Çì„Åß„ÅÑ„Åü„Å†„Åë„Çå„Å∞„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ
:::

**„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞„Åã„ÇâÂ≠¶„Çì„Å†„Åì„Å®**

1. **Ë§áÊï∞„ÅÆ„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÊâãÊ≥ï„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Çã**: ÂàùÊâã„ÅØ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞„ÄÅ„Åù„Åì„Åã„ÇâÈáçË¶Å„Å™„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„Å´Âêë„Åë„Å¶Ê∑±„Åº„Å£„Å¶„ÅÑ„Åè„ÅÆ„ÅåËâØ„ÅÑ„ÄÇ
2. **Ê∏¨ÂÆöÊù°‰ª∂„ÇíÊÖéÈáç„Å´Ë®≠Ë®à„Åô„Çã**: `--benchmark` „Éï„É©„Ç∞„ÅÆ„Çà„ÅÜ„Å™Èö†„Çå„ÅüÂà∂Á¥Ñ„Å´Ê≥®ÊÑè„Åó„Å™„Åå„ÇâË®≠ÂÆö„ÇíÂÖ•„Çå„Çã„ÄÇ
3. **‰∫àÊÉ≥Â§ñ„ÅÆÁµêÊûú„ÇíÊ∑±Êéò„Çä„Åô„Çã**: Prefix Caching Ë®≠ÂÆö„ÅÆ„É¨„Ç§„ÉÜ„É≥„Ç∑ÊÇ™Âåñ„Å®„ÅÑ„ÅÜÁµêÊûú„Åã„Çâ„ÄÅMaximum Concurrency „ÅÆÂà∂Á¥ÑÁü•Ë¶ã„ÅåÂæó„Çâ„Çå„Åü„ÄÇ
4. **ÂÆüË£Ö„ÅÆË©≥Á¥∞„ÇíÁêÜËß£„Åô„Çã**: vLLM „Å® NxD Inference „ÅÆÁµ±ÂêàÊñπÂºè„ÅÆÈÅï„ÅÑ„Åå„ÄÅPrefix Caching „ÅÆ„Çµ„Éù„Éº„ÉàÁä∂Ê≥Å„Å´ÂΩ±Èüø„Åô„Çã„ÄÇ
5. **„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ„É¨„Éô„É´„Åß„ÅÆÊ§úË®º**: „É≠„Ç∞„ÇÑ„É°„Éà„É™„ÇØ„Çπ„ÅÆËÉåÂæå„Å´„ÅÇ„ÇãË®àÁÆó„É≠„Ç∏„ÉÉ„ÇØ„Çí„ÇΩ„Éº„Çπ„Ç≥„Éº„Éâ„Åã„ÇâÁ¢∫Ë™ç„Åô„Çã„Åì„Å®„Åß„ÄÅÁèæË±°„ÅÆÊ†πÊú¨ÂéüÂõ†„ÇíÊ≠£Á¢∫„Å´ÁêÜËß£„Åß„Åç„Çã„ÄÇ„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞„Çí‰ªïËæº„ÇÄ„ÅÆ„ÇÇÂçòÁ¥î„Å†„ÅåÊúâÁî®„Åß„ÅÇ„Çã„ÄÇ