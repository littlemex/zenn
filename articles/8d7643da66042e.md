---
title: "vllm-neuron ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã§å¾—ãŸçŸ¥è¦‹"
emoji: "ğŸ”"
type: "tech"
topics: ["vllm", "AWSNeuron", "Profiler", "Python", "æ€§èƒ½æœ€é©åŒ–"]
published: false
---

## ã¯ã˜ã‚ã«

[å‰å›ã®è¨˜äº‹](https://zenn.dev/tosshi/articles/d68bd091d1934d) ã§ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®é–‹ç™ºã«ã»ã¼è¶£å‘³ã§é›†ä¸­ã—ã¦ã—ã¾ã—ãŸãŒã€ä»Šå›ã¯ï¼ˆçœŸé¢ç›®ã«ï¼‰ AWS Inferentia2 ä¸Šã§ vllm-neuron ã‚’ä½¿ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°åˆ†æã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¾ã™ã€‚

https://zenn.dev/tosshi/articles/ef61e14fe73399

æœ¬è¨˜äº‹ã§ã¯ã€ä¸Šè¨˜ã®è¨˜äº‹ã§å¾—ã‚‰ã‚ŒãŸ bucketing ã¨ prefix caching ã®è¨­å®šã«ã‚ˆã‚‹å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®çµæœã«ã¤ã„ã¦ãªãœãã†ãªã‚‹ã®ã‹ã‚’è€ƒå¯Ÿã™ã‚‹ã“ã¨ãŒä¸»ãªç›®çš„ã§ã™ã€‚

å®Ÿæ–½ã—ãŸèª¿æŸ»ã‚’ 4 ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«åˆ†ã‘ã¾ã™ã€‚ã¾ãš Phase 1 ã§ã¯ AWS Neuron Profiler ã«ã‚ˆã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’è©¦è¡ŒéŒ¯èª¤ã—ã¾ã—ãŸã€‚æ¬¡ã« Phase 2 ã§ã¯ Python ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚Phase 3 ã§ã¯ NxD Inference ã‚’ç›´æ¥ä½¿ç”¨ã—ãŸæ¸¬å®šã‚’è¡Œã„ã€vLLM ã¨ã®æ¯”è¼ƒã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚æœ€å¾Œã« Phase 4 ã§ã¯ vLLM ã® bucketing ON/OFF ã®å†…éƒ¨å‹•ä½œã‚’åˆ†æã—ã¾ã—ãŸã€‚

:::message
**ä»Šå›ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®é€²ã‚æ–¹ã¯çµæœçš„ã«ã‹ãªã‚Šé–“é•ã£ã¦ã„ã¾ã—ãŸï¼** è‰²ã€…è©¦è¡ŒéŒ¯èª¤ã—ãŸã‚“ã ãªã€ã¨æ€ã„ãªãŒã‚‰æœ¬è¨˜äº‹ã‚’èª­ã‚“ã§ãã ã•ã„ã€‚ç´è±†ã® 10å€ãã‚‰ã„ç²˜ã£ã¦æ¸¬å®šçµæœã«å¯¾ã™ã‚‹é•å’Œæ„Ÿã‚’æ¨ã¦ãšã«ã„ãã¤ã‹ã®å•é¡Œã®è§£æ˜ã«è‡³ã£ãŸç‚¹ã¯è‰¯ã‹ã£ãŸã¨æ€ã„ã¾ã™ã€‚**ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¯ç²˜ã‚Š**ã ã¨ã„ã†ã“ã¨ã‚’å­¦ã³ã¾ã—ãŸã€‚
:::

:::message alert
æœ¬è¨˜äº‹ã¯å¤šåˆ†ä¸Šç´šè€…å‘ã‘ã®ãŸã‚ LLM æ¨è«–ã®çŸ¥è­˜ã€vLLM ã®çŸ¥è­˜ã€AWS Neuron ã®çŸ¥è­˜ãŒã‚ã‚‹ã“ã¨ãŒå‰æã§ã™ã€‚
:::

## Phase 1: AWS Neuron Profiler ã§ã®è©¦è¡ŒéŒ¯èª¤

### 1.1 ãªãœãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‹ã‚‰å§‹ã‚ã‚‹ã®ã‹

æ€§èƒ½æœ€é©åŒ–ã‚’è¡Œã†éš›ã€ã¾ãšç¾çŠ¶ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã§ã¯æ€§èƒ½ã®çµæœã¯åˆ†ã‹ã‚Šã¾ã™ãŒã€æ€§èƒ½ã®ç†ç”±ã€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®å ´æ‰€ã€ãã—ã¦æ”¹å–„ã®ä½™åœ°ã¯åˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚

ä»¥ä¸‹ã«å®Ÿé¨“ç’°å¢ƒã¨è¨­å®šæƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãŠãã¾ã™ã€‚ä»¥å‰ã® Zenn è¨˜äº‹ã®å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æœ€é©å€¤ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚

::::details å®Ÿé¨“ç’°å¢ƒã¨è¨­å®šæƒ…å ±

æœ¬èª¿æŸ»ã§ä½¿ç”¨ã—ãŸå®Ÿé¨“ç’°å¢ƒã¨è¨­å®šã®è©³ç´°ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ç’°å¢ƒ**:
- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: `inf2.xlarge`

**ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒãƒ¼ã‚¸ãƒ§ãƒ³**:
- Neuron SDK: 2.27.x
- vLLM: 0.13.0ï¼ˆNeuron å¯¾å¿œç‰ˆï¼‰
- neuronx-distributed-inference (NxD Inference): 0.7.0
- Python: 3.12

**ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿**:
- ãƒ¢ãƒ‡ãƒ«: Qwen3-0.6B-Reranker
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·:
  - Phase 1-3 åˆæœŸæ¸¬å®š: 97 ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå›ºå®šé•·ï¼‰
  - è¿½åŠ èª¿æŸ»: 18-125 ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå¯å¤‰é•·ã€16 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
- ã‚¿ã‚¹ã‚¯: Rerankerï¼ˆæ–‡æ›¸ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 4

**vLLM è¨­å®šï¼ˆéå»ã® Zenn è¨˜äº‹ã®å®Ÿé¨“ã§ã®æœ€é©å€¤ï¼‰**:
```yaml
vllm:
  tensor_parallel_size: 2           # 2 NeuronCore ä½¿ç”¨
  max_num_seqs: 4                   # åŒæ™‚å‡¦ç†æ•°
  block_size: 32                    # KV cache block size
  max_model_len: 2048
  max_num_batched_tokens: 256
  num_gpu_blocks_override: 512
  enable_prefix_caching: false      # Phase 1-5 ã§ã¯ç„¡åŠ¹
  dtype: "bfloat16"

  additional_config:
    override_neuron_config:
      skip_warmup: True
      enable_bucketing: true        # å‹•çš„ãƒãƒƒãƒãƒ³ã‚°æœ‰åŠ¹
      pa_num_blocks: 512
      pa_block_size: 32
```

ã“ã‚Œã‚‰ã®è¨­å®šã¯ã€[å‰å›ã® Zenn è¨˜äº‹](https://zenn.dev/tosshi/articles/ef61e14fe73399) ã§æœ€é©åŒ–ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

æœ¬èª¿æŸ»ã§ã¯ã€ã“ã®ç‰¹å®šã®è¨­å®šã«ãŠã‘ã‚‹ vllm-neuron ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã¯ã€ç•°ãªã‚‹æ€§èƒ½ç‰¹æ€§ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
::::

### 1.2 Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã®åŸºæœ¬åˆ†æ

å‰å›ã‚‚å°‘ã—ç´¹ä»‹ã—ãŸ Perfetto ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ãˆã¾ã™ã€‚ã¾ãšä»¥ä¸‹ã®ã‚ˆã†ãªåˆ†æã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚

:::details Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚³ãƒ¼ãƒ‰

```python
from perfetto.trace_processor import TraceProcessor
tp = TraceProcessor(trace='profile_output/trace.perfetto-trace')

# Operation ã”ã¨ã®é›†è¨ˆ
sql = """
SELECT name, COUNT(*) as count,
       SUM(dur) / 1e9 as total_seconds,
       AVG(dur) / 1e9 as avg_seconds
FROM slice WHERE dur > 0
GROUP BY name ORDER BY total_seconds DESC LIMIT 10
"""
```

**çµæœã®ä¸€éƒ¨**:
```
                  name   count total_seconds avg_seconds
0              unknown  156427      0.038387         0.0
1               MATMUL   21582      0.010941    0.000001
2 custom_call.17_sg0002      36      0.007028    0.000195
3            LDWEIGHTS   21212      0.004914         0.0
```

**ã‚¯ã‚¨ãƒªã®è¦‹æ–¹**:
`slice` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯å„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œè¨˜éŒ²ãŒæ ¼ç´ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚¯ã‚¨ãƒªã¯ä»¥ä¸‹ã‚’å–å¾—ã—ã¾ã™ã€‚
- `name`: ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åï¼ˆMATMUL ãªã©ã€Neuron ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒç”Ÿæˆã—ãŸæ¼”ç®—ã®ç¨®é¡ï¼‰
- `count`: ãã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œã•ã‚ŒãŸå›æ•°
- `dur`: å„å®Ÿè¡Œã®ç¶™ç¶šæ™‚é–“ï¼ˆãƒŠãƒç§’å˜ä½ã§è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€1e9 ã§å‰²ã£ã¦ç§’ã«å¤‰æ›ï¼‰
- `total_seconds`: ãã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆè¨ˆå®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰
- `avg_seconds`: 1 å›ã‚ãŸã‚Šã®å¹³å‡å®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰
:::

çµæœã¨ã—ã¦ã€ã¾ãšã€`custom_call.17_sg0002` ã¨ã„ã†æ“ä½œãŒãŸã£ãŸ 36 å›ã®å®Ÿè¡Œã§ 7ms ã‚‚æ¶ˆè²»ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚æ¬¡ã«ã€MATMUL ã¨ LDWEIGHTS ãŒã»ã¼åŒã˜å›æ•°å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€`unknown` ã¨ã„ã†åˆ†é¡ã®æ“ä½œãŒ 38ms ã§æœ€å¤§ã®æ™‚é–“ã‚’æ¶ˆè²»ã—ã¦ã„ã¾ã—ãŸã€‚

`custom_call.17_sg0002`ã€‚ã€‚ã€‚ä½•ã§ã™ã‹ã­ã“ã‚Œã¯ã€‚ã€‚

:::details [ç™ºå±•çš„å†…å®¹] NEFF ã«ã‚ˆã‚‹ custom_call ã®èª¿æŸ»

**ç–‘å•**: `custom_call.17_sg0002` ã¨ã¯ä½•ã‹ï¼ŸRoPEï¼Ÿæ´»æ€§åŒ–é–¢æ•°ï¼Ÿä½•ã‚‰ã‹ã®ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ï¼Ÿ

Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã§ã¯å®Ÿè¡Œå›æ•°ã¨æ™‚é–“ã—ã‹åˆ†ã‹ã‚‰ãªã„ãŸã‚ã€NEFF (Neuron Executable File Format) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ [unpacking](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html) ã—ã¦é™çš„ãªæ§‹é€ ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚(uppack ã«ã¯ `neuron-packager unpack` ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ©ç”¨ã—ã¦ã‚‚è‰¯ã„ã§ã™)

**NEFF ã‹ã‚‰åˆ¤æ˜ã—ãŸã“ã¨**:

```bash
# NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ unpacking
$ dd if=neff_322059935237836.neff of=neff.tar.gz bs=1024 skip=1
$ tar -xzf neff.tar.gz

# tensor_map.json ã‚’ç¢ºèª
$ cat sg00/tensor_map.json | jq '.["custom_call.17_sg0002"]'
{
  "dtype": "float32",
  "sim_shape": [256, 1, 1],
  "kind": null,
  "is_const": false,
  "layer_name": "custom_call.17"
}
```

**åˆ†ã‹ã‚‹ã“ã¨**:
- ãƒ‡ãƒ¼ã‚¿å‹: `float32`ï¼ˆç²¾åº¦é‡è¦–ã®æ¼”ç®—ï¼‰
- ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: `[256, 1, 1]`ï¼ˆæ¯”è¼ƒçš„å°ã•ã„ï¼‰
- ã‚µãƒ–ã‚°ãƒ©ãƒ•: `sg0002`
- å‹•çš„ã«è¨ˆç®—ã•ã‚Œã‚‹ä¸­é–“ãƒ†ãƒ³ã‚½ãƒ«
- `custom_call.14` ï½ `17` ã®é€£ç¶šã—ãŸæ¼”ç®—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹

**Qwen3 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰æ¨æ¸¬**:

å½¢çŠ¶ `[256, 1, 1]` ã¨å‘¨è¾ºã® `dot` (MATMUL) æ“ä½œã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ“ä½œã¨æ¨æ¸¬
- **RoPE (Rotary Position Embedding)**: ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨ˆç®—
- **RMSNorm**: æ­£è¦åŒ–å±¤ã®çµ±è¨ˆå€¤è¨ˆç®—
- **ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹**: Softmax å‰ã®ä¸­é–“è¨ˆç®—

NEFF ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã®é™çš„ãªæƒ…å ±ï¼ˆã‚°ãƒ©ãƒ•æ§‹é€ ã€ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ã€ãƒ‡ãƒ¼ã‚¿å‹ï¼‰ã‚’å«ã¿ã¾ã™ãŒã€ä»¥ä¸‹ã¯åˆ¤æ˜ã—ãªã„ã‚ˆã†ã§ã™ã€‚
- å…·ä½“çš„ãªæ¼”ç®—ãƒ­ã‚¸ãƒƒã‚¯
- å®Ÿè¡Œå›æ•°
- å®Ÿè¡Œæ™‚é–“
- åˆå›å®Ÿè¡Œæ™‚ã®é…å»¶

NEFF åˆ†æã‹ã‚‰ã¯ã€ä½•ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã¯åˆ†ã‹ã‚Šã¾ã™ãŒã€ã©ã†å‹•ãã‹ã¯ Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã§å®Ÿè¡Œæ™‚ã«æ¸¬å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
:::

### 1.3 skip_warmup è¨­å®šã®å½±éŸ¿

è©¦è¡ŒéŒ¯èª¤ã—ãªãŒã‚‰å®Ÿè¡Œã—ãŸã‚¯ã‚¨ãƒªã‚’å…¨ã¦ç´¹ä»‹ã—ã¦ã„ã‚‹ã¨è†¨å¤§ã«ãªã£ã¦ã—ã¾ã†ãŸã‚å‰²æ„›ã—ã¾ã™ãŒ custom_call ãŒåˆå›å®Ÿè¡Œæ™‚ã«å¤§ããªé…å»¶ã‚’èµ·ã“ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸãŸã‚ã€NxD Inference ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ `skip_warmup=False` ã‚’è©¦ã—ã¦ã¿ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ `False` ãªã®ã§ã™ãŒä»¥å‰ã®å®Ÿé¨“ã®è©¦è¡ŒéŒ¯èª¤ã§ `True` ã«ã—ã¦ã„ã¾ã—ãŸã€‚ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¾Œã« 1 å›ã® forward å®Ÿè¡Œã‚’è¡Œã„ã€é…å»¶åˆæœŸåŒ–ã‚’å®Œäº†ã•ã›ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚
                                                                                                                  
| è¨­å®š | å¹³å‡æ™‚é–“ |
|------|---------|
| Baseline (skip_warmup=True) | 2.992ç§’ |
| Warmup (skip_warmup=False) | 3.110ç§’ (+3.9%) |

ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã™ã‚Œã°é€Ÿããªã‚‹ã¨äºˆæƒ³ã—ã¦ã„ã¾ã—ãŸãŒã€å®Ÿéš›ã«ã¯ç´„ 4% é…ããªã‚Šã¾ã—ãŸã€‚å†åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¤‰åŒ–ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

:::details Operation æ•°ã®å¤‰åŒ–

```
Baseline (skip_warmup=True):
  MATMUL: 21,582å›, 10.94ms
  LDWEIGHTS: 21,212å›, 4.91ms
  ACTIVATE: 4,702å›, 1.65ms
  COPY: 83å›, 0.03ms

Warmup (skip_warmup=False):
  MATMUL: 13,497å› (-37%), 2.64ms (-76%)
  LDWEIGHTS: 13,497å› (-36%), 1.17ms (-76%)
  ACTIVATE: 4,207å› (-11%), 2.94ms (+78%)
  COPY: 554å› (+567%), 1.01ms (+3,267%)
```
:::

`skip_warmup=False` ã§ MATMUL/LDWEIGHTS ã®ä¸»è¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯å®Ÿè¡Œæ™‚é–“ãŒ 76% æ¸›å°‘ã—ãŸã‚‚ã®ã®ã€ACTIVATE ã®å®Ÿè¡Œæ™‚é–“ãŒ +78%ã€COPY ã®å®Ÿè¡Œæ™‚é–“ãŒ +3,267% å¢—åŠ ã—ã€ãƒˆãƒ¼ã‚¿ãƒ«ã§ã¯é…ããªã‚Šã¾ã—ãŸã€‚


### 1.4 Neuron Profiler ã®æ¸¬å®šç¯„å›²ã®é™ç•Œ

:::message alert
**ã“ã“ã§é‡è¦ãªæ°—ã¥ã**ï¼šNeuron Profiler ã®ãƒˆãƒ¬ãƒ¼ã‚¹æ™‚é–“ã¯ 16-17ms ãªã®ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å…¨ä½“ã¯ç´„ 3 ç§’ã‹ã‹ã£ã¦ã„ã‚‹ã€‚**ã“ã® 16-17ms ã£ã¦ã©ã“ã‹ã‚‰ã©ã“ã¾ã§ã®ãªã‚“ã®å€¤ï¼Ÿ**
:::

æ¶™ã®èª¿æŸ»ã®çµæœã€Neuron Profiler ã®æ¸¬å®šç¯„å›²ã«é–¢ã™ã‚‹é‡è¦ãªç‰¹æ€§ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚Neuron Profiler ã¯å®Ÿè¡Œæ™‚ã« NTFF (Neuron Trace File Format) ã¨ã„ã†ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã«å¤‰æ›ã—ã¾ã™ã€‚å„ NTFF ãƒ•ã‚¡ã‚¤ãƒ«ã¯ 1 ã¤ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œè¨˜éŒ²ã‚’è¡¨ã—ã¦ãŠã‚Šã€ç•°ãªã‚‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚„ sequence length ç”¨ã®è¤‡æ•°ã‚°ãƒ©ãƒ•ãŒå­˜åœ¨ã—ã¾ã™ã€‚ãã®ãŸã‚ã“ã‚Œã ã‘ã‚’è¦‹ã‚Œã° NeuronCore ã®ãƒˆãƒ¼ã‚¿ãƒ«ã®å®Ÿè¡Œæ™‚é–“ãŒç¢ºå®Ÿã«ã‚ã‹ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

```bash
$ find profile_output -name "*.ntff" | wc -l
22  # 11ç¨®é¡ã®ã‚°ãƒ©ãƒ• Ã— 2ã‚³ã‚¢(tensor_parallel_size=2)

# NTFF ã¯ Perfetto ã«å¤‰æ›ã•ã‚Œã‚‹
$ ls profile_output/trace.perfetto-trace
trace.perfetto-trace  # ã“ã‚Œã‚’ TraceProcessor ã‚„ Perfetto UI ã§åˆ†æ
```

:::message alert
**ä»Šå›ã®éã¡ã‹ã‚‰ã®å­¦ã³**: Neuron Profiler ã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®åˆ†æã«ã¯æœ‰ç”¨ã ãŒã€vllm-neuron å…¨ä½“ã®æœ€é©åŒ–ã«ãŠã„ã¦åˆæ‰‹ã§ä½¿ã†ã‚‚ã®ã§ã¯ãªã„ã€‚
:::

ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã‚’å®Ÿè£…ã™ã‚‹ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã¯ Neuron Profiler ã¯å¿…é ˆã¨è¨€ãˆã¾ã™ãŒã€æœ€é©ãªè¨­å®šã‚’æ¢ã™éš›ã®åˆæ‰‹ã§å®Ÿæ–½ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãã—ã¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®æ”¹å–„ã‚’ã™ã‚‹å‰ã« vllm-neuron å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã®å†…ã®ã©ã®ç¨‹åº¦ã‚’ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢å´ã®æ¨è«–å‡¦ç†ãŒå ã‚ã¦ã„ã‚‹ã®ã‹ã«ã‚ˆã£ã¦æ”¹å–„ã®å„ªå…ˆåº¦ãŒå¤‰ã‚ã£ã¦ãã‚‹ã®ã§ vllm-neuron å…¨ä½“ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’ã—ãªã„ã¨æ„å‘³ãªã„ãã€ã¨æ€ã„ã¾ã—ãŸã€‚ã€‚ã¨ã¯ã„ãˆã€ä»Šå›å¾—ãŸ Neuron Profiler ã«é–¢ã™ã‚‹çŸ¥è¦‹ã¯æœ‰ç”¨ãªãŸã‚ã‚·ã‚§ã‚¢ã®æ„å‘³ã‚’è¾¼ã‚ã¦ Phase 1 ã‚’æ¶ˆã•ãšã«ãã®ã¾ã¾å…¬é–‹ã—ã¾ã™ã€‚

### 1.5 NEFFã€Perfetto ã¨ã¯

Phase 1 ã§ç™»å ´ã—ãŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦æ•´ç†ã—ã¾ã™ã€‚

:::message
NEFFï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ï¼‰ â†’ NTFFï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œæ™‚ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ â†’ **Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹**ï¼ˆåˆ†æã«ä½¿ç”¨ï¼‰
:::

#### NEFF (Neuron Executable File Format)

[å‚è€ƒ: Work with NEFF Files](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/explore/work-with-neff-files.html)

**å½¹å‰²**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«

```bash
# NEFF ã®æ§‹é€ 
neff_322059935237836.neff (801KB)
â”œâ”€â”€ [1024 byte header]
â””â”€â”€ [tar.gz archive]
    â”œâ”€â”€ info.json              # ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æƒ…å ±
    â”œâ”€â”€ hlo_stats.json         # æ¼”ç®—çµ±è¨ˆï¼ˆHloMacCount: 29.2B ãªã©ï¼‰
    â”œâ”€â”€ metrics.json           # æ¨å®šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
    â”œâ”€â”€ neff.json              # ã‚°ãƒ©ãƒ•å®šç¾©ï¼ˆ373 ãƒãƒ¼ãƒ‰ï¼‰
    â””â”€â”€ sg00/                  # ã‚µãƒ–ã‚°ãƒ©ãƒ• 0
        â”œâ”€â”€ tensor_map.json    # ãƒ†ãƒ³ã‚½ãƒ«æƒ…å ±ï¼ˆ458 ãƒ†ãƒ³ã‚½ãƒ«ï¼‰
        â”œâ”€â”€ PE.bin             # Processing Element å‘½ä»¤
        â”œâ”€â”€ Activation.bin     # æ´»æ€§åŒ–é–¢æ•°å‘½ä»¤
        â”œâ”€â”€ DVE.bin            # Data Vector Engine å‘½ä»¤
        â””â”€â”€ debug_info_*.dbg   # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
```

::::details NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã¨ bucketing ã®é–¢ä¿‚

**NEFF (Neuron Executable File Format)** ã¯ã€AWS NeuronCore ä¸Šã§å®Ÿè¡Œã•ã‚Œã‚‹ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚bucketing ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€è¤‡æ•°ã® (batch_size, sequence_length) ã®çµ„ã¿åˆã‚ã›ã«å¯¾å¿œã™ã‚‹è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ãŒäº‹å‰ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¾ã™ã€‚

```bash
# NEFF ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
$ find profile_output -name "*.neff" | wc -l
77  # è¤‡æ•°ã® PID ã‹ã‚‰ 11 ç¨®é¡ã®ã‚°ãƒ©ãƒ• Ã— è¤‡æ•°å›ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

$ ls -lh profile_output/*/neff_*.neff | awk '{print $5}' | sort -u
801K   # Graph 1: æœ€å°ãƒã‚±ãƒƒãƒˆ
881K   # Graph 2
991K   # Graph 3
1.1M   # Graph 4
1.3M   # Graph 5
2.1M   # Graph 6
2.3M   # Graph 7
2.4M   # Graph 8
2.6M   # Graph 9
3.0M   # Graph 10
       # (åˆè¨ˆ 11 ç¨®é¡ã€124 MB)
```

bucketing ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã€è¤‡æ•°ã®ã‚µã‚¤ã‚ºã®ã‚°ãƒ©ãƒ•ã‚’äº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ãŠãã€ãã‚Œã‚‰ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–ã«åˆ©ç”¨ã—ã¾ã™ã€‚å®Ÿè¡Œæ™‚ã«å…¥åŠ›ã‚µã‚¤ã‚ºã«å¿œã˜ãŸæœ€é©ã‚°ãƒ©ãƒ•ã‚’é¸æŠã™ã‚‹ã“ã¨ã‹ã‚‰ã€ã‚°ãƒ©ãƒ•é¸æŠã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã©ãŒç™ºç”Ÿã—ã¾ã™ã€‚å›ºå®šé•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã€å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã®ã¯è¤‡æ•°ã‚°ãƒ©ãƒ•ã®ã†ã¡ 1 ã¤ã ã‘ã§ã‚ã‚Šã€ç‰¹ã« bucketing ã®æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãªãã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒè¿½åŠ ã•ã‚Œã‚‹ã¨æ€ã‚ã‚Œã¾ã™ã€‚ä¸€èˆ¬çš„ãª LLM ã®ç”Ÿæˆã®ã‚ˆã†ãªå¯å¤‰é•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯ç•°ãªã‚‹é•·ã•ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¤‡æ•°ã‚°ãƒ©ãƒ•ã«åˆ†æ•£ã•ã‚Œã‚‹ã®ã§å†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ã“ã¨ãªãåŠ¹ç‡çš„ãªãƒãƒƒãƒãƒ³ã‚°ãŒå¯èƒ½ãªãŸã‚ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å·®ã—å¼•ã„ã¦ã‚‚é«˜é€ŸåŒ–ã«è²¢çŒ®ã™ã‚‹ã¨æ€ã‚ã‚Œã¾ã™ã€‚

:::message
**ã“ã®ã‚ˆã†ã«ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ bucketing ã®æ€§èƒ½ã¯ ON/OFF ã§ã©ã¡ã‚‰ãŒè‰¯ã„ã‹å¤‰å‹•ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’è¦šãˆã¦ãŠã„ã¦ãã ã•ã„ï¼**
:::
::::

#### NTFF (Neuron Trace File Format) - ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«

**å½¹å‰²**: Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹ã«å¤‰æ›ã•ã‚Œã‚‹å‰ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«

```bash
# NTFF ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ï¼ˆNeuron Profiler ãŒç”Ÿæˆï¼‰
profile_output/i-0049acfde6046f237_pid_520024/
â”œâ”€â”€ 322059935237836_instid_0_vnc_0.ntff  # Graph 1, Core 0
â”œâ”€â”€ 322059935237836_instid_0_vnc_1.ntff  # Graph 1, Core 1
â”œâ”€â”€ 729292360268366_instid_0_vnc_0.ntff  # Graph 4, Core 0
â”œâ”€â”€ 729292360268366_instid_0_vnc_1.ntff  # Graph 4, Core 1
...
â””â”€â”€ (22 files = 11 graphs Ã— 2 cores)

# Neuron Profiler ã§ Perfetto ã«å¤‰æ›
$ neuron-profile view --output-format perfetto profile_output
```

#### Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹

**å½¹å‰²**: NeuronCore ä¸Šã®ä½ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹

```bash
# Perfetto ãƒˆãƒ¬ãƒ¼ã‚¹
trace.perfetto-trace (110 MB)
â””â”€â”€ SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    â”œâ”€â”€ slice ãƒ†ãƒ¼ãƒ–ãƒ«          # ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œè¨˜éŒ²
    â”‚   â””â”€â”€ MATMUL: 21,582å›, 10.94ms
    â”‚       COPY: 83å›, 0.03ms
    â”‚       custom_call.17: 36å›, 7ms
    â”œâ”€â”€ thread ãƒ†ãƒ¼ãƒ–ãƒ«         # ã‚¹ãƒ¬ãƒƒãƒ‰æƒ…å ±
    â””â”€â”€ process ãƒ†ãƒ¼ãƒ–ãƒ«        # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±
```

::::details NEFF ã¨ Perfetto ã®æ¯”è¼ƒ

ä»¥ä¸‹ã¯ã¾ã å®Œå…¨ã«ã¯æ•´ç†ã—ãã‚Œã¦ã„ãªã„ãŸã‚å‚è€ƒç¨‹åº¦ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚

| æƒ…å ± | NEFF | Perfetto |
|------|------|----------|
| **é™çš„æ§‹é€ ** | | |
| ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆãƒãƒ¼ãƒ‰ã€ãƒ†ãƒ³ã‚½ãƒ«æ•°ï¼‰ | âœ… | âŒ |
| ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ãƒ»ãƒ‡ãƒ¼ã‚¿å‹ | âœ… | âŒ |
| æ¼”ç®—é‡ï¼ˆç†è«–å€¤ï¼‰ | âœ… | âŒ |
| ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆç†è«–å€¤ï¼‰ | âœ… | âŒ |
| DMA ã‚­ãƒ¥ãƒ¼æ§‹æˆ | âœ… | âŒ |
| **ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œ** | | |
| ã‚°ãƒ©ãƒ•ã”ã¨ã®å®Ÿè¡Œæ™‚é–“ | âŒ | âš ï¸ |
| NeuronCore ã”ã¨ã®å†…è¨³ | âŒ | âš ï¸ |
| ä½¿ç”¨ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã®è­˜åˆ¥ | âŒ | âš ï¸ |
| ã‚°ãƒ©ãƒ•é–“ã®é·ç§»æ™‚é–“ | âŒ | âš ï¸ | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰æ¨å®š |
| **ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œ** | | | |
| å®Ÿè¡Œæ™‚é–“ï¼ˆå®Ÿæ¸¬å€¤ï¼‰ | âŒ | âœ… | slice.dur |
| å®Ÿè¡Œå›æ•° | âŒ | âœ… | COUNT(*) |
| ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©³ç´°ï¼ˆMATMULã€COPY ãªã©ï¼‰ | âŒ | âœ… | slice.name |
| ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨å®Ÿè¡Œé †åº | âŒ | âœ… | slice.ts |
| ä¸¦åˆ—å®Ÿè¡Œã®å¯è¦–åŒ– | âŒ | âœ… | Perfetto UI |
| åˆæœŸåŒ–é…å»¶ï¼ˆskip_warmup åŠ¹æœï¼‰ | âŒ | âœ… | åˆå›å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒ |
| **é«˜ãƒ¬ãƒ™ãƒ«æƒ…å ±** | | | |
| Python ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ | âŒ | âŒ | line_profiler ãªã©ãŒå¿…è¦ |
| æ¼”ç®—å†…å®¹ã®æ„å‘³ï¼ˆRoPEã€RMSNorm ãªã©ï¼‰ | âš ï¸ | âŒ | å½¢çŠ¶ã‹ã‚‰æ¨æ¸¬ã®ã¿ |

**å‡¡ä¾‹**: âœ… ç›´æ¥å–å¾—å¯èƒ½ã€âš ï¸ æ¨æ¸¬ãƒ»è¨ˆç®—ãŒå¿…è¦ã€âŒ å–å¾—ä¸å¯èƒ½
::::

## Phase 2: line_profiler ã«ã‚ˆã‚‹ Python ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

Phase 1 ã§ã¯ Neuron Profiler ã«ã‚ˆã‚Š NeuronCore ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ãªåˆ†æã‚’è¡Œã„ã¾ã—ãŸãŒã€Python ãƒ¬ãƒ™ãƒ«ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ¼ã‚¿æº–å‚™ãªã©ï¼‰ã®æ¸¬å®šã«ã¯åˆ¥ã®ãƒ„ãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚ãã“ã§ line_profiler ã‚’ä½¿ç”¨ã—ã¦ Python ã‚³ãƒ¼ãƒ‰ã®è¡Œã”ã¨ã®å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®šã—ã¾ã™ã€‚

### æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æº–å‚™

Phase 1 ã§ä½¿ç”¨ã—ãŸ `test_reranker.py` ã¯ pytest + benchmark_capture ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€line_profiler ã¨çµ„ã¿åˆã‚ã›ã‚‹ã¨å‡ºåŠ›ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãã“ã§ã€line_profiler å°‚ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ `profile_line.py` ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ï¼ˆã“ã®è¾ºã‚Šã‚‚ vllm-neuron ã® Python ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã†ã¾ãå–ã‚Œã‚‹ã‚ˆã†ã«ä»Šå¾Œ benchmark_capture ã®å®Ÿè£…ã‚’æ”¹å–„ã—ã¾ã™ï¼‰

::::details ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ§‹é€ 

```python:profile_line.py
try:
    profile
except NameError:
    def profile(func):
        return func

# config.yaml ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆtest_reranker.py ã¨åŒã˜ï¼‰
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# æ¸¬å®šå¯¾è±¡ã®é–¢æ•°ã« @profile ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
    # ... (test_reranker.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)

@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id,
                 prefix_tokens, suffix_tokens):
    """ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ... (test_reranker.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆpytest éä¾å­˜ï¼‰"""
    llm = vllm.LLM(model=model_path, **vllm_config)
    # ... åˆæœŸåŒ–ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ

if __name__ == "__main__":
    main()
```

::::

::::details ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Œå…¨ç‰ˆ
```python:profile_line.py
"""
Line profiler script for vLLM-Neuron Reranker

Run with:
    kernprof -l -v profile_line.py

Or for more detailed output:
    kernprof -l profile_line.py
    python -m line_profiler profile_line.py.lprof
"""

# line_profiler compatibility: make @profile decorator optional
try:
    profile
except NameError:
    # If not running under kernprof, @profile is a no-op
    def profile(func):
        return func

import csv
import gc
import logging
import os
import sys
from pathlib import Path

import yaml

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load configuration
config_path = Path(__file__).parent / 'config.yaml'
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

# Get model path
model_path = config['model']['path']

# Get vLLM config
vllm_config = {
    "tensor_parallel_size": config['vllm']['tensor_parallel_size'],
    "max_num_seqs": config['vllm']['max_num_seqs'],
    "block_size": config['vllm']['block_size'],
    "max_model_len": config['vllm']['max_model_len'],
    "max_num_batched_tokens": config['vllm']['max_num_batched_tokens'],
    "num_gpu_blocks_override": config['vllm']['num_gpu_blocks_override'],
    "enable_prefix_caching": config['vllm']['enable_prefix_caching'],
    "dtype": config['vllm']['dtype'],
    "disable_log_stats": config['vllm'].get('disable_log_stats', False),
}

# Add additional_config if present (Zenn article optimal settings)
if 'additional_config' in config['vllm']:
    vllm_config['additional_config'] = config['vllm']['additional_config']

# Get reranker config
reranker_config = config['reranker']
benchmark_config = config['benchmark']

# Reranker prompts
reranker_prompts = {
    'instruction': reranker_config['instruction'],
    'prefix': reranker_config['prefix'],
    'suffix': reranker_config['suffix']
}

# Token IDs
token_ids = {
    'true': reranker_config['token_true'],
    'false': reranker_config['token_false']
}

# Load CSV data
csv_file = Path(__file__).parent / reranker_config['input_file']
with open(csv_file, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    rows = list(reader)

num_queries = min(len(rows), benchmark_config['num_test_queries'])
search_num = reranker_config['search_num']
batch_size = reranker_config['batch_size']
max_length = reranker_config['max_length']

logger.info(f"Loaded {len(rows)} queries from {csv_file}")
logger.info(f"Testing with first {num_queries} queries")


def format_instruction(query: str, doc: str) -> str:
    """Format instruction for reranker"""
    instruction = reranker_prompts['instruction']
    output = f"<Instruct>: {instruction}\n<Query>: {query}\n<Document>: {doc}"
    # Truncate if too long
    if len(output) >= 2000:
        output = output[:2000]
    return output


@profile
def build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens):
    """Build prompts with proper tokenization - PROFILING TARGET"""
    prompts = []
    budget = max_length - len(prefix_tokens) - len(suffix_tokens)

    # Tokenize pairs
    enc = tokenizer(
        list(pairs),
        padding=False,
        truncation="longest_first",
        return_attention_mask=False,
        add_special_tokens=False,
        max_length=max(8, budget),
    )

    # Build final prompts: prefix + content + suffix
    for ids in enc["input_ids"]:
        final_ids = prefix_tokens + ids + suffix_tokens
        text = tokenizer.decode(final_ids, skip_special_tokens=False)
        prompts.append(text)

    return prompts


@profile
def run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens):
    """Run reranker on queries - MAIN PROFILING TARGET"""

    import vllm
    from vllm import SamplingParams

    # Get use_tqdm setting from benchmark config
    use_tqdm = benchmark_config.get('use_tqdm', True)

    # Create SamplingParams
    sampling_params = SamplingParams(
        max_tokens=1,
        temperature=0.0,
        logprobs=20,
        detokenize=True,
        allowed_token_ids=[token_true_id, token_false_id]
    )

    logger.info(f"SamplingParams configured: max_tokens=1, "
                f"allowed_tokens=[{token_ids['true']}, {token_ids['false']}]")

    # Process each query
    total_processed = 0
    for query_idx, row in enumerate(rows[:num_queries]):
        query = row["query"]

        # Get candidates
        candidates = [
            row[f"answer_{i}"]
            for i in range(search_num)
            if f"answer_{i}" in row
        ]

        # Format query-document pairs
        pairs = [format_instruction(query, doc) for doc in candidates[:search_num]]

        # Build prompts with tokenization
        prompts = build_prompts_for_vllm(pairs, tokenizer, prefix_tokens, suffix_tokens)

        # Process in batches
        query_outputs = []
        for s in range(0, len(prompts), batch_size):
            batch_prompts = prompts[s:s + batch_size]
            outputs = llm.generate(batch_prompts, sampling_params, use_tqdm=use_tqdm)
            query_outputs.extend(outputs)

        total_processed += len(query_outputs)

        if query_idx == 0:
            # Show first result for verification
            logger.info(f"Query 1: {query[:80]}...")
            logger.info(f"Generated {len(query_outputs)} scores for "
                       f"{len(candidates[:search_num])} candidates")
            if query_outputs:
                first_output = query_outputs[0]
                logger.info(f"First output: {first_output.outputs[0].text} "
                           f"(token_ids={first_output.outputs[0].token_ids})")

    logger.info(f"Profiling completed: processed {total_processed} reranker pairs")
    return total_processed


def main():
    """Main profiling function"""
    import vllm

    logger.info("Initializing vLLM-Neuron reranker...")
    logger.info(f"Model: {model_path}")
    logger.info(f"Config: block_size={vllm_config['block_size']}, "
               f"max_num_seqs={vllm_config['max_num_seqs']}, "
               f"tensor_parallel_size={vllm_config['tensor_parallel_size']}")

    # Initialize vLLM
    llm = vllm.LLM(model=model_path, **vllm_config)

    # Get tokenizer and token IDs
    tokenizer = llm.get_tokenizer()
    token_false_id = tokenizer.convert_tokens_to_ids(token_ids['false'])
    token_true_id = tokenizer.convert_tokens_to_ids(token_ids['true'])

    logger.info(f"Token IDs: {token_ids['true']}={token_true_id}, "
               f"{token_ids['false']}={token_false_id}")

    # Encode prompt templates
    prefix_tokens = tokenizer.encode(
        reranker_prompts['prefix'], add_special_tokens=False
    )
    suffix_tokens = tokenizer.encode(
        reranker_prompts['suffix'], add_special_tokens=False
    )

    logger.info(f"Prefix tokens: {len(prefix_tokens)}, Suffix tokens: {len(suffix_tokens)}")

    # Run profiling
    logger.info("Starting profiling run...")
    total = run_reranker(llm, tokenizer, token_true_id, token_false_id, prefix_tokens, suffix_tokens)

    logger.info(f"Profiling complete. Processed {total} pairs.")

    # Cleanup
    del llm
    gc.collect()


if __name__ == "__main__":
    main()
````

```yaml:config.yaml
# vLLM-Neuron Reranker Benchmark Configuration

# Model configuration
model:
  # Path to the reranker model
  # Example: "/path/to/models/Qwen3-0.6B-Reranker"
  # Use environment variable: export RERANKER_MODEL_PATH="/your/model/path"
  path: "/home/coder/data-science/investigations/inf2-vllm-performance/models/Qwen3-0.6B-Reranker"

# vLLM-Neuron engine settings
vllm:
  tensor_parallel_size: 2           # Number of NeuronCores
  max_num_seqs: 4                   # Batch size
  block_size: 32                    # KV cache block size (32 for Zenn best case, 128 for stability)
  max_model_len: 2048               # Maximum sequence length
  max_num_batched_tokens: 256       # Performance optimization
  num_gpu_blocks_override: 512      # pa_num_blocks equivalent
  enable_prefix_caching: false      # Explicit disable
  dtype: "bfloat16"                 # Data type

  # Neuron-specific overrides (Zenn article optimal settings)
  additional_config:
    override_neuron_config:
      skip_warmup: true             # Phase 1-5 ã®è¨­å®šï¼ˆè¨˜äº‹ã¨ä¸€è‡´ï¼‰
      enable_bucketing: true        # å‹•çš„ãƒãƒƒãƒãƒ³ã‚°æœ‰åŠ¹
      pa_num_blocks: 512
      pa_block_size: 32

# Reranker-specific settings
reranker:
  # Input data
  input_file: "input_sample.csv"    # CSV file with queries and candidates

  # Processing parameters
  search_num: 20                    # Number of candidates per query to process
  batch_size: 8                     # Batch size for processing prompts
  max_length: 1500                  # Maximum prompt length

  # Model-specific tokens (for Qwen3-Reranker)
  # Change these for other reranker models
  token_true: "yes"
  token_false: "no"

  # Prompt templates (for Qwen3-Reranker)
  # Customize these for your model
  prefix: |
    <|im_start|>system
    Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be "yes" or "no".<|im_end|>
    <|im_start|>user

  # Note: "assitant" typo is intentional for Qwen3-Reranker compatibility
  suffix: |
    <|im_end|>
    <|im_start|>assitant
    <think>

    </think>


  instruction: "Given a web search query, retrieve relevant passages that answer the query"

# Benchmark settings
benchmark:
  rounds: 5                         # Number of benchmark rounds
  warmup_rounds: 1                  # Number of warmup rounds
  num_test_queries: 10              # Number of queries to use for testing (è¨˜äº‹ã¨åŒã˜æ¡ä»¶)

# Profiler settings (optional)
profiler:
  # Clear Neuron compilation cache before benchmark
  # WARNING: First run after clearing will recompile (10-15 minutes)
  # Useful when:
  # - Model configuration changed (batch size, sequence length, etc.)
  # - Neuron SDK version changed
  # - Testing clean compilation performance
  clear_cache_before: false

  # Clear cache after benchmark (useful for CI/CD to save disk space)
  clear_cache_after: false
```
::::

ã“ã‚Œã«ã‚ˆã‚Šã€**Phase 1 ã¨åŒã˜æ¸¬å®šæ¡ä»¶**ï¼ˆåŒã˜ config.yamlã€åŒã˜å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã‚’ç¶­æŒã—ãªãŒã‚‰ã€line_profiler ã«ã‚ˆã‚‹è©³ç´°ãª Python ãƒ¬ãƒ™ãƒ«ã®åˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

### 2.1 æ¸¬å®šå¯¾è±¡ã®ç†è§£

**æ¸¬å®šå¯¾è±¡**: 1 ã‚¯ã‚¨ãƒªï¼ˆ20 å€™è£œæ–‡æ›¸ã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ã‚’å‡¦ç†ã™ã‚‹æ™‚é–“

```yaml
reranker:
  search_num: 20        # 1 ã‚¯ã‚¨ãƒªã‚ãŸã‚Š 20 å€™è£œæ–‡æ›¸
  batch_size: 8         # 8 ãƒšã‚¢ãšã¤ãƒãƒƒãƒå‡¦ç†

vllm:
  max_num_seqs: 4       # vLLM ã®åŒæ™‚å‡¦ç†æ•°
```

```
1  ã‚¯ã‚¨ãƒª = 20 ãƒšã‚¢ Ã· batch_size=8 = 3 ãƒãƒƒãƒ
10 ã‚¯ã‚¨ãƒª = 30 ãƒãƒƒãƒ
åˆè¨ˆæ™‚é–“ = 2,992ms â†’ 1 ã‚¯ã‚¨ãƒªã‚ãŸã‚Šç´„ 300ms
```

### 2.2 line_profiler æ¸¬å®šçµæœ

::::details line_profiler ã®å®Ÿè¡Œ

**å®Ÿè¡Œç’°å¢ƒã®æº–å‚™**:

```bash
# vLLM-Neuron ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source /opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin/activate

# PATH ã« Neuron SDK ã®ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ 
export PATH="/opt/aws_neuronx_venv_pytorch_inference_vllm_0_13/bin:$PATH"

# line_profiler ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ
pip install line-profiler
```

**ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ**:

```bash
cd /path/to/my-reranker
kernprof -l -v -p vllm.v1.engine profile_line.py
```

:::message
**kernprof ã‚ªãƒ—ã‚·ãƒ§ãƒ³èª¬æ˜**:
- `-l` (--line-by-line): è¡Œã”ã¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
- `-v` (--view): çµæœã‚’å³åº§ã«è¡¨ç¤º
- `-p vllm.v1.engine` (--prof-mod): **vllm.v1.engine ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è‡ªå‹•ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯¾è±¡ã«æŒ‡å®š**ï¼ˆã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®å…¨é–¢æ•°ã‚’è‡ªå‹•çš„ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼‰
:::

å®Ÿè¡Œå¾Œã€`profile_line.py.lprof` ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°ãªè¡Œã”ã¨ã®å®Ÿè¡Œæ™‚é–“ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
::::

ä»¥ä¸‹ã«å®Ÿéš›ã« line_profiler ã®çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’ç¤ºã—ã¾ã™ã€‚

```python
# llm.generate() - 30 ãƒãƒƒãƒå‡¦ç†
Line 157: outputs = llm.generate(batch_prompts, sampling_params)
  - Hits: 30 batches
  - Time: 3781.560 ms (3.78 ç§’)
  - Per Hit: 126.052 ms/batch
  - % Time: 99.1%

# LLMEngine.step() ã®å†…è¨³
Line 293: outputs = self.engine_core.get_output()
  - Hits: 229 steps (7.6 steps/batch)
  - Time: 3197.372 ms
  - Per Hit: 13.962 ms/step
  - % Time: 95.3%
```

line_profiler ã«ã‚ˆã‚‹æ¸¬å®šã®çµæœã€10 ã‚¯ã‚¨ãƒªï¼ˆ30 ãƒãƒƒãƒï¼‰ã®å‡¦ç†ã«åˆè¨ˆ 3.78 ç§’ã‹ã‹ã‚Šã€ãã®ã†ã¡ `llm.generate()` ã®å‘¼ã³å‡ºã—ã ã‘ã§ **99.1%ï¼ˆ3.78 ç§’ï¼‰** ã‚’å ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚ç´„ 3 ç§’ã‹ã‚‰æ™‚é–“ãŒå¢—ãˆã¦ã„ã‚‹ã®ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§ã™ã€‚

ã•ã‚‰ã«é‡è¦ãªç™ºè¦‹ã¨ã—ã¦ã€**1 ãƒãƒƒãƒã‚ãŸã‚Šã®å‡¦ç†æ™‚é–“ãŒ 126.052ms** ã¨ã„ã†æ¸¬å®šå€¤ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ãŸã ã—ã€ã“ã®å€¤ã¯ **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å«ã‚€** ãŸã‚ã€Phase 3 ã§ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã‚’åˆ¥é€”å®Ÿæ–½ã—ã¾ã™ã€‚ã¾ãŸã€vLLM ã®å†…éƒ¨å‡¦ç†ã‚’è¦‹ã‚‹ã¨ã€`LLMEngine.step()` ãŒ 229 å›å‘¼ã°ã‚Œã¦ãŠã‚Šã€30 ãƒãƒƒãƒã«å¯¾ã—ã¦ **å¹³å‡ 7.6 steps/batch** ã¨ã„ã†è¬ã®å€¤ãŒè¦³æ¸¬ã•ã‚Œã¾ã—ãŸã€‚ãªãœ 1 ãƒãƒƒãƒã®å‡¦ç†ã« 7.6 å›ã‚‚ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦ãªã®ã‹ã€ã“ã®æ™‚ç‚¹ã§ã¯ç†è§£ã§ãã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚

### 2.3 7.6 steps/batch ã®ç†ç”±ã‚’è¿½ã†

ã“ã®æ•°å€¤ã®è§£æ˜ã™ã‚‹ãŸã‚ã€`LLMEngine.step()` ã®ä¸­èº«ã‚’ã•ã‚‰ã«è©³ã—ãèª¿ã¹ã¾ã—ãŸã€‚line_profiler ã® `-p vllm.v1.engine` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šã€vLLM å†…éƒ¨ã®ã‚³ãƒ¼ãƒ‰ã‚‚è‡ªå‹•ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚

`LLMEngine.step()` ã®å‡¦ç†æ™‚é–“ã®ã»ã¼å…¨ã¦ï¼ˆ95.3%ï¼‰ãŒ `engine_core.get_output()` ã¨ã„ã†å˜ä¸€ã®é–¢æ•°å‘¼ã³å‡ºã—ã§è²»ã‚„ã•ã‚Œã¦ã„ã¾ã—ãŸã€‚ã•ã‚‰ã«ãã® `get_output()` é–¢æ•°ã®ä¸­èº«ã‚’è¦‹ã‚‹ã¨ã€**100% ãŒ `outputs_queue.get()` ã¨ã„ã†ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†**ã§ã—ãŸã€‚

```python
# LLMEngine.step() ã®ä¸­èº«
Line 293: outputs = self.engine_core.get_output()
  - Time: 3197.372 ms (95.3% of step())

# get_output() ã®ä¸­èº«
Line 715: outputs = self.outputs_queue.get()
  - Time: 3194.6 ms
  - % Time: 100.0% of get_output()
```

ã¤ã¾ã‚Šã€ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¯ `outputs_queue.get()` ã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰çµæœãŒé€ã‚‰ã‚Œã¦ãã‚‹ã®ã‚’ãŸã **å¾…ã£ã¦ã„ã‚‹ã ã‘**ã§ã—ãŸã€‚ã“ã‚Œã¯å®Ÿéš›ã®æ¨è«–å‡¦ç†ãŒåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§è¡Œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã“ã“ã§ vLLM v1 ã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å­˜åœ¨ã‚’æ€ã„å‡ºã—ã¾ã—ãŸã€‚

ï¼ˆä»¥ä¸‹ã®è¨˜äº‹ã«å†…éƒ¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è§£èª¬ãŒã‚ã‚Šã¾ã™ï¼‰

https://zenn.dev/tosshi/articles/f64ba0b86e330b

vLLM v1 ã§ã¯ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ã‘å–ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¨ã€å®Ÿéš›ã«æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ Worker ãƒ—ãƒ­ã‚»ã‚¹ãŒåˆ†é›¢ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã¯ `llm.generate()` ã‚’å‘¼ã³å‡ºã™ã¨ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ Worker ãƒ—ãƒ­ã‚»ã‚¹ã«é€ä¿¡ã—ã€`outputs_queue.get()` ã§ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦çµæœã‚’å¾…ã¡ã¾ã™ã€‚ä¸€æ–¹ã€Worker ãƒ—ãƒ­ã‚»ã‚¹ã¯ NeuronCore ã§ã®æ¨è«–å®Ÿè¡Œã€çµæœã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ã‚’é€šã˜ã¦ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã«çµæœã‚’è¿”ã—ã¾ã™ã€‚ã“ã®æ§‹é€ ã‚’å›³ç¤ºã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

**vLLM v1 ã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (vllm-neuron)**

```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    subgraph MainProcess["Main Process"]
        A[LLMEngine.step] --> B[get_output]
        B --> C[outputs_queue.get<br/>13.962 ms/step]
    end

    subgraph WorkerProcess["Worker Process"]
        D[EngineCore] --> E[execute_model]
        E --> F[Neuron å®Ÿè¡Œ]
        F --> G[ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³]
        G --> H[ZMQ é€ä¿¡]
    end

    H -->|IPC| C

    style MainProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style WorkerProcess fill:#1a1a2e,stroke:#16213e,stroke-width:2px,color:#fff
    style C fill:#0f3460,stroke:#16213e,color:#fff
    style F fill:#0f3460,stroke:#16213e,color:#fff
```

line_profiler ã¯ Python ã®æ¨™æº–çš„ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ã¨åŒæ§˜ã«ã€**å®Ÿè¡Œä¸­ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ã‚³ãƒ¼ãƒ‰ã—ã‹æ¸¬å®šã§ãã¾ã›ã‚“**ã€‚ã¤ã¾ã‚Šã€Worker ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œã•ã‚Œã‚‹ `execute_model()` ã‚„ NeuronCore ã§ã®æ¨è«–å‡¦ç†ã¯ã€ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã™ã€‚

æ¸¬å®šã§ããŸã®ã¯ `outputs_queue.get()` ã§å¾…æ©Ÿã—ã¦ã„ã‚‹æ™‚é–“ï¼ˆ13.962ms/stepï¼‰ã ã‘ã§ã‚ã‚Šã€ã“ã®æ™‚é–“ã«ã¯æ¨è«–ã€IPC ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã©ã®ã™ã¹ã¦ã®æ™‚é–“ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

ã§ã¯ã€ãªãœ 1 ãƒãƒƒãƒã®å‡¦ç†ã«å¹³å‡ 7.6 å›ã‚‚ `step()` ãŒå‘¼ã°ã‚Œã‚‹ã®ã§ã—ã‚‡ã†ã‹ã€‚ã“ã‚Œã¯ vLLM v1 ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å‹•ä½œæ–¹æ³•ã¨ã—ã¦ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ãŒä½•åº¦ã‚‚ `step()` ã‚’ç¢ºèªã—ã¦ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ç¶šã‘ã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€‚1 ãƒãƒƒãƒã‚ãŸã‚Šå¹³å‡ã—ã¦ 7.6 å›ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ãŸã¨ã„ã†ã“ã¨ã§ã™ã€‚

è¬ã¯è§£ã‘ã¾ã—ãŸãŒã€è‚å¿ƒã® **Worker ãƒ—ãƒ­ã‚»ã‚¹å†…ã§ã® NeuronCore ã®æ¨è«–å‡¦ç†æ™‚é–“**ã‚’åˆ†è§£ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚`outputs_queue.get()` ã® 13.962 ms ã«ã¯ã€æ¨è«–å®Ÿè¡Œã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€IPC é€šä¿¡ã®ã™ã¹ã¦ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€line_profiler ã§ã¯ã“ã‚Œä»¥ä¸Šåˆ†è§£ã‚’ã™ã‚‹ã®ã¯é›£ã—ãã†ã§ã™ã€‚

:::message alert
**ä»Šå›ã®éã¡ã‹ã‚‰ã®å­¦ã³**: line_profiler ã§ã¯ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã«é™ç•ŒãŒã‚ã‚‹ãŸã‚ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£ã—ãŸä¸Šã§æ¬²ã—ã„æƒ…å ±ã‚’å–å¾—ã§ãã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’é¸å®šã—ãŸæ–¹ãŒè‰¯ã„ã€‚py-spy ã¯ Worker å´ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¾ã§å®Ÿæ–½ã§ãã¾ã™ã€‚
:::

### 2.4 æ¸¬å®šã®é™ç•Œã¨ä»Šå¾Œã®æ–¹å‘æ€§

line_profiler ã«ã‚ˆã‚‹æ¸¬å®šã§åˆ¤æ˜ã—ãŸã“ã¨ã‚’æ•´ç†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹é€ ã«ãªã‚Šã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ 126.052 ms/batch ã¨ã„ã†å‡¦ç†æ™‚é–“ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¾¼ã¿ï¼‰ã¯æ¸¬å®šã§ãã¾ã—ãŸãŒã€ãã®å†…è¨³ã®å¤§éƒ¨åˆ†ï¼ˆ84.2%ï¼‰ã®è©³ç´°ãŒä¸æ˜ã¨ã„ã†çŠ¶æ³ã§ã™ã€‚

ã“ã®çŠ¶æ³ã‚’æ‰“é–‹ã™ã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å«ã¾ãªã„ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šã¨ã€NxD Inference ã‚’ç›´æ¥ä½¿ã£ãŸæ¸¬å®šã‚’è©¦ã¿ã¾ã—ãŸã€‚
## Phase 3: NxD Inference æ¸¬å®š

Worker ãƒ—ãƒ­ã‚»ã‚¹ã®ç›´æ¥æ¸¬å®šãŒå›°é›£ãªãŸã‚ã€**vLLM ã‚’ä½¿ã‚ãšã« NxD Inference ã‚’ç›´æ¥ä½¿ç”¨**ã—ã¦ç´”ç²‹ãªæ¨è«–å®Ÿè¡Œæ™‚é–“ã‚‚æ¸¬å®šã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€Bucketing ã¨ Prefix Caching ã®å…¨çµ„ã¿åˆã‚ã›ã‚’æ¸¬å®šã—ã¾ã—ãŸã€‚

:::message alert
**Phase 1-2 ã¨ã®æ¸¬å®šæ–¹æ³•ã®é•ã„ã«ã¤ã„ã¦:**

Phase 1-2 ã§ã¯ä¸»ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¤œè¨¼ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€å®šé‡çš„ãªæ€§èƒ½å€¤ã®æ¸¬å®šç²¾åº¦ã¯ Phase 3 ãŒæœ€ã‚‚é«˜ããªã£ã¦ã„ã¾ã™ã€‚

- **Phase 1**: Neuron Profiler ã«ã‚ˆã‚‹è©¦è¡ŒéŒ¯èª¤ï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ï¼‰
- **Phase 2**: line_profiler åˆ†æï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¾¼ã¿ã€126.052 ms/batchï¼‰
- **Phase 3**: ç´”ç²‹ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¸¬å®šï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è»½å¾®ã€çµ±ä¸€æ¡ä»¶ï¼‰

Phase 3 ã§ã¯å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ä»¥ä¸‹ã®æ¡ä»¶ã‚’çµ±ä¸€ã—ã¦ã„ã¾ã™ã€‚
- æ¸¬å®šã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 100 å›ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— 3 å›å¾Œï¼‰
- çµ±ä¸€ vLLM è¨­å®šï¼ˆmax_num_batched_tokens=256, num_gpu_blocks_override=512ï¼‰
- åŒä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒãƒƒãƒã‚µã‚¤ã‚º

Phase 1-2 ã®å®Ÿé¨“çµæœã¯ã€Œãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ‰‹æ³•ã®æœ‰ç”¨æ€§æ¤œè¨¼ã€ã¨ã—ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚**å®šé‡çš„ãªæ€§èƒ½æ¯”è¼ƒã«ã¯ Phase 3 ã®çµæœã‚’ä½¿ç”¨ã—ã¾ã™ã€‚**
:::

### 3.0 æ¸¬å®šçµæœã‚µãƒãƒªãƒ¼ï¼ˆå…¨ 16 ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

ä»¥ä¸‹ã®è¡¨ã¯ã€NxD Inference ã¨ vllm-neuron ã®ä¸¡æ–¹ã§ã€Bucketing ON/OFFã€Prefix Caching ON/OFFã€å›ºå®šé•·ï¼ˆ97 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰/ å¯å¤‰é•·ï¼ˆ81-126 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€ã®å…¨çµ„ã¿åˆã‚ã›ã§ã™ã€‚

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | BucketingåŠ¹æœ |
|----|---------|-----------|----------------|------------|-------------------|-------------|
| |
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **196.56** | - |
| 02 | NxD | ON | OFF | å›ºå®šé•· | **188.97** | -3.9% |
| 03 | NxD | OFF | ON | å›ºå®šé•· | - | - |
| 04 | NxD | ON | ON | å›ºå®šé•· | - | - |
| 09 | vLLM | OFF | OFF | å›ºå®šé•· | **252.42** | - |
| 10 | vLLM | ON | OFF | å›ºå®šé•· | **59.23** | -76.5% |
| 11 | vLLM | OFF | ON | å›ºå®šé•· | **237.54** | - |
| 12 | vLLM | ON | ON | å›ºå®šé•· | **85.92** | - |
| |
| 05 | NxD | OFF | OFF | å¯å¤‰é•· | **194.73** | - |
| 06 | NxD | ON | OFF | å¯å¤‰é•· | **20.42** | **-89.5%** |
| 07 | NxD | OFF | ON | å¯å¤‰é•· | - | - |
| 08 | NxD | ON | ON | å¯å¤‰é•· | - | - |
| 13 | vLLM | OFF | OFF | å¯å¤‰é•· | **254.80** | - |
| 14 | vLLM | ON | OFF | å¯å¤‰é•· | **60.62** | **-76.2%** |
| 15 | vLLM | OFF | ON | å¯å¤‰é•· | **239.24** | - |
| 16 | vLLM | ON | ON | å¯å¤‰é•· | **85.28** | **-64.4%** |

### 3.1 Bucketing ã®åŠ¹æœ

#### Bucketing OFF æ™‚ã®æŒ™å‹•

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | BucketingåŠ¹æœ |
|----|------|-----------|----------------|------------|-------------------|---------------|
| |
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **196.56** | - |
| 09 | vLLM | OFF | OFF | å›ºå®šé•· | **252.42** | +326% |
| |
| 05 | NxD | OFF | OFF | å¯å¤‰é•· | **194.73** | -0.9% |
| 13 | vLLM | OFF | OFF | å¯å¤‰é•· | **254.80** | - |

ã¾ãšç¬¬ä¸€ã«ã‚ã‹ã‚Šã‚„ã™ãè€ƒå¯Ÿã§ãã‚‹ç‚¹ã‹ã‚‰ç¢ºèªã—ã¾ã™ã€‚$[No.01, No.05]$ã€$[No.09, No.13]$ ã‚’è¦‹ã¦ã¿ã‚‹ã¨ã€NxD/vLLMã€å›ºå®šé•·/å¯å¤‰é•·ã«ã‚ˆã‚‰ãš `Bucketing=OFF` ã®å ´åˆã¯çµæœã¯ã»ã¼å¤‰ã‚ã‚Šã¾ã›ã‚“ã€‚OFF ã®å ´åˆã¯å˜ä¸€ã® NEFF ãŒç”Ÿæˆã•ã‚Œã€NeuronCore ãŒå¸¸ã«åŒã˜ NEFF ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãŒå›ºå®šã§ã‚ã‚ã†ã¨å¯å¤‰ã§ã‚ã‚ã†ã¨ã»ã¼åŒã˜çµæœã«ãªã‚Šã¾ã™ã€‚

#### å›ºå®šé•·ã«ãŠã‘ã‚‹ NxD ã¨ vLLM ã® Bucketing æŒ™å‹•ã®é•ã„

| No | ç’°å¢ƒ | Bucketing | Prefix Caching | ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ | å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms) | BucketingåŠ¹æœ |
|----|------|-----------|----------------|------------|-------------------|---------------|
| |
| 01 | NxD | OFF | OFF | å›ºå®šé•· | **196.56** | - |
| 02 | NxD | ON | OFF | å›ºå®šé•· | **188.97** | -3.9% |
| 09 | vLLM | OFF | OFF | å›ºå®šé•· | **252.42** | +326% |
| 10 | vLLM | ON | OFF | å›ºå®šé•· | **59.23** | -76.5% |

æ¬¡ã«å›ºå®šé•·ã«ãŠã„ã¦ Bucketing ã‚’æœ‰åŠ¹ã«ã—ãŸå ´åˆã®é•ã„ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚$[No.01, No.02]$ ãŒ **Bucketing ã‚’æœ‰åŠ¹ã«ã—ãŸå ´åˆã§ã‚‚ã»ã¼çµæœã«å·®ãŒãªã„**ã«ã‚‚é–¢ã‚ã‚‰ãšã€$[No.09, No.10]$ ã§ã¯å›ºå®šé•·ã«ã‚‚é–¢ã‚ã‚‰ãšå¤§å¹…ãªãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å‰Šæ¸›ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ãªãœã§ã—ã‚‡ã†ã‹ï¼Ÿ

ç«¯çš„ã« No.01 ã¨ No.02 ã®çµæœã«å·®ãŒãªã‹ã£ãŸç†ç”±ã¯ã€`--benchmark` ã¨ã„ã† NxD Inference ã§ä¸ãˆã‚‹å¼•æ•°ã®å®Ÿè£…ä¸Šã®éæ˜ç¤ºçš„ãªåˆ¶ç´„ã«ã‚ˆã‚‹ã‚‚ã®ã§ã—ãŸã€‚

::::details No.01 ã¨ No.02 ã®å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã«å·®ãŒãªã‹ã£ãŸç†ç”±

:::message alert
ç«¯çš„ã«çµè«–ã‚’è¿°ã¹ã‚‹ã¨ã€`--benchmark` ãƒ•ãƒ©ã‚°ã®å®Ÿè£…ã«ã‚ˆã‚Šå¸¸ã« `max_context_length`ï¼ˆ2048 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã®ãƒ€ãƒŸãƒ¼å…¥åŠ›ãŒç”Ÿæˆã•ã‚Œã¦ã„ãŸãŸã‚ã€Bucketing ON ã§ã‚‚ Bucketing OFF ã§ã‚‚åŒã˜ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã—ãŸã€‚
:::

## `--benchmark` ãƒ•ãƒ©ã‚°ã®å®Ÿè£…

neuronx-distributed-inference ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® `benchmark.py` ã«ãŠã„ã¦ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ãŒå•é¡Œã®ã§ã—ãŸã€‚

```python
def get_sample_inputs(model_type, config: InferenceConfig, sampling_params, image=False):
    max_context_length = neuron_config.max_context_length
    input_length = max_context_length  # å¸¸ã« 2048 ãƒˆãƒ¼ã‚¯ãƒ³
```

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/utils/benchmark.py#L206-L217

ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€`--benchmark` ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã—ãŸæ¸¬å®šã§ã¯å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ï¼ˆæœ¬èª¿æŸ»ã§ã¯ 94 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã«é–¢ã‚ã‚‰ãšå¸¸ã« 2048 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ€ãƒŸãƒ¼å…¥åŠ›ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã—ãŸã€‚

## Bucketing ã®ãƒã‚±ãƒƒãƒˆé¸æŠãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

Bucketing ãŒæœ‰åŠ¹ãªå ´åˆã€`model_wrapper.py` ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ `get_target_bucket()` ãƒ¡ã‚½ãƒƒãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/models/model_wrapper.py#L1015-L1037

ã“ã® first_fit æˆ¦ç•¥ã§ã¯ã€å…¥åŠ›é•·ã‚ˆã‚Šå¤§ãã„æœ€åˆã®ãƒã‚±ãƒƒãƒˆã‚’é¸æŠã—ã¾ã™ã€‚ã—ã‹ã— 2048 ãƒˆãƒ¼ã‚¯ãƒ³ã®å…¥åŠ›ã«å¯¾ã—ã¦ã¯ã€æœ€å¤§ãƒã‚±ãƒƒãƒˆï¼ˆ2048 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ãŒé¸æŠã•ã‚Œã¾ã™ã€‚

## No.01 ã¨ No.02 ã§åŒã˜çµæœã«ãªã£ãŸç†ç”±

```
No.01 (Bucketing OFF):
  â†’ å˜ä¸€ã® 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆä½¿ç”¨
  â†’ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡: 2048 - 2048 = 0 ãƒˆãƒ¼ã‚¯ãƒ³
  â†’ å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 196.56 ms

No.02 (Bucketing ON):
  â†’ ãƒ€ãƒŸãƒ¼å…¥åŠ›: 2048 ãƒˆãƒ¼ã‚¯ãƒ³
  â†’ get_target_bucket(2048) â†’ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆé¸æŠ
  â†’ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡: 2048 - 2048 = 0 ãƒˆãƒ¼ã‚¯ãƒ³
  â†’ å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 188.97 msï¼ˆã»ã¼åŒã˜ï¼‰
```

ä¸¡è€…ã¨ã‚‚åŒã˜ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ãŸãŸã‚ã€Bucketing ã®åŠ¹æœãŒç¾ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ç´„ 3.9% ã®å·®ã¯ Bucketing ã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•é¸æŠã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã©ã€å‰¯æ¬¡çš„ãªè¦å› ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

## å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ94 ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã§ã®æ¸¬å®šçµæœ

ã“ã®å•é¡Œã‚’ç™ºè¦‹ã—ãŸå¾Œã€`--benchmark` ãƒ•ãƒ©ã‚°ã‚’ä½¿ã‚ãšå®Ÿéš›ã® 94 ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†æ¸¬å®šã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚

```
No.01 (Bucketing OFF, å®Ÿãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ):
  â†’ 2048 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆä½¿ç”¨
  â†’ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡: 2048 - 94 = 1954 ãƒˆãƒ¼ã‚¯ãƒ³
  â†’ å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 211.29 ms

No.02 (Bucketing ON, å®Ÿãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ):
  â†’ get_target_bucket(94) â†’ 128 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆé¸æŠ
  â†’ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡: 128 - 94 = 34 ãƒˆãƒ¼ã‚¯ãƒ³
  â†’ å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 13.36 ms
  â†’ æ”¹å–„ç‡: 93.7%ï¼ˆ15.8 å€é«˜é€ŸåŒ–ï¼‰
```

å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸå ´åˆã€Bucketing ON ã§ã¯ 128 ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆãŒé¸æŠã•ã‚Œã€**93.7% ã®æ”¹å–„**ã¨ã„ã†åŠ‡çš„ãªæ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡ãŒ 1954 ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ 34 ãƒˆãƒ¼ã‚¯ãƒ³ã«å‰Šæ¸›ã•ã‚ŒãŸã“ã¨ï¼ˆ57 å€ã®å‰Šæ¸›ï¼‰ãŒã€ã“ã®å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã®ä¸»è¦å› ã§ã™ã€‚

## `--benchmark` ãƒ•ãƒ©ã‚°ã®è¨­è¨ˆæ„å›³ã¨é™ç•Œ

:::message alert
**çŸ¥è¦‹**: `--benchmark` ãƒ•ãƒ©ã‚°ã¯ä¸€å®šã®å…¥åŠ›é•·ã§ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚„ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ¸¬å®šã™ã‚‹ç”¨é€”ã‚’æƒ³å®šã—ã¦è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€å‹•çš„ãªå…¥åŠ›é•·ã«å¯¾ã™ã‚‹æ€§èƒ½è©•ä¾¡ã«ã¯é©ã—ã¦ã„ã¾ã›ã‚“ã€‚Bucketing ã®ã‚ˆã†ã«å…¥åŠ›é•·ã«å¿œã˜ã¦å‹•çš„ã«æœ€é©åŒ–ãŒè¡Œã‚ã‚Œã‚‹æ©Ÿèƒ½ã‚’è©•ä¾¡ã™ã‚‹å ´åˆã¯ã€å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ãŸæ¸¬å®šãŒå¿…é ˆã¨ãªã‚Šã¾ã™ã€‚
:::

::::


::::details NxD Inference ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå•é¡Œã®ç™ºè¦‹ã¨ä¿®æ­£

`--benchmark` ã‚’å¤–ã—ã¦å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®æ¸¬å®šã‚’è©¦ã¿ãŸéš›ã«ã€Neuron SDK 2.27.0 ã§å°å…¥ã•ã‚ŒãŸ tensor_replacement æ©Ÿèƒ½ã«é–¢é€£ã™ã‚‹å®Ÿè£…ãƒã‚°ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚

## ç™ºè¦‹ã•ã‚ŒãŸãƒã‚°

[`hf_adapter.py`](https://github.com/aws-neuron/neuronx-distributed-inference/blob/v0.7.14366/src/neuronx_distributed_inference/utils/hf_adapter.py#L289-L300) ã«ãŠã„ã¦ã€ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

```
TypeError: NeuronBaseForCausalLM.forward() got an unexpected keyword argument 'tensor_capture_hook'
```

## ãƒã‚°ã®è©³ç´°

`hf_adapter.py` ã§ `tensor_capture_hook` å€¤ã‚’ã€`model_inputs` è¾æ›¸ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚

https://github.com/aws-neuron/neuronx-distributed-inference/blob/fcb5a8688d237e1af429d6e72445db17277d630a/src/neuronx_distributed_inference/utils/hf_adapter.py#L289-L300

ã—ã‹ã— `model_base.py` ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ `NeuronBaseForCausalLM.forward()` ãƒ¡ã‚½ãƒƒãƒ‰ã¯ `tensor_capture_hook` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘ä»˜ã‘ã¾ã›ã‚“ã€‚

https://github.com/aws-neuron/neuronx-distributed-inference/blob/aa7987ffc66ac2bd9894427621ca9b6f3fc40ed9/src/neuronx_distributed_inference/models/model_base.py#L3373-L3397

## ãƒã‚°ã®åŸå› 

**`tensor_capture_hook` ã¯**ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã®å‡ºåŠ›ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã§ã™ã€‚ä¸»ã«ãƒ‡ãƒãƒƒã‚°ã‚„ç²¾åº¦æ¤œè¨¼ã§ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

**`forward()` ãƒ¡ã‚½ãƒƒãƒ‰ã¯** PyTorch ãƒ¢ãƒ‡ãƒ«ãŒæŒã¤ã€Œ1 å›ã®è¨ˆç®—ã€ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã§ã™ã€‚

SDK 2.27.0 ã§ã¯ã€`tensor_capture_hook` ã‚’èª¤ã£ã¦ `forward()` ã«æ¸¡ã—ã¦ã—ã¾ã£ãŸãŸã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã—ãŸã€‚

## æš«å®šä¿®æ­£

`hf_adapter.py` ã® `"tensor_capture_hook": tensor_capture_hook` ã®è¡Œã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€ã“ã®å•é¡Œã‚’å›é¿ã—ã¾ã—ãŸã€‚ä»Šå¾Œå†…å®¹ã‚’ã‚ˆã‚Šç²¾æŸ»ã—ãŸå¾Œã« Issue ã¨ã—ã¦å ±å‘Šã™ã‚‹äºˆå®šã§ã™ã€‚ã“ã®ä¿®æ­£ã«ã‚ˆã‚Šã€No.5, No.6 ã®å¯å¤‰é•·ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã§ã®å®Ÿãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¸¬å®šãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚

## ãªãœç™ºè¦‹ã•ã‚Œãªã‹ã£ãŸã®ã‹

**`--benchmark` ãƒ•ãƒ©ã‚°ãŒå•é¡Œã‚’éš è”½**ã—ã¦ã„ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãƒ€ãƒŸãƒ¼å…¥åŠ›ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã®ãƒã‚°ãŒé¡•åœ¨åŒ–ã—ã¾ã›ã‚“ã€‚ä»Šå›ã®ç™ºè¦‹ã¯ã€Bucketing ã®åŠ¹æœã‚’å®Ÿãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æ¸¬å®šã—ã‚ˆã†ã¨ã—ãŸéš›ã®å‰¯ç”£ç‰©ã§ã™ã€‚é€šå¸¸ vllm-neuron ã‚’ä½¿ã£ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã§ã¯ `--benchmark` ã‚’ä½¿ã†ã“ã¨ã¯ãªãã€å®Ÿéš›ã®å¯å¤‰é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ `generate()` ã«ç›´æ¥æ¸¡ã—ã¦ã„ã‚‹ã®ã§ã“ã®æ€§èƒ½å›ºå®šåŒ–ã®åˆ¶ç´„ã‚’å—ã‘ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã•ã‚‰ã« vllm-neuron ã®ä½¿ã£ã¦ã„ã‚‹ NxD Inference ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã¾ã ä»Šå›ã®ãƒã‚°ã®ãªã„ã‚‚ã®ã‚’ä½¿ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
::::
