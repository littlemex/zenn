---
title: "Amazon Bedrock アプリケーション推論プロファイルによるコスト管理の実践"
emoji: "✨"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Amazon Bedrock"]
published: false
---


## はじめに

企業が生成 AI を本格的に活用し始めるにつれて、コスト管理の重要性が増しています。複数のプロジェクトや事業部門にまたがる生成 AI 活用において、正確なコスト配分とトラッキングは重要な課題となっています。特に、顧客セグメントや利用目的に応じた適切な価格設定、部門間でのチャージバック、使用量ベースの課金モデルの確立には、詳細なコスト可視化が不可欠です。

しかし、これまで Amazon Bedrock では、プロビジョニングされたモデル、カスタムモデル、エージェント、モデル評価、プロンプト、ナレッジベースなど、様々なリソースにタグ付けが可能でしたが、オンデマンドの基礎モデルに対するタグ付けができませんでした。この制限により、生成 AI イニシアチブのコスト管理が複雑化していました。

この課題に対応するため、Amazon Bedrock は新たにアプリケーション推論プロファイル機能を導入しました。この機能により、組織は AWS コスト配分タグを使用してオンデマンドモデルにラベルを付け、コストセンター、事業部門、アプリケーションなどの組織分類に基づいて使用状況を追跡できるようになりました。

## アプリケーション推論プロファイルの概要

### システム定義プロファイルとの違い

アプリケーション推論プロファイルを理解する上で重要なのは、システム定義プロファイルとの違いです。

1. システム定義推論プロファイル
   - タイプ属性は「SYSTEM_DEFINED」
   - inference-profile リソースタイプを使用
   - クロスリージョンおよびマルチモデル機能をサポート
   - AWS によって一元管理

```json
{
 "inferenceProfileArn": "arn:aws:bedrock:us-east-1:<Account ID>:inference-profile/us-1.anthropic.claude-3-sonnet-20240229-v1:0",
 "inferenceProfileId": "us-1.anthropic.claude-3-sonnet-20240229-v1:0",
 "inferenceProfileName": "US-1 Anthropic Claude 3 Sonnet",
 "status": "ACTIVE",
 "type": "SYSTEM_DEFINED"
}
```

2. アプリケーション推論プロファイル
   - タイプ属性は「APPLICATION」
   - application-inference-profile リソースタイプを使用
   - ユーザー定義で、モデル設定のきめ細かな制御が可能
   - AWS Identity and Access Management (IAM) を使用した属性ベースのアクセス制御（ABAC）をサポート

```json
{
 "inferenceProfileArn": "arn:aws:bedrock:us-east-1:<Account ID>:application-inference-profile/<Auto generated ID>",
 "inferenceProfileId": "<Auto generated ID>",
 "inferenceProfileName": "<User defined name>",
 "status": "ACTIVE",
 "type": "APPLICATION"
}
```

### 作成方法

アプリケーション推論プロファイルは以下の 2 つの方法で作成できます：

1. 単一モデル ARN 設定
   - 特定のオンデマンド基礎モデルの ARN を使用して直接作成
   - シンプルな設定で素早くセットアップ可能

2. システム定義推論プロファイルからのコピー
   - 既存のシステム定義プロファイルの設定を継承
   - クロスリージョン推論などの高度な機能も利用可能

## 実装例：保険会社でのユースケース

ここでは、保険会社が生成 AI を活用して顧客体験を向上させる例を通じて、アプリケーション推論プロファイルの実装方法を説明します。

### 1. 推論プロファイルの作成と管理

まず、部門ごとに異なる推論プロファイルを作成し、適切なタグを付与します：

```python
def create_inference_profile(profile_name, model_arn, tags):
    """
    推論プロファイルを作成する関数
    
    Args:
        profile_name (str): 作成する推論プロファイルの名前
        model_arn (str): 基となるモデルの ARN
        tags (list): プロファイルに付与するタグのリスト
    """
    bedrock_client = boto3.client('bedrock')
    try:
        response = bedrock_client.create_inference_profile(
            inferenceProfileName=profile_name,
            modelSource={
                'copyFrom': model_arn
            },
            description=f"Inference profile for {profile_name}",
            tags=tags
        )
        return response
    except Exception as e:
        logger.error(f"推論プロファイルの作成中にエラーが発生: {str(e)}")
        raise

# Claims 部門用の Claude 3 Sonnet プロファイル作成
claude_3_sonnet_arn = "arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0"
claims_dept_claude_profile = create_inference_profile(
    "claims_dept_claude_3_sonnet_profile",
    claude_3_sonnet_arn,
    [{'key': 'dept', 'value': 'claims'}]
)

# Underwriting 部門用の Llama 3 プロファイル作成
llama_3_arn = "arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0"
underwriting_dept_llama_profile = create_inference_profile(
    "underwriting_dept_llama3_70b_profile",
    llama_3_arn,
    [{'key': 'dept', 'value': 'underwriting'}]
)
```

### 2. コスト分析の実装

部門ごとのコストを追跡し、予算管理を行うための実装：

```python
def get_cost_by_department(start_date, end_date):
    """
    部門ごとのコストを取得する関数
    
    Args:
        start_date (str): 開始日 (YYYY-MM-DD形式)
        end_date (str): 終了日 (YYYY-MM-DD形式)
    """
    ce_client = boto3.client('ce')
    try:
        response = ce_client.get_cost_and_usage(
            TimePeriod={
                'Start': start_date,
                'End': end_date
            },
            Granularity='MONTHLY',
            Metrics=['BlendedCost', 'UsageQuantity'],
            GroupBy=[
                {'Type': 'TAG', 'Key': 'dept'}
            ],
            Filter={
                'And': [
                    {
                        'Dimensions': {
                            'Key': 'SERVICE',
                            'Values': ['Amazon Bedrock']
                        }
                    },
                    {
                        'Tags': {
                            'Key': 'dept',
                            'Values': dept_values
                        }
                    }
                ]
            }
        )
        return response
    except Exception as e:
        logger.error(f"コスト情報の取得中にエラーが発生: {str(e)}")
        raise
```

### 3. 使用状況のモニタリング

Amazon CloudWatch メトリクスを使用した詳細な使用状況の追跡：

```python
def get_usage_metrics(profile_name, hours=24):
    """
    Amazon CloudWatch メトリクスから使用状況を取得する関数
    
    Args:
        profile_name (str): 推論プロファイル名
        hours (int): 取得する期間（時間）
    """
    cloudwatch = boto3.client('cloudwatch')
    try:
        metrics = {
            'InvocationCount': [],  # 呼び出し回数
            'ProcessingTime': [],   # 処理時間
            'TokenCount': [],       # トークン数
            'CharacterCount': []    # 文字数
        }
        
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=hours)
        
        for metric_name in metrics.keys():
            response = cloudwatch.get_metric_statistics(
                Namespace='AWS/Bedrock',
                MetricName=metric_name,
                Dimensions=[
                    {
                        'Name': 'InferenceProfileName',
                        'Value': profile_name
                    }
                ],
                StartTime=start_time,
                EndTime=end_time,
                Period=3600,
                Statistics=['Sum', 'Average']
            )
            metrics[metric_name] = response['Datapoints']
        
        return metrics
    except Exception as e:
        logger.error(f"メトリクス取得中にエラーが発生: {str(e)}")
        raise
```

## コスト管理のベストプラクティス

### 1. タグ設計戦略

効果的なコスト管理のためには、適切なタグ設計が重要です：

- **部門タグ（必須）**: コストセンターや事業部門の識別
- **プロジェクトタグ**: 特定のイニシアチブやプロジェクトの追跡
- **環境タグ**: 開発、ステージング、本番環境の区別
- **アプリケーションタグ**: 特定のアプリケーションやサービスの識別
- **チームタグ**: 責任所在の明確化

### 2. 予算管理とアラート設定

Amazon Budgets を使用した予算管理の実装：

1. タグベースの予算設定
   - 部門やプロジェクトごとの予算上限設定
   - 使用量ベースのアラート閾値設定

2. コスト異常検知
   - AWS Cost Anomaly Detection による異常検知
   - 予期せぬコスト増加の早期発見

3. 予算アクション
   - 予算超過時の自動アクション設定
   - 関係者への通知設定

### 3. モニタリングとレポーティング

1. Amazon CloudWatch ダッシュボード
   - リアルタイムの使用状況モニタリング
   - カスタムメトリクスの追加

2. Amazon Cost Explorer
   - タグベースのコスト分析
   - トレンド分析とコスト予測

3. AWS Cost and Usage Report (CUR)
   - 詳細なコストレポート生成
   - データウェアハウスとの連携

## アプリケーション推論プロファイル ARN の動的取得

大規模な環境では、推論プロファイル ARN の動的取得が重要になります。主に以下の 2 つのアプローチがあります：

### 1. 静的設定アプローチ

AWS Systems Manager Parameter Store や AWS Secrets Manager を使用して、テナント/ワークロードキーと推論プロファイル ARN のマッピングを管理する方法です。

**メリット**:
- 実装がシンプル
- 直接的なマッピング

**デメリット**:
- スケーラビリティに制限
- 手動更新が必要
- 大規模環境での管理が複雑

### 2. AWS Resource Groups API を使用した動的取得

AWS Resource Groups の GetResources API を使用して、タグベースで動的に推論プロファイル ARN を取得する方法です。

```python
def get_inference_profile_arn_by_tags(tags):
    """
    タグに基づいて推論プロファイル ARN を取得する関数
    
    Args:
        tags (dict): 検索用のタグ（キーと値のペア）
    """
    client = boto3.client('resourcegroupstaggingapi')
    
    # タグフィルターの作成
    tag_filters = [
        {
            'Key': key,
            'Values': [value]
        }
        for key, value in tags.items()
    ]
    
    try:
        response = client.get_resources(
            TagFilters=tag_filters,
            ResourceTypeFilters=['bedrock:application-inference-profile']
        )
        
        # 該当するリソースが見つかった場合、最初の ARN を返す
        if response['ResourceTagMappingList']:
            return response['ResourceTagMappingList'][0]['ResourceARN']
        return None
        
    except Exception as e:
        logger.error(f"推論プロファイル ARN の取得中にエラーが発生: {str(e)}")
        raise
```

**メリット**:
- 高いスケーラビリティ
- 動的な更新が可能
- タグベースの柔軟な検索

**デメリット**:
- API 制限への考慮が必要
- キャッシュ戦略の実装が必要

### キャッシュ戦略の実装

大規模環境での効率的な運用のために、キャッシュ戦略の実装が重要です：

```python
from datetime import datetime, timedelta
from threading import Lock

class InferenceProfileCache:
    def __init__(self, ttl_seconds=300):
        self.cache = {}
        self.ttl = ttl_seconds
        self.lock = Lock()
    
    def get(self, tags):
        """
        キャッシュからプロファイル ARN を取得
        存在しない場合や TTL 切れの場合は新規取得
        """
        cache_key = self._create_cache_key(tags)
        
        with self.lock:
            cached_item = self.cache.get(cache_key)
            
            if cached_item:
                if datetime.now() < cached_item['expiry']:
                    return cached_item['arn']
                else:
                    del self.cache[cache_key]
            
            # キャッシュミスまたは TTL 切れの場合、新規取得
            arn = get_inference_profile_arn_by_tags(tags)
            if arn:
                self.cache[cache_key] = {
                    'arn': arn,
                    'expiry': datetime.now() + timedelta(seconds=self.ttl)
                }
            return arn
    
    def _create_cache_key(self, tags):
        """タグから一意のキャッシュキーを生成"""
        return frozenset(tags.items())
```

## マルチアカウント環境での実装

AWS Control Tower を使用した複数アカウント環境での実装について説明します。

### 1. アカウント構造

一般的なマルチアカウント構成：

- マネジメントアカウント
  - コスト管理
  - 一元的なモニタリング
  
- 開発アカウント
  - 開発環境用の推論プロファイル
  - 開発者向けの権限設定
  
- ステージングアカウント
  - テスト用の推論プロファイル
  - QA 環境の設定
  
- 本番アカウント
  - 本番環境用の推論プロファイル
  - 厳格なアクセス制御

### 2. クロスアカウントのタグ付け戦略

```python
def create_cross_account_profile(account_id, profile_name, model_arn, tags):
    """
    クロスアカウントで推論プロファイルを作成する関数
    
    Args:
        account_id (str): AWS アカウント ID
        profile_name (str): プロファイル名
        model_arn (str): モデル ARN
        tags (list): タグのリスト
    """
    # アカウントの認証情報を取得
    sts_client = boto3.client('sts')
    assumed_role_object = sts_client.assume_role(
        RoleArn=f"arn:aws:iam::{account_id}:role/BedrockManagementRole",
        RoleSessionName="CrossAccountProfileCreation"
    )
    
    # 一時的な認証情報を使用してクライアントを作成
    credentials = assumed_role_object['Credentials']
    bedrock_client = boto3.client(
        'bedrock',
        aws_access_key_id=credentials['AccessKeyId'],
        aws_secret_access_key=credentials['SecretAccessKey'],
        aws_session_token=credentials['SessionToken']
    )
    
    try:
        response = bedrock_client.create_inference_profile(
            inferenceProfileName=profile_name,
            modelSource={'copyFrom': model_arn},
            tags=tags
        )
        return response
    except Exception as e:
        logger.error(f"クロスアカウントプロファイル作成中にエラーが発生: {str(e)}")
        raise
```

### 3. 一元的なコスト管理

マネジメントアカウントでの一元的なコスト管理の実装：

```python
def get_organization_costs(start_date, end_date):
    """
    組織全体のコストを取得する関数
    
    Args:
        start_date (str): 開始日
        end_date (str): 終了日
    """
    ce_client = boto3.client('ce')
    try:
        response = ce_client.get_cost_and_usage(
            TimePeriod={
                'Start': start_date,
                'End': end_date
            },
            Granularity='MONTHLY',
            Metrics=['BlendedCost', 'UsageQuantity'],
            GroupBy=[
                {'Type': 'DIMENSION', 'Key': 'LINKED_ACCOUNT'},
                {'Type': 'TAG', 'Key': 'dept'}
            ],
            Filter={
                'Dimensions': {
                    'Key': 'SERVICE',
                    'Values': ['Amazon Bedrock']
                }
            }
        )
        return response
    except Exception as e:
        logger.error(f"組織コストの取得中にエラーが発生: {str(e)}")
        raise
```

## Next Steps

今回の検証で明らかになった今後の課題について説明します。

### 1. スケーラビリティの検証

- 数百〜数千の推論プロファイル管理
  - プロファイルの自動作成メカニズム
  - 大規模環境でのタグ管理戦略
  - AWS Resource Groups API の制限への対応

- キャッシュ戦略の最適化
  - TTL 設定の最適化
  - キャッシュ更新メカニズムの改善
  - 分散キャッシュの検討

### 2. コスト最適化

- 使用パターン分析
  - 時間帯別の使用量パターン把握
  - モデル別のコストパフォーマンス分析
  - 部門別の使用効率評価

- 自動スケーリング
  - 需要予測に基づく容量調整
  - コスト効率の最適化
  - 予算超過の自動防止

### 3. セキュリティ強化

- AWS IAM ポリシーの詳細設計
  - 最小権限の原則の適用
  - タグベースのアクセス制御（ABAC）の展開
  - クロスアカウントアクセスの制御

- 監査とコンプライアンス
  - 使用状況の監査ログ
  - コンプライアンス要件への対応
  - セキュリティベストプラクティスの適用

### 4. 運用自動化

- CI/CD パイプラインの統合
  - プロファイル作成の自動化
  - タグ付けの自動化
  - テスト自動化

- モニタリングの強化
  - カスタムメトリクスの追加
  - アラート設定の最適化
  - 異常検知の精度向上

### 5. クロスリージョン対応

- グローバル展開
  - リージョン間でのプロファイル同期
  - グローバルタグ戦略
  - レイテンシー最適化

- 災害対策
  - リージョン間フェイルオーバー
  - データレプリケーション
  - 可用性の向上

## まとめ

Amazon Bedrock のアプリケーション推論プロファイルは、生成 AI 利用のコスト管理を大きく改善する機能です。本記事で紹介した実装例とベストプラクティスを参考に、組織の要件に合わせた効果的なコスト管理の仕組みを構築することができます。

特に重要なポイントは以下の通りです：

1. 適切なタグ設計による正確なコスト配分
2. Amazon Budgets を活用した予算管理の自動化
3. Amazon CloudWatch メトリクスによる詳細な使用状況モニタリング
4. スケーラブルな ARN 管理の実装
5. マルチアカウント環境での一元的な管理

今後は、より大規模な環境での検証や、高度な自動化、セキュリティ強化など、さらなる改善を進めていく予定です。
