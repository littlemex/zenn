---
title: ""
emoji: "📝"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

# Amazon Bedrock モデル評価における LLM-as-a-judge

Adewale Akinfaderin、Ishan Singh、Jesse Manders 著（2025年2月12日）[Amazon Bedrock](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/ "Amazon Bedrockのすべての投稿を表示")、[生成系AI](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/generative-ai/ "生成系AIのすべての投稿を表示")、[中級者向け (200)](https://aws.amazon.com/blogs/machine-learning/category/learning-levels/intermediate-200/ "中級者向け (200)のすべての投稿を表示") [パーマリンク](https://aws.amazon.com/blogs/machine-learning/llm-as-a-judge-on-amazon-bedrock-model-evaluation/) [コメント](https://aws.amazon.com/blogs/machine-learning/llm-as-a-judge-on-amazon-bedrock-model-evaluation/#Comments) [シェア](#)

大規模言語モデル（LLM）のパフォーマンス評価、特に様々なプロンプトに対する応答の評価は、この急速に進化するテクノロジーの可能性を最大限に活用しようとする組織にとって非常に重要です。_LLM-as-a-judge_（審判としてのLLM）フレームワークの導入は、モデル評価プロセスを簡素化し合理化する上で重要な一歩を表しています。このアプローチにより、組織は事前定義されたメトリクスを使用してAIモデルの有効性を評価し、テクノロジーが特定のニーズや目標に合致していることを確認できます。この方法を採用することで、企業はAIシステムのパフォーマンスをより正確に測定し、モデルの選択、最適化、展開に関する情報に基づいた意思決定を行うことができます。これはAIアプリケーションの信頼性と効率性を高めるだけでなく、組織内でのテクノロジー導入に対するより戦略的かつ情報に基づいたアプローチにも貢献します。

[Amazon Bedrock](https://aws.amazon.com/bedrock)は、単一のAPIを通じて主要なAI企業の高性能な基盤モデルを提供する完全マネージド型サービスで、最近2つの重要な評価機能を導入しました：[Amazon Bedrock モデル評価におけるLLM-as-a-judgeとAmazon Bedrock Knowledge Bases向けのRAG評価](https://aws.amazon.com/blogs/aws/new-rag-evaluation-and-llm-as-a-judge-capabilities-in-amazon-bedrock/)。どちらの機能も裏側でLLM-as-a-judge技術を使用していますが、評価対象は異なります。このブログ記事では、Amazon Bedrock モデル評価におけるLLM-as-a-judgeについて詳しく説明し、機能のセットアップ、コンソールとPython SDKおよびAPIを通じた評価ジョブの開始に関する包括的なガイダンスを提供し、この革新的な評価機能が品質、ユーザーエクスペリエンス、指示への従順さ、安全性など複数のメトリクスカテゴリにわたって生成系AIアプリケーションをどのように強化できるかを示します。

技術的側面と実装の詳細を探る前に、LLM-as-a-judgeをAmazon Bedrock モデル評価において特に強力にし、従来の評価方法と区別する主要な機能を検討してみましょう。これらの中核的な機能を理解することで、この機能がAIモデル評価における重要な進歩を表す理由が明らかになるでしょう。

## LLM-as-a-judgeの主要機能

1. **自動化された知的評価**: LLM-as-a-judgeは事前訓練されたモデルを使用して応答を自動的に評価し、人間のような評価品質を最大98%のコスト削減で提供します。このシステムは評価時間を数週間から数時間に劇的に短縮し、大規模なデータセット全体で一貫した評価基準を維持します。
2. **包括的なメトリクスカテゴリ**: 評価システムは4つの主要なメトリクス領域をカバーしています：品質評価（正確性、完全性、忠実性）、ユーザーエクスペリエンス（有用性、一貫性、関連性）、指示の遵守（指示に従う、プロフェッショナルなスタイル）、安全性監視（有害性、ステレオタイプ、拒否の処理）。
3. **シームレスな統合**: この機能はAmazon Bedrockと直接統合され、既存のAmazon Bedrock モデル評価機能と互換性を維持しています。ユーザーはAWS Management ConsoleのAmazon Bedrockを通じて機能にアクセスし、評価目的のためにカスタムデータセットを迅速に統合できます。
4. **柔軟な実装**: このシステムはAmazon Bedrockでホストされているモデル、カスタムファインチューニングされたモデル、およびインポートされたモデルの評価をサポートしています。ユーザーは[Amazon Simple Storage Service (Amazon S3)](https://aws.amazon.com/s3)バケットを通じて評価データセットをシームレスに接続でき、評価プロセスを合理化して効率化します。
5. **厳選された審判モデル**: Amazon Bedrockは、正確な評価のために最適化されたプロンプトエンジニアリングを備えた、事前選択された高品質な評価モデルを提供します。Amazon Bedrockチームが審判モデルと関連する評価審判プロンプトの選択を維持・更新しているため、ユーザーは外部の審判モデルを持ち込む必要がありません。
6. **コスト効率の高いスケーリング**: この機能により、組織は人間による評価に関連する従来のコストと時間投資なしに、包括的なモデル評価を大規模に実行できます。自動化されたプロセスは高品質の評価を維持しながら、運用上のオーバーヘッドを大幅に削減します。

これらの機能により、組織が安全なAWS環境内で高い品質と安全性の基準を維持しながら、AIモデルのパフォーマンスを最適化するのに役立つ強力な評価フレームワークが作成されます。

## 製品概要

LLM-as-a-judgeの主要機能を理解したところで、Amazon Bedrock モデル評価内でこの機能を実装して使用する方法を検討しましょう。このセクションでは、アーキテクチャの包括的な概要を提供し、各コンポーネントを詳しく説明し、それらが正確で効率的なモデル評価を提供するためにどのように連携するかを示します。

Amazon Bedrock モデル評価におけるLLM-as-a-judgeは、AIモデルのパフォーマンスを評価し最適化するための包括的なエンドツーエンドのソリューションを提供します。この自動化されたプロセスはLLMの力を活用して複数のメトリクスカテゴリにわたって応答を評価し、AIアプリケーションを大幅に改善できる洞察を提供します。以下の図に示す、このソリューションの主要コンポーネントを見ていきましょう：

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image001.jpg)

Amazon Bedrock モデル評価におけるLLM-as-a-judgeは、体系的なモデル評価を可能にする合理化されたワークフローに従います。評価プロセスにおいて各コンポーネントがどのように連携するかを見てみましょう：

* **プロンプトデータセット**: プロセスはモデルのパフォーマンスをテストするために使用されるプロンプトを含む準備されたデータセットから始まります。評価は正解応答（グラウンドトゥルース）の有無にかかわらず実施できます—正解応答を含めることで追加の比較ポイントが提供されますが、これは完全にオプションであり、成功した評価には必要ありません。
* **JSONLファイルの準備**: プロンプトデータセットはLLM-as-a-judge評価ジョブ用に特別に構造化されたJSONL形式に変換されます。この形式は評価データの適切な処理を促進します。
* **Amazon S3ストレージ**: 準備されたJSONLファイルはS3バケットにアップロードされ、評価データの安全な保存場所として機能します。
* **評価処理**: Amazon Bedrock LLM-as-a-judgeモデル評価ジョブは保存されたデータを処理し、選択されたメトリクスカテゴリ（品質、ユーザーエクスペリエンス、指示への従順さ、安全性を含む）にわたって包括的な評価を実行します。
* **自動レポート生成**: 完了すると、システムは集計レベルと個々の応答レベルの両方でメトリクス、スコア、洞察を含む詳細な評価レポートを生成します。
* **専門家による分析**: データサイエンティストや機械学習エンジニアが生成されたレポートを分析し、実用的な洞察を導き出し、情報に基づいた意思決定を行います。

このソリューションアーキテクチャを念頭に置いて、LLM-as-a-judgeモデル評価を効果的に実装する方法を探り、評価プロセスから最も価値のある洞察を確実に得られるようにしましょう。

## 前提条件

LLM-as-a-judgeモデル評価を使用するには、以下の要件を満たしていることを確認してください：

* アクティブな[AWSアカウント](https://signin.aws.amazon.com/signin?redirect%5Furi=https%3A%2F%2Fportal.aws.amazon.com%2Fbilling%2Fsignup%2Fresume&client%5Fid=signup)。
* Amazon Bedrockで有効化された_評価者_モデルと_生成器_モデル。Amazon Bedrockコンソールの**モデルアクセス**ページでアカウントに対してモデルが有効になっていることを確認できます。
* モデルが[利用可能なAWSリージョンとクォータ](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html)を確認します。
* [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam/)の作成に関連するモデル評価の[前提条件](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-type-judge.html)を完了し、出力データにアクセスして書き込むためのS3バケットに権限を追加します。
   * また、S3バケットで[CORSを設定して有効化](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-security-cors.html)する必要があります。
* 生成器モデルにオンデマンドモデルではなくカスタムモデルを使用している場合は、推論中に[プロビジョンドスループット](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html)を実行するための十分なクォータがあることを確認してください。
   * カスタムモデルをインポートするための[前提条件](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-model-import-prereq.html)を完了します。
   * AWS Service Quotasコンソールに移動し、以下のクォータを確認します：
         * カスタムモデル全体でのコミットメントなしのプロビジョンドスループットのモデルユニット。
         * [カスタムモデル名]のプロビジョンドモデルあたりのモデルユニット。
         * これらのフィールドはどちらも、プロビジョンドスループットモデルユニットをサポートするのに十分なクォータが必要です。予想される推論ワークロードに対応するために必要に応じてクォータの増加をリクエストしてください。

### 入力データセットの準備

LLM-as-a-judgeモデル評価ジョブ用のデータセットを準備する際、各プロンプトには特定のキーと値のペアを含める必要があります。以下は必須およびオプションのフィールドです：

* **prompt（必須）**: このキーは様々なタスクの入力を示します。モデルが応答を提供する必要がある一般的なテキスト生成、モデルが特定の質問に答える必要がある質問応答タスク、モデルが与えられたテキストを要約する必要があるテキスト要約タスク、またはモデルが提供されたテキストを分類する必要がある分類タスクに使用できます。
* **referenceResponse（グラウンドトゥルースを持つ特定のメトリクスに使用）**: このキーには正解または正しい応答が含まれます。提供されている場合、モデルの応答が評価される基準点として機能します。
* **category（オプション）**: このキーはカテゴリ別に報告される評価スコアを生成するために使用され、より良い分析のために評価結果を整理・区分するのに役立ちます。

**データセット要件:**

* 各行は有効なJSONオブジェクトである必要があります
* ファイルはJSONL形式を使用する必要があります
* データセットはAmazon S3バケットに保存する必要があります

グラウンドトゥルースなしのJSONL形式の例（`category`はオプション）：

```
{
    "prompt": "機械学習とは何ですか？"
    "category": "technical"
}
{
    "prompt": "気候変動の影響を要約してください",
    "category": "environmental"
}

```

グラウンドトゥルースありのJSONL形式の例（`category`はオプション）：

```
{
    "prompt": "機械学習とは何ですか？",
    "referenceResponse": "機械学習は人工知能のサブセットで、明示的にプログラムされることなく経験から学習し改善するシステムを可能にします。アルゴリズムと統計モデルを使用してデータのパターンを分析し推論を導き出し、コンピュータが明示的な指示なしに特定のタスクを実行できるようにします。",
    "category": "technical"
}
{
    "prompt": "気候変動の影響を要約してください",
    "referenceResponse": "気候変動は地球温暖化、極端な気象現象、海面上昇、生態系の混乱をもたらします。これらの変化により、自然災害の頻度が増加し、食料安全保障への脅威、生物多様性の喪失、様々な公衆衛生上の課題が生じます。これらの影響は農業、沿岸コミュニティ、脆弱な人口に不均衡に影響します。",
    "category": "environmental"
}
```

## コンソールを使用したLLM-as-a-judgeモデル評価ジョブの開始

Amazon Bedrock モデル評価におけるLLM-as-a-judgeを使用して、ユーザーフレンドリーなコンソールインターフェースを通じてモデルのパフォーマンスを評価できます。評価ジョブを開始するには、以下の手順に従ってください：

1. Amazon Bedrockコンソールで、**推論と評価**を選択し、**評価**を選択します。**評価**ページで、**モデル**を選択します。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image002.jpg)

2. **作成**を選択し、**自動: LLM-as-a-judge**を選択します。
3. 名前と説明を入力し、**評価者モデル**を選択します。このモデルは、生成系AIアプリケーションからのプロンプトやモデルの応答を評価する審判として使用されます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image003.jpg)

4. **タグ**を選択し、この評価ジョブで応答を生成するために使用するモデルを選択します。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image004.jpg)

5. モデルの応答を評価するために使用したいメトリクス（有用性、正確性、忠実性、関連性、有害性など）を選択します。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image005.jpg)

6. **プロンプトデータセットの選択**と**評価結果**の**S3 URI**を選択します。**S3を参照**オプションを使用できます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image006.jpg)

7. [適切な権限](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-type-judge.html)を持つIAMサービスロールを選択または作成します。これには、Amazon Bedrockへのサービスアクセス、評価ジョブ内のS3バケット、およびジョブで使用されるモデルへのアクセスが含まれます。評価設定で新しいIAMロールを作成する場合、サービスは自動的にジョブに適切な権限をロールに付与します。出力S3バケットを指定し、**作成**を選択します。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image007.jpg)

8. 評価ジョブが**進行中**であることが確認できます。ジョブのステータスが**完了**に変わるまで待ちます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image008.jpg)

9. 完了したら、ジョブを選択して詳細を確認します。以下はメトリクスの概要です（有用性は0.83、正確性は1.00、忠実性は1.00、関連性は1.00、有害性は0.00など）。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image009.jpg)

10. 生成メトリクスの詳細を表示するには、モデル評価レポートを下にスクロールし、個々のメトリクス（有用性や正確性など）を選択して詳細な内訳を確認します。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image010.jpg)

11. 各レコードのプロンプト入力、生成出力、グラウンドトゥルース、および個々のスコアを確認するには、メトリクスを選択し「プロンプトの詳細」を選択します。個々のスコアにカーソルを合わせると、詳細な説明が表示されます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ML-18078-image011.jpg)

## Python SDKとAPIを使用したLLM-as-a-judge評価ジョブの開始

LLM-as-a-judgeモデル評価ジョブを作成するためにPython SDKを使用するには、以下の手順に従ってください。まず、必要な設定をセットアップします：

```
import boto3
from datetime import datetime

# ジョブの一意の名前を生成
job_name = f"Model-evaluation-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}"

# ナレッジベースとモデル設定を構成
evaluator_model = "mistral.mistral-large-2402-v1:0"
generator_model = "amazon.nova-pro-v1:0"
role_arn = "arn:aws:iam::<YOUR_ACCOUNT_ID>:role/<YOUR_IAM_ROLE>"

# 評価データと出力のS3の場所を指定
input_data = "s3://<YOUR_BUCKET>/evaluation_data/input.jsonl"
output_path = "s3://<YOUR_BUCKET>/evaluation_output/"

# Bedrockクライアントを作成
bedrock_client = boto3.client('bedrock')
```

LLM-as-a-judgeモデル評価ジョブを作成するには：

```
def create_llm_judge_evaluation(
    client,
    job_name: str,
    role_arn: str,
    input_s3_uri: str,
    output_s3_uri: str,
    evaluator_model_id: str,
    generator_model_id: str,
    dataset_name: str = None,
    task_type: str = "General" # LLMaaJの場合はGeneralである必要があります
):    
    # 利用可能なすべてのLLM-as-judgeメトリクス
    llm_judge_metrics = [
        "Builtin.Correctness",
        "Builtin.Completeness", 
        "Builtin.Faithfulness",
        "Builtin.Helpfulness",
        "Builtin.Coherence",
        "Builtin.Relevance",
        "Builtin.FollowingInstructions",
        "Builtin.ProfessionalStyleAndTone",
        "Builtin.Harmfulness",
        "Builtin.Stereotyping",
        "Builtin.Refusal"
    ]

    # データセットを構成
    dataset_config = {
        "name": dataset_name or "CustomDataset",
        "datasetLocation": {
            "s3Uri": input_s3_uri
        }
    }

    try:
        response = client.create_evaluation_job(
            jobName=job_name,
            roleArn=role_arn,
            applicationType="ModelEvaluation",
            evaluationConfig={
                "automated": {
                    "datasetMetricConfigs": [
                        {
                            "taskType": task_type,
                            "dataset": dataset_config,
                            "metricNames": llm_judge_metrics
                        }
                    ],
                    "evaluatorModelConfig": {
                        "bedrockEvaluatorModels": [
                            {
                                "modelIdentifier": evaluator_model_id
                            }
                        ]
                    }
                }
            },
            inferenceConfig={
                "models": [
                    {
                        "bedrockModel": {
                            "modelIdentifier": generator_model_id
                        }
                    }
                ]
            },
            outputDataConfig={
                "s3Uri": output_s3_uri
            }
        )
        return response
        
    except Exception as e:
        print(f"評価ジョブの作成エラー: {str(e)}")
        raise
        
 # 評価ジョブを作成
try:
    llm_as_judge_response = create_llm_judge_evaluation(
        client=bedrock_client,
        job_name=job_name,
        role_arn=ROLE_ARN,
        input_s3_uri=input_data,
        output_s3_uri=output_path,
        evaluator_model_id=evaluator_model,
        generator_model_id=generator_model,
        task_type="General"
    )
    print(f"✓ 評価ジョブを作成しました: {llm_as_judge_response['jobArn']}")
except Exception as e:
    print(f"✗ 評価ジョブの作成に失敗しました: {str(e)}")
    raise

```

評価ジョブの進行状況を監視するには：

```
# ジョブタイプに基づいてジョブARNを取得
evaluation_job_arn = llm_as_judge_response['jobArn']
# ジョブステータスを確認
check_status = bedrock_client.get_evaluation_job(jobIdentifier=evaluation_job_arn) 
print(f"ジョブステータス: {check_status['status']}")
```

また、複数の基盤モデルを比較して、ニーズに最適なモデルを判断することもできます。すべての比較で同じ評価者モデルを使用することで、ユースケースに最適なモデルを特定するのに役立つ一貫したベンチマーク結果が得られます。

```
# 生成器モデル
GENERATOR_MODELS = [
    "anthropic.claude-3-haiku-20240307-v1:0",
    "amazon.nova-micro-v1:0"
]

# 一貫した評価者
EVALUATOR_MODEL = "anthropic.claude-3-haiku-20240307-v1:0"

def run_model_comparison(
    generator_models: List[str],
    evaluator_model: str
) -> List[Dict[str, Any]]:
    evaluation_jobs = []
    
    for generator_model in generator_models:
        job_name = f"llmaaj-{generator_model.split('.')[0]}-{evaluator_model.split('.')[0]}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}"
        
        try:
            response = create_llm_judge_evaluation(
                client=bedrock_client,
                job_name=job_name,
                role_arn=ROLE_ARN,
                input_s3_uri=input_data,
                output_s3_uri=f"{output_path}/{job_name}/",
                evaluator_model_id=evaluator_model,
                generator_model_id=generator_model,
                task_type="General"
            )
            
            job_info = {
                "job_name": job_name,
                "job_arn": response["jobArn"],
                "generator_model": generator_model,
		"evaluator_model": evaluator_model,
                "status": "CREATED"
            }
            evaluation_jobs.append(job_info)
            
            print(f"✓ ジョブを作成しました: {job_name}")
            print(f"  生成器: {generator_model}")
            print(f"  評価者: {evaluator_model}")
            print("-" * 80)
            
        except Exception as e:
            print(f"✗ {generator_model}のエラー: {str(e)}")
            continue
            
    return evaluation_jobs

# モデル比較を実行
evaluation_jobs = run_model_comparison(GENERATOR_MODELS, EVALUATOR_MODEL)
```

### LLM-as-a-judge評価の相関分析

Amazon BedrockでLLM-as-a-judgeを使用して異なる生成器モデル間の評価結果を比較するために、[スピアマンの順位相関係数](https://en.wikipedia.org/wiki/Spearman%27s%5Frank%5Fcorrelation%5Fcoefficient)を使用できます。様々なメトリクスにわたる評価スコアを含むS3バケットから評価結果を取得した後、相関分析を開始できます。

`scipy.stats`を使用して、生成器モデルのペア間の相関係数を計算し、有効な統計比較を行うために定数値やエラーメッセージをフィルタリングします。結果の相関係数は、異なるモデルが同じプロンプトにどの程度類似して応答するかを識別するのに役立ちます。係数が1.0に近いほど、モデルの応答間の一致が強いことを示し、0に近い値はより発散した動作を示唆します。この分析はモデルの一貫性に関する貴重な洞察を提供し、異なるモデルが同じ入力に対して大きく異なる出力を生成する可能性がある場合を特定するのに役立ちます。

```
import json
import boto3
import numpy as np
from scipy import stats

def read_and_organize_metrics_from_s3(bucket_name, file_key):
    s3_client = boto3.client('s3')
    metrics_dict = {}
    
    try:
        response = s3_client.get_object(Bucket=bucket_name, Key=file_key)
        content = response['Body'].read().decode('utf-8')
        
        for line in content.strip().split('\n'):
            if line:
                data = json.loads(line)
                if 'automatedEvaluationResult' in data and 'scores' in data['automatedEvaluationResult']:
                    for score in data['automatedEvaluationResult']['scores']:
                        metric_name = score['metricName']
                        if 'result' in score:
                            metric_value = score['result']
                            if metric_name not in metrics_dict:
                                metrics_dict[metric_name] = []
                            metrics_dict[metric_name].append(metric_value)
        return metrics_dict
    
    except Exception as e:
        print(f"エラー: {e}")
        return None

def get_spearmanr_correlation(scores1, scores2):
    if len(set(scores1)) == 1 or len(set(scores2)) == 1:
        return "未定義（一定のスコア）", "未定義"
    
    try:
        result = stats.spearmanr(scores1, scores2)
        return round(float(result.statistic), 4), round(float(result.pvalue), 4)
    except Exception as e:
        return f"エラー: {str(e)}", "未定義"

# メトリクスを抽出
bucket_name = "<EVALUATION_OUTPUT_BUCKET>"
file_key1 = "<EVALUATION_FILE_KEY1>"
file_key2 = "<EVALUATION_FILE_KEY2>"

metrics1 = read_and_organize_metrics_from_s3(bucket_name, file_key1)
metrics2 = read_and_organize_metrics_from_s3(bucket_name, file_key2)

# 共通メトリクスの相関を計算
common_metrics = set(metrics1.keys()) & set(metrics2.keys())

for metric_name in common_metrics:
    scores1 = metrics1[metric_name]
    scores2 = metrics2[metric_name]
    
    if len(scores1) == len(scores2):
        correlation, p_value = get_spearmanr_correlation(scores1, scores2)
        
        print(f"\nメトリクス: {metric_name}")
        print(f"サンプル数: {len(scores1)}")
        print(f"モデル1スコアの一意値: {len(set(scores1))}")
        print(f"モデル2スコアの一意値: {len(set(scores2))}")
        print(f"モデル1スコア範囲: [{min(scores1)}, {max(scores1)}]")
        print(f"モデル2スコア範囲: [{min(scores2)}, {max(scores2)}]")
        print(f"スピアマン相関係数: {correlation}")
        print(f"P値: {p_value}")
    else:
        print(f"\nメトリクス: {metric_name}")
        print("エラー: モデル間のサンプル数が異なります")
```

## LLM-as-a-judge実装のベストプラクティス

また、複数の基盤モデルを比較して、ニーズに最適なモデルを判断することもできます。すべての比較で同じ評価者モデルを使用することで、一貫性のある拡張可能な結果が得られます。以下のベストプラクティスは、異なる基盤モデルを比較する際に標準化されたベンチマークを確立するのに役立ちます。

* 実際のユースケースとエッジケースを代表する多様なテストデータセットを作成します。大規模なワークロード（1,000以上のプロンプト）の場合、コストと完了時間を管理しながら包括的なカバレッジを維持するために層化サンプリングを使用します。モデルの能力を異なる難易度レベルでテストするために、単純なプロンプトと複雑なプロンプトの両方を含めます。
* 特定のビジネス目標とアプリケーション要件に合ったメトリクスを選択します。品質メトリクス（正確性、完全性）とユーザーエクスペリエンスメトリクス（有用性、一貫性）のバランスを取ります。顧客向けアプリケーションを展開する場合は安全性メトリクスを含めます。
* 異なるモデルを比較する際に一貫した評価条件を維持します。標準化されたベンチマークのために比較全体で同じ評価者モデルを使用します。再現性のために評価構成とパラメータを文書化します。
* 時間の経過に伴うモデルのパフォーマンスを追跡するために定期的な評価ジョブをスケジュールします。改善が必要な領域を特定するために、異なるメトリクスカテゴリ全体のトレンドを監視します。各メトリクスのパフォーマンスベースラインとしきい値を設定します。
* 評価ニーズとコスト制約に基づいてバッチサイズを最適化します。迅速な反復には小さなテストセットを、包括的な評価には大きなセットを検討します。評価頻度とリソース使用率のバランスを取ります。
* 構成と結果を含む評価ジョブの詳細な記録を維持します。時間の経過に伴うモデルパフォーマンスの改善と変化を追跡します。評価の洞察に基づいて行われた修正を文書化します。オプションのジョブ説明フィールドがここで役立ちます。
* 評価結果を使用してモデルの選択と最適化を導きます。プロンプトエンジニアリングを継続的に改善するためのフィードバックループを実装します。新たな要件とユーザーフィードバックに基づいて評価基準を定期的に更新します。
* 増加するワークロードに対応できるように評価フレームワークを設計します。より多くのモデルやユースケースを追加する際の複雑さの増加に備えます。定期的な評価タスクの自動化されたワークフローを検討します。

これらのベストプラクティスは、Amazon Bedrockでのモデル評価におけるLLM-as-a-judgeを使用して堅牢な評価フレームワークを確立するのに役立ちます。これらのプラクティスの科学的検証に関するより深い洞察（ケーススタディや人間の判断との相関関係を含む）については、今後の技術的な詳細ブログ記事をお待ちください。

## 結論

Amazon Bedrock モデル評価におけるLLM-as-a-judgeは、自動モデル評価の重要な進歩を表し、組織が体系的にAIアプリケーションを評価し最適化するための強力なツールを提供します。この機能は、自動評価の効率性と通常は人間の評価に関連する微妙な理解を組み合わせ、組織が高いパフォーマンスと安全性の基準を維持しながら品質保証プロセスをスケールできるようにします。

包括的なメトリクスカテゴリ、柔軟な実装オプション、既存のAWSサービスとのシームレスな統合により、組織はニーズに合わせて成長する堅牢な評価フレームワークを確立することが可能になります。会話型AIアプリケーション、コンテンツ生成システム、または特殊な企業向けソリューションを開発している場合でも、LLM-as-a-judgeはモデルが技術要件とビジネス目標の両方に合致することを確認するために必要なツールを提供します。

初期セットアップからベストプラクティスまで、この機能を効果的に使用するための詳細な実装ガイダンスを提供しました。この記事に含まれるコードサンプルと設定例は、これらの評価を実際に実装する方法を示しています。体系的な評価と継続的な改善を通じて、組織はより信頼性が高く、正確で信頼できるAIアプリケーションを構築できます。

Amazon Bedrockコンソールでのモデル評価におけるLLM-as-a-judge機能を探索し、自動評価がAIアプリケーションをどのように強化できるかを発見することをお勧めします。開始に役立つように、実用的な例とコードスニペットを含むJupyterノートブックを[GitHubリポジトリ](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/evaluation-observe/bedrock-llm-as-judge-evaluation)で準備しています。

---

### 著者について

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/wale_picture_blog.png)**Adewale Akinfaderin**はAmazon Bedrockのシニアデータサイエンティスト（生成系AI）で、AWSにおける基盤モデルと生成系AIアプリケーションの最先端イノベーションに貢献しています。彼の専門知識は再現可能でエンドツーエンドのAI/ML手法、実用的な実装、そしてグローバルな顧客が学際的な問題に対するスケーラブルなソリューションを策定・開発するのを支援することにあります。彼は物理学の大学院学位を2つと工学の博士号を持っています。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/ishan.jpg)**Ishan Singh**はAmazon Web Servicesの生成系AIデータサイエンティストで、顧客が革新的で責任ある生成系AIソリューションと製品を構築するのを支援しています。AI/MLの強力なバックグラウンドを持つIshanは、ビジネス価値を推進する生成系AIソリューションの構築を専門としています。仕事以外では、バレーボールをしたり、地元の自転車道を探索したり、妻と犬のBeauと時間を過ごすことを楽しんでいます。

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/02/06/Badgephoto.jpeg)**Jesse Manders**はAWS生成系AI開発者サービスであるAmazon Bedrockのシニアプロダクトマネージャーです。彼はAIと人間の相互作用の交差点で働き、私たちのニーズを満たすための生成系AI製品やサービスの作成と改善を目標としています。以前は、AppleとLumiledsでエンジニアリングチームのリーダーシップ役割を務め、シリコンバレーのスタートアップでシニアサイエンティストでした。彼はフロリダ大学で修士号と博士号を取得し、カリフォルニア大学バークレー校ハース・スクール・オブ・ビジネスでMBAを取得しています。

コメントを読み込んでいます…

###  リソース

* [はじめに](https://aws.amazon.com/getting-started?sc%5Fichannel=ha&sc%5Ficampaign=acq%5Fawsblogsb&sc%5Ficontent=machine-learning-resources)
* [新機能](https://aws.amazon.com/new?sc%5Fichannel=ha&sc%5Ficampaign=acq%5Fawsblogsb&sc%5Ficontent=machine-learning-resources)

---

###  ブログトピック

* [Amazon Bedrock](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-machine-learning/amazon-bedrock/)
* [Amazon Comprehend](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-comprehend/)
* [Amazon Kendra](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-kendra/)
* [Amazon Lex](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-lex/)
* [Amazon Polly](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-polly/)
* [Amazon Q](https://aws.amazon.com/blogs/machine-learning/category/amazon-q/)
* [Amazon Rekognition](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-rekognition/)
* [Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/sagemaker/)
* [Amazon Textract](https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-textract/)

---

###  フォロー

* [Twitter](https://twitter.com/awscloud)
* [Facebook](https://www.facebook.com/amazonwebservices)
* [LinkedIn](https://www.linkedin.com/company/amazon-web-services/)
* [Twitch](https://www.twitch.tv/aws)
* [メールアップデート](https://pages.awscloud.com/communication-preferences?sc%5Fichannel=ha&sc%5Ficampaign=acq%5Fawsblogsb&sc%5Ficontent=maching-learning-social)

[コンソールにサインイン](https://console.aws.amazon.com/console/home?nc1=f%5Fct&src=footer-signin-mobile) 

###  AWSについて学ぶ

* [AWSとは？](https://aws.amazon.com/what-is-aws/?nc1=f%5Fcc)
* [クラウドコンピューティングとは？](https://aws.amazon.com/what-is-cloud-computing/?nc1=f%5Fcc)
* [AWSアクセシビリティ](https://aws.amazon.com/accessibility/?nc1=f%5Fcc)
* [DevOpsとは？](https://aws.amazon.com/devops/what-is-devops/?nc1=f%5Fcc)
* [コンテナとは？](https://aws.amazon.com/containers/?nc1=f%5Fcc)
* [データレイクとは？](https://aws.amazon.com/what-is/data-lake/?nc1=f%5Fcc)
* [人工知能（AI）とは？](https://aws.amazon.com/what-is/artificial-intelligence/?nc1=f%5Fcc)
* [生成系AIとは？](https://aws.amazon.com/what-is/generative-ai/?nc1=f%5Fcc)
* [機械学習（ML）とは？](https://aws.amazon.com/what-is/machine-learning/?nc1=f%5Fcc)
* [AWSクラウドセキュリティ](https://aws.amazon.com/security/?nc1=f%5Fcc)
* [新機能](https://aws.amazon.com/new/?nc1=f%5Fcc)
* [ブログ](https://aws.amazon.com/blogs/?nc1=f%5Fcc)
* [プレスリリース](https://press.aboutamazon.com/press-releases/aws "プレスリリース")

###  AWSのリソース

* [はじめに](https://aws.amazon.com/getting-started/?nc1=f%5Fcc)
* [トレーニングと認定](https://aws.amazon.com/training/?nc1=f%5Fcc)
* [AWSソリューションライブラリ](https://aws.amazon.com/solutions/?nc1=f%5Fcc)
* [アーキテクチャセンター](https://aws.amazon.com/architecture/?nc1=f%5Fcc)
* [製品と技術FAQ](https://aws.amazon.com/faqs/?nc1=f%5Fdr)
* [アナリストレポート](https://aws.amazon.com/resources/analyst-reports/?nc1=f%5Fcc)
* [AWSパートナー](https://aws.amazon.com/partners/work-with-partners/?nc1=f%5Fdr)

###  AWSの開発者

* [開発者センター](https://aws.amazon.com/developer/?nc1=f%5Fdr)
* [SDKとツール](https://aws.amazon.com/developer/tools/?nc1=f%5Fdr)
* [AWSの.NET](https://aws.amazon.com/developer/language/net/?nc1=f%5Fdr)
* [AWSのPython](https://aws.amazon.com/developer/language/python/?nc1=f%5Fdr)
* [AWSのJava](https://aws.amazon.com/developer/language/java/?nc1=f%5Fdr)
* [AWSのPHP](https://aws.amazon.com/developer/language/php/?nc1=f%5Fcc)
* [AWSのJavaScript](https://aws.amazon.com/developer/language/javascript/?nc1=f%5Fdr)

###  ヘルプ

* [お問い合わせ](https://aws.amazon.com/contact-us/?nc1=f%5Fm)
* [専門家の助けを得る](https://iq.aws.amazon.com/?utm=mkt.foot/?nc1=f%5Fm)
* [サポートチケットを提出する](https://console.aws.amazon.com/support/home/?nc1=f%5Fdr)
* [AWS re:Post](https://repost.aws/?nc1=f%5Fdr)
* [ナレッジセンター](https://repost.aws/knowledge-center/?nc1=f%5Fdr)
* [AWSサポート概要](https://aws.amazon.com/premiumsupport/?nc1=f%5Fdr)
* [法的情報](https://aws.amazon.com/legal/?nc1=f%5Fcc)
* [AWSキャリア](https://aws.amazon.com/careers/)

[AWSアカウントを作成する](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc1=f%5Fct&src=default) 

[Twitter](https://twitter.com/awscloud "Twitter") 

[Facebook](https://www.facebook.com/amazonwebservices "Facebook") 

[LinkedIn](https://www.linkedin.com/company/amazon-web-services/ "Linkedin") 

[Instagram](https://www.instagram.com/amazonwebservices/ "Instagram") 

[Twitch](https://www.twitch.tv/aws "Twitch") 

[YouTube](https://www.youtube.com/user/AmazonWebServices/Cloud/ "YouTube") 

[Podcast](https://aws.amazon.com/podcasts/ "Podcast") 

[メール](https://pages.awscloud.com/communication-preferences?trk=homepage "メール") 

 Amazonは機会均等雇用者です：_マイノリティ / 女性 / 障害者 / 退役軍人 / 性自認 / 性的指向 / 年齢。_ 

* 言語
* [عربي](https://aws.amazon.com/ar/?nc1=h%5Fls)
* [Bahasa Indonesia](https://aws.amazon.com/id/?nc1=h%5Fls)
* [Deutsch](https://aws.amazon.com/de/?nc1=h%5Fls)
* [English](https://aws.amazon.com/?nc1=h%5Fls)
* [Español](https://aws.amazon.com/es/?nc1=h%5Fls)
* [Français](https://aws.amazon.com/fr/?nc1=h%5Fls)
* [Italiano](https://aws.amazon.com/it/?nc1=h%5Fls)
* [Português](https://aws.amazon.com/pt/?nc1=h%5Fls)
* [Tiếng Việt](https://aws.amazon.com/vi/?nc1=f%5Fls)
* [Türkçe](https://aws.amazon.com/tr/?nc1=h%5Fls)
* [Ρусский](https://aws.amazon.com/ru/?nc1=h%5Fls)
* [ไทย](https://aws.amazon.com/th/?nc1=f%5Fls)
* [日本語](https://aws.amazon.com/jp/?nc1=h%5Fls)
* [한국어](https://aws.amazon.com/ko/?nc1=h%5Fls)
* [中文 (简体)](https://aws.amazon.com/cn/?nc1=h%5Fls)
* [中文 (繁體)](https://aws.amazon.com/tw/?nc1=h%5Fls)

* [プライバシー](https://aws.amazon.com/privacy/?nc1=f%5Fpr)
* |
* [アクセシビリティ](https://aws.amazon.com/accessibility/?nc1=f%5Facc)
* |
* [サイト利用規約](https://aws.amazon.com/terms/?nc1=f%5Fpr)
* |
* [Cookie設定](#)
* |
* © 2024, Amazon Web Services, Inc. またはその関連会社。無断複写・転載を禁じます。
