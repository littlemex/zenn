---
title: "Appendix: VAST Data - LLM 学習のためのチェックポイント帯域幅の最適化"
emoji: "🚀"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["aws", "sagemaker", "hyperpod", "ai", "ml"]
free: true
---

## 要約

実環境のシステムにおける 85,000 のチェックポイントを分析し、本番学習ワークロードが実際にどのようにストレージと対話するかを調査しました。その結果、グローバルチェックポイント帯域幅の要件は控えめであり、兆パラメータ規模のモデルでも通常 1 TB/s を大きく下回ることがわかりました。これらの知見を実用的にするために、GPU 規模と信頼性を必要なグローバルチェックポイント帯域幅に関連付けるシンプルなサイジングモデルを開発しました。これにより、システム設計者は GPU に可能な限り多くの電力、スペース、予算を割り当てながら、効率的なチェックポイント処理をサポートするストレージをプロビジョニングできます。

## 背景

大規模 LLM の学習分野は急速に進化しており、AI サービスプロバイダは最先端モデルの現在と将来のニーズを満たすインフラストラクチャの設計に苦労しています。GPU クラスタの規模とスループットが新しいモデルの開発速度を制限するため、関連するネットワークとストレージサブシステムがそれに追従することが合理的です。しかし、GPU 設計者はアクセラレータを完全に飽和させるために必要な I/O 帯域幅を定量化するリファレンスアーキテクチャを公開していますが、これらのガイドラインは設計方程式の半分しか捉えていません。理想的な条件下で GPU が消費できる量を記述する供給側に焦点を当てていますが、本番ワークロードが実際にどのようにストレージと対話するかは考慮していません。

VAST は世界最大級の AI 学習クラスタの多くにデータプラットフォームを提供しており、方程式のもう半分、つまり需要側を可視化できます。GPU ノードでの学習を直接観察することはありませんが、事前学習とファインチューニング中に生成される I/O パターンをシステムが捉えます。これにより、チェックポイントの頻度、期間、帯域幅を特性評価し、チェックポイント処理がどの程度計算とオーバーラップするかを評価できます。学習が実際にストレージに何を要求するかを定量化することで、GPU、ストレージ、ネットワーキング、電力、冷却、スペースへの投資を最適にバランスさせる支援ができます。

## 調査結果

需要側の視点を根拠づけるため、数十の最先端規模の学習実行におけるチェックポイント動作を分析しました。

### 調査対象

18 のクラスタにまたがる AI クラウドプロバイダで、40 の大規模（1,024 GPU 以上）本番学習実行を調査し、85,000 以上のチェックポイントをカバーしました。モデルサイズは 450 億から 1 兆パラメータ以上に及び、中規模から最先端規模の LLM をカバーしています。

### 主要な発見

**1. GPU あたりのチェックポイント帯域幅はモデルサイズの増加とともに減少**

このトレンドはデータ並列学習のメカニクスを反映しています。大きなモデルは学習により多くの GPU を必要としますが、チェックポイント処理時に書き込む必要があるのは単一のデータ並列レプリカのみです。その結果、チェックポイント帯域幅はクラスタサイズに比例して拡大せず、より多くのデータ並列レプリカがより多くの GPU に組み込まれるにつれて GPU あたりの需要は減少します。

**2. 最大モデルで必要な絶対帯域幅が減少**

これは直感に反するように見えるかもしれません。大きなモデルは学習により多くの GPU を必要とし、コンポーネントが多いほど故障が学習を中断する可能性が高くなります。したがって、大規模モデルの効率的な学習を維持するには、チェックポイントをより頻繁に書き込み、より迅速に完了させることが予想され、ストレージへの帯域幅要求が増加するはずです。しかし、データは、モデル学習者が**非同期チェックポイント処理**に依存していることを示唆しています。これは、頻繁なチェックポイントをノードローカルストレージに迅速に書き込み、その後より低い固定頻度でグローバルストレージにドレインする技術です。サブコンポーネントの問題（リンクフラップや GPU ECC エラーなど）と比較してノード全体の故障は稀であるため、これらのローカルチェックポイントは通常クラッシュを生き残ります。分析によると、モデル学習者は、ノードローカルチェックポイントが失われる比較的稀なケースから保護するのに十分な頻度でのみ、チェックポイントを共有ストレージに同期することで最適化していることが示唆されます。

Meta の Llama チームによる研究では、ノード全体の故障は全故障のわずか 5% であることがわかりました。これが意味することは明確です。グローバルストレージは、ノードローカルチェックポイントの定期的なドレインを吸収するのに十分な帯域幅のみを必要とし、GPU スループットが示す完全な書き込み速度は必要ありません。

### チェックポイントオーバーラップの分析

これを検証するために、チェックポイント期間（VAST へのチェックポイントのコピーに必要な時間）とチェックポイント間隔（VAST に到着する連続したチェックポイント間の時間）を比較しました。

**800B パラメータの学習実行の例**
- チェックポイント間隔: 40 分
- チェックポイント期間の中央値: 3.6 分
- チェックポイントオーバーラップ: 約 9%

調査した 40 の本番実行全体で、ほぼすべてが中央値チェックポイントオーバーラップを総学習時間の 10% 未満に保っていました。

「許容可能な」チェックポイントオーバーラップの正式な閾値はありませんが、この結果の一貫性は、モデル学習者が実際にチェックポイント処理のオーバーラップをどのように管理しているかを強調しています。

すべての実行を通じて、非同期チェックポイントは 50～200 GB/s の速度でグローバルストレージにドレインされ、モデルサイズとの明確な相関はありませんでした。これは、最先端規模の学習でさえ比較的控えめなグローバルチェックポイント帯域幅で維持できることを示しています（原理的には、より高いチェックポイントオーバーラップを許容し、さらに低い帯域幅で動作できます）。グローバルストレージはピーク GPU スループットに一致する必要はありません。

## インフラストラクチャ設計への影響

この需要側の視点は、計算、ネットワーク、ストレージにわたってバランスの取れた学習インフラストラクチャを設計する上で重要な意味を持ちます。

適切に設計された高性能ストレージシステムでは、帯域幅はネットワーキング、ソフトウェア、ドライブ容量ではなく、並列に書き込める SSD の数に応じて拡大します。その結果、ほとんどの AI 学習サーバーは、単一の大容量デバイスではなく 4～8 の NVMe SSD を搭載しています。しかし、このパフォーマンスにはコストが伴います。ドライブが多いほど TB あたりのコストが増加し、分散ストレージシステムに適用すると、より多くのサーバー、ネットワーキング、電力、スペース、冷却が必要になります。

理論的な GPU 機能に一致する最高の I/O パフォーマンスを要求することは魅力的かもしれませんが、それはやり過ぎかもしれません。実際、分析によると、兆パラメータ規模のモデルでさえ、1 TB/s を大きく下回るチェックポイント帯域幅で効率的に学習できることが示唆されています（多くの大規模 VAST デプロイメントは TB/s 規模のスループットが可能ですが）。チェックポイントは、規模で利用可能なすべての I/O 帯域幅を最終的に使用するため、より多くの帯域幅をプロビジョニングすると、チェックポイントはより速くドレインされます。しかし、オーバープロビジョニングは、学習時間のパフォーマンスを改善することなく、より多くの GPU をサポートするために使用できたはずのリソースを消費します。チェックポイントが非同期にドレインされている間、GPU はブロックされていないことを覚えておいてください。

## 推奨事項

AI 学習の最適なアーキテクチャは、I/O 帯域幅を最小化も最大化もせず、GPU 機能、信頼性、チェックポイントドレインスループットのバランスを取り、電力、スペース、冷却の制約内で学習効率を最大化します。

10% のチェックポイントオーバーラップを仮定すると、必要なグローバル帯域幅は、最高のチェックポイント頻度と最大モデルを除くすべてで控えめです。

### システムアーキテクトのためのガイドライン

1. **チェックポイントオーバーラップが最も関連性の高いパフォーマンス指標**
   GB/s ではなくオーバーラップに注目してください。オーバーラップが低いほど良好です。なぜなら、チェックポイントが共有ストレージに同期される前に壊滅的な故障が発生する可能性が減少するためです。調査結果は、10% のオーバーラップが十分であることを示しています。

2. **非同期チェックポイントをドレインするようにグローバルストレージを設計**
   すべての GPU の理論的最大値に一致するパフォーマンスをプロビジョニングしようとすると、全体的な学習効率にほとんど追加されません。同期チェックポイントは、ノードローカル NVMe への書き込みに必要な時間だけ GPU をブロックし、ノードローカル NVMe はすでに GPU 数とモデルサイズに応じて拡大しています。

3. **ヒーロー帯域幅ではなく、ジョブの信頼性のために設計**
   グローバルストレージは、稀なノード全体の故障から保護するために使用する必要があります。ほとんどの故障は個々の GPU やネットワークリンクに影響し、ノードローカルチェックポイントを使用して復旧できます。

4. **GPU 投資に対してパフォーマンス余裕をバランス**
   I/O パフォーマンスのオーバープロビジョニングは、データセンターがサポートできる GPU の数を減らします。ストレージは学習効率の促進要因であるべきであり、最高の I/O ベンチマーク番号を求める独立した競争ではありません。

## サイジングモデル

モデルサイズ、チェックポイント間隔、許容可能なオーバーラップを必要なグローバルチェックポイント帯域幅に関連付けるシンプルなサイジングモデル:

**必要帯域幅 = (モデルサイズ × bytes/parameter) / (チェックポイント間隔 × 許容オーバーラップ)**

### 実例: Llama 3.1 405B

実際には、チェックポイント間隔はジョブがクラッシュする速度に比例する必要があり、これは使用する GPU の数に応じて拡大します。例えば、16,000 台の H100 GPU で学習された 405B パラメータモデルは、平均中断時間（MTTI）が 150 分でした。その規模では、合理的なチェックポイント間隔はこれの約 10 分の 1、つまり約 15 分でした。パラメータあたり 14 バイトのチェックポイントを仮定すると、必要なチェックポイント帯域幅は次のとおりです。

**必要帯域幅 = (405B × 14 bytes) / (15分 × 60秒 × 0.1) ≈ 631 GB/s**

この例は、サイジングモデルがクラスタの信頼性とモデル設計を防御可能なグローバル帯域幅要件にどのように変換するかを示しています。

## 結論

85,000 のチェックポイントから得られる教訓は、最大規模の LLM でさえ控えめなグローバルチェックポイント帯域幅で効率的に学習でき、データセンターリソースをより多くの計算とより速い学習完了時間のために解放できるということです。