---
title: "ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼ -- å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ãŠã‘ã‚‹éšœå®³å¯¾ç­–ã®é‡è¦æ€§"
emoji: "ğŸ¶"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["aws", "sagemaker", "hyperpod", "distributed", "infrastructure"]
free: true
---

::::details å‰æ
:::message
**å¯¾è±¡èª­è€…**: å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãŒã©ã†ã„ã†ã‚‚ã®ã‹ã‚’ç†è§£ã—ã¦ã„ã‚‹æ–¹ã€ã“ã‚Œã‹ã‚‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’è¡Œã†æ–¹
:::
:::message
**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: Â© 2025 littlemex.
æœ¬æ–‡ãŠã‚ˆã³è‡ªä½œå›³è¡¨: CC BY 4.0
â€»å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã®å¼•ç”¨ã‚„ç¿»è¨³éƒ¨åˆ†ã¯åŸå…¸ã®è‘—ä½œæ¨©ã«å¾“ã„ã¾ã™ã€‚
å¼•ç”¨ç”»åƒ: å„ç”»åƒã®å‡ºå…¸ã«è¨˜è¼‰ã•ã‚ŒãŸãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«å¾“ã„ã¾ã™ã€‚
:::
:::message
ä¸€éƒ¨ AI ã‚’ç”¨ã„ã¦æ–‡ç« ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯å®Ÿæ–½ã—ã¾ã™ãŒã€è¦‹é€ƒã›ãªã„é‡å¤§ãªé–“é•ã„ãªã©ãŒã‚ã‚Œã°[ã“ã¡ã‚‰ã®Issue](https://github.com/littlemex/samples/issues)ã‹ã‚‰é€£çµ¡ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
:::
::::

# å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ãŠã‘ã‚‹éšœå®³ç‡

å¤§è¦æ¨¡ãª GPU ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹éš›ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®éšœå®³ã¯é¿ã‘ã‚‰ã‚Œãªã„ç¾å®Ÿã§ã™ã€‚æœ¬ç« ã§ã¯ã€å®Ÿéš›ã®å­¦ç¿’ã§ç™ºç”Ÿã™ã‚‹éšœå®³ã®é »åº¦ã¨ãã®å½±éŸ¿ã€ãã—ã¦ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼ã®é‡è¦æ€§ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚

:::message alert
**é‡è¦ãªäº‹å®Ÿ**

[100,000 GPU ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã¯å¹³å‡ 30 åˆ†ã”ã¨ã« GPU éšœå®³ãŒç™ºç”Ÿ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã—ã¾ã™ã€‚æ•°é€±é–“ã‹ã‚‰æ•°ãƒ¶æœˆã«ã‚ãŸã‚‹å­¦ç¿’ã§ã¯ã€éšœå®³æ¤œå‡ºã¨è‡ªå‹•å¾©æ—§ãªã—ã«å®Œäº†ã™ã‚‹ã“ã¨ã¯äº‹å®Ÿä¸Šä¸å¯èƒ½ã§ã™ã€‚
:::

## ã‚¹ã‚±ãƒ¼ãƒ«ã¨éšœå®³é »åº¦ã®é–¢ä¿‚

::::details ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¼´ã†é¿ã‘ã‚‰ã‚Œãªã„éšœå®³

GPU ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãããªã‚‹ã»ã©ã€éšœå®³ã®ç™ºç”Ÿé »åº¦ã¯ç·šå½¢ã«å¢—åŠ ã—ã¾ã™ã€‚[å˜ä¸€ã® H100 GPU ãŒå¹³å‡ 50,000 æ™‚é–“ï¼ˆç´„ 6 å¹´ï¼‰ã« 1 å›éšœå®³ã‚’èµ·ã“ã™](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã¨ä»®å®šã—ãŸå ´åˆã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å…¨ä½“ã®å¹³å‡éšœå®³é–“éš”ï¼ˆMTBFï¼‰ã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã® GPU æ•°ã«åæ¯”ä¾‹ã—ã¾ã™ã€‚

| ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è¦æ¨¡ | å¹³å‡éšœå®³é–“éš” (MTBF) | 1 æ—¥ã‚ãŸã‚Šã®éšœå®³å›æ•° |
|--------------|-------------------|------------------|
| 1,000 GPU | 50 æ™‚é–“ (ç´„ 2 æ—¥) | 0.48 å› |
| 10,000 GPU | 5 æ™‚é–“ | 4.8 å› |
| 100,000 GPU | 30 åˆ† | 48 å› |
| 1,000,000 GPU | 3 åˆ† | 480 å› |

*å‡ºå…¸: [Epoch AI - Hardware failures won't limit AI scaling](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)*

ã“ã®è¨ˆç®—ã‹ã‚‰æ˜ã‚‰ã‹ãªã‚ˆã†ã«ã€[100,000 GPU ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã¯ 30 åˆ†ã”ã¨ã«ã€1,000,000 GPU ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã¯ã‚ãšã‹ 3 åˆ†ã”ã¨ã«ä½•ã‚‰ã‹ã® GPU éšœå®³ãŒç™ºç”Ÿ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã—ã¾ã™ã€‚æ•°é€±é–“ã‹ã‚‰æ•°ãƒ¶æœˆã«ã‚ãŸã‚‹å¤§è¦æ¨¡å­¦ç¿’ã§ã¯ã€éšœå®³ã¸ã®å¯¾å¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãªã—ã«å­¦ç¿’ã‚’å®Œäº†ã™ã‚‹ã“ã¨ã¯äº‹å®Ÿä¸Šä¸å¯èƒ½ã§ã™ã€‚

:::message
éšœå®³æ¤œå‡ºã¨è‡ªå‹•å¾©æ—§ã¯ã€å¤§è¦æ¨¡å­¦ç¿’ã«ãŠã‘ã‚‹å¿…é ˆè¦ä»¶ã¨ãªã£ã¦ã„ã¾ã™ã€‚
:::
::::

## Meta Llama 3 405B ã®å®Ÿéš›ã®éšœå®³ãƒ‡ãƒ¼ã‚¿

::::details 54 æ—¥é–“ã®å­¦ç¿’ã§è¨˜éŒ²ã•ã‚ŒãŸ 419 å›ã®ä¸­æ–­

[Meta ãŒå…¬é–‹ã—ãŸ Llama 3 405B ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã¯ã€å¤§è¦æ¨¡å­¦ç¿’ã«ãŠã‘ã‚‹éšœå®³ã®ç¾å®Ÿã‚’ç¤ºã™è²´é‡ãªè³‡æ–™ã§ã™ã€‚

### å­¦ç¿’ç’°å¢ƒ
- **GPU æ•°**: [16,384 GPU (H100 80GB)](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)
- **å­¦ç¿’æœŸé–“**: [54 æ—¥é–“](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)
- **ç·ä¸­æ–­å›æ•°**: [419 å›ã®äºˆæœŸã—ãªã„ä¸­æ–­](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)
- **éšœå®³é »åº¦**: [å¹³å‡ 3 æ™‚é–“ã”ã¨ã« 1 å›ï¼ˆ1 æ—¥ã‚ãŸã‚Š 7.76 å›ï¼‰](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster)
- **é”æˆã—ãŸç¨¼åƒç‡**: [90% ä»¥ä¸Šã®åŠ¹æœçš„ãªå­¦ç¿’æ™‚é–“](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)
- **æ‰‹å‹•ä»‹å…¥**: [ã‚ãšã‹ 3 å›ã®ã¿ï¼ˆæ®‹ã‚Š 416 å›ã¯è‡ªå‹•åŒ–ã§å¯¾å¿œï¼‰](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)

### éšœå®³ã®å†…è¨³

| éšœå®³ã‚¿ã‚¤ãƒ— | ç™ºç”Ÿå›æ•° | å‰²åˆ |
|----------|---------|------|
| GPU éšœå®³ | 148 | 30.1% |
| HBM3 ãƒ¡ãƒ¢ãƒªéšœå®³ | 72 | 17.2% |
| GPU SRAM | 19 | 4.5% |
| GPU ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ã‚»ãƒƒã‚µ | 17 | 4.1% |
| ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ | 35 | 8.4% |
| CPU | 2 | 0.5% |
| ãã®ä»– | 126 | 30.1% |

*å‡ºå…¸: [Meta Llama 3 training report](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)*

:::message
**GPU é–¢é€£ã®éšœå®³ãŒéåŠæ•°ã‚’å ã‚ã‚‹**

[GPU æœ¬ä½“ã¨ HBM3 ãƒ¡ãƒ¢ãƒªã‚’åˆã‚ã›ã‚‹ã¨ã€å…¨ä½“ã® 58.7% ã‚’å ã‚ã¾ã™](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster)ã€‚[H100 GPU ã¯ 700W ã¨ã„ã†é«˜ã„æ¶ˆè²»é›»åŠ›ã«ã‚ˆã‚Šå¤§ããªç†±ã‚¹ãƒˆãƒ¬ã‚¹ã‚’å—ã‘ã‚‹](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster)ãŸã‚ã€éšœå®³ç‡ãŒé«˜ããªã‚Šã¾ã™ã€‚

ä¸€æ–¹ã€[CPU ã®éšœå®³ã¯ã‚ãšã‹ 2 å›ã®ã¿](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã§ã€GPU ã¨æ¯”è¼ƒã—ã¦ CPU ã®ä¿¡é ¼æ€§ã¯æ¥µã‚ã¦é«˜ã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚
:::

ã“ã®é«˜åº¦ãªè‡ªå‹•åŒ–ã«ã‚ˆã‚Šã€[Meta ã¯ 419 å›ã®ä¸­æ–­ã®ã†ã¡ 416 å›ã‚’è‡ªå‹•å‡¦ç†ã—ã€90% ä»¥ä¸Šã®åŠ¹æœçš„ãªå­¦ç¿’æ™‚é–“ã‚’ç¶­æŒ](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã§ãã¾ã—ãŸã€‚æ‰‹å‹•ä»‹å…¥ã«ä¾å­˜ã—ã¦ã„ãŸå ´åˆã€ç ”ç©¶è€…ã¯ 3 æ™‚é–“ã”ã¨ã«ç™ºç”Ÿã™ã‚‹éšœå®³ã«å¯¾å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ã“ã‚Œã¯ç¾å®Ÿçš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
::::

## ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®æ§‹æˆã¨æœ€é©åŒ–

::::details ç ”ç©¶è€…è¦–ç‚¹ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ åˆ†æ

[NVIDIA ã®ç ”ç©¶](https://developer.nvidia.com/blog/ensuring-reliable-model-training-on-nvidia-dgx-cloud/)ã«ã‚ˆã‚‹ã¨ã€å­¦ç¿’ã«ãŠã‘ã‚‹å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯è¤‡æ•°ã®è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚å¾“æ¥ã® MFUï¼ˆModel FLOPS Utilizationï¼‰ã‚„ MTTFï¼ˆMean Time To Failureï¼‰ã¨ã„ã£ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®åˆ©ç”¨åŠ¹ç‡ã‚„å¹³å‡æ•…éšœé–“éš”ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€ç ”ç©¶è€…ãŒå®Ÿéš›ã«çµŒé¨“ã™ã‚‹å­¦ç¿’ã®ä¸­æ–­ã‚„ãã‚Œã«ä¼´ã†æ™‚é–“çš„ã‚³ã‚¹ãƒˆã‚’ååˆ†ã«åæ˜ ã—ã¦ã„ã¾ã›ã‚“ã€‚

### ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®å…¬å¼

```
Downtime = Checkpoint Overhead + ErrorCount Ã— (Detection Time + Recovery Time)
```

*å‡ºå…¸: [NVIDIA - Ensuring Reliable Model Training on NVIDIA DGX Cloud](https://developer.nvidia.com/blog/ensuring-reliable-model-training-on-nvidia-dgx-cloud/)*

**å„è¦ç´ ã®èª¬æ˜**

ç ”ç©¶è€…ã®è¦³ç‚¹ã‹ã‚‰ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã«è¦ã™ã‚‹æ™‚é–“ã€ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå¾Œã®å¤±ã‚ã‚ŒãŸä½œæ¥­ã€ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚é–“ã€ãã—ã¦å­¦ç¿’ã‚’å†é–‹ã™ã‚‹ã¾ã§ã®æ™‚é–“ã€ã“ã‚Œã‚‰å…¨ã¦ãŒç”Ÿç”£çš„ãªå­¦ç¿’æ™‚é–“ã‚’å‰Šæ¸›ã—ã¾ã™ã€‚

- **Checkpoint Overhead**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ä¸­ã¯å­¦ç¿’ãƒ«ãƒ¼ãƒ—ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹
- **Detection Time**: éšœå®³ã‚„ã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼ã‚’æ¤œå‡ºã™ã‚‹ã¾ã§ã®æ™‚é–“
- **Recovery Time**: æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä»¥é™ã®å¤±ã‚ã‚ŒãŸä½œæ¥­ + ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ + å†èµ·å‹•

:::message
ã“ã®å…¬å¼ã‹ã‚‰æ˜ã‚‰ã‹ãªã‚ˆã†ã«ã€éšœå®³ã®æ¤œå‡ºã¨å¾©æ—§ã‚’é«˜é€ŸåŒ–ã™ã‚‹ã“ã¨ãŒã€ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®æœ€å°åŒ–ã«ç›´çµã—ã¾ã™ã€‚
:::

### Llama 3 405B ã®å®Ÿç¸¾

Llama 3 405B ã®å­¦ç¿’ã§ã¯ã€[ç´„ 2.5 ç§’ã‹ã‘ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã—ã€ã“ã‚Œã‚’ 4 åˆ†ã”ã¨ã«å®Ÿè¡Œ](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã—ã¾ã—ãŸã€‚[Epoch AI ã®åˆ†æ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã«ã‚ˆã‚‹æ•°å­¦çš„æœ€é©åŒ–ã«ã‚ˆã‚Šã€[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨éšœå®³å¾©æ—§ã«ã‚ˆã‚‹æ™‚é–“æå¤±ã¯å…¨å­¦ç¿’æ™‚é–“ã®ç´„ 2.1% ã«æŠ‘ãˆã‚‰ã‚Œã¾ã—ãŸ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã€‚
::::

## éšœå®³ã®ã‚¿ã‚¤ãƒ—ã¨æ¤œå‡ºã®èª²é¡Œ

::::details ç ”ç©¶è€…ãŒé­é‡ã™ã‚‹ 3 ã¤ã®ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªãƒ¼

[NVIDIA ã®åˆ†æ](https://developer.nvidia.com/blog/ensuring-reliable-model-training-on-nvidia-dgx-cloud/)ã«ã‚ˆã‚‹ã¨ã€ç ”ç©¶è€…ãŒé­é‡ã™ã‚‹ã‚¨ãƒ©ãƒ¼ã¯å¤§ãã 3 ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚

### 1. å³åº§ã®ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ (Immediate Crashes)

**åŸå› **: BIOSã€é›»æºã€ç†±å•é¡Œã€è¨‚æ­£ä¸å¯èƒ½ãª ECC ã‚¨ãƒ©ãƒ¼ã€ã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ç ´æã«ã‚ˆã‚‹ NaN ã®ç™ºç”Ÿã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸å®‰å®šæ€§ãªã©ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®æ ¹æœ¬çš„ãªéšœå®³ã«èµ·å› ã—ã¾ã™ã€‚

**å½±éŸ¿**: å­¦ç¿’ãŒå³åº§ã«åœæ­¢ã—ã€å†èµ·å‹•ãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚

### 2. é€šä¿¡ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ³ã‚° (Communication Hangs)

**ç—‡çŠ¶**: PyTorch ã® NCCL watch dog ã‚¨ãƒ©ãƒ¼ã‚„ [Transformer Engine](https://github.com/NVIDIA/TransformerEngine) ã®é€šä¿¡ãƒãƒ³ã‚°ã¨ã—ã¦ç¾ã‚Œã¾ã™ã€‚

**åŸå› **: ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä»‹ã—ãŸãƒ†ãƒ³ã‚½ãƒ«ï¼ˆå‹¾é…ã‚„ä¸­é–“ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã®è»¢é€ã«ãŠã‘ã‚‹è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚

**å½±éŸ¿**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒå¿œç­”ã—ãªããªã‚Šã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ã§å¾…æ©ŸãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚

:::message
ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†…ã§ã®å …ç‰¢ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒˆãƒˆãƒ¬ãƒ©ãƒ³ã‚¹ã€å°ã˜è¾¼ã‚ã€æ—©æœŸæ¤œå‡ºãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒé‡è¦ã§ã™ã€‚
:::

### 3. é€Ÿåº¦ä½ä¸‹ (Speed Regressions)

**ä¸€æ™‚çš„ãªé€Ÿåº¦ä½ä¸‹**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ä¸€æ™‚çš„ãªå•é¡Œã€æ¸©åº¦å¤‰å‹•ã«ã‚ˆã‚‹ GPU ã®ã‚¯ãƒ­ãƒƒã‚¯èª¿æ•´ã«ã‚ˆã£ã¦ç™ºç”Ÿã—ã¾ã™ã€‚[Meta ã®å­¦ç¿’ã§ã¯ã€æ—¥ä¸­ã®æ¸©åº¦å¤‰å‹•ã«ã‚ˆã‚Š 1-2% ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¤‰å‹•ãŒè¦³æ¸¬](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster)ã•ã‚Œã¾ã—ãŸã€‚

**æŒç¶šçš„ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯**: å¤§è¦æ¨¡ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®ç‰¹å®šã® GPU ãŒå¸¸ã«é…ã„çŠ¶æ…‹ï¼ˆã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼ï¼‰ã«ã‚ã‚‹ã“ã¨ã§ç™ºç”Ÿã—ã¾ã™ã€‚ã“ã®ã‚ˆã†ãªã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼ GPU ã¯ã€æ•°åƒã®ä»–ã® GPU ã«å½±éŸ¿ã‚’åŠã¼ã—ã€å…¨ä½“ã®å­¦ç¿’é€Ÿåº¦ã‚’ä½ä¸‹ã•ã›ã¾ã™ã€‚

ã“ã‚Œã‚‰ã®éšœå®³ã¯ã€ç ”ç©¶è€…ã®è¦–ç‚¹ã‹ã‚‰ã¯çªç„¶ã®ä¸­æ–­ã¾ãŸã¯å¤§å¹…ãªé€Ÿåº¦ä½ä¸‹ã¨ã—ã¦ç¾ã‚Œã¾ã™ã€‚å˜ä¸€ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘ã§ã¯çœŸã®åŸå› ã‚’ç‰¹å®šã™ã‚‹ã®ã¯å›°é›£ã§ã‚ã‚Šã€è¤‡æ•°ã®ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã‚½ãƒ¼ã‚¹ã‚’ç›¸é–¢åˆ†æã™ã‚‹ã“ã¨ã§ã€æ¤œå‡ºã¨å¾©æ—§ã®é€Ÿåº¦ã¨ç²¾åº¦ã‚’å‘ä¸Šã§ãã¾ã™ã€‚
::::

## DCGM ã«ã‚ˆã‚‹éšå±¤çš„ãªéšœå®³æ¤œå‡º

::::details DCGM ã® 4 ã¤ã® Run Level

[NVIDIA Data Center GPU Manager (DCGM)](https://developer.nvidia.com/dcgm) ã¯ã€GPU ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å¥å…¨æ€§ã‚’ç›£è¦–ã—ã€éšœå®³ã‚’æ—©æœŸã«æ¤œå‡ºã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚DCGM Diagnostics ã¯ [4 ã¤ã® Run Level](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/dcgm-diagnostics.html#run-levels-and-tests) ã‚’æä¾›ã—ã€ãã‚Œãã‚Œç•°ãªã‚‹æ·±ã•ã¨æ‰€è¦æ™‚é–“ã§ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

| ãƒ¬ãƒ™ãƒ« | æ‰€è¦æ™‚é–“ (8 GPU) | å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚° | ä¸»ãªç”¨é€” |
|--------|----------------|--------------|---------|
| Level 1 (Quick) | <2.5 ç§’ | ãƒãƒ¼ãƒ‰èµ·å‹•æ™‚ã€ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå‰ | åŸºæœ¬çš„ãªå¥å…¨æ€§ç¢ºèª |
| Level 2 (Medium) | 2.5-10.5 åˆ† | ã‚¸ãƒ§ãƒ–å¤±æ•—æ™‚ã®ã‚¨ãƒ”ãƒ­ãƒ¼ã‚° | æ‹¡å¼µæ¤œè¨¼ã¨è»½ã„è² è·ãƒ†ã‚¹ãƒˆ |
| Level 3 (Long) | 10-35 åˆ† | éšœå®³èª¿æŸ»ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚ | ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¨ºæ–­ |
| Level 4 (Extended) | 30-120 åˆ† | RMA å‰ã€è©³ç´°èª¿æŸ» | å¾¹åº•è¨ºæ–­ |

*å‡ºå…¸: [DCGM Diagnostics Documentation](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/dcgm-diagnostics.html#run-levels-and-tests)*

### Level 1 (Quick) - åŸºæœ¬çš„ãªå¥å…¨æ€§ç¢ºèª

ã“ã®ãƒ¬ãƒ™ãƒ«ã§ã¯ã€CUDA ã‚„ NVML ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèªã€PCIe ãƒªãƒ³ã‚¯ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã€GPU ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã®ãƒã‚§ãƒƒã‚¯ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ãƒãƒ¼ãƒ‰èµ·å‹•æ™‚ã‚„ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå‰ã®å¥å…¨æ€§ç¢ºèªã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã€å®šæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã«ã‚‚é©ã—ã¦ã„ã¾ã™ã€‚

### Level 2 (Medium) - æ‹¡å¼µæ¤œè¨¼

Level 1 ã®å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã«åŠ ãˆã¦ã€ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã®æ¸¬å®šã€GPU ã®åŸºæœ¬çš„ãªè¨ˆç®—ãƒ†ã‚¹ãƒˆã€PCIe å¸¯åŸŸå¹…ã®æ¸¬å®šãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã‚¸ãƒ§ãƒ–å¤±æ•—æ™‚ã®ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ãƒã‚§ãƒƒã‚¯ã‚„å®šæœŸçš„ãªè©³ç´°ãƒã‚§ãƒƒã‚¯ã«ä½¿ç”¨ã•ã‚Œã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã‚’æä¾›ã—ã¾ã™ã€‚

### Level 3 (Long) - ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¨ºæ–­

Level 1 ã¨ Level 2 ã®å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã«åŠ ãˆã¦ã€GPU ã‚³ã‚¢ã¸ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã€é›»åŠ›åˆ¶é™ã®ãƒ†ã‚¹ãƒˆã€ãƒ¡ãƒ¢ãƒªã¸ã®è² è·ãƒ†ã‚¹ãƒˆã€NVLink æ¥ç¶šã®ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚GPU éšœå®³ãŒç–‘ã‚ã‚Œã‚‹æ™‚ã‚„ã€ç®¡ç†è€…ã«ã‚ˆã‚‹è©³ç´°èª¿æŸ»ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚ã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

### Level 4 (Extended) - å¾¹åº•è¨ºæ–­

Level 1 ã‹ã‚‰ Level 3 ã®å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã«åŠ ãˆã¦ã€ã‚ˆã‚Šé•·æ™‚é–“ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã€æ–­ç¶šçš„ãªè² è·ã‚’ä¸ãˆã‚‹ãƒ‘ãƒ«ã‚¹ãƒ†ã‚¹ãƒˆã€é›»åŠ›é…åˆ†ã®è©³ç´°ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚RMAï¼ˆè¿”å“æ‰¿èªï¼‰å‰ã®æœ€çµ‚æ¤œè¨¼ã‚„ã€åŸå› ä¸æ˜ã®éšœå®³ã®å¾¹åº•èª¿æŸ»ã€æ–°è¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®å—ã‘å…¥ã‚Œãƒ†ã‚¹ãƒˆã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
::::

## çµ±åˆãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã«ã‚ˆã‚‹æ ¹æœ¬åŸå› ã®ç‰¹å®š

::::details 3 å±¤ã®ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã¨ç›¸é–¢åˆ†æ

å¤§è¦æ¨¡ãª GPU ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã¯ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã€ãƒãƒ¼ãƒ‰ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã„ã† 3 ã¤ã®å±¤ã‹ã‚‰ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ã“ã‚Œã‚‰ã‚’ç›¸é–¢åˆ†æã™ã‚‹ã“ã¨ã§æ ¹æœ¬åŸå› ã‚’è¿…é€Ÿã«ç‰¹å®šã§ãã¾ã™ã€‚

### 1. ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ†ãƒ¬ãƒ¡ãƒˆãƒª

ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œã‚„èª­ã¿æ›¸ãæ“ä½œã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ã‚¤ãƒƒãƒã®çŠ¶æ…‹ã‚’ç›£è¦–ã—ã¾ã™ã€‚ã“ã‚ŒãŒé‡è¦ãªã®ã¯ã€1 ã¤ã®ãƒãƒ¼ãƒ‰ã®éšœå®³ãŒé€šä¿¡å‘¼ã³å‡ºã—ã‚„ç ´æã—ãŸå‹¾é…ã®ä¼æ’­ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ ã®éè² è·ã‚’é€šã˜ã¦ä»–ã®ãƒãƒ¼ãƒ‰ã«æ³¢åŠã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã§ã™ã€‚

ä¾‹ãˆã°ã€å˜ä¸€ã®ã‚¸ãƒ§ãƒ–ãŒéå‰°ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œã‚’ç”Ÿæˆã—ã¦ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒãƒ¼ãƒ‰ã‚’åœ§è¿«ã™ã‚‹ã¨ã€ä»–ã®ã‚¸ãƒ§ãƒ–ã‚„ãƒãƒ¼ãƒ‰ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã«ç›´é¢ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

### 2. ãƒãƒ¼ãƒ‰ãƒ†ãƒ¬ãƒ¡ãƒˆãƒª

**ãƒ—ãƒ­ãƒ­ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚¸ãƒ§ãƒ–é–‹å§‹å‰ï¼‰**
- ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢çŠ¶æ…‹ã®æ¤œè¨¼
- ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
- ç’°å¢ƒã®è¨­å®š
- **å®Ÿè¡Œã•ã‚Œã‚‹ DCGM ãƒ¬ãƒ™ãƒ«**: Level 1ï¼ˆã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ï¼‰

**å®šæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿè¡Œä¸­ï¼‰**
- GPUã€CPUã€ãƒ¡ãƒ¢ãƒªã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã€ã‚µãƒ¼ãƒ“ã‚¹ã®ç›£è¦–
- **å®Ÿè¡Œã•ã‚Œã‚‹ DCGM ãƒ¬ãƒ™ãƒ«**: ç¶™ç¶šçš„ãªç›£è¦–

**ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚¸ãƒ§ãƒ–çµ‚äº†å¾Œ/éšœå®³æ™‚ï¼‰**
- ãƒªã‚½ãƒ¼ã‚¹ã®è§£æ”¾ã€ãƒ­ã‚°ã®ä¿å­˜ã€ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¯ãƒªãƒ¼ãƒ³çŠ¶æ…‹ã¸ã®å¾©å…ƒ
- **å®Ÿè¡Œã•ã‚Œã‚‹ DCGM ãƒ¬ãƒ™ãƒ«**: Level 2ï¼ˆæ‹¡å¼µæ¤œè¨¼ï¼‰

:::message
å•é¡Œã®æ—©æœŸæ¤œå‡ºã«ã‚ˆã‚Šå¾Œç¶šã®ãƒ‡ãƒãƒƒã‚°æ™‚é–“ã‚’å‰Šæ¸›ã—ã€å…¨ä½“çš„ãªä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
:::

### 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°

é‡è¦ãªåˆ¶å¾¡ãƒã‚¤ãƒ³ãƒˆã€ä¸å¤‰æ¡ä»¶ã€é€²æ—ã®æ¸¬å®šã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ­ã‚°ã¯ã€ä¸­å¤®ãƒªãƒã‚¸ãƒˆãƒªã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã¨ç›¸é–¢åˆ†æã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼ã€ãƒãƒ³ã‚°ã€æ–­ç¶šçš„ã¾ãŸã¯å†ç™ºã™ã‚‹éšœå®³ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®æœ€ã‚‚å¼·åŠ›ãªã‚·ã‚°ãƒŠãƒ«ã¨ãªã‚Šã¾ã™ã€‚

**ç›¸é–¢åˆ†æã®ä¾‹**

åŒã˜ NaN ã‚¨ãƒ©ãƒ¼ãŒç•°ãªã‚‹ç‰©ç†ãƒãƒ¼ãƒ‰ã§åŒã˜ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ©ãƒ³ã‚¯ã«æ±ºå®šè«–çš„ã«ç¾ã‚Œã‚‹å ´åˆã€ã“ã‚Œã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ãŒé«˜ã„ã¨åˆ¤æ–­ã§ãã¾ã™ã€‚ä¸€æ–¹ã€ç‰¹å®šã®ãƒãƒ¼ãƒ‰ã§ç¹°ã‚Šè¿”ã—ç™ºç”Ÿã™ã‚‹åŒã˜ã‚¨ãƒ©ãƒ¼ã¯ã€æ·±åˆ»ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢éšœå®³ã‚’ç¤ºå”†ã—ã¾ã™ã€‚

### ã‚¸ãƒ§ãƒ–å†…å¤–ã®åˆ†æ

**ã‚¸ãƒ§ãƒ–å†…åˆ†æ (Intra-job)**: å˜ä¸€ã‚¸ãƒ§ãƒ–å†…ã§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼æ¤œå‡ºã€å³åº§ã®å¾©æ—§åˆ¤æ–­

**ã‚¸ãƒ§ãƒ–é–“åˆ†æ (Inter-job)**: è¤‡æ•°ã‚¸ãƒ§ãƒ–ã«ã‚ãŸã‚‹éšœå®³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®šã€å†ç™ºã™ã‚‹å•é¡Œã®äºˆé˜²çš„ãªå¯¾ç­–ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®çµŒå¹´åŠ£åŒ–ã®è¿½è·¡

:::message
ã“ã®ã‚ˆã†ãªç›¸é–¢åˆ†æã«ã‚ˆã‚Šã€ç ”ç©¶è€…ã¨é‹ç”¨ãƒãƒ¼ãƒ ã¯å…±é€šã®ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œã¨éšœå®³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç†è§£ã‚’å…±æœ‰ã§ãã¾ã™ã€‚
:::
::::

## è‡ªå‹•åŒ–ã®é‡è¦æ€§

::::details Meta ã®å®Ÿç¸¾ï¼š416/419 å›ã‚’è‡ªå‹•å‡¦ç†

Meta ã® Llama 3 å­¦ç¿’ã«ãŠã„ã¦ã€[419 å›ã®äºˆæœŸã—ãªã„ä¸­æ–­ã®ã†ã¡é‡å¤§ãªæ‰‹å‹•ä»‹å…¥ãŒå¿…è¦ã ã£ãŸã®ã¯ã‚ãšã‹ 3 å›ã®ã¿](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã§ã—ãŸã€‚[æ®‹ã‚Šã® 416 å›ã¯è‡ªå‹•åŒ–ã«ã‚ˆã‚Šå‡¦ç†](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã•ã‚Œã€ã“ã‚ŒãŒ [90% ä»¥ä¸Šã®åŠ¹æœçš„ãªå­¦ç¿’æ™‚é–“ã‚’ç¶­æŒ](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã™ã‚‹éµã¨ãªã‚Šã¾ã—ãŸã€‚

### è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹æˆ

**éšœå®³æ¤œå‡º**
- DCGM ã«ã‚ˆã‚‹ç¶™ç¶šçš„ãª GPU ç›£è¦–
- [PyTorch NCCL Flight Recorder](https://pytorch.org/docs/stable/distributed.html#torch.distributed.distributed_c10d.Flight) ã«ã‚ˆã‚‹ãƒãƒ³ã‚°ã®è¨ºæ–­
- ã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼æ¤œå‡ºãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚‹é…å»¶ GPU ã®ç‰¹å®š

**è‡ªå‹•å¾©æ—§**
- å•é¡Œãƒãƒ¼ãƒ‰ã®è‡ªå‹•é™¤å¤–
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®è‡ªå‹•å†èµ·å‹•
- ã‚¸ãƒ§ãƒ–ã®å†çµ±åˆ

**é€šçŸ¥ã¨æ¨å¥¨**
- é‹ç”¨ãƒãƒ¼ãƒ ã¨ç ”ç©¶è€…ã¸ã®è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ
- æ ¹æœ¬åŸå› ã®åˆ†æã¨æ¨å¥¨äº‹é …ã®æç¤º
- å¯è¦–åŒ–ã•ã‚ŒãŸãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

:::message alert
è‡ªå‹•åŒ–ãŒãªã‘ã‚Œã°ã€ç ”ç©¶è€…ã¯ 24 æ™‚é–“ä½“åˆ¶ã§ã‚¸ãƒ§ãƒ–ã‚’ç›£è¦–ã—ã€3 æ™‚é–“ã”ã¨ã«ç™ºç”Ÿã™ã‚‹éšœå®³ã«æ‰‹å‹•ã§å¯¾å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ç ”ç©¶è€…ã®æœ¬æ¥ã®ç›®çš„ã§ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚„ç§‘å­¦ã®é€²æ­©ã‹ã‚‰æ™‚é–“ã‚’å¥ªã„ã€é–‹ç™ºã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’é…å»¶ã•ã›ã¾ã™ã€‚
:::

ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®çµ„ã¿åˆã‚ã›çš„è¤‡é›‘æ€§ã‚‚å¢—å¤§ã—ã€å•é¡Œã‚’ã•ã‚‰ã«æ‚ªåŒ–ã•ã›ã¾ã™ã€‚è‡ªå‹•åŒ–ã¯å¤§è¦æ¨¡å­¦ç¿’ã®å¿…é ˆè¦ä»¶ã§ã™ã€‚
::::

## ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæˆ¦ç•¥

::::details æ•°å­¦çš„æœ€é©åŒ–ã¨ GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®é »åº¦ã¯ã€è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¨éšœå®³æ™‚ã®å¤±ã‚ã‚Œã‚‹é€²æ—ã®é–“ã§ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### æœ€é©ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”ã®å°å‡º

[Epoch AI ã®åˆ†æ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã«ã‚ˆã‚‹æ•°å­¦çš„ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šã€æœ€é©ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜æ™‚é–“ã€GPU æ•°ã€GPU ã‚ãŸã‚Šã®éšœå®³ç‡ã‹ã‚‰å°å‡ºã§ãã¾ã™ã€‚

**Llama 3 405B ã®ä¾‹**
- [ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ™‚é–“: 2.5 ç§’](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)
- [æœ€é©ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”: ç´„ 4 åˆ†](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)
- [å…¨å­¦ç¿’æ™‚é–“ã«å ã‚ã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: ç´„ 2.1%](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)

### ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯

å¾“æ¥ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ã¯ã€GPU æ•°ãŒå¢—åŠ ã™ã‚‹ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¸¯åŸŸå¹…ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚[Meta ã®å­¦ç¿’ã§ã¯ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹ã‚’æ›¸ãè¾¼ã‚€éš›ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¸¯åŸŸå¹…ã¯ 2TB/s ã«åˆ¶é™](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã•ã‚Œã¦ã„ã¾ã—ãŸã€‚å¾©æ—§æ™‚ã«ã¯ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—å­¦ç¿’ã«ã‚ˆã‚Šè¤‡æ•°ã® GPU ãŒéƒ¨åˆ†çš„ã«é‡è¤‡ã™ã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹ã‚’èª­ã¿å–ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ã•ã‚‰ã«é«˜ã„å¸¯åŸŸå¹…ãŒè¦æ±‚ã•ã‚Œã¾ã™ã€‚

### GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

ã“ã®å•é¡Œã«å¯¾ã™ã‚‹ä»£æ›¿æ‰‹æ³•ã¨ã—ã¦ã€ä»–ã® GPU ã®ãƒ¡ãƒ¢ãƒªã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’åˆ†æ•£ä¿å­˜ã™ã‚‹ [GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚

**ç‰¹å¾´**
- Google DeepMind ã® Gemini ã§ã‚‚ä½¿ç”¨
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¸¯åŸŸå¹…ã®åˆ¶ç´„ã‚’å›é¿
- ã‚ˆã‚Šé«˜é€Ÿãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨å¾©æ—§ã‚’å®Ÿç¾

**å®Ÿè£…æ–¹æ³•**
- [é€šå¸¸ 3 ã‹ã‚‰ 4 ã¤ã®ãƒ¬ãƒ—ãƒªã‚«ã‚’ GPU ãƒ¡ãƒ¢ãƒªã«ä¿æŒ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)
- ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦äºˆå‚™ãƒãƒ¼ãƒ‰ã‚’æº–å‚™
- ãƒ”ã‚¢ GPU ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã®ç›´æ¥èª­ã¿å–ã‚Šã«ã‚ˆã‚‹é«˜é€Ÿãªå¾©æ—§

:::message
GPU æ•°ãŒéå¸¸ã«å¤§ãã„å ´åˆã¯ã€GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ¡ç”¨ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’å›é¿ã§ãã¾ã™ã€‚
:::
::::

## ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼æˆ¦ç•¥ã®å®Ÿè£…

::::details å¤šå±¤çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

å¤§è¦æ¨¡å­¦ç¿’ã§ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’æœ€å°åŒ–ã™ã‚‹ã«ã¯ã€å¤šå±¤çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚

### ç¶™ç¶šçš„ãªç›£è¦–ã¨éšå±¤çš„ãªè¨ºæ–­

ãƒãƒ¼ãƒ‰èµ·å‹•æ™‚ã«ã¯ DCGM Level 1 ã«ã‚ˆã‚‹ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã€ã‚·ã‚¹ãƒ†ãƒ ãŒåŸºæœ¬çš„ã«å‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚å­¦ç¿’å®Ÿè¡Œä¸­ã¯ã€GPU ã®æ¸©åº¦ã€é›»åŠ›ã€ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–ã—ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‹ã‚‰é€²æ—ã¨ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½è·¡ã—ã¾ã™ã€‚

### éšœå®³ç™ºç”Ÿæ™‚ã®å¯¾å¿œãƒ•ãƒ­ãƒ¼

1. **Level 2 ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ãƒã‚§ãƒƒã‚¯**: éšœå®³ã®è©³ç´°ã‚’ç¢ºèª
2. **éšœå®³ç‰¹å®šæˆåŠŸ**: è‡ªå‹•å¾©æ—§ãƒ—ãƒ­ã‚»ã‚¹ã¸ï¼ˆå•é¡Œãƒãƒ¼ãƒ‰é™¤å¤–ã€å†èµ·å‹•ï¼‰
3. **éšœå®³ç‰¹å®šå¤±æ•—**: Level 3 è©³ç´°è¨ºæ–­ã¸
4. **åŸå› ä¸æ˜**: Level 4 å¾¹åº•è¨ºæ–­ã¸
5. **æœ€çµ‚æ‰‹æ®µ**: æ‰‹å‹•ä»‹å…¥ï¼ˆåé›†ã•ã‚ŒãŸãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã§ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ™‚é–“ã‚’å¤§å¹…å‰Šæ¸›ï¼‰

### ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå¯¾ç­–

**å®šæœŸè¨ºæ–­**
- å®šæœŸçš„ãª Level 2 ã¾ãŸã¯ Level 3 è¨ºæ–­
- éšœå®³äºˆå…†ã®ã‚ã‚‹ GPU ã‚’äº‹å‰ã«ç‰¹å®šã—äº¤æ›

**ç’°å¢ƒæœ€é©åŒ–**
- æ¸©åº¦ã‚„é›»åŠ›ã®æœ€é©åŒ–
- ã‚¹ãƒˆãƒ©ã‚°ãƒ©ãƒ¼æ¤œå‡ºãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚‹é…å»¶ GPU ã®æ—©æœŸç™ºè¦‹

**ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæœ€é©åŒ–**
- æ•°å­¦çš„æœ€é©åŒ–ã«ã‚ˆã‚Šé–“éš”ã‚’æ±ºå®š
- å¯èƒ½ã§ã‚ã‚Œã°ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¸¯åŸŸå¹…ã‚’æ‹¡å¼µ
- GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ¡ç”¨æ¤œè¨

:::message
[Meta ã®å®Ÿç¸¾ãŒç¤ºã™ã‚ˆã†ã«ã€419 å›ã®ä¸­æ–­ã®ã†ã¡ 416 å›ã‚’è‡ªå‹•åŒ–ã§å‡¦ç†](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã™ã‚‹ã“ã¨ã§ã€ç ”ç©¶è€…ã¯å­¦ç¿’ã«é›†ä¸­ã§ãã¾ã™ã€‚
:::
::::

## NVIDIA DGX Cloud ã®å®Ÿè¨¼æˆæœ

::::details 2K-10K GPU ã§é”æˆã—ãŸ <1% ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ 

[NVIDIA DGX Cloud](https://www.nvidia.com/en-us/data-center/dgx-cloud) ã§ã¯ã€çµ±åˆãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã¨è‡ªå‹•åŒ–æŠ€è¡“ã«ã‚ˆã‚Šã€[2K ã‹ã‚‰ 10K GPU è¦æ¨¡ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ 1% æœªæº€ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’é”æˆ](https://developer.nvidia.com/blog/ensuring-reliable-model-training-on-nvidia-dgx-cloud/)ã—ã¾ã—ãŸã€‚ã“ã®æˆæœã¯ 2024 å¹´ã‹ã‚‰ 2025 å¹´ã«ã‹ã‘ã¦ã® [Nemotron ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼](https://blogs.nvidia.com/blog/nemotron-model-families/)ã®å­¦ç¿’ã§å®Ÿè¨¼ã•ã‚Œã¦ã„ã¾ã™ã€‚

### æˆåŠŸè¦å› 

**é«˜é€Ÿãªéšœå®³æ¤œå‡º**: è¤‡æ•°ã®ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã‚½ãƒ¼ã‚¹ã®ç›¸é–¢åˆ†æã«ã‚ˆã‚Šã€æ ¹æœ¬åŸå› ã‚’è¿…é€Ÿã«ç‰¹å®š

**è‡ªå‹•å¾©æ—§**: å•é¡Œãƒãƒ¼ãƒ‰ã®è‡ªå‹•é™¤å¤–ã¨å†èµ·å‹•ã«ã‚ˆã‚‹è¿…é€Ÿãªå¾©æ—§ãƒ—ãƒ­ã‚»ã‚¹

**ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªç›£è¦–**: å•é¡ŒãŒæ·±åˆ»åŒ–ã™ã‚‹å‰ã«æ¤œå‡ºã—ã€äºˆé˜²çš„ã«å¯¾å‡¦

**æƒ…å ±å…±æœ‰**: é‹ç”¨ãƒãƒ¼ãƒ ã¨ç ”ç©¶è€…ãŒå…±é€šã®ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œã¨éšœå®³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç†è§£

### ç›¸äº’çš„ãªæƒ…å ±ã®æµã‚Œ

ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€ç ”ç©¶è€…ã¯ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦ãƒ‡ãƒãƒƒã‚°ã‚’æ”¹å–„ã§ãã€ä¸€æ–¹ã§é‹ç”¨ãƒãƒ¼ãƒ ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚·ã‚¹ãƒ†ãƒ ã®è‡ªå‹•åŒ–ã‚’æ”¹å–„ã—ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚

:::message
ã“ã®ç›¸äº’çš„ãªæƒ…å ±ã®æµã‚ŒãŒã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼ã‚’å®Ÿç¾ã™ã‚‹éµã¨ãªã£ã¦ã„ã¾ã™ã€‚
:::
::::


## ã¾ã¨ã‚

å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ãŠã„ã¦ã€ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼ã¯å¿…é ˆè¦ä»¶ã§ã™ã€‚

**éšœå®³ã¯é¿ã‘ã‚‰ã‚Œãªã„**: [100,000 GPU ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã§ã¯ 30 åˆ†ã”ã¨ã«éšœå®³ãŒç™ºç”Ÿ](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling)ã—ã€æ•°é€±é–“ã‹ã‚‰æ•°ãƒ¶æœˆã®å­¦ç¿’ã§ã¯éšœå®³å¯¾å¿œãªã—ã«å®Œäº†ã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã§ã™ã€‚[Meta ã® Llama 3 å­¦ç¿’ã¯ã€16,384 GPU ã§ 3 æ™‚é–“ã”ã¨ã«éšœå®³ãŒç™ºç”Ÿã—ãªãŒã‚‰ã‚‚ã€è‡ªå‹•åŒ–ã«ã‚ˆã‚Š 90% ä»¥ä¸Šã®ç¨¼åƒç‡ã‚’ç¶­æŒ](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚

**æ—©æœŸæ¤œå‡ºã®é‡è¦æ€§**: éšœå®³ã®æ—©æœŸæ¤œå‡ºã«ã‚ˆã‚Šã€å¤±ã‚ã‚Œã‚‹å­¦ç¿’ã®é€²æ—ã‚’æœ€å°åŒ–ã§ãã¾ã™ã€‚DCGM ã®éšå±¤çš„ãªè¨ºæ–­ãƒ¬ãƒ™ãƒ«ã¯ã€ãƒãƒ¼ãƒ‰èµ·å‹•æ™‚ã® 2.5 ç§’ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ã‹ã‚‰ã€å¾¹åº•èª¿æŸ»ã®ãŸã‚ã® 2 æ™‚é–“ã®è¨ºæ–­ã¾ã§ã€çŠ¶æ³ã«å¿œã˜ãŸé©åˆ‡ãªæ·±ã•ã§è¿…é€Ÿã«å•é¡Œã‚’ç‰¹å®šã™ã‚‹æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚

**è‡ªå‹•åŒ–ãŒéµ**: [Meta ã¯ 419 å›ã®ä¸­æ–­ã®ã†ã¡ 416 å›ã‚’è‡ªå‹•åŒ–ã§å‡¦ç†](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã—ã¾ã—ãŸã€‚æ‰‹å‹•ä»‹å…¥ã«ä¾å­˜ã™ã‚‹ã¨ã€ç ”ç©¶è€…ã¯æœ¬æ¥ã®ç›®çš„ã§ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã§ã¯ãªãã€ã‚·ã‚¹ãƒ†ãƒ ã®ä¿å®ˆã«æ™‚é–“ã‚’å¥ªã‚ã‚Œã¾ã™ã€‚ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã€ãƒãƒ¼ãƒ‰ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¤‡æ•°ã®ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã‚’ç›¸é–¢åˆ†æã™ã‚‹ã“ã¨ã§ã€æ ¹æœ¬åŸå› ã‚’è¿…é€Ÿã«ç‰¹å®šã—ã€è‡ªå‹•å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ ãŒé©åˆ‡ãªå¯¾å¿œã‚’åˆ¤æ–­ã§ãã¾ã™ã€‚

**ç¶™ç¶šçš„ãªæ”¹å–„**: ã‚¸ãƒ§ãƒ–é–“ã§ã®ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªåˆ†æã«ã‚ˆã‚Šã€å†ç™ºã™ã‚‹å•é¡Œã‚’äºˆé˜²çš„ã«å¯¾å‡¦ã—ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ä¿¡é ¼æ€§ã‚’ç¶™ç¶šçš„ã«å‘ä¸Šã§ãã¾ã™ã€‚DCGM ã«ã‚ˆã‚‹éšœå®³æ¤œå‡ºã¨è‡ªå‹•å¾©æ—§ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã€å¤§è¦æ¨¡å­¦ç¿’ã‚’å®Ÿç¾å¯èƒ½ã«ã™ã‚‹åŸºç›¤æŠ€è¡“ã§ã™ã€‚

:::message
é©åˆ‡ãªãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼æˆ¦ç•¥ãªã—ã«ã€æ•°ç™¾ä¸‡ GPU è¦æ¨¡ã®å­¦ç¿’ã¯å®Ÿç¾ã§ãã¾ã›ã‚“ã€‚é«˜ã„ GPU ç¨¼åƒç‡ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã¯é‡è¦ã§ã™ãŒã€ãã‚Œä»¥ä¸Šã«é‡è¦ãªã®ã¯ã€ç ”ç©¶è€…ãŒãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã¨ç§‘å­¦ã®é€²æ­©ã«é›†ä¸­ã§ãã‚‹ç’°å¢ƒã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã™ã€‚
:::

## å‚è€ƒè³‡æ–™

- [Ensuring Reliable Model Training on NVIDIA DGX Cloud](https://developer.nvidia.com/blog/ensuring-reliable-model-training-on-nvidia-dgx-cloud/) (NVIDIA, 2025)
- [Meta report details hundreds of GPU and HBM3 related interruptions to Llama 3 training run](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/) (Data Center Dynamics, 2024)
- [Faulty Nvidia H100 GPUs and HBM3 memory caused half of the failures during Llama 3 training](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster) (Tom's Hardware, 2024)
- [Hardware failures won't limit AI scaling](https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling) (Epoch AI, 2024)
- [DCGM Diagnostics â€” NVIDIA DCGM Documentation](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/dcgm-diagnostics.html) (NVIDIA)

## ã‚³ãƒ©ãƒ 

::::details ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼

:::message alert
ãŸã ã®ãƒã‚¨ãƒ ã§ã™ã€‚
:::

## Meta Llama 3 å­¦ç¿’ã«ãŠã‘ã‚‹ CPU vs GPU ã®éšœå®³æ¯”è¼ƒ

[Meta ãŒå…¬é–‹ã—ãŸ Llama 3 405B ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿](https://www.datacenterdynamics.com/en/news/meta-report-details-hundreds-of-gpu-and-hbm3-related-interruptions-to-llama-3-training-run/)ã«ãŠã„ã¦ã€CPU ã¨ GPU ã®éšœå®³ç‡ã«ã¯é¡•è‘—ãªé•ã„ãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚

| éšœå®³ã‚¿ã‚¤ãƒ— | ç™ºç”Ÿå›æ•° | å‰²åˆ | å‚™è€ƒ |
|----------|---------|------|------|
| GPU éšœå®³ | 148 | 30.1% | GPU æœ¬ä½“ã®éšœå®³ |
| HBM3 ãƒ¡ãƒ¢ãƒªéšœå®³ | 72 | 17.2% | GPU æ­è¼‰ãƒ¡ãƒ¢ãƒª |
| GPU SRAM | 19 | 4.5% | GPU å†…éƒ¨ãƒ¡ãƒ¢ãƒª |
| GPU ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ã‚»ãƒƒã‚µ | 17 | 4.1% | GPU å†…éƒ¨ãƒ—ãƒ­ã‚»ãƒƒã‚µ |
| **GPU é–¢é€£åˆè¨ˆ** | **256** | **58.7%** | GPU ã¨ãã®ãƒ¡ãƒ¢ãƒª |
| **CPU** | **2** | **0.5%** | CPU ã®éšœå®³ |
| ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ | 35 | 8.4% | ã‚¹ã‚¤ãƒƒãƒãƒ»ã‚±ãƒ¼ãƒ–ãƒ« |
| ãã®ä»– | 126 | 30.1% | ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãªã© |

[ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿å¯Œå²³ã¯ 158,976 ã® CPU ãƒãƒ¼ãƒ‰](https://www.r-ccs.riken.jp/fugaku/system/)ã¨ã„ã†åœ§å€’çš„ãªè¦æ¨¡ã‚’èª‡ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ Meta ã® Llama 3 å­¦ç¿’ã§ä½¿ç”¨ã•ã‚ŒãŸ 16,384 GPU ã®ç´„ 10 å€ã«ç›¸å½“ã—ã¾ã™ã€‚ã—ã‹ã—ã€å‰è¿°ã®è¡¨ãŒç¤ºã™ã‚ˆã†ã«ã€ã‚ãšã‹ 54 æ—¥é–“ã§ 419 å›ã‚‚ã®ä¸­æ–­ãŒè¨˜éŒ²ã•ã‚ŒãŸ GPU ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ãŠã„ã¦ã€CPU ã®éšœå®³ã¯ã‚ãšã‹ 2 å›ã®ã¿ã§ã—ãŸã€‚GPU é–¢é€£ã®éšœå®³ãŒ 256 å›ï¼ˆ58.7%ï¼‰ã‚’å ã‚ã‚‹ã®ã«å¯¾ã—ã€CPU ã¯ 0.5% ã¨ã„ã†æ¥µã‚ã¦ä½ã„éšœå®³ç‡ã§ã™ã€‚ã“ã®åœ§å€’çš„ãªå·®ã®èƒŒæ™¯ã«ã¯ã€CPU ã¨ GPU ã®å‹•ä½œç‰¹æ€§ã®æ ¹æœ¬çš„ãªé•ã„ãŒã‚ã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚

## CPU ã¨ GPU ã®å‹•ä½œç‰¹æ€§ã®é•ã„

CPU ã¨ GPU ã®å‹•ä½œç‰¹æ€§ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€é‡è¦ãªæŠ€è¡“çš„ç›¸é•ç‚¹ãŒæµ®ã‹ã³ä¸ŠãŒã‚Šã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€CPU ã¯ GPU ã‚ˆã‚Šã‚‚é«˜ã„å‹•ä½œå‘¨æ³¢æ•°ã§å‹•ä½œã—ã¾ã™ã€‚ã“ã®é«˜å‘¨æ³¢å‹•ä½œã«ã‚ˆã‚Šã€ç´ å­ã®ã‚¹ã‚¤ãƒƒãƒãƒ³ã‚°é…å»¶ã®ã°ã‚‰ã¤ãã®å½±éŸ¿ã‚’ã‚ˆã‚Šå¼·ãå—ã‘ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ãƒƒãƒã®åˆ»ã¿æ–¹ã‚„ä¿¡å·ä¼æ’­ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã‚ãšã‹ãªã‚ºãƒ¬ãŒç”Ÿã˜ã‚‹ã¨ã€ãã‚ŒãŒèª¤ã£ãŸè«–ç†å€¤ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ã¾ã‚Šã¾ã™ã€‚ã“ã®ãŸã‚ã€CPU ã®è£½é€ ã§ã¯ GPU ã‚ˆã‚Šã‚‚å³ã—ã„æ­©ç•™ã¾ã‚Šç®¡ç†ãŒå¿…è¦ã¨ãªã‚Šã€è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã§ã®ä¸è‰¯å“ã®é¸åˆ¥ãŒã‚ˆã‚Šé‡è¦ã«ãªã‚Šã¾ã™ã€‚

ã—ã‹ã—ã€é‡ç”£è©¦é¨“ã‚’ç„¡äº‹ã«æ½œã‚ŠæŠœã‘ãŸ CPU ã§ã‚ã£ã¦ã‚‚ã€å®Ÿéš›ã®ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã«çµ„ã¿è¾¼ã¾ã‚Œã¦ç¨¼åƒã‚’é–‹å§‹ã™ã‚‹ã¨ã€äºˆæœŸã—ãªã„å•é¡Œã«ç›´é¢ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã‚ãšã‹ãªé›»åœ§ã®ä½ä¸‹ã‚„ã€å‹•ä½œä¸­ã®ç†±ã®å½±éŸ¿ã«ã‚ˆã‚Šã€é€šå¸¸ã¯å•é¡Œãªãå‹•ä½œã—ã¦ã„ãŸå›è·¯ãŒä¸€æ™‚çš„ã«ã‚½ãƒ•ãƒˆã‚¨ãƒ©ãƒ¼ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã•ã‚‰ã«æ·±åˆ»ãªã‚±ãƒ¼ã‚¹ã§ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ¼ã‚¶ãƒ¼ã®å¾®ç´°ãªç ´æã‚„ã€è£½é€ å·¥ç¨‹ã§ã®æ²»å…·ã®å½±éŸ¿ã«ã‚ˆã‚‹ã‚¯ãƒ©ãƒƒã‚¯ãªã©ã€ç‰©ç†çš„ãªæ¬ é™¥ãŒé‡ç”£è©¦é¨“ã§ã¯æ¤œå‡ºã•ã‚Œãšã«ã€å®Ÿéš›ã®é‹ç”¨ç’°å¢ƒã§é¡•åœ¨åŒ–ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã“ã†ã—ãŸå•é¡Œã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹ä½œæ¥­ã¯ã€è¤‡é›‘ãªè§£æã¨å¤šå¤§ãªæ™‚é–“ã‚’è¦ã™ã‚‹å›°é›£ãªèª¿æŸ»ã¨ãªã‚Šã¾ã™ã€‚

ä¸€æ–¹ã€GPU ã¯å‹•ä½œå‘¨æ³¢æ•°ã“ã CPU ã‚ˆã‚Šä½ã„ã‚‚ã®ã®ã€ä¸¦åˆ—å‡¦ç†ã«æœ€é©åŒ–ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€åŒæ™‚ã«å‹•ä½œã™ã‚‹è«–ç†ç´ å­ã®æ•°ãŒ CPU ã¨ã¯æ¡é•ã„ã«å¤šããªã£ã¦ã„ã¾ã™ã€‚ã“ã®å¤§è¦æ¨¡ãªä¸¦åˆ—æ€§ã«ã‚ˆã‚Šã€å¤šæ•°ã®ç´ å­ãŒåŒæ™‚ã«ãƒˆã‚°ãƒ«ï¼ˆçŠ¶æ…‹é·ç§»ï¼‰ã™ã‚‹éš›ã«å¼•ãè¾¼ã¾ã‚Œã‚‹é›»æµãŒæ¥µã‚ã¦å¤§ãããªã‚Šã€çµæœã¨ã—ã¦é›»æºé›»åœ§ã®ç¬é–“çš„ãªä½ä¸‹ã®å½±éŸ¿ã‚’ CPU ã‚ˆã‚Šã‚‚å¼·ãå—ã‘ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¶ˆè²»é›»åŠ›ã¯ã€Œå‘¨æ³¢æ•° Ã— å®¹é‡ Ã— é›»æºé›»åœ§^2ã€ã®å¼ã§è¡¨ã•ã‚Œã¾ã™ã€‚GPU ã¯æ•°åƒã‹ã‚‰æ•°ä¸‡ã®ã‚³ã‚¢ãŒåŒæ™‚ã«å‹•ä½œã™ã‚‹ãŸã‚ã€ã‚¹ã‚¤ãƒƒãƒãƒ³ã‚°ã™ã‚‹å®¹é‡ã®ç·å’ŒãŒ CPU ã‚’å¤§ããä¸Šå›ã‚Šã€H100 GPU ãŒ 700W ã¨ã„ã†é«˜ã„æ¶ˆè²»é›»åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹ç†ç”±ãŒã“ã“ã«ã‚ã‚Šã¾ã™ã€‚ã“ã®é«˜ã„æ¶ˆè²»é›»åŠ›ã¯å¿…ç„¶çš„ã«å¤§ããªç†±ã®ç™ºç”Ÿã‚’ä¼´ã„ã€ãƒãƒƒãƒ—å…¨ä½“ã«å¼·ã„ç†±ã‚¹ãƒˆãƒ¬ã‚¹ã‚’ä¸ãˆã¾ã™ã€‚Meta ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç¤ºã™ã‚ˆã†ã«ã€ã“ã®ç†±ã‚¹ãƒˆãƒ¬ã‚¹ã¯ GPU æœ¬ä½“ã¨ HBM3 ãƒ¡ãƒ¢ãƒªã®é«˜ã„éšœå®³ç‡ã®ä¸»è¦ãªè¦å› ã¨ãªã£ã¦ã„ã¾ã™ã€‚

ã•ã‚‰ã«ã€å¤šæ•°ã®ç´ å­ãŒåŒæ™‚ã«ãƒˆã‚°ãƒ«ã™ã‚‹ã“ã¨ã§ç™ºç”Ÿã™ã‚‹ã‚¹ã‚¤ãƒƒãƒãƒ³ã‚°ãƒã‚¤ã‚ºã‚‚ã€GPU ã®ä¿¡é ¼æ€§ã«å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚é›»æºãƒ©ã‚¤ãƒ³ã‚„ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã«ç™ºç”Ÿã™ã‚‹é›»åœ§å¤‰å‹•ãŒã€è¿‘å‚ã®å›è·¯ã«èª¤å‹•ä½œã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚åŠ ãˆã¦ã€GPU ã¨ CPU ã§ã¯å›è·¯ã®åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ ¹æœ¬çš„ã«ç•°ãªã‚Šã¾ã™ã€‚GPU ã¯ä¸¦åˆ—è¨ˆç®—ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«ãŠã„ã¦ã€åŒã˜æ¼”ç®—å›è·¯ã‚’ç¶™ç¶šçš„ã‹ã¤é«˜é »åº¦ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ç‰¹å®šã®å›è·¯ãƒ‘ã‚¹ãŒå¸¸æ™‚ãƒˆã‚°ãƒ«ã—ç¶šã‘ã‚‹ã“ã¨ã«ã‚ˆã‚‹ä¸€æ™‚çš„ãªè–„è†œåŠ£åŒ–ã®å½±éŸ¿ã‚’ã‚ˆã‚Šå¼·ãå—ã‘ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

é•·æœŸçš„ãªè¦³ç‚¹ã§ã¯ã€å¼·ã„é›»æµå¯†åº¦ã«ã‚ˆã‚‹ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆé‡‘å±é…ç·šå†…ã§ã®åŸå­ã®ç§»å‹•ï¼‰ã®å½±éŸ¿ã‚‚ç„¡è¦–ã§ãã¾ã›ã‚“ã€‚é«˜ã„æ¶ˆè²»é›»åŠ›ã¨ç¶™ç¶šçš„ãªé«˜è² è·å‹•ä½œã«ã‚ˆã‚Šã€GPU ã¯ CPU ã‚ˆã‚Šã‚‚ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹é…ç·šåŠ£åŒ–ã®é€²è¡ŒãŒé€Ÿãã€çµæœã¨ã—ã¦ãƒãƒƒãƒ—ã®å®ŸåŠ¹å¯¿å‘½ãŒçŸ­ããªã‚‹å‚¾å‘ã«ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®è¤‡åˆçš„ãªè¦å› ã«ã‚ˆã‚Šã€GPU ã¯ CPU ã¨æ¯”è¼ƒã—ã¦æœ¬è³ªçš„ã«é«˜ã„éšœå®³ç‡ã‚’æŒã¤ã“ã¨ã«ãªã‚Šã€Meta ã®ãƒ‡ãƒ¼ã‚¿ãŒç¤ºã™ 100 å€ä»¥ä¸Šã®éšœå®³ç‡ã®å·®ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚

## å®‡å®™ç·šã¨ã‚½ãƒ•ãƒˆã‚¨ãƒ©ãƒ¼ã®ç‰©ç†ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

å®‡å®™ç·šã®å½±éŸ¿ã«ã¤ã„ã¦ã¯ã€ã—ã°ã—ã°ã€Œå®‡å®™ç·šãŒãƒ¡ãƒ¢ãƒªãƒ“ãƒƒãƒˆã‚’åè»¢ã•ã›ã‚‹ã€ã¨ã„ã†ç°¡ç•¥åŒ–ã•ã‚ŒãŸèª¬æ˜ãŒãªã•ã‚Œã¾ã™ãŒã€å®Ÿéš›ã®ç‰©ç†ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã‚ˆã‚Šè¤‡é›‘ã§èˆˆå‘³æ·±ã„ã‚‚ã®ã§ã™ã€‚[1979 å¹´ã« IBM ã® James Ziegler ã‚‰ã«ã‚ˆã£ã¦åˆã‚ã¦è¨˜è¿°ã•ã‚ŒãŸ](https://en.wikipedia.org/wiki/Single-event_upset)ã‚ˆã†ã«ã€åœ°çƒã®å¤§æ°—åœã§å®‡å®™ç·šãŒç›¸äº’ä½œç”¨ã™ã‚‹ã“ã¨ã§ç”Ÿæˆã•ã‚Œã‚‹é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¸­æ€§å­ãŒã€ã‚·ãƒªã‚³ãƒ³æ ¸ã¨éå¼¾æ€§è¡çªã‚’èµ·ã“ã—ã¾ã™ã€‚ã“ã®æ ¸åå¿œã«ã‚ˆã‚Šã€ã‚¢ãƒ«ãƒ•ã‚¡ç²’å­ã‚„ãƒã‚°ãƒã‚·ã‚¦ãƒ ã€ã‚¢ãƒ«ãƒŸãƒ‹ã‚¦ãƒ ãªã©ã®äºŒæ¬¡æ ¸åˆ†è£‚ç‰‡ãŒç”Ÿæˆã•ã‚Œã€ã“ã‚Œã‚‰ã®è·é›»ç²’å­ãŒé€šéã™ã‚‹çµŒè·¯ã§é›»å­ãƒ»æ­£å­”å¯¾ã®ã‚¤ã‚ªãƒ³åŒ–ãŒç™ºç”Ÿã—ã¾ã™ã€‚

é‡è¦ãªã®ã¯ã€ç²’å­ã®å½“ãŸã‚Šã©ã“ã‚ã§ã™ã€‚ä»®ã«è·é›»ç²’å­ãŒãƒ©ãƒƒãƒã®å‡ºåŠ›éƒ¨åˆ†ã‚ˆã‚Šå¾Œæ®µã®è«–ç†å›è·¯éƒ¨åˆ†ã«å½“ãŸã£ãŸå ´åˆã€ãã®éƒ¨åˆ†ã®è«–ç†å€¤ãŒä¸€æ™‚çš„ã«åè»¢ã—ã¦ã‚‚ã€è«–ç†ã‚²ãƒ¼ãƒˆã®ä¼æ’­é…å»¶ã«ã‚ˆã‚Šå‡ºåŠ›ã¯ç¬æ™‚ã«æ­£ã—ã„å€¤ã«æˆ»ã‚Šã¾ã™ã€‚ã“ã®å ´åˆã®å½±éŸ¿ã¯ä¸€æ™‚çš„ãªãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç¨‹åº¦ã«ã¨ã©ã¾ã‚Šã€å®Ÿéš›ã®ãƒ“ãƒƒãƒˆåè»¢ã«ã¯è‡³ã‚Šã¾ã›ã‚“ã€‚çœŸã«å•é¡Œã¨ãªã‚‹ã®ã¯ã€è·é›»ç²’å­ãŒãƒ©ãƒƒãƒè‡ªä½“ã®ä¿æŒãƒãƒ¼ãƒ‰ã«ååˆ†ãªé›»è·ã‚’æ³¨å…¥ã—ã€ãƒ•ãƒªãƒƒãƒ—ãƒ•ãƒ­ãƒƒãƒ—ã®çŠ¶æ…‹ã‚’æ’ä¹…çš„ã«åè»¢ã•ã›ã‚‹ã‚±ãƒ¼ã‚¹ã§ã™ã€‚

## ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã®å¤šå±¤çš„ãªå¯¾ç­–

ã“ã†ã—ãŸã‚½ãƒ•ãƒˆã‚¨ãƒ©ãƒ¼ã«å¯¾ã—ã¦ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã¯å¤šå±¤çš„ã‹ã¤æ´—ç·´ã•ã‚ŒãŸå¯¾ç­–ãŒé•·å¹´ã«ã‚ãŸã‚Šå®Ÿè£…ã•ã‚Œã¦ãã¾ã—ãŸã€‚ãƒ‘ãƒªãƒ†ã‚£ãƒ“ãƒƒãƒˆã‚„ ECCï¼ˆError Correcting Codeï¼‰ã«ã‚ˆã‚Šã€ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡ºã¨ä¸€éƒ¨ã®ã‚±ãƒ¼ã‚¹ã§ã¯è‡ªå‹•è¨‚æ­£ãŒå¯èƒ½ã§ã™ã€‚RASï¼ˆReliability, Availability, Serviceabilityï¼‰æ©Ÿæ§‹ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’é›†ç´„ã—ã€å°‚ç”¨ã®ãƒ¬ã‚¸ã‚¹ã‚¿ã«è¨˜éŒ²ã™ã‚‹ã“ã¨ã§ã€ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æã€å†ç™ºã™ã‚‹å•é¡Œã®è¿½è·¡ã€ãã—ã¦äºˆé˜²çš„ãªä¿å®ˆã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ã“ã® RAS æ©Ÿæ§‹ã«ã‚ˆã‚Šã€é‹ç”¨ãƒãƒ¼ãƒ ã¯æ½œåœ¨çš„ãªéšœå®³ã‚’æ—©æœŸã«ç™ºè¦‹ã—ã€æ·±åˆ»åŒ–ã™ã‚‹å‰ã«å¯¾å¿œã§ãã¾ã™ã€‚

ã•ã‚‰ã«æ ¹æœ¬çš„ãªå¯¾ç­–ã¨ã—ã¦ã€LSI ã®ãƒã‚¹ã‚¯ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­è¨ˆæ®µéšã§ã¯ã€å®‡å®™ç·šç”±æ¥ã®è·é›»ç²’å­ã®ç‰©ç†çš„ç‰¹æ€§ãŒè€ƒæ…®ã•ã‚Œã¾ã™ã€‚ç²’å­ã®ç›´å¾„ã‚„é£›è·¡ã®ç‰¹æ€§ã‚’è¸ã¾ãˆã€ãŸã¨ãˆç²’å­ãŒç›´æ’ƒã—ã¦ã‚‚ãƒ©ãƒƒãƒãŒåè»¢ã—ã«ãã„ç‰©ç†é…ç½®ã‚„å›è·¯æ§‹é€ ãŒæ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹æŠ€è¡“ãƒ¬ãƒ™ãƒ«ã§ã‚‚ç¶™ç¶šçš„ãªæ”¹å–„ãŒè¡Œã‚ã‚Œã¦ãŠã‚Šã€SOIï¼ˆSilicon On Insulatorï¼‰ã®æ¡ç”¨ã«ã‚ˆã‚ŠåŸºæ¿ã‹ã‚‰ã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã—ã€ã‚½ãƒ•ãƒˆã‚¨ãƒ©ãƒ¼ã®ä¸»è¦ãªåŸå› ã¨ãªã‚‹ãƒœãƒ­ãƒ³-10 ä¸ç´”ç‰©ã‚’è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰é™¤å»ã™ã‚‹ãªã©ã€ææ–™ãƒ¬ãƒ™ãƒ«ã‹ã‚‰ã®å¯¾ç­–ãŒæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®é¿ã‘ã‚‰ã‚Œãªã„ç¾å®Ÿ

ãã‚Œã§ã‚‚ã€å¯Œå²³ã®ã‚ˆã†ã« 15 ä¸‡ã‚’è¶…ãˆã‚‹ CPU ãƒãƒ¼ãƒ‰ãŒç¨¼åƒã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€å€‹ã€…ã® CPU ã®ä¿¡é ¼æ€§ãŒã©ã‚Œã ã‘é«˜åº¦ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯çµ±è¨ˆçš„ã«é¿ã‘ã‚‰ã‚Œãªã„é »åº¦ã§éšœå®³ãŒç™ºç”Ÿã—ã¾ã™ã€‚æ•°åä¸‡ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒåŒæ™‚ã«å‹•ä½œã™ã‚‹ç’°å¢ƒã§ã¯ã€æ¥µã‚ã¦ä½ã„ç¢ºç‡ã®éšœå®³ã§ã‚ã£ã¦ã‚‚ã€ãã‚ŒãŒé¡•åœ¨åŒ–ã™ã‚‹æ©Ÿä¼šã¯åŠ‡çš„ã«å¢—åŠ ã—ã¾ã™ã€‚é‡ç”£è©¦é¨“ã§å®Œç’§ã«è¦‹ãˆãŸ CPU ã§ã‚‚ã€ã‚ãšã‹ãªç’°å¢ƒå¤‰åŒ–ã€é›»åœ§ã®å¾®å¦™ãªå¤‰å‹•ã€ã‚ã‚‹ã„ã¯é•·æœŸé–“ã®ç¨¼åƒã«ã‚ˆã‚‹çµŒå¹´åŠ£åŒ–ã«ã‚ˆã‚Šã€å®Ÿç¨¼åƒç’°å¢ƒã§å•é¡ŒãŒé¡•åœ¨åŒ–ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

ã“ã®ã‚ˆã†ã«ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ä½•åå¹´ã«ã‚‚ã‚ãŸã‚Šã€ãƒ‘ãƒªãƒ†ã‚£ã‹ã‚‰ RASã€ãƒã‚¹ã‚¯ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­è¨ˆã€ãƒ—ãƒ­ã‚»ã‚¹æŠ€è¡“ã®æ”¹å–„ã«è‡³ã‚‹ã¾ã§ã€æ¶™ãã¾ã—ã„åŠªåŠ›ã‚’é‡ã­ã¦ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã¦ãã¾ã—ãŸã€‚Meta ã®ãƒ‡ãƒ¼ã‚¿ãŒç¤ºã™ã‚ˆã†ã«ã€CPU ã®éšœå®³ç‡ã¯ GPU ã® 100 åˆ†ã® 1 ä»¥ä¸‹ã¨ã„ã†æ°´æº–ã§ã™ã€‚ã—ã‹ã—ã€ã“ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®è†¨å¤§ãªåŠªåŠ›ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã§ã¯éšœå®³ã‚’å®Œå…¨ã«æ’é™¤ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚

ã—ãŸãŒã£ã¦ã€ç§ãŸã¡å¤§è¦æ¨¡å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨è€…ã«ã¯ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®åŠªåŠ›ã‚’ç†è§£ã—ãŸä¸Šã§ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å´ã§ã®ãƒ¬ã‚¸ãƒªã‚¨ãƒ³ã‚·ãƒ¼å¯¾ç­–ã‚’å®Ÿè£…ã™ã‚‹è²¬ä»»ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®å¯¾ç­–ã«ã‚ˆã‚Šå€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®éšœå®³ç‡ã¯æœ€å°åŒ–ã•ã‚Œã¦ã„ã¾ã™ãŒã€ãã‚Œã§ã‚‚ãªãŠç™ºç”Ÿã™ã‚‹éšœå®³ã«å¯¾ã—ã¦ã€DCGM ã®ã‚ˆã†ãªç›£è¦–ãƒ„ãƒ¼ãƒ«ã€çµ±åˆãƒ†ãƒ¬ãƒ¡ãƒˆãƒªã«ã‚ˆã‚‹æ ¹æœ¬åŸå› ã®è¿…é€Ÿãªç‰¹å®šã€è‡ªå‹•å¾©æ—§ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãã—ã¦é©åˆ‡ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæˆ¦ç•¥ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å¯ç”¨æ€§ã‚’ç¶­æŒã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ä¸¡é¢ã‹ã‚‰ã®åŒ…æ‹¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã“ããŒã€æ•°åä¸‡ã‹ã‚‰æ•°ç™¾ä¸‡ã®æ¼”ç®—ãƒ¦ãƒ‹ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹å¤§è¦æ¨¡å­¦ç¿’ã‚’å®Ÿç¾å¯èƒ½ã«ã™ã‚‹éµã¨ãªã‚Šã¾ã™ã€‚
::::
